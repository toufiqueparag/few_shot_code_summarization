{"repo": "h2oai/h2o-3", "path": "py2/h2o_summ.py", "func_name": "percentileOnSortedList", "original_string": "def percentileOnSortedList(N, percent, key=lambda x:x, interpolate='mean'):\n    # 5 ways of resolving fractional\n    # floor, ceil, funky, linear, mean\n    interpolateChoices = ['floor', 'ceil', 'funky', 'linear', 'mean']\n    if interpolate not in interpolateChoices:\n        print \"Bad choice for interpolate:\", interpolate\n        print \"Supported choices:\", interpolateChoices\n    \"\"\"\n    Find the percentile of a list of values.\n\n    @parameter N - is a list of values. Note N MUST BE already sorted.\n    @parameter percent - a float value from 0.0 to 1.0.\n    @parameter key - optional key function to compute value from each element of N.\n\n    @return - the percentile of the values\n    \"\"\"\n    if N is None:\n        return None\n    k = (len(N)-1) * percent\n    f = int(math.floor(k))\n    c = int(math.ceil(k))\n    \n    if f == c:\n        d = key(N[f])\n        msg = \"aligned:\" \n\n    elif interpolate=='floor':\n        d = key(N[f])\n        msg = \"fractional with floor:\" \n\n    elif interpolate=='ceil':\n        d = key(N[c])\n        msg = \"fractional with ceil:\" \n\n    elif interpolate=='funky':\n        d0 = key(N[f]) * (c-k)\n        d1 = key(N[c]) * (k-f)\n        d = d0+d1\n        msg = \"fractional with Tung(floor and ceil) :\" \n    \n    elif interpolate=='linear':\n        assert (c-f)==1\n        assert (k>=f) and (k<=c)\n        pctDiff = k-f\n        dDiff = pctDiff * (key(N[c]) - key(N[f]))\n        d = key(N[f] + dDiff)\n        msg = \"fractional %s with linear(floor and ceil):\" % pctDiff\n\n    elif interpolate=='mean':\n        d = (key(N[c]) + key(N[f])) / 2.0\n        msg = \"fractional with mean(floor and ceil):\" \n\n    # print 3 around the floored k, for eyeballing when we're close\n    flooredK = int(f)\n    # print the 3 around the median\n    if flooredK > 0:\n        print \"prior->\", key(N[flooredK-1]), \" \"\n    else:\n        print \"prior->\", \"<bof>\"\n    print \"floor->\", key(N[flooredK]), \" \", msg, 'result:', d, \"f:\", f, \"len(N):\", len(N)\n    if flooredK+1 < len(N):\n        print \" ceil->\", key(N[flooredK+1]), \"c:\", c\n    else:\n        print \" ceil-> <eof>\", \"c:\", c\n\n    return d", "language": "python", "code": "def percentileOnSortedList(N, percent, key=lambda x:x, interpolate='mean'):\n    # 5 ways of resolving fractional\n    # floor, ceil, funky, linear, mean\n    interpolateChoices = ['floor', 'ceil', 'funky', 'linear', 'mean']\n    if interpolate not in interpolateChoices:\n        print \"Bad choice for interpolate:\", interpolate\n        print \"Supported choices:\", interpolateChoices\n    \"\"\"\n    Find the percentile of a list of values.\n\n    @parameter N - is a list of values. Note N MUST BE already sorted.\n    @parameter percent - a float value from 0.0 to 1.0.\n    @parameter key - optional key function to compute value from each element of N.\n\n    @return - the percentile of the values\n    \"\"\"\n    if N is None:\n        return None\n    k = (len(N)-1) * percent\n    f = int(math.floor(k))\n    c = int(math.ceil(k))\n    \n    if f == c:\n        d = key(N[f])\n        msg = \"aligned:\" \n\n    elif interpolate=='floor':\n        d = key(N[f])\n        msg = \"fractional with floor:\" \n\n    elif interpolate=='ceil':\n        d = key(N[c])\n        msg = \"fractional with ceil:\" \n\n    elif interpolate=='funky':\n        d0 = key(N[f]) * (c-k)\n        d1 = key(N[c]) * (k-f)\n        d = d0+d1\n        msg = \"fractional with Tung(floor and ceil) :\" \n    \n    elif interpolate=='linear':\n        assert (c-f)==1\n        assert (k>=f) and (k<=c)\n        pctDiff = k-f\n        dDiff = pctDiff * (key(N[c]) - key(N[f]))\n        d = key(N[f] + dDiff)\n        msg = \"fractional %s with linear(floor and ceil):\" % pctDiff\n\n    elif interpolate=='mean':\n        d = (key(N[c]) + key(N[f])) / 2.0\n        msg = \"fractional with mean(floor and ceil):\" \n\n    # print 3 around the floored k, for eyeballing when we're close\n    flooredK = int(f)\n    # print the 3 around the median\n    if flooredK > 0:\n        print \"prior->\", key(N[flooredK-1]), \" \"\n    else:\n        print \"prior->\", \"<bof>\"\n    print \"floor->\", key(N[flooredK]), \" \", msg, 'result:', d, \"f:\", f, \"len(N):\", len(N)\n    if flooredK+1 < len(N):\n        print \" ceil->\", key(N[flooredK+1]), \"c:\", c\n    else:\n        print \" ceil-> <eof>\", \"c:\", c\n\n    return d", "code_tokens": ["def", "percentileOnSortedList", "(", "N", ",", "percent", ",", "key", "=", "lambda", "x", ":", "x", ",", "interpolate", "=", "'mean'", ")", ":", "# 5 ways of resolving fractional", "# floor, ceil, funky, linear, mean", "interpolateChoices", "=", "[", "'floor'", ",", "'ceil'", ",", "'funky'", ",", "'linear'", ",", "'mean'", "]", "if", "interpolate", "not", "in", "interpolateChoices", ":", "print", "\"Bad choice for interpolate:\"", ",", "interpolate", "print", "\"Supported choices:\"", ",", "interpolateChoices", "if", "N", "is", "None", ":", "return", "None", "k", "=", "(", "len", "(", "N", ")", "-", "1", ")", "*", "percent", "f", "=", "int", "(", "math", ".", "floor", "(", "k", ")", ")", "c", "=", "int", "(", "math", ".", "ceil", "(", "k", ")", ")", "if", "f", "==", "c", ":", "d", "=", "key", "(", "N", "[", "f", "]", ")", "msg", "=", "\"aligned:\"", "elif", "interpolate", "==", "'floor'", ":", "d", "=", "key", "(", "N", "[", "f", "]", ")", "msg", "=", "\"fractional with floor:\"", "elif", "interpolate", "==", "'ceil'", ":", "d", "=", "key", "(", "N", "[", "c", "]", ")", "msg", "=", "\"fractional with ceil:\"", "elif", "interpolate", "==", "'funky'", ":", "d0", "=", "key", "(", "N", "[", "f", "]", ")", "*", "(", "c", "-", "k", ")", "d1", "=", "key", "(", "N", "[", "c", "]", ")", "*", "(", "k", "-", "f", ")", "d", "=", "d0", "+", "d1", "msg", "=", "\"fractional with Tung(floor and ceil) :\"", "elif", "interpolate", "==", "'linear'", ":", "assert", "(", "c", "-", "f", ")", "==", "1", "assert", "(", "k", ">=", "f", ")", "and", "(", "k", "<=", "c", ")", "pctDiff", "=", "k", "-", "f", "dDiff", "=", "pctDiff", "*", "(", "key", "(", "N", "[", "c", "]", ")", "-", "key", "(", "N", "[", "f", "]", ")", ")", "d", "=", "key", "(", "N", "[", "f", "]", "+", "dDiff", ")", "msg", "=", "\"fractional %s with linear(floor and ceil):\"", "%", "pctDiff", "elif", "interpolate", "==", "'mean'", ":", "d", "=", "(", "key", "(", "N", "[", "c", "]", ")", "+", "key", "(", "N", "[", "f", "]", ")", ")", "/", "2.0", "msg", "=", "\"fractional with mean(floor and ceil):\"", "# print 3 around the floored k, for eyeballing when we're close", "flooredK", "=", "int", "(", "f", ")", "# print the 3 around the median", "if", "flooredK", ">", "0", ":", "print", "\"prior->\"", ",", "key", "(", "N", "[", "flooredK", "-", "1", "]", ")", ",", "\" \"", "else", ":", "print", "\"prior->\"", ",", "\"<bof>\"", "print", "\"floor->\"", ",", "key", "(", "N", "[", "flooredK", "]", ")", ",", "\" \"", ",", "msg", ",", "'result:'", ",", "d", ",", "\"f:\"", ",", "f", ",", "\"len(N):\"", ",", "len", "(", "N", ")", "if", "flooredK", "+", "1", "<", "len", "(", "N", ")", ":", "print", "\" ceil->\"", ",", "key", "(", "N", "[", "flooredK", "+", "1", "]", ")", ",", "\"c:\"", ",", "c", "else", ":", "print", "\" ceil-> <eof>\"", ",", "\"c:\"", ",", "c", "return", "d"], "docstring": "Find the percentile of a list of values.\n\n    @parameter N - is a list of values. Note N MUST BE already sorted.\n    @parameter percent - a float value from 0.0 to 1.0.\n    @parameter key - optional key function to compute value from each element of N.\n\n    @return - the percentile of the values", "docstring_tokens": ["Find", "the", "percentile", "of", "a", "list", "of", "values", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/py2/h2o_summ.py#L9-L74", "partition": "test", "index": 1532, "time": "2014-11-16 02:02:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/two_dim_table.py", "func_name": "H2OTwoDimTable.show", "original_string": "def show(self, header=True):\n        \"\"\"Print the contents of this table.\"\"\"\n        # if h2o.can_use_pandas():\n        #  import pandas\n        #  pandas.options.display.max_rows = 20\n        #  print pandas.DataFrame(self._cell_values,columns=self._col_header)\n        #  return\n        if header and self._table_header:\n            print(self._table_header + \":\", end=' ')\n            if self._table_description: print(self._table_description)\n        print()\n        table = copy.deepcopy(self._cell_values)\n        nr = 0\n        if _is_list_of_lists(table): nr = len(\n            table)  # only set if we truly have multiple rows... not just one long row :)\n        if nr > 20:  # create a truncated view of the table, first/last 5 rows\n            trunc_table = []\n            trunc_table += [v for v in table[:5]]\n            trunc_table.append([\"---\"] * len(table[0]))\n            trunc_table += [v for v in table[(nr - 5):]]\n            table = trunc_table\n\n        H2ODisplay(table, self._col_header, numalign=\"left\", stralign=\"left\")\n        if nr > 20 and can_use_pandas(): print('\\nSee the whole table with table.as_data_frame()')", "language": "python", "code": "def show(self, header=True):\n        \"\"\"Print the contents of this table.\"\"\"\n        # if h2o.can_use_pandas():\n        #  import pandas\n        #  pandas.options.display.max_rows = 20\n        #  print pandas.DataFrame(self._cell_values,columns=self._col_header)\n        #  return\n        if header and self._table_header:\n            print(self._table_header + \":\", end=' ')\n            if self._table_description: print(self._table_description)\n        print()\n        table = copy.deepcopy(self._cell_values)\n        nr = 0\n        if _is_list_of_lists(table): nr = len(\n            table)  # only set if we truly have multiple rows... not just one long row :)\n        if nr > 20:  # create a truncated view of the table, first/last 5 rows\n            trunc_table = []\n            trunc_table += [v for v in table[:5]]\n            trunc_table.append([\"---\"] * len(table[0]))\n            trunc_table += [v for v in table[(nr - 5):]]\n            table = trunc_table\n\n        H2ODisplay(table, self._col_header, numalign=\"left\", stralign=\"left\")\n        if nr > 20 and can_use_pandas(): print('\\nSee the whole table with table.as_data_frame()')", "code_tokens": ["def", "show", "(", "self", ",", "header", "=", "True", ")", ":", "# if h2o.can_use_pandas():", "#  import pandas", "#  pandas.options.display.max_rows = 20", "#  print pandas.DataFrame(self._cell_values,columns=self._col_header)", "#  return", "if", "header", "and", "self", ".", "_table_header", ":", "print", "(", "self", ".", "_table_header", "+", "\":\"", ",", "end", "=", "' '", ")", "if", "self", ".", "_table_description", ":", "print", "(", "self", ".", "_table_description", ")", "print", "(", ")", "table", "=", "copy", ".", "deepcopy", "(", "self", ".", "_cell_values", ")", "nr", "=", "0", "if", "_is_list_of_lists", "(", "table", ")", ":", "nr", "=", "len", "(", "table", ")", "# only set if we truly have multiple rows... not just one long row :)", "if", "nr", ">", "20", ":", "# create a truncated view of the table, first/last 5 rows", "trunc_table", "=", "[", "]", "trunc_table", "+=", "[", "v", "for", "v", "in", "table", "[", ":", "5", "]", "]", "trunc_table", ".", "append", "(", "[", "\"---\"", "]", "*", "len", "(", "table", "[", "0", "]", ")", ")", "trunc_table", "+=", "[", "v", "for", "v", "in", "table", "[", "(", "nr", "-", "5", ")", ":", "]", "]", "table", "=", "trunc_table", "H2ODisplay", "(", "table", ",", "self", ".", "_col_header", ",", "numalign", "=", "\"left\"", ",", "stralign", "=", "\"left\"", ")", "if", "nr", ">", "20", "and", "can_use_pandas", "(", ")", ":", "print", "(", "'\\nSee the whole table with table.as_data_frame()'", ")"], "docstring": "Print the contents of this table.", "docstring_tokens": ["Print", "the", "contents", "of", "this", "table", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/two_dim_table.py#L86-L109", "partition": "test", "index": 1551, "time": "2015-02-04 17:01:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "lazy_import", "original_string": "def lazy_import(path, pattern=None):\n    \"\"\"\n    Import a single file or collection of files.\n\n    :param path: A path to a data file (remote or local).\n    :param pattern: Character string containing a regular expression to match file(s) in the folder.\n    :returns: either a :class:`H2OFrame` with the content of the provided file, or a list of such frames if\n        importing multiple files.\n    \"\"\"\n    assert_is_type(path, str, [str])\n    assert_is_type(pattern, str, None)\n    paths = [path] if is_type(path, str) else path\n    return _import_multi(paths, pattern)", "language": "python", "code": "def lazy_import(path, pattern=None):\n    \"\"\"\n    Import a single file or collection of files.\n\n    :param path: A path to a data file (remote or local).\n    :param pattern: Character string containing a regular expression to match file(s) in the folder.\n    :returns: either a :class:`H2OFrame` with the content of the provided file, or a list of such frames if\n        importing multiple files.\n    \"\"\"\n    assert_is_type(path, str, [str])\n    assert_is_type(pattern, str, None)\n    paths = [path] if is_type(path, str) else path\n    return _import_multi(paths, pattern)", "code_tokens": ["def", "lazy_import", "(", "path", ",", "pattern", "=", "None", ")", ":", "assert_is_type", "(", "path", ",", "str", ",", "[", "str", "]", ")", "assert_is_type", "(", "pattern", ",", "str", ",", "None", ")", "paths", "=", "[", "path", "]", "if", "is_type", "(", "path", ",", "str", ")", "else", "path", "return", "_import_multi", "(", "paths", ",", "pattern", ")"], "docstring": "Import a single file or collection of files.\n\n    :param path: A path to a data file (remote or local).\n    :param pattern: Character string containing a regular expression to match file(s) in the folder.\n    :returns: either a :class:`H2OFrame` with the content of the provided file, or a list of such frames if\n        importing multiple files.", "docstring_tokens": ["Import", "a", "single", "file", "or", "collection", "of", "files", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L287-L299", "partition": "test", "index": 1455, "time": "2015-02-27 16:52:06"}
{"repo": "h2oai/h2o-3", "path": "scripts/run.py", "func_name": "signal_handler", "original_string": "def signal_handler(signum, stackframe):\n    \"\"\"Helper function to handle caught signals.\"\"\"\n    global g_runner\n    global g_handling_signal\n\n    if g_handling_signal:\n        # Don't do this recursively.\n        return\n    g_handling_signal = True\n\n    print(\"\")\n    print(\"----------------------------------------------------------------------\")\n    print(\"\")\n    print(\"SIGNAL CAUGHT (\" + str(signum) + \").  TEARING DOWN CLOUDS.\")\n    print(\"\")\n    print(\"----------------------------------------------------------------------\")\n    g_runner.terminate()", "language": "python", "code": "def signal_handler(signum, stackframe):\n    \"\"\"Helper function to handle caught signals.\"\"\"\n    global g_runner\n    global g_handling_signal\n\n    if g_handling_signal:\n        # Don't do this recursively.\n        return\n    g_handling_signal = True\n\n    print(\"\")\n    print(\"----------------------------------------------------------------------\")\n    print(\"\")\n    print(\"SIGNAL CAUGHT (\" + str(signum) + \").  TEARING DOWN CLOUDS.\")\n    print(\"\")\n    print(\"----------------------------------------------------------------------\")\n    g_runner.terminate()", "code_tokens": ["def", "signal_handler", "(", "signum", ",", "stackframe", ")", ":", "global", "g_runner", "global", "g_handling_signal", "if", "g_handling_signal", ":", "# Don't do this recursively.", "return", "g_handling_signal", "=", "True", "print", "(", "\"\"", ")", "print", "(", "\"----------------------------------------------------------------------\"", ")", "print", "(", "\"\"", ")", "print", "(", "\"SIGNAL CAUGHT (\"", "+", "str", "(", "signum", ")", "+", "\").  TEARING DOWN CLOUDS.\"", ")", "print", "(", "\"\"", ")", "print", "(", "\"----------------------------------------------------------------------\"", ")", "g_runner", ".", "terminate", "(", ")"], "docstring": "Helper function to handle caught signals.", "docstring_tokens": ["Helper", "function", "to", "handle", "caught", "signals", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/run.py#L2073-L2089", "partition": "test", "index": 1349, "time": "2015-02-28 13:24:03"}
{"repo": "h2oai/h2o-3", "path": "scripts/run.py", "func_name": "wipe_output_dir", "original_string": "def wipe_output_dir():\n    \"\"\"Clear the output directory.\"\"\"\n    print(\"Wiping output directory.\")\n    try:\n        if os.path.exists(g_output_dir):\n            shutil.rmtree(str(g_output_dir))\n    except OSError as e:\n        print(\"ERROR: Removing output directory %s failed: \" % g_output_dir)\n        print(\"       (errno {0}): {1}\".format(e.errno, e.strerror))\n        print(\"\")\n        sys.exit(1)", "language": "python", "code": "def wipe_output_dir():\n    \"\"\"Clear the output directory.\"\"\"\n    print(\"Wiping output directory.\")\n    try:\n        if os.path.exists(g_output_dir):\n            shutil.rmtree(str(g_output_dir))\n    except OSError as e:\n        print(\"ERROR: Removing output directory %s failed: \" % g_output_dir)\n        print(\"       (errno {0}): {1}\".format(e.errno, e.strerror))\n        print(\"\")\n        sys.exit(1)", "code_tokens": ["def", "wipe_output_dir", "(", ")", ":", "print", "(", "\"Wiping output directory.\"", ")", "try", ":", "if", "os", ".", "path", ".", "exists", "(", "g_output_dir", ")", ":", "shutil", ".", "rmtree", "(", "str", "(", "g_output_dir", ")", ")", "except", "OSError", "as", "e", ":", "print", "(", "\"ERROR: Removing output directory %s failed: \"", "%", "g_output_dir", ")", "print", "(", "\"       (errno {0}): {1}\"", ".", "format", "(", "e", ".", "errno", ",", "e", ".", "strerror", ")", ")", "print", "(", "\"\"", ")", "sys", ".", "exit", "(", "1", ")"], "docstring": "Clear the output directory.", "docstring_tokens": ["Clear", "the", "output", "directory", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/run.py#L2530-L2540", "partition": "test", "index": 1350, "time": "2015-02-28 13:24:03"}
{"repo": "h2oai/h2o-3", "path": "scripts/run.py", "func_name": "H2OCloudNode.scrape_cloudsize_from_stdout", "original_string": "def scrape_cloudsize_from_stdout(self, nodes_per_cloud):\n        \"\"\"\n        Look at the stdout log and wait until the cluster of proper size is formed.\n        This call is blocking.\n        Exit if this fails.\n\n        :param nodes_per_cloud:\n        :return none\n        \"\"\"\n        retries = 60\n        while retries > 0:\n            if self.terminated: return\n            f = open(self.output_file_name, \"r\")\n            s = f.readline()\n            while len(s) > 0:\n                if self.terminated: return\n                match_groups = re.search(r\"Cloud of size (\\d+) formed\", s)\n                if match_groups is not None:\n                    size = match_groups.group(1)\n                    if size is not None:\n                        size = int(size)\n                        if size == nodes_per_cloud:\n                            f.close()\n                            return\n\n                s = f.readline()\n\n            f.close()\n            retries -= 1\n            if self.terminated: return\n            time.sleep(1)\n\n        print(\"\")\n        print(\"ERROR: Too many retries starting cloud.\")\n        print(\"\")\n        sys.exit(1)", "language": "python", "code": "def scrape_cloudsize_from_stdout(self, nodes_per_cloud):\n        \"\"\"\n        Look at the stdout log and wait until the cluster of proper size is formed.\n        This call is blocking.\n        Exit if this fails.\n\n        :param nodes_per_cloud:\n        :return none\n        \"\"\"\n        retries = 60\n        while retries > 0:\n            if self.terminated: return\n            f = open(self.output_file_name, \"r\")\n            s = f.readline()\n            while len(s) > 0:\n                if self.terminated: return\n                match_groups = re.search(r\"Cloud of size (\\d+) formed\", s)\n                if match_groups is not None:\n                    size = match_groups.group(1)\n                    if size is not None:\n                        size = int(size)\n                        if size == nodes_per_cloud:\n                            f.close()\n                            return\n\n                s = f.readline()\n\n            f.close()\n            retries -= 1\n            if self.terminated: return\n            time.sleep(1)\n\n        print(\"\")\n        print(\"ERROR: Too many retries starting cloud.\")\n        print(\"\")\n        sys.exit(1)", "code_tokens": ["def", "scrape_cloudsize_from_stdout", "(", "self", ",", "nodes_per_cloud", ")", ":", "retries", "=", "60", "while", "retries", ">", "0", ":", "if", "self", ".", "terminated", ":", "return", "f", "=", "open", "(", "self", ".", "output_file_name", ",", "\"r\"", ")", "s", "=", "f", ".", "readline", "(", ")", "while", "len", "(", "s", ")", ">", "0", ":", "if", "self", ".", "terminated", ":", "return", "match_groups", "=", "re", ".", "search", "(", "r\"Cloud of size (\\d+) formed\"", ",", "s", ")", "if", "match_groups", "is", "not", "None", ":", "size", "=", "match_groups", ".", "group", "(", "1", ")", "if", "size", "is", "not", "None", ":", "size", "=", "int", "(", "size", ")", "if", "size", "==", "nodes_per_cloud", ":", "f", ".", "close", "(", ")", "return", "s", "=", "f", ".", "readline", "(", ")", "f", ".", "close", "(", ")", "retries", "-=", "1", "if", "self", ".", "terminated", ":", "return", "time", ".", "sleep", "(", "1", ")", "print", "(", "\"\"", ")", "print", "(", "\"ERROR: Too many retries starting cloud.\"", ")", "print", "(", "\"\"", ")", "sys", ".", "exit", "(", "1", ")"], "docstring": "Look at the stdout log and wait until the cluster of proper size is formed.\n        This call is blocking.\n        Exit if this fails.\n\n        :param nodes_per_cloud:\n        :return none", "docstring_tokens": ["Look", "at", "the", "stdout", "log", "and", "wait", "until", "the", "cluster", "of", "proper", "size", "is", "formed", ".", "This", "call", "is", "blocking", ".", "Exit", "if", "this", "fails", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/run.py#L447-L482", "partition": "test", "index": 1353, "time": "2015-02-28 13:24:03"}
{"repo": "h2oai/h2o-3", "path": "scripts/run.py", "func_name": "H2OCloudNode.stop", "original_string": "def stop(self):\n        \"\"\"\n        Normal node shutdown.\n        Ignore failures for now.\n\n        :return none\n        \"\"\"\n        if self.pid > 0:\n            print(\"Killing JVM with PID {}\".format(self.pid))\n            try:\n                self.child.terminate()\n                self.child.wait()\n            except OSError:\n                pass\n            self.pid = -1", "language": "python", "code": "def stop(self):\n        \"\"\"\n        Normal node shutdown.\n        Ignore failures for now.\n\n        :return none\n        \"\"\"\n        if self.pid > 0:\n            print(\"Killing JVM with PID {}\".format(self.pid))\n            try:\n                self.child.terminate()\n                self.child.wait()\n            except OSError:\n                pass\n            self.pid = -1", "code_tokens": ["def", "stop", "(", "self", ")", ":", "if", "self", ".", "pid", ">", "0", ":", "print", "(", "\"Killing JVM with PID {}\"", ".", "format", "(", "self", ".", "pid", ")", ")", "try", ":", "self", ".", "child", ".", "terminate", "(", ")", "self", ".", "child", ".", "wait", "(", ")", "except", "OSError", ":", "pass", "self", ".", "pid", "=", "-", "1"], "docstring": "Normal node shutdown.\n        Ignore failures for now.\n\n        :return none", "docstring_tokens": ["Normal", "node", "shutdown", ".", "Ignore", "failures", "for", "now", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/run.py#L484-L498", "partition": "test", "index": 1354, "time": "2015-02-28 13:24:03"}
{"repo": "h2oai/h2o-3", "path": "scripts/run.py", "func_name": "H2OCloud.stop", "original_string": "def stop(self):\n        \"\"\"\n        Normal cluster shutdown.\n\n        :return none\n        \"\"\"\n        for node in self.nodes:\n            node.stop()\n\n        for node in self.client_nodes:\n            node.stop()", "language": "python", "code": "def stop(self):\n        \"\"\"\n        Normal cluster shutdown.\n\n        :return none\n        \"\"\"\n        for node in self.nodes:\n            node.stop()\n\n        for node in self.client_nodes:\n            node.stop()", "code_tokens": ["def", "stop", "(", "self", ")", ":", "for", "node", "in", "self", ".", "nodes", ":", "node", ".", "stop", "(", ")", "for", "node", "in", "self", ".", "client_nodes", ":", "node", ".", "stop", "(", ")"], "docstring": "Normal cluster shutdown.\n\n        :return none", "docstring_tokens": ["Normal", "cluster", "shutdown", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/run.py#L613-L623", "partition": "test", "index": 1355, "time": "2015-02-28 13:24:03"}
{"repo": "h2oai/h2o-3", "path": "scripts/run.py", "func_name": "H2OCloud.get_ip", "original_string": "def get_ip(self):\n        \"\"\" Return an ip to use to talk to this cluster. \"\"\"\n        if len(self.client_nodes) > 0:\n            node = self.client_nodes[0]\n        else:\n            node = self.nodes[0]\n        return node.get_ip()", "language": "python", "code": "def get_ip(self):\n        \"\"\" Return an ip to use to talk to this cluster. \"\"\"\n        if len(self.client_nodes) > 0:\n            node = self.client_nodes[0]\n        else:\n            node = self.nodes[0]\n        return node.get_ip()", "code_tokens": ["def", "get_ip", "(", "self", ")", ":", "if", "len", "(", "self", ".", "client_nodes", ")", ">", "0", ":", "node", "=", "self", ".", "client_nodes", "[", "0", "]", "else", ":", "node", "=", "self", ".", "nodes", "[", "0", "]", "return", "node", ".", "get_ip", "(", ")"], "docstring": "Return an ip to use to talk to this cluster.", "docstring_tokens": ["Return", "an", "ip", "to", "use", "to", "talk", "to", "this", "cluster", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/run.py#L637-L643", "partition": "test", "index": 1356, "time": "2015-02-28 13:24:03"}
{"repo": "h2oai/h2o-3", "path": "scripts/run.py", "func_name": "H2OCloud.get_port", "original_string": "def get_port(self):\n        \"\"\" Return a port to use to talk to this cluster. \"\"\"\n        if len(self.client_nodes) > 0:\n            node = self.client_nodes[0]\n        else:\n            node = self.nodes[0]\n        return node.get_port()", "language": "python", "code": "def get_port(self):\n        \"\"\" Return a port to use to talk to this cluster. \"\"\"\n        if len(self.client_nodes) > 0:\n            node = self.client_nodes[0]\n        else:\n            node = self.nodes[0]\n        return node.get_port()", "code_tokens": ["def", "get_port", "(", "self", ")", ":", "if", "len", "(", "self", ".", "client_nodes", ")", ">", "0", ":", "node", "=", "self", ".", "client_nodes", "[", "0", "]", "else", ":", "node", "=", "self", ".", "nodes", "[", "0", "]", "return", "node", ".", "get_port", "(", ")"], "docstring": "Return a port to use to talk to this cluster.", "docstring_tokens": ["Return", "a", "port", "to", "use", "to", "talk", "to", "this", "cluster", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/run.py#L645-L651", "partition": "test", "index": 1357, "time": "2015-02-28 13:24:03"}
{"repo": "h2oai/h2o-3", "path": "scripts/run.py", "func_name": "H2OCloudNode.scrape_port_from_stdout", "original_string": "def scrape_port_from_stdout(self):\n        \"\"\"\n        Look at the stdout log and figure out which port the JVM chose.\n\n        If successful, port number is stored in self.port; otherwise the\n        program is terminated. This call is blocking, and will wait for\n        up to 30s for the server to start up.\n        \"\"\"\n        regex = re.compile(r\"Open H2O Flow in your web browser: https?://([^:]+):(\\d+)\")\n        retries_left = 30\n        while retries_left and not self.terminated:\n            with open(self.output_file_name, \"r\") as f:\n                for line in f:\n                    mm = re.search(regex, line)\n                    if mm is not None:\n                        self.port = mm.group(2)\n                        print(\"H2O cloud %d node %d listening on port %s\\n    with output file %s\" %\n                              (self.cloud_num, self.node_num, self.port, self.output_file_name))\n                        return\n            if self.terminated: break\n            retries_left -= 1\n            time.sleep(1)\n\n        if self.terminated: return\n        print(\"\\nERROR: Too many retries starting cloud %d.\\nCheck the output log %s.\\n\" %\n              (self.cloud_num, self.output_file_name))\n        sys.exit(1)", "language": "python", "code": "def scrape_port_from_stdout(self):\n        \"\"\"\n        Look at the stdout log and figure out which port the JVM chose.\n\n        If successful, port number is stored in self.port; otherwise the\n        program is terminated. This call is blocking, and will wait for\n        up to 30s for the server to start up.\n        \"\"\"\n        regex = re.compile(r\"Open H2O Flow in your web browser: https?://([^:]+):(\\d+)\")\n        retries_left = 30\n        while retries_left and not self.terminated:\n            with open(self.output_file_name, \"r\") as f:\n                for line in f:\n                    mm = re.search(regex, line)\n                    if mm is not None:\n                        self.port = mm.group(2)\n                        print(\"H2O cloud %d node %d listening on port %s\\n    with output file %s\" %\n                              (self.cloud_num, self.node_num, self.port, self.output_file_name))\n                        return\n            if self.terminated: break\n            retries_left -= 1\n            time.sleep(1)\n\n        if self.terminated: return\n        print(\"\\nERROR: Too many retries starting cloud %d.\\nCheck the output log %s.\\n\" %\n              (self.cloud_num, self.output_file_name))\n        sys.exit(1)", "code_tokens": ["def", "scrape_port_from_stdout", "(", "self", ")", ":", "regex", "=", "re", ".", "compile", "(", "r\"Open H2O Flow in your web browser: https?://([^:]+):(\\d+)\"", ")", "retries_left", "=", "30", "while", "retries_left", "and", "not", "self", ".", "terminated", ":", "with", "open", "(", "self", ".", "output_file_name", ",", "\"r\"", ")", "as", "f", ":", "for", "line", "in", "f", ":", "mm", "=", "re", ".", "search", "(", "regex", ",", "line", ")", "if", "mm", "is", "not", "None", ":", "self", ".", "port", "=", "mm", ".", "group", "(", "2", ")", "print", "(", "\"H2O cloud %d node %d listening on port %s\\n    with output file %s\"", "%", "(", "self", ".", "cloud_num", ",", "self", ".", "node_num", ",", "self", ".", "port", ",", "self", ".", "output_file_name", ")", ")", "return", "if", "self", ".", "terminated", ":", "break", "retries_left", "-=", "1", "time", ".", "sleep", "(", "1", ")", "if", "self", ".", "terminated", ":", "return", "print", "(", "\"\\nERROR: Too many retries starting cloud %d.\\nCheck the output log %s.\\n\"", "%", "(", "self", ".", "cloud_num", ",", "self", ".", "output_file_name", ")", ")", "sys", ".", "exit", "(", "1", ")"], "docstring": "Look at the stdout log and figure out which port the JVM chose.\n\n        If successful, port number is stored in self.port; otherwise the\n        program is terminated. This call is blocking, and will wait for\n        up to 30s for the server to start up.", "docstring_tokens": ["Look", "at", "the", "stdout", "log", "and", "figure", "out", "which", "port", "the", "JVM", "chose", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/run.py#L418-L444", "partition": "test", "index": 1352, "time": "2015-02-28 13:24:03"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "as_list", "original_string": "def as_list(data, use_pandas=True, header=True):\n    \"\"\"\n    Convert an H2O data object into a python-specific object.\n\n    WARNING! This will pull all data local!\n\n    If Pandas is available (and use_pandas is True), then pandas will be used to parse the\n    data frame. Otherwise, a list-of-lists populated by character data will be returned (so\n    the types of data will all be str).\n\n    :param data: an H2O data object.\n    :param use_pandas: If True, try to use pandas for reading in the data.\n    :param header: If True, return column names as first element in list\n\n    :returns: List of lists (Rows x Columns).\n    \"\"\"\n    assert_is_type(data, H2OFrame)\n    assert_is_type(use_pandas, bool)\n    assert_is_type(header, bool)\n    return H2OFrame.as_data_frame(data, use_pandas=use_pandas, header=header)", "language": "python", "code": "def as_list(data, use_pandas=True, header=True):\n    \"\"\"\n    Convert an H2O data object into a python-specific object.\n\n    WARNING! This will pull all data local!\n\n    If Pandas is available (and use_pandas is True), then pandas will be used to parse the\n    data frame. Otherwise, a list-of-lists populated by character data will be returned (so\n    the types of data will all be str).\n\n    :param data: an H2O data object.\n    :param use_pandas: If True, try to use pandas for reading in the data.\n    :param header: If True, return column names as first element in list\n\n    :returns: List of lists (Rows x Columns).\n    \"\"\"\n    assert_is_type(data, H2OFrame)\n    assert_is_type(use_pandas, bool)\n    assert_is_type(header, bool)\n    return H2OFrame.as_data_frame(data, use_pandas=use_pandas, header=header)", "code_tokens": ["def", "as_list", "(", "data", ",", "use_pandas", "=", "True", ",", "header", "=", "True", ")", ":", "assert_is_type", "(", "data", ",", "H2OFrame", ")", "assert_is_type", "(", "use_pandas", ",", "bool", ")", "assert_is_type", "(", "header", ",", "bool", ")", "return", "H2OFrame", ".", "as_data_frame", "(", "data", ",", "use_pandas", "=", "use_pandas", ",", "header", "=", "header", ")"], "docstring": "Convert an H2O data object into a python-specific object.\n\n    WARNING! This will pull all data local!\n\n    If Pandas is available (and use_pandas is True), then pandas will be used to parse the\n    data frame. Otherwise, a list-of-lists populated by character data will be returned (so\n    the types of data will all be str).\n\n    :param data: an H2O data object.\n    :param use_pandas: If True, try to use pandas for reading in the data.\n    :param header: If True, return column names as first element in list\n\n    :returns: List of lists (Rows x Columns).", "docstring_tokens": ["Convert", "an", "H2O", "data", "object", "into", "a", "python", "-", "specific", "object", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L1297-L1316", "partition": "test", "index": 1470, "time": "2015-04-26 14:08:57"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "get_model", "original_string": "def get_model(model_id):\n    \"\"\"\n    Load a model from the server.\n\n    :param model_id: The model identification in H2O\n\n    :returns: Model object, a subclass of H2OEstimator\n    \"\"\"\n    assert_is_type(model_id, str)\n    model_json = api(\"GET /3/Models/%s\" % model_id)[\"models\"][0]\n    algo = model_json[\"algo\"]\n    if algo == \"svd\":            m = H2OSVD()\n    elif algo == \"pca\":          m = H2OPrincipalComponentAnalysisEstimator()\n    elif algo == \"drf\":          m = H2ORandomForestEstimator()\n    elif algo == \"naivebayes\":   m = H2ONaiveBayesEstimator()\n    elif algo == \"kmeans\":       m = H2OKMeansEstimator()\n    elif algo == \"glrm\":         m = H2OGeneralizedLowRankEstimator()\n    elif algo == \"glm\":          m = H2OGeneralizedLinearEstimator()\n    elif algo == \"gbm\":          m = H2OGradientBoostingEstimator()\n    elif algo == \"deepwater\":    m = H2ODeepWaterEstimator()\n    elif algo == \"xgboost\":      m = H2OXGBoostEstimator()\n    elif algo == \"word2vec\":     m = H2OWord2vecEstimator()\n    elif algo == \"generic\": m = H2OGenericEstimator()\n    elif algo == \"deeplearning\":\n        if model_json[\"output\"][\"model_category\"] == \"AutoEncoder\":\n            m = H2OAutoEncoderEstimator()\n        else:\n            m = H2ODeepLearningEstimator()\n    elif algo == \"stackedensemble\": m = H2OStackedEnsembleEstimator()\n    elif algo == \"isolationforest\": m = H2OIsolationForestEstimator()\n    else:\n        raise ValueError(\"Unknown algo type: \" + algo)\n    m._resolve_model(model_id, model_json)\n    return m", "language": "python", "code": "def get_model(model_id):\n    \"\"\"\n    Load a model from the server.\n\n    :param model_id: The model identification in H2O\n\n    :returns: Model object, a subclass of H2OEstimator\n    \"\"\"\n    assert_is_type(model_id, str)\n    model_json = api(\"GET /3/Models/%s\" % model_id)[\"models\"][0]\n    algo = model_json[\"algo\"]\n    if algo == \"svd\":            m = H2OSVD()\n    elif algo == \"pca\":          m = H2OPrincipalComponentAnalysisEstimator()\n    elif algo == \"drf\":          m = H2ORandomForestEstimator()\n    elif algo == \"naivebayes\":   m = H2ONaiveBayesEstimator()\n    elif algo == \"kmeans\":       m = H2OKMeansEstimator()\n    elif algo == \"glrm\":         m = H2OGeneralizedLowRankEstimator()\n    elif algo == \"glm\":          m = H2OGeneralizedLinearEstimator()\n    elif algo == \"gbm\":          m = H2OGradientBoostingEstimator()\n    elif algo == \"deepwater\":    m = H2ODeepWaterEstimator()\n    elif algo == \"xgboost\":      m = H2OXGBoostEstimator()\n    elif algo == \"word2vec\":     m = H2OWord2vecEstimator()\n    elif algo == \"generic\": m = H2OGenericEstimator()\n    elif algo == \"deeplearning\":\n        if model_json[\"output\"][\"model_category\"] == \"AutoEncoder\":\n            m = H2OAutoEncoderEstimator()\n        else:\n            m = H2ODeepLearningEstimator()\n    elif algo == \"stackedensemble\": m = H2OStackedEnsembleEstimator()\n    elif algo == \"isolationforest\": m = H2OIsolationForestEstimator()\n    else:\n        raise ValueError(\"Unknown algo type: \" + algo)\n    m._resolve_model(model_id, model_json)\n    return m", "code_tokens": ["def", "get_model", "(", "model_id", ")", ":", "assert_is_type", "(", "model_id", ",", "str", ")", "model_json", "=", "api", "(", "\"GET /3/Models/%s\"", "%", "model_id", ")", "[", "\"models\"", "]", "[", "0", "]", "algo", "=", "model_json", "[", "\"algo\"", "]", "if", "algo", "==", "\"svd\"", ":", "m", "=", "H2OSVD", "(", ")", "elif", "algo", "==", "\"pca\"", ":", "m", "=", "H2OPrincipalComponentAnalysisEstimator", "(", ")", "elif", "algo", "==", "\"drf\"", ":", "m", "=", "H2ORandomForestEstimator", "(", ")", "elif", "algo", "==", "\"naivebayes\"", ":", "m", "=", "H2ONaiveBayesEstimator", "(", ")", "elif", "algo", "==", "\"kmeans\"", ":", "m", "=", "H2OKMeansEstimator", "(", ")", "elif", "algo", "==", "\"glrm\"", ":", "m", "=", "H2OGeneralizedLowRankEstimator", "(", ")", "elif", "algo", "==", "\"glm\"", ":", "m", "=", "H2OGeneralizedLinearEstimator", "(", ")", "elif", "algo", "==", "\"gbm\"", ":", "m", "=", "H2OGradientBoostingEstimator", "(", ")", "elif", "algo", "==", "\"deepwater\"", ":", "m", "=", "H2ODeepWaterEstimator", "(", ")", "elif", "algo", "==", "\"xgboost\"", ":", "m", "=", "H2OXGBoostEstimator", "(", ")", "elif", "algo", "==", "\"word2vec\"", ":", "m", "=", "H2OWord2vecEstimator", "(", ")", "elif", "algo", "==", "\"generic\"", ":", "m", "=", "H2OGenericEstimator", "(", ")", "elif", "algo", "==", "\"deeplearning\"", ":", "if", "model_json", "[", "\"output\"", "]", "[", "\"model_category\"", "]", "==", "\"AutoEncoder\"", ":", "m", "=", "H2OAutoEncoderEstimator", "(", ")", "else", ":", "m", "=", "H2ODeepLearningEstimator", "(", ")", "elif", "algo", "==", "\"stackedensemble\"", ":", "m", "=", "H2OStackedEnsembleEstimator", "(", ")", "elif", "algo", "==", "\"isolationforest\"", ":", "m", "=", "H2OIsolationForestEstimator", "(", ")", "else", ":", "raise", "ValueError", "(", "\"Unknown algo type: \"", "+", "algo", ")", "m", ".", "_resolve_model", "(", "model_id", ",", "model_json", ")", "return", "m"], "docstring": "Load a model from the server.\n\n    :param model_id: The model identification in H2O\n\n    :returns: Model object, a subclass of H2OEstimator", "docstring_tokens": ["Load", "a", "model", "from", "the", "server", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L792-L825", "partition": "test", "index": 1463, "time": "2015-05-29 16:54:38"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "download_csv", "original_string": "def download_csv(data, filename):\n    \"\"\"\n    Download an H2O data set to a CSV file on the local disk.\n\n    Warning: Files located on the H2O server may be very large! Make sure you have enough\n    hard drive space to accommodate the entire file.\n\n    :param data: an H2OFrame object to be downloaded.\n    :param filename: name for the CSV file where the data should be saved to.\n    \"\"\"\n    assert_is_type(data, H2OFrame)\n    assert_is_type(filename, str)\n    url = h2oconn.make_url(\"DownloadDataset\", 3) + \"?frame_id={}&hex_string=false\".format(data.frame_id)\n    with open(filename, \"wb\") as f:\n        f.write(urlopen()(url).read())", "language": "python", "code": "def download_csv(data, filename):\n    \"\"\"\n    Download an H2O data set to a CSV file on the local disk.\n\n    Warning: Files located on the H2O server may be very large! Make sure you have enough\n    hard drive space to accommodate the entire file.\n\n    :param data: an H2OFrame object to be downloaded.\n    :param filename: name for the CSV file where the data should be saved to.\n    \"\"\"\n    assert_is_type(data, H2OFrame)\n    assert_is_type(filename, str)\n    url = h2oconn.make_url(\"DownloadDataset\", 3) + \"?frame_id={}&hex_string=false\".format(data.frame_id)\n    with open(filename, \"wb\") as f:\n        f.write(urlopen()(url).read())", "code_tokens": ["def", "download_csv", "(", "data", ",", "filename", ")", ":", "assert_is_type", "(", "data", ",", "H2OFrame", ")", "assert_is_type", "(", "filename", ",", "str", ")", "url", "=", "h2oconn", ".", "make_url", "(", "\"DownloadDataset\"", ",", "3", ")", "+", "\"?frame_id={}&hex_string=false\"", ".", "format", "(", "data", ".", "frame_id", ")", "with", "open", "(", "filename", ",", "\"wb\"", ")", "as", "f", ":", "f", ".", "write", "(", "urlopen", "(", ")", "(", "url", ")", ".", "read", "(", ")", ")"], "docstring": "Download an H2O data set to a CSV file on the local disk.\n\n    Warning: Files located on the H2O server may be very large! Make sure you have enough\n    hard drive space to accommodate the entire file.\n\n    :param data: an H2OFrame object to be downloaded.\n    :param filename: name for the CSV file where the data should be saved to.", "docstring_tokens": ["Download", "an", "H2O", "data", "set", "to", "a", "CSV", "file", "on", "the", "local", "disk", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L1009-L1023", "partition": "test", "index": 1467, "time": "2015-06-17 11:03:15"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/dim_reduction.py", "func_name": "H2ODimReductionModel.screeplot", "original_string": "def screeplot(self, type=\"barplot\", **kwargs):\n        \"\"\"\n        Produce the scree plot.\n\n        Library ``matplotlib`` is required for this function.\n\n        :param str type: either ``\"barplot\"`` or ``\"lines\"``.\n        \"\"\"\n        # check for matplotlib. exit if absent.\n        is_server = kwargs.pop(\"server\")\n        if kwargs:\n            raise ValueError(\"Unknown arguments %s to screeplot()\" % \", \".join(kwargs.keys()))\n        try:\n            import matplotlib\n            if is_server: matplotlib.use('Agg', warn=False)\n            import matplotlib.pyplot as plt\n        except ImportError:\n            print(\"matplotlib is required for this function!\")\n            return\n\n        variances = [s ** 2 for s in self._model_json['output']['importance'].cell_values[0][1:]]\n        plt.xlabel('Components')\n        plt.ylabel('Variances')\n        plt.title('Scree Plot')\n        plt.xticks(list(range(1, len(variances) + 1)))\n        if type == \"barplot\":\n            plt.bar(list(range(1, len(variances) + 1)), variances)\n        elif type == \"lines\":\n            plt.plot(list(range(1, len(variances) + 1)), variances, 'b--')\n        if not is_server: plt.show()", "language": "python", "code": "def screeplot(self, type=\"barplot\", **kwargs):\n        \"\"\"\n        Produce the scree plot.\n\n        Library ``matplotlib`` is required for this function.\n\n        :param str type: either ``\"barplot\"`` or ``\"lines\"``.\n        \"\"\"\n        # check for matplotlib. exit if absent.\n        is_server = kwargs.pop(\"server\")\n        if kwargs:\n            raise ValueError(\"Unknown arguments %s to screeplot()\" % \", \".join(kwargs.keys()))\n        try:\n            import matplotlib\n            if is_server: matplotlib.use('Agg', warn=False)\n            import matplotlib.pyplot as plt\n        except ImportError:\n            print(\"matplotlib is required for this function!\")\n            return\n\n        variances = [s ** 2 for s in self._model_json['output']['importance'].cell_values[0][1:]]\n        plt.xlabel('Components')\n        plt.ylabel('Variances')\n        plt.title('Scree Plot')\n        plt.xticks(list(range(1, len(variances) + 1)))\n        if type == \"barplot\":\n            plt.bar(list(range(1, len(variances) + 1)), variances)\n        elif type == \"lines\":\n            plt.plot(list(range(1, len(variances) + 1)), variances, 'b--')\n        if not is_server: plt.show()", "code_tokens": ["def", "screeplot", "(", "self", ",", "type", "=", "\"barplot\"", ",", "*", "*", "kwargs", ")", ":", "# check for matplotlib. exit if absent.", "is_server", "=", "kwargs", ".", "pop", "(", "\"server\"", ")", "if", "kwargs", ":", "raise", "ValueError", "(", "\"Unknown arguments %s to screeplot()\"", "%", "\", \"", ".", "join", "(", "kwargs", ".", "keys", "(", ")", ")", ")", "try", ":", "import", "matplotlib", "if", "is_server", ":", "matplotlib", ".", "use", "(", "'Agg'", ",", "warn", "=", "False", ")", "import", "matplotlib", ".", "pyplot", "as", "plt", "except", "ImportError", ":", "print", "(", "\"matplotlib is required for this function!\"", ")", "return", "variances", "=", "[", "s", "**", "2", "for", "s", "in", "self", ".", "_model_json", "[", "'output'", "]", "[", "'importance'", "]", ".", "cell_values", "[", "0", "]", "[", "1", ":", "]", "]", "plt", ".", "xlabel", "(", "'Components'", ")", "plt", ".", "ylabel", "(", "'Variances'", ")", "plt", ".", "title", "(", "'Scree Plot'", ")", "plt", ".", "xticks", "(", "list", "(", "range", "(", "1", ",", "len", "(", "variances", ")", "+", "1", ")", ")", ")", "if", "type", "==", "\"barplot\"", ":", "plt", ".", "bar", "(", "list", "(", "range", "(", "1", ",", "len", "(", "variances", ")", "+", "1", ")", ")", ",", "variances", ")", "elif", "type", "==", "\"lines\"", ":", "plt", ".", "plot", "(", "list", "(", "range", "(", "1", ",", "len", "(", "variances", ")", "+", "1", ")", ")", ",", "variances", ",", "'b--'", ")", "if", "not", "is_server", ":", "plt", ".", "show", "(", ")"], "docstring": "Produce the scree plot.\n\n        Library ``matplotlib`` is required for this function.\n\n        :param str type: either ``\"barplot\"`` or ``\"lines\"``.", "docstring_tokens": ["Produce", "the", "scree", "plot", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/dim_reduction.py#L95-L124", "partition": "test", "index": 1493, "time": "2015-06-18 19:31:03"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/demos.py", "func_name": "_wait_for_keypress", "original_string": "def _wait_for_keypress():\n    \"\"\"\n    Wait for a key press on the console and return it.\n\n    Borrowed from http://stackoverflow.com/questions/983354/how-do-i-make-python-to-wait-for-a-pressed-key\n    \"\"\"\n    result = None\n    if os.name == \"nt\":\n        # noinspection PyUnresolvedReferences\n        import msvcrt\n        result = msvcrt.getch()\n    else:\n        import termios\n        fd = sys.stdin.fileno()\n\n        oldterm = termios.tcgetattr(fd)\n        newattr = termios.tcgetattr(fd)\n        newattr[3] = newattr[3] & ~termios.ICANON & ~termios.ECHO\n        termios.tcsetattr(fd, termios.TCSANOW, newattr)\n\n        try:\n            result = sys.stdin.read(1)\n        except IOError:\n            pass\n        finally:\n            termios.tcsetattr(fd, termios.TCSAFLUSH, oldterm)\n\n    return result", "language": "python", "code": "def _wait_for_keypress():\n    \"\"\"\n    Wait for a key press on the console and return it.\n\n    Borrowed from http://stackoverflow.com/questions/983354/how-do-i-make-python-to-wait-for-a-pressed-key\n    \"\"\"\n    result = None\n    if os.name == \"nt\":\n        # noinspection PyUnresolvedReferences\n        import msvcrt\n        result = msvcrt.getch()\n    else:\n        import termios\n        fd = sys.stdin.fileno()\n\n        oldterm = termios.tcgetattr(fd)\n        newattr = termios.tcgetattr(fd)\n        newattr[3] = newattr[3] & ~termios.ICANON & ~termios.ECHO\n        termios.tcsetattr(fd, termios.TCSANOW, newattr)\n\n        try:\n            result = sys.stdin.read(1)\n        except IOError:\n            pass\n        finally:\n            termios.tcsetattr(fd, termios.TCSAFLUSH, oldterm)\n\n    return result", "code_tokens": ["def", "_wait_for_keypress", "(", ")", ":", "result", "=", "None", "if", "os", ".", "name", "==", "\"nt\"", ":", "# noinspection PyUnresolvedReferences", "import", "msvcrt", "result", "=", "msvcrt", ".", "getch", "(", ")", "else", ":", "import", "termios", "fd", "=", "sys", ".", "stdin", ".", "fileno", "(", ")", "oldterm", "=", "termios", ".", "tcgetattr", "(", "fd", ")", "newattr", "=", "termios", ".", "tcgetattr", "(", "fd", ")", "newattr", "[", "3", "]", "=", "newattr", "[", "3", "]", "&", "~", "termios", ".", "ICANON", "&", "~", "termios", ".", "ECHO", "termios", ".", "tcsetattr", "(", "fd", ",", "termios", ".", "TCSANOW", ",", "newattr", ")", "try", ":", "result", "=", "sys", ".", "stdin", ".", "read", "(", "1", ")", "except", "IOError", ":", "pass", "finally", ":", "termios", ".", "tcsetattr", "(", "fd", ",", "termios", ".", "TCSAFLUSH", ",", "oldterm", ")", "return", "result"], "docstring": "Wait for a key press on the console and return it.\n\n    Borrowed from http://stackoverflow.com/questions/983354/how-do-i-make-python-to-wait-for-a-pressed-key", "docstring_tokens": ["Wait", "for", "a", "key", "press", "on", "the", "console", "and", "return", "it", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/demos.py#L306-L333", "partition": "test", "index": 1549, "time": "2015-08-11 12:50:17"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/regression.py", "func_name": "h2o_mean_absolute_error", "original_string": "def h2o_mean_absolute_error(y_actual, y_predicted, weights=None):\n    \"\"\"\n    Mean absolute error regression loss.\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :param weights: (Optional) sample weights\n    :returns: mean absolute error loss (best is 0.0).\n    \"\"\"\n    ModelBase._check_targets(y_actual, y_predicted)\n    return _colmean((y_predicted - y_actual).abs())", "language": "python", "code": "def h2o_mean_absolute_error(y_actual, y_predicted, weights=None):\n    \"\"\"\n    Mean absolute error regression loss.\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :param weights: (Optional) sample weights\n    :returns: mean absolute error loss (best is 0.0).\n    \"\"\"\n    ModelBase._check_targets(y_actual, y_predicted)\n    return _colmean((y_predicted - y_actual).abs())", "code_tokens": ["def", "h2o_mean_absolute_error", "(", "y_actual", ",", "y_predicted", ",", "weights", "=", "None", ")", ":", "ModelBase", ".", "_check_targets", "(", "y_actual", ",", "y_predicted", ")", "return", "_colmean", "(", "(", "y_predicted", "-", "y_actual", ")", ".", "abs", "(", ")", ")"], "docstring": "Mean absolute error regression loss.\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :param weights: (Optional) sample weights\n    :returns: mean absolute error loss (best is 0.0).", "docstring_tokens": ["Mean", "absolute", "error", "regression", "loss", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/regression.py#L43-L53", "partition": "test", "index": 1360, "time": "2015-08-25 15:52:42"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/regression.py", "func_name": "h2o_explained_variance_score", "original_string": "def h2o_explained_variance_score(y_actual, y_predicted, weights=None):\n    \"\"\"\n    Explained variance regression score function.\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :param weights: (Optional) sample weights\n    :returns: the explained variance score.\n    \"\"\"\n    ModelBase._check_targets(y_actual, y_predicted)\n\n    _, numerator = _mean_var(y_actual - y_predicted, weights)\n    _, denominator = _mean_var(y_actual, weights)\n    if denominator == 0.0:\n        return 1. if numerator == 0 else 0.  # 0/0 => 1, otherwise, 0\n    return 1 - numerator / denominator", "language": "python", "code": "def h2o_explained_variance_score(y_actual, y_predicted, weights=None):\n    \"\"\"\n    Explained variance regression score function.\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :param weights: (Optional) sample weights\n    :returns: the explained variance score.\n    \"\"\"\n    ModelBase._check_targets(y_actual, y_predicted)\n\n    _, numerator = _mean_var(y_actual - y_predicted, weights)\n    _, denominator = _mean_var(y_actual, weights)\n    if denominator == 0.0:\n        return 1. if numerator == 0 else 0.  # 0/0 => 1, otherwise, 0\n    return 1 - numerator / denominator", "code_tokens": ["def", "h2o_explained_variance_score", "(", "y_actual", ",", "y_predicted", ",", "weights", "=", "None", ")", ":", "ModelBase", ".", "_check_targets", "(", "y_actual", ",", "y_predicted", ")", "_", ",", "numerator", "=", "_mean_var", "(", "y_actual", "-", "y_predicted", ",", "weights", ")", "_", ",", "denominator", "=", "_mean_var", "(", "y_actual", ",", "weights", ")", "if", "denominator", "==", "0.0", ":", "return", "1.", "if", "numerator", "==", "0", "else", "0.", "# 0/0 => 1, otherwise, 0", "return", "1", "-", "numerator", "/", "denominator"], "docstring": "Explained variance regression score function.\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :param weights: (Optional) sample weights\n    :returns: the explained variance score.", "docstring_tokens": ["Explained", "variance", "regression", "score", "function", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/regression.py#L81-L96", "partition": "test", "index": 1363, "time": "2015-08-25 15:52:42"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/regression.py", "func_name": "h2o_median_absolute_error", "original_string": "def h2o_median_absolute_error(y_actual, y_predicted):\n    \"\"\"\n    Median absolute error regression loss\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :returns: median absolute error loss (best is 0.0)\n    \"\"\"\n    ModelBase._check_targets(y_actual, y_predicted)\n    return (y_predicted - y_actual).abs().median()", "language": "python", "code": "def h2o_median_absolute_error(y_actual, y_predicted):\n    \"\"\"\n    Median absolute error regression loss\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :returns: median absolute error loss (best is 0.0)\n    \"\"\"\n    ModelBase._check_targets(y_actual, y_predicted)\n    return (y_predicted - y_actual).abs().median()", "code_tokens": ["def", "h2o_median_absolute_error", "(", "y_actual", ",", "y_predicted", ")", ":", "ModelBase", ".", "_check_targets", "(", "y_actual", ",", "y_predicted", ")", "return", "(", "y_predicted", "-", "y_actual", ")", ".", "abs", "(", ")", ".", "median", "(", ")"], "docstring": "Median absolute error regression loss\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :returns: median absolute error loss (best is 0.0)", "docstring_tokens": ["Median", "absolute", "error", "regression", "loss"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/regression.py#L69-L78", "partition": "test", "index": 1362, "time": "2015-08-25 15:52:42"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/regression.py", "func_name": "h2o_mean_squared_error", "original_string": "def h2o_mean_squared_error(y_actual, y_predicted, weights=None):\n    \"\"\"\n    Mean squared error regression loss\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :param weights: (Optional) sample weights\n    :returns: mean squared error loss (best is 0.0).\n    \"\"\"\n    ModelBase._check_targets(y_actual, y_predicted)\n    return _colmean((y_predicted - y_actual) ** 2)", "language": "python", "code": "def h2o_mean_squared_error(y_actual, y_predicted, weights=None):\n    \"\"\"\n    Mean squared error regression loss\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :param weights: (Optional) sample weights\n    :returns: mean squared error loss (best is 0.0).\n    \"\"\"\n    ModelBase._check_targets(y_actual, y_predicted)\n    return _colmean((y_predicted - y_actual) ** 2)", "code_tokens": ["def", "h2o_mean_squared_error", "(", "y_actual", ",", "y_predicted", ",", "weights", "=", "None", ")", ":", "ModelBase", ".", "_check_targets", "(", "y_actual", ",", "y_predicted", ")", "return", "_colmean", "(", "(", "y_predicted", "-", "y_actual", ")", "**", "2", ")"], "docstring": "Mean squared error regression loss\n\n    :param y_actual: H2OFrame of actual response.\n    :param y_predicted: H2OFrame of predicted response.\n    :param weights: (Optional) sample weights\n    :returns: mean squared error loss (best is 0.0).", "docstring_tokens": ["Mean", "squared", "error", "regression", "loss"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/regression.py#L56-L66", "partition": "test", "index": 1361, "time": "2015-08-25 15:52:42"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "download_all_logs", "original_string": "def download_all_logs(dirname=\".\", filename=None):\n    \"\"\"\n    Download H2O log files to disk.\n\n    :param dirname: a character string indicating the directory that the log file should be saved in.\n    :param filename: a string indicating the name that the CSV file should be. Note that the saved format is .zip, so the file name must include the .zip extension.\n\n    :returns: path of logs written in a zip file.\n\n    :examples: The following code will save the zip file `'autoh2o_log.zip'` in a directory that is one down from where you are currently working into a directory called `your_directory_name`. (Please note that `your_directory_name` should be replaced with the name of the directory that you've created and that already exists.)\n\n        >>> h2o.download_all_logs(dirname='./your_directory_name/', filename = 'autoh2o_log.zip')\n\n    \"\"\"\n    assert_is_type(dirname, str)\n    assert_is_type(filename, str, None)\n    url = \"%s/3/Logs/download\" % h2oconn.base_url\n    opener = urlopen()\n    response = opener(url)\n\n    if not os.path.exists(dirname): os.mkdir(dirname)\n    if filename is None:\n        if PY3:\n            headers = [h[1] for h in response.headers._headers]\n        else:\n            headers = response.headers.headers\n        for h in headers:\n            if \"filename=\" in h:\n                filename = h.split(\"filename=\")[1].strip()\n                break\n    path = os.path.join(dirname, filename)\n    response = opener(url).read()\n\n    print(\"Writing H2O logs to \" + path)\n    with open(path, \"wb\") as f:\n        f.write(response)\n    return path", "language": "python", "code": "def download_all_logs(dirname=\".\", filename=None):\n    \"\"\"\n    Download H2O log files to disk.\n\n    :param dirname: a character string indicating the directory that the log file should be saved in.\n    :param filename: a string indicating the name that the CSV file should be. Note that the saved format is .zip, so the file name must include the .zip extension.\n\n    :returns: path of logs written in a zip file.\n\n    :examples: The following code will save the zip file `'autoh2o_log.zip'` in a directory that is one down from where you are currently working into a directory called `your_directory_name`. (Please note that `your_directory_name` should be replaced with the name of the directory that you've created and that already exists.)\n\n        >>> h2o.download_all_logs(dirname='./your_directory_name/', filename = 'autoh2o_log.zip')\n\n    \"\"\"\n    assert_is_type(dirname, str)\n    assert_is_type(filename, str, None)\n    url = \"%s/3/Logs/download\" % h2oconn.base_url\n    opener = urlopen()\n    response = opener(url)\n\n    if not os.path.exists(dirname): os.mkdir(dirname)\n    if filename is None:\n        if PY3:\n            headers = [h[1] for h in response.headers._headers]\n        else:\n            headers = response.headers.headers\n        for h in headers:\n            if \"filename=\" in h:\n                filename = h.split(\"filename=\")[1].strip()\n                break\n    path = os.path.join(dirname, filename)\n    response = opener(url).read()\n\n    print(\"Writing H2O logs to \" + path)\n    with open(path, \"wb\") as f:\n        f.write(response)\n    return path", "code_tokens": ["def", "download_all_logs", "(", "dirname", "=", "\".\"", ",", "filename", "=", "None", ")", ":", "assert_is_type", "(", "dirname", ",", "str", ")", "assert_is_type", "(", "filename", ",", "str", ",", "None", ")", "url", "=", "\"%s/3/Logs/download\"", "%", "h2oconn", ".", "base_url", "opener", "=", "urlopen", "(", ")", "response", "=", "opener", "(", "url", ")", "if", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "os", ".", "mkdir", "(", "dirname", ")", "if", "filename", "is", "None", ":", "if", "PY3", ":", "headers", "=", "[", "h", "[", "1", "]", "for", "h", "in", "response", ".", "headers", ".", "_headers", "]", "else", ":", "headers", "=", "response", ".", "headers", ".", "headers", "for", "h", "in", "headers", ":", "if", "\"filename=\"", "in", "h", ":", "filename", "=", "h", ".", "split", "(", "\"filename=\"", ")", "[", "1", "]", ".", "strip", "(", ")", "break", "path", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "filename", ")", "response", "=", "opener", "(", "url", ")", ".", "read", "(", ")", "print", "(", "\"Writing H2O logs to \"", "+", "path", ")", "with", "open", "(", "path", ",", "\"wb\"", ")", "as", "f", ":", "f", ".", "write", "(", "response", ")", "return", "path"], "docstring": "Download H2O log files to disk.\n\n    :param dirname: a character string indicating the directory that the log file should be saved in.\n    :param filename: a string indicating the name that the CSV file should be. Note that the saved format is .zip, so the file name must include the .zip extension.\n\n    :returns: path of logs written in a zip file.\n\n    :examples: The following code will save the zip file `'autoh2o_log.zip'` in a directory that is one down from where you are currently working into a directory called `your_directory_name`. (Please note that `your_directory_name` should be replaced with the name of the directory that you've created and that already exists.)\n\n        >>> h2o.download_all_logs(dirname='./your_directory_name/', filename = 'autoh2o_log.zip')", "docstring_tokens": ["Download", "H2O", "log", "files", "to", "disk", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L1026-L1062", "partition": "test", "index": 1468, "time": "2015-09-04 15:50:27"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "upload_file", "original_string": "def upload_file(path, destination_frame=None, header=0, sep=None, col_names=None, col_types=None,\n                na_strings=None, skipped_columns=None):\n    \"\"\"\n    Upload a dataset from the provided local path to the H2O cluster.\n\n    Does a single-threaded push to H2O. Also see :meth:`import_file`.\n\n    :param path: A path specifying the location of the data to upload.\n    :param destination_frame:  The unique hex key assigned to the imported file. If none is given, a key will\n        be automatically generated.\n    :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n    :param sep: The field separator character. Values on each line of the file are separated by\n        this character. If not provided, the parser will automatically detect the separator.\n    :param col_names: A list of column names for the file.\n    :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n        should be forced to a certain type upon import parsing. If a list, the types for elements that are\n        one will be guessed. The possible types a column may have are:\n\n        - \"unknown\" - this will force the column to be parsed as all NA\n        - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n        - \"string\"  - force the column to be parsed as a string\n        - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n          data in the optimal manner.\n        - \"enum\"    - force the column to be parsed as a categorical column.\n        - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n          list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n          \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n          Times can also contain \"AM\" or \"PM\".\n    :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n        of column names to strings which are to be interpreted as missing values.\n    :param skipped_columns: an integer lists of column indices to skip and not parsed into the final frame from the import file.\n\n    :returns: a new :class:`H2OFrame` instance.\n\n    :examples:\n        >>> frame = h2o.upload_file(\"/path/to/local/data\")\n    \"\"\"\n    coltype = U(None, \"unknown\", \"uuid\", \"string\", \"float\", \"real\", \"double\", \"int\", \"numeric\",\n                \"categorical\", \"factor\", \"enum\", \"time\")\n    natype = U(str, [str])\n    assert_is_type(path, str)\n    assert_is_type(destination_frame, str, None)\n    assert_is_type(header, -1, 0, 1)\n    assert_is_type(sep, None, I(str, lambda s: len(s) == 1))\n    assert_is_type(col_names, [str], None)\n    assert_is_type(col_types, [coltype], {str: coltype}, None)\n    assert_is_type(na_strings, [natype], {str: natype}, None)\n    assert (skipped_columns==None) or isinstance(skipped_columns, list), \\\n        \"The skipped_columns should be an list of column names!\"\n\n    check_frame_id(destination_frame)\n    if path.startswith(\"~\"):\n        path = os.path.expanduser(path)\n    return H2OFrame()._upload_parse(path, destination_frame, header, sep, col_names, col_types, na_strings, skipped_columns)", "language": "python", "code": "def upload_file(path, destination_frame=None, header=0, sep=None, col_names=None, col_types=None,\n                na_strings=None, skipped_columns=None):\n    \"\"\"\n    Upload a dataset from the provided local path to the H2O cluster.\n\n    Does a single-threaded push to H2O. Also see :meth:`import_file`.\n\n    :param path: A path specifying the location of the data to upload.\n    :param destination_frame:  The unique hex key assigned to the imported file. If none is given, a key will\n        be automatically generated.\n    :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n    :param sep: The field separator character. Values on each line of the file are separated by\n        this character. If not provided, the parser will automatically detect the separator.\n    :param col_names: A list of column names for the file.\n    :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n        should be forced to a certain type upon import parsing. If a list, the types for elements that are\n        one will be guessed. The possible types a column may have are:\n\n        - \"unknown\" - this will force the column to be parsed as all NA\n        - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n        - \"string\"  - force the column to be parsed as a string\n        - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n          data in the optimal manner.\n        - \"enum\"    - force the column to be parsed as a categorical column.\n        - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n          list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n          \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n          Times can also contain \"AM\" or \"PM\".\n    :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n        of column names to strings which are to be interpreted as missing values.\n    :param skipped_columns: an integer lists of column indices to skip and not parsed into the final frame from the import file.\n\n    :returns: a new :class:`H2OFrame` instance.\n\n    :examples:\n        >>> frame = h2o.upload_file(\"/path/to/local/data\")\n    \"\"\"\n    coltype = U(None, \"unknown\", \"uuid\", \"string\", \"float\", \"real\", \"double\", \"int\", \"numeric\",\n                \"categorical\", \"factor\", \"enum\", \"time\")\n    natype = U(str, [str])\n    assert_is_type(path, str)\n    assert_is_type(destination_frame, str, None)\n    assert_is_type(header, -1, 0, 1)\n    assert_is_type(sep, None, I(str, lambda s: len(s) == 1))\n    assert_is_type(col_names, [str], None)\n    assert_is_type(col_types, [coltype], {str: coltype}, None)\n    assert_is_type(na_strings, [natype], {str: natype}, None)\n    assert (skipped_columns==None) or isinstance(skipped_columns, list), \\\n        \"The skipped_columns should be an list of column names!\"\n\n    check_frame_id(destination_frame)\n    if path.startswith(\"~\"):\n        path = os.path.expanduser(path)\n    return H2OFrame()._upload_parse(path, destination_frame, header, sep, col_names, col_types, na_strings, skipped_columns)", "code_tokens": ["def", "upload_file", "(", "path", ",", "destination_frame", "=", "None", ",", "header", "=", "0", ",", "sep", "=", "None", ",", "col_names", "=", "None", ",", "col_types", "=", "None", ",", "na_strings", "=", "None", ",", "skipped_columns", "=", "None", ")", ":", "coltype", "=", "U", "(", "None", ",", "\"unknown\"", ",", "\"uuid\"", ",", "\"string\"", ",", "\"float\"", ",", "\"real\"", ",", "\"double\"", ",", "\"int\"", ",", "\"numeric\"", ",", "\"categorical\"", ",", "\"factor\"", ",", "\"enum\"", ",", "\"time\"", ")", "natype", "=", "U", "(", "str", ",", "[", "str", "]", ")", "assert_is_type", "(", "path", ",", "str", ")", "assert_is_type", "(", "destination_frame", ",", "str", ",", "None", ")", "assert_is_type", "(", "header", ",", "-", "1", ",", "0", ",", "1", ")", "assert_is_type", "(", "sep", ",", "None", ",", "I", "(", "str", ",", "lambda", "s", ":", "len", "(", "s", ")", "==", "1", ")", ")", "assert_is_type", "(", "col_names", ",", "[", "str", "]", ",", "None", ")", "assert_is_type", "(", "col_types", ",", "[", "coltype", "]", ",", "{", "str", ":", "coltype", "}", ",", "None", ")", "assert_is_type", "(", "na_strings", ",", "[", "natype", "]", ",", "{", "str", ":", "natype", "}", ",", "None", ")", "assert", "(", "skipped_columns", "==", "None", ")", "or", "isinstance", "(", "skipped_columns", ",", "list", ")", ",", "\"The skipped_columns should be an list of column names!\"", "check_frame_id", "(", "destination_frame", ")", "if", "path", ".", "startswith", "(", "\"~\"", ")", ":", "path", "=", "os", ".", "path", ".", "expanduser", "(", "path", ")", "return", "H2OFrame", "(", ")", ".", "_upload_parse", "(", "path", ",", "destination_frame", ",", "header", ",", "sep", ",", "col_names", ",", "col_types", ",", "na_strings", ",", "skipped_columns", ")"], "docstring": "Upload a dataset from the provided local path to the H2O cluster.\n\n    Does a single-threaded push to H2O. Also see :meth:`import_file`.\n\n    :param path: A path specifying the location of the data to upload.\n    :param destination_frame:  The unique hex key assigned to the imported file. If none is given, a key will\n        be automatically generated.\n    :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n    :param sep: The field separator character. Values on each line of the file are separated by\n        this character. If not provided, the parser will automatically detect the separator.\n    :param col_names: A list of column names for the file.\n    :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n        should be forced to a certain type upon import parsing. If a list, the types for elements that are\n        one will be guessed. The possible types a column may have are:\n\n        - \"unknown\" - this will force the column to be parsed as all NA\n        - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n        - \"string\"  - force the column to be parsed as a string\n        - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n          data in the optimal manner.\n        - \"enum\"    - force the column to be parsed as a categorical column.\n        - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n          list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n          \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n          Times can also contain \"AM\" or \"PM\".\n    :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n        of column names to strings which are to be interpreted as missing values.\n    :param skipped_columns: an integer lists of column indices to skip and not parsed into the final frame from the import file.\n\n    :returns: a new :class:`H2OFrame` instance.\n\n    :examples:\n        >>> frame = h2o.upload_file(\"/path/to/local/data\")", "docstring_tokens": ["Upload", "a", "dataset", "from", "the", "provided", "local", "path", "to", "the", "H2O", "cluster", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L310-L363", "partition": "test", "index": 1456, "time": "2015-10-12 16:50:41"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "import_sql_select", "original_string": "def import_sql_select(connection_url, select_query, username, password, optimize=True, \n                      use_temp_table=None, temp_table_name=None, fetch_mode=None):\n    \"\"\"\n    Import the SQL table that is the result of the specified SQL query to H2OFrame in memory.\n\n    Creates a temporary SQL table from the specified sql_query.\n    Runs multiple SELECT SQL queries on the temporary table concurrently for parallel ingestion, then drops the table.\n    Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n\n      java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n\n    Also see h2o.import_sql_table. Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, Hive, Oracle \n    and Microsoft SQL Server.\n\n    :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n        Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n    :param select_query: SQL query starting with `SELECT` that returns rows from one or more database tables.\n    :param username: username for SQL server\n    :param password: password for SQL server\n    :param optimize: DEPRECATED. Ignored - use fetch_mode instead. Optimize import of SQL table for faster imports.\n    :param use_temp_table: whether a temporary table should be created from select_query\n    :param temp_table_name: name of temporary table to be created from select_query\n    :param fetch_mode: Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read by a single node\n        from the database.\n\n    :returns: an :class:`H2OFrame` containing data of the specified SQL query.\n\n    :examples:\n        >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n        >>> select_query = \"SELECT bikeid from citibike20k\"\n        >>> username = \"root\"\n        >>> password = \"abc123\"\n        >>> my_citibike_data = h2o.import_sql_select(conn_url, select_query,\n        ...                                          username, password, fetch_mode)\n    \"\"\"\n    assert_is_type(connection_url, str)\n    assert_is_type(select_query, str)\n    assert_is_type(username, str)\n    assert_is_type(password, str)\n    assert_is_type(optimize, bool)\n    assert_is_type(use_temp_table, bool, None)\n    assert_is_type(temp_table_name, str, None)\n    assert_is_type(fetch_mode, str, None)\n    p = {\"connection_url\": connection_url, \"select_query\": select_query, \"username\": username, \"password\": password,\n         \"use_temp_table\": use_temp_table, \"temp_table_name\": temp_table_name, \"fetch_mode\": fetch_mode}\n    j = H2OJob(api(\"POST /99/ImportSQLTable\", data=p), \"Import SQL Table\").poll()\n    return get_frame(j.dest_key)", "language": "python", "code": "def import_sql_select(connection_url, select_query, username, password, optimize=True, \n                      use_temp_table=None, temp_table_name=None, fetch_mode=None):\n    \"\"\"\n    Import the SQL table that is the result of the specified SQL query to H2OFrame in memory.\n\n    Creates a temporary SQL table from the specified sql_query.\n    Runs multiple SELECT SQL queries on the temporary table concurrently for parallel ingestion, then drops the table.\n    Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n\n      java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n\n    Also see h2o.import_sql_table. Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, Hive, Oracle \n    and Microsoft SQL Server.\n\n    :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n        Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n    :param select_query: SQL query starting with `SELECT` that returns rows from one or more database tables.\n    :param username: username for SQL server\n    :param password: password for SQL server\n    :param optimize: DEPRECATED. Ignored - use fetch_mode instead. Optimize import of SQL table for faster imports.\n    :param use_temp_table: whether a temporary table should be created from select_query\n    :param temp_table_name: name of temporary table to be created from select_query\n    :param fetch_mode: Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read by a single node\n        from the database.\n\n    :returns: an :class:`H2OFrame` containing data of the specified SQL query.\n\n    :examples:\n        >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n        >>> select_query = \"SELECT bikeid from citibike20k\"\n        >>> username = \"root\"\n        >>> password = \"abc123\"\n        >>> my_citibike_data = h2o.import_sql_select(conn_url, select_query,\n        ...                                          username, password, fetch_mode)\n    \"\"\"\n    assert_is_type(connection_url, str)\n    assert_is_type(select_query, str)\n    assert_is_type(username, str)\n    assert_is_type(password, str)\n    assert_is_type(optimize, bool)\n    assert_is_type(use_temp_table, bool, None)\n    assert_is_type(temp_table_name, str, None)\n    assert_is_type(fetch_mode, str, None)\n    p = {\"connection_url\": connection_url, \"select_query\": select_query, \"username\": username, \"password\": password,\n         \"use_temp_table\": use_temp_table, \"temp_table_name\": temp_table_name, \"fetch_mode\": fetch_mode}\n    j = H2OJob(api(\"POST /99/ImportSQLTable\", data=p), \"Import SQL Table\").poll()\n    return get_frame(j.dest_key)", "code_tokens": ["def", "import_sql_select", "(", "connection_url", ",", "select_query", ",", "username", ",", "password", ",", "optimize", "=", "True", ",", "use_temp_table", "=", "None", ",", "temp_table_name", "=", "None", ",", "fetch_mode", "=", "None", ")", ":", "assert_is_type", "(", "connection_url", ",", "str", ")", "assert_is_type", "(", "select_query", ",", "str", ")", "assert_is_type", "(", "username", ",", "str", ")", "assert_is_type", "(", "password", ",", "str", ")", "assert_is_type", "(", "optimize", ",", "bool", ")", "assert_is_type", "(", "use_temp_table", ",", "bool", ",", "None", ")", "assert_is_type", "(", "temp_table_name", ",", "str", ",", "None", ")", "assert_is_type", "(", "fetch_mode", ",", "str", ",", "None", ")", "p", "=", "{", "\"connection_url\"", ":", "connection_url", ",", "\"select_query\"", ":", "select_query", ",", "\"username\"", ":", "username", ",", "\"password\"", ":", "password", ",", "\"use_temp_table\"", ":", "use_temp_table", ",", "\"temp_table_name\"", ":", "temp_table_name", ",", "\"fetch_mode\"", ":", "fetch_mode", "}", "j", "=", "H2OJob", "(", "api", "(", "\"POST /99/ImportSQLTable\"", ",", "data", "=", "p", ")", ",", "\"Import SQL Table\"", ")", ".", "poll", "(", ")", "return", "get_frame", "(", "j", ".", "dest_key", ")"], "docstring": "Import the SQL table that is the result of the specified SQL query to H2OFrame in memory.\n\n    Creates a temporary SQL table from the specified sql_query.\n    Runs multiple SELECT SQL queries on the temporary table concurrently for parallel ingestion, then drops the table.\n    Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n\n      java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n\n    Also see h2o.import_sql_table. Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, Hive, Oracle \n    and Microsoft SQL Server.\n\n    :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n        Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n    :param select_query: SQL query starting with `SELECT` that returns rows from one or more database tables.\n    :param username: username for SQL server\n    :param password: password for SQL server\n    :param optimize: DEPRECATED. Ignored - use fetch_mode instead. Optimize import of SQL table for faster imports.\n    :param use_temp_table: whether a temporary table should be created from select_query\n    :param temp_table_name: name of temporary table to be created from select_query\n    :param fetch_mode: Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read by a single node\n        from the database.\n\n    :returns: an :class:`H2OFrame` containing data of the specified SQL query.\n\n    :examples:\n        >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n        >>> select_query = \"SELECT bikeid from citibike20k\"\n        >>> username = \"root\"\n        >>> password = \"abc123\"\n        >>> my_citibike_data = h2o.import_sql_select(conn_url, select_query,\n        ...                                          username, password, fetch_mode)", "docstring_tokens": ["Import", "the", "SQL", "table", "that", "is", "the", "result", "of", "the", "specified", "SQL", "query", "to", "H2OFrame", "in", "memory", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L511-L557", "partition": "test", "index": 1460, "time": "2015-10-12 16:50:41"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "get_frame", "original_string": "def get_frame(frame_id, **kwargs):\n    \"\"\"\n    Obtain a handle to the frame in H2O with the frame_id key.\n\n    :param str frame_id: id of the frame to retrieve.\n    :returns: an :class:`H2OFrame` object\n    \"\"\"\n    assert_is_type(frame_id, str)\n    return H2OFrame.get_frame(frame_id, **kwargs)", "language": "python", "code": "def get_frame(frame_id, **kwargs):\n    \"\"\"\n    Obtain a handle to the frame in H2O with the frame_id key.\n\n    :param str frame_id: id of the frame to retrieve.\n    :returns: an :class:`H2OFrame` object\n    \"\"\"\n    assert_is_type(frame_id, str)\n    return H2OFrame.get_frame(frame_id, **kwargs)", "code_tokens": ["def", "get_frame", "(", "frame_id", ",", "*", "*", "kwargs", ")", ":", "assert_is_type", "(", "frame_id", ",", "str", ")", "return", "H2OFrame", ".", "get_frame", "(", "frame_id", ",", "*", "*", "kwargs", ")"], "docstring": "Obtain a handle to the frame in H2O with the frame_id key.\n\n    :param str frame_id: id of the frame to retrieve.\n    :returns: an :class:`H2OFrame` object", "docstring_tokens": ["Obtain", "a", "handle", "to", "the", "frame", "in", "H2O", "with", "the", "frame_id", "key", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L858-L866", "partition": "test", "index": 1465, "time": "2015-11-02 13:05:01"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/dim_reduction.py", "func_name": "H2ODimReductionModel.proj_archetypes", "original_string": "def proj_archetypes(self, test_data, reverse_transform=False):\n        \"\"\"\n        Convert archetypes of the model into original feature space.\n\n        :param H2OFrame test_data: The dataset upon which the model was trained.\n        :param bool reverse_transform: Whether the transformation of the training data during model-building\n            should be reversed on the projected archetypes.\n\n        :returns: model archetypes projected back into the original training data's feature space.\n        \"\"\"\n        if test_data is None or test_data.nrow == 0: raise ValueError(\"Must specify test data\")\n        j = h2o.api(\"POST /3/Predictions/models/%s/frames/%s\" % (self.model_id, test_data.frame_id),\n                    data={\"project_archetypes\": True, \"reverse_transform\": reverse_transform})\n        return h2o.get_frame(j[\"model_metrics\"][0][\"predictions\"][\"frame_id\"][\"name\"])", "language": "python", "code": "def proj_archetypes(self, test_data, reverse_transform=False):\n        \"\"\"\n        Convert archetypes of the model into original feature space.\n\n        :param H2OFrame test_data: The dataset upon which the model was trained.\n        :param bool reverse_transform: Whether the transformation of the training data during model-building\n            should be reversed on the projected archetypes.\n\n        :returns: model archetypes projected back into the original training data's feature space.\n        \"\"\"\n        if test_data is None or test_data.nrow == 0: raise ValueError(\"Must specify test data\")\n        j = h2o.api(\"POST /3/Predictions/models/%s/frames/%s\" % (self.model_id, test_data.frame_id),\n                    data={\"project_archetypes\": True, \"reverse_transform\": reverse_transform})\n        return h2o.get_frame(j[\"model_metrics\"][0][\"predictions\"][\"frame_id\"][\"name\"])", "code_tokens": ["def", "proj_archetypes", "(", "self", ",", "test_data", ",", "reverse_transform", "=", "False", ")", ":", "if", "test_data", "is", "None", "or", "test_data", ".", "nrow", "==", "0", ":", "raise", "ValueError", "(", "\"Must specify test data\"", ")", "j", "=", "h2o", ".", "api", "(", "\"POST /3/Predictions/models/%s/frames/%s\"", "%", "(", "self", ".", "model_id", ",", "test_data", ".", "frame_id", ")", ",", "data", "=", "{", "\"project_archetypes\"", ":", "True", ",", "\"reverse_transform\"", ":", "reverse_transform", "}", ")", "return", "h2o", ".", "get_frame", "(", "j", "[", "\"model_metrics\"", "]", "[", "0", "]", "[", "\"predictions\"", "]", "[", "\"frame_id\"", "]", "[", "\"name\"", "]", ")"], "docstring": "Convert archetypes of the model into original feature space.\n\n        :param H2OFrame test_data: The dataset upon which the model was trained.\n        :param bool reverse_transform: Whether the transformation of the training data during model-building\n            should be reversed on the projected archetypes.\n\n        :returns: model archetypes projected back into the original training data's feature space.", "docstring_tokens": ["Convert", "archetypes", "of", "the", "model", "into", "original", "feature", "space", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/dim_reduction.py#L79-L92", "partition": "test", "index": 1492, "time": "2015-11-17 18:26:30"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "update_summary_file", "original_string": "def update_summary_file():\n    \"\"\"\n    Concatecate all log file into a summary text file to be sent to users\n    at the end of a daily log scraping.\n\n    :return: none\n    \"\"\"\n    global g_summary_text_filename\n    global g_output_filename_failed_tests\n    global g_output_filename_passed_tests\n\n    with open(g_summary_text_filename,'a') as tempfile:\n        write_file_content(tempfile,g_output_filename_failed_tests)\n        write_file_content(tempfile,g_output_filename_passed_tests)", "language": "python", "code": "def update_summary_file():\n    \"\"\"\n    Concatecate all log file into a summary text file to be sent to users\n    at the end of a daily log scraping.\n\n    :return: none\n    \"\"\"\n    global g_summary_text_filename\n    global g_output_filename_failed_tests\n    global g_output_filename_passed_tests\n\n    with open(g_summary_text_filename,'a') as tempfile:\n        write_file_content(tempfile,g_output_filename_failed_tests)\n        write_file_content(tempfile,g_output_filename_passed_tests)", "code_tokens": ["def", "update_summary_file", "(", ")", ":", "global", "g_summary_text_filename", "global", "g_output_filename_failed_tests", "global", "g_output_filename_passed_tests", "with", "open", "(", "g_summary_text_filename", ",", "'a'", ")", "as", "tempfile", ":", "write_file_content", "(", "tempfile", ",", "g_output_filename_failed_tests", ")", "write_file_content", "(", "tempfile", ",", "g_output_filename_passed_tests", ")"], "docstring": "Concatecate all log file into a summary text file to be sent to users\n    at the end of a daily log scraping.\n\n    :return: none", "docstring_tokens": ["Concatecate", "all", "log", "file", "into", "a", "summary", "text", "file", "to", "be", "sent", "to", "users", "at", "the", "end", "of", "a", "daily", "log", "scraping", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L845-L858", "partition": "test", "index": 1523, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "extract_true_string", "original_string": "def extract_true_string(string_content):\n    \"\"\"\n    remove extra characters before the actual string we are\n    looking for.  The Jenkins console output is encoded using utf-8.  However, the stupid\n    redirect function can only encode using ASCII.  I have googled for half a day with no\n    results to how to resolve the issue.  Hence, we are going to the heat and just manually\n    get rid of the junk.\n\n    Parameters\n    ----------\n\n    string_content :  str\n        contains a line read in from jenkins console\n\n    :return: str: contains the content of the line after the string '[0m'\n\n    \"\"\"\n\n    startL,found,endL = string_content.partition('[0m')\n\n    if found:\n        return endL\n    else:\n        return string_content", "language": "python", "code": "def extract_true_string(string_content):\n    \"\"\"\n    remove extra characters before the actual string we are\n    looking for.  The Jenkins console output is encoded using utf-8.  However, the stupid\n    redirect function can only encode using ASCII.  I have googled for half a day with no\n    results to how to resolve the issue.  Hence, we are going to the heat and just manually\n    get rid of the junk.\n\n    Parameters\n    ----------\n\n    string_content :  str\n        contains a line read in from jenkins console\n\n    :return: str: contains the content of the line after the string '[0m'\n\n    \"\"\"\n\n    startL,found,endL = string_content.partition('[0m')\n\n    if found:\n        return endL\n    else:\n        return string_content", "code_tokens": ["def", "extract_true_string", "(", "string_content", ")", ":", "startL", ",", "found", ",", "endL", "=", "string_content", ".", "partition", "(", "'[0m'", ")", "if", "found", ":", "return", "endL", "else", ":", "return", "string_content"], "docstring": "remove extra characters before the actual string we are\n    looking for.  The Jenkins console output is encoded using utf-8.  However, the stupid\n    redirect function can only encode using ASCII.  I have googled for half a day with no\n    results to how to resolve the issue.  Hence, we are going to the heat and just manually\n    get rid of the junk.\n\n    Parameters\n    ----------\n\n    string_content :  str\n        contains a line read in from jenkins console\n\n    :return: str: contains the content of the line after the string '[0m'", "docstring_tokens": ["remove", "extra", "characters", "before", "the", "actual", "string", "we", "are", "looking", "for", ".", "The", "Jenkins", "console", "output", "is", "encoded", "using", "utf", "-", "8", ".", "However", "the", "stupid", "redirect", "function", "can", "only", "encode", "using", "ASCII", ".", "I", "have", "googled", "for", "half", "a", "day", "with", "no", "results", "to", "how", "to", "resolve", "the", "issue", ".", "Hence", "we", "are", "going", "to", "the", "heat", "and", "just", "manually", "get", "rid", "of", "the", "junk", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L118-L141", "partition": "test", "index": 1514, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "find_node_name", "original_string": "def find_node_name(each_line,temp_func_list):\n    \"\"\"\n    Find the slave machine where a Jenkins job was executed on.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will\n    delete this particular function handle off the temp_func_list as we do not need\n    to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text\n    \"\"\"\n    global g_node_name\n    global g_failed_test_info_dict\n\n    if g_node_name in each_line:\n        temp_strings = each_line.split()\n        [start,found,endstr] = each_line.partition(g_node_name)\n\n        if found:\n            temp_strings = endstr.split()\n            g_failed_test_info_dict[\"6.node_name\"] = extract_true_string(temp_strings[1])\n            temp_func_list.remove(find_node_name)\n\n    return True", "language": "python", "code": "def find_node_name(each_line,temp_func_list):\n    \"\"\"\n    Find the slave machine where a Jenkins job was executed on.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will\n    delete this particular function handle off the temp_func_list as we do not need\n    to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text\n    \"\"\"\n    global g_node_name\n    global g_failed_test_info_dict\n\n    if g_node_name in each_line:\n        temp_strings = each_line.split()\n        [start,found,endstr] = each_line.partition(g_node_name)\n\n        if found:\n            temp_strings = endstr.split()\n            g_failed_test_info_dict[\"6.node_name\"] = extract_true_string(temp_strings[1])\n            temp_func_list.remove(find_node_name)\n\n    return True", "code_tokens": ["def", "find_node_name", "(", "each_line", ",", "temp_func_list", ")", ":", "global", "g_node_name", "global", "g_failed_test_info_dict", "if", "g_node_name", "in", "each_line", ":", "temp_strings", "=", "each_line", ".", "split", "(", ")", "[", "start", ",", "found", ",", "endstr", "]", "=", "each_line", ".", "partition", "(", "g_node_name", ")", "if", "found", ":", "temp_strings", "=", "endstr", ".", "split", "(", ")", "g_failed_test_info_dict", "[", "\"6.node_name\"", "]", "=", "extract_true_string", "(", "temp_strings", "[", "1", "]", ")", "temp_func_list", ".", "remove", "(", "find_node_name", ")", "return", "True"], "docstring": "Find the slave machine where a Jenkins job was executed on.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will\n    delete this particular function handle off the temp_func_list as we do not need\n    to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text", "docstring_tokens": ["Find", "the", "slave", "machine", "where", "a", "Jenkins", "job", "was", "executed", "on", ".", "It", "will", "save", "this", "information", "in", "g_failed_test_info_dict", ".", "In", "addition", "it", "will", "delete", "this", "particular", "function", "handle", "off", "the", "temp_func_list", "as", "we", "do", "not", "need", "to", "perform", "this", "action", "again", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L178-L208", "partition": "test", "index": 1515, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "find_git_hash_branch", "original_string": "def find_git_hash_branch(each_line,temp_func_list):\n    \"\"\"\n    Find the git hash and branch info that  a Jenkins job was taken from.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will delete this particular\n    function handle off the temp_func_list as we do not need to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text\n    \"\"\"\n    global g_git_hash_branch\n    global g_failed_test_info_dict\n\n    if g_git_hash_branch in each_line:\n        [start,found,endstr] = each_line.partition(g_git_hash_branch)\n        temp_strings = endstr.strip().split()\n\n        if len(temp_strings) > 1:\n            g_failed_test_info_dict[\"4.git_hash\"] = temp_strings[0]\n            g_failed_test_info_dict[\"5.git_branch\"] = temp_strings[1]\n\n        temp_func_list.remove(find_git_hash_branch)\n\n    return True", "language": "python", "code": "def find_git_hash_branch(each_line,temp_func_list):\n    \"\"\"\n    Find the git hash and branch info that  a Jenkins job was taken from.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will delete this particular\n    function handle off the temp_func_list as we do not need to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text\n    \"\"\"\n    global g_git_hash_branch\n    global g_failed_test_info_dict\n\n    if g_git_hash_branch in each_line:\n        [start,found,endstr] = each_line.partition(g_git_hash_branch)\n        temp_strings = endstr.strip().split()\n\n        if len(temp_strings) > 1:\n            g_failed_test_info_dict[\"4.git_hash\"] = temp_strings[0]\n            g_failed_test_info_dict[\"5.git_branch\"] = temp_strings[1]\n\n        temp_func_list.remove(find_git_hash_branch)\n\n    return True", "code_tokens": ["def", "find_git_hash_branch", "(", "each_line", ",", "temp_func_list", ")", ":", "global", "g_git_hash_branch", "global", "g_failed_test_info_dict", "if", "g_git_hash_branch", "in", "each_line", ":", "[", "start", ",", "found", ",", "endstr", "]", "=", "each_line", ".", "partition", "(", "g_git_hash_branch", ")", "temp_strings", "=", "endstr", ".", "strip", "(", ")", ".", "split", "(", ")", "if", "len", "(", "temp_strings", ")", ">", "1", ":", "g_failed_test_info_dict", "[", "\"4.git_hash\"", "]", "=", "temp_strings", "[", "0", "]", "g_failed_test_info_dict", "[", "\"5.git_branch\"", "]", "=", "temp_strings", "[", "1", "]", "temp_func_list", ".", "remove", "(", "find_git_hash_branch", ")", "return", "True"], "docstring": "Find the git hash and branch info that  a Jenkins job was taken from.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will delete this particular\n    function handle off the temp_func_list as we do not need to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text", "docstring_tokens": ["Find", "the", "git", "hash", "and", "branch", "info", "that", "a", "Jenkins", "job", "was", "taken", "from", ".", "It", "will", "save", "this", "information", "in", "g_failed_test_info_dict", ".", "In", "addition", "it", "will", "delete", "this", "particular", "function", "handle", "off", "the", "temp_func_list", "as", "we", "do", "not", "need", "to", "perform", "this", "action", "again", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L211-L241", "partition": "test", "index": 1516, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "find_build_timeout", "original_string": "def find_build_timeout(each_line,temp_func_list):\n    \"\"\"\n    Find if a Jenkins job has taken too long to finish and was killed.  It will save this\n    information in g_failed_test_info_dict.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text\n\"\"\"\n    global g_build_timeout\n    global g_failed_test_info_dict\n    global g_failure_occurred\n\n    if g_build_timeout in each_line:\n        g_failed_test_info_dict[\"8.build_timeout\"] = 'Yes'\n        g_failure_occurred = True\n        return False    # build timeout was found, no need to continue mining the console text\n    else:\n        return True", "language": "python", "code": "def find_build_timeout(each_line,temp_func_list):\n    \"\"\"\n    Find if a Jenkins job has taken too long to finish and was killed.  It will save this\n    information in g_failed_test_info_dict.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text\n\"\"\"\n    global g_build_timeout\n    global g_failed_test_info_dict\n    global g_failure_occurred\n\n    if g_build_timeout in each_line:\n        g_failed_test_info_dict[\"8.build_timeout\"] = 'Yes'\n        g_failure_occurred = True\n        return False    # build timeout was found, no need to continue mining the console text\n    else:\n        return True", "code_tokens": ["def", "find_build_timeout", "(", "each_line", ",", "temp_func_list", ")", ":", "global", "g_build_timeout", "global", "g_failed_test_info_dict", "global", "g_failure_occurred", "if", "g_build_timeout", "in", "each_line", ":", "g_failed_test_info_dict", "[", "\"8.build_timeout\"", "]", "=", "'Yes'", "g_failure_occurred", "=", "True", "return", "False", "# build timeout was found, no need to continue mining the console text", "else", ":", "return", "True"], "docstring": "Find if a Jenkins job has taken too long to finish and was killed.  It will save this\n    information in g_failed_test_info_dict.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text", "docstring_tokens": ["Find", "if", "a", "Jenkins", "job", "has", "taken", "too", "long", "to", "finish", "and", "was", "killed", ".", "It", "will", "save", "this", "information", "in", "g_failed_test_info_dict", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L244-L269", "partition": "test", "index": 1517, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "find_build_failure", "original_string": "def find_build_failure(each_line,temp_func_list):\n    \"\"\"\n    Find if a Jenkins job has failed to build.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will delete this particular\n    function handle off the temp_func_list as we do not need to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text\n    \"\"\"\n    global g_build_success\n    global g_build_success_tests\n    global g_failed_test_info_dict\n    global g_failure_occurred\n    global g_build_failed_message\n\n    for ind in range(0,len(g_build_failed_message)):\n        if g_build_failed_message[ind] in each_line.lower():\n            if ((ind == 0) and (len(g_failed_jobs) > 0)):\n                continue\n            else:\n                g_failure_occurred = True\n                g_failed_test_info_dict[\"7.build_failure\"] = 'Yes'\n                temp_func_list.remove(find_build_failure)\n                return False\n\n    return True", "language": "python", "code": "def find_build_failure(each_line,temp_func_list):\n    \"\"\"\n    Find if a Jenkins job has failed to build.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will delete this particular\n    function handle off the temp_func_list as we do not need to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text\n    \"\"\"\n    global g_build_success\n    global g_build_success_tests\n    global g_failed_test_info_dict\n    global g_failure_occurred\n    global g_build_failed_message\n\n    for ind in range(0,len(g_build_failed_message)):\n        if g_build_failed_message[ind] in each_line.lower():\n            if ((ind == 0) and (len(g_failed_jobs) > 0)):\n                continue\n            else:\n                g_failure_occurred = True\n                g_failed_test_info_dict[\"7.build_failure\"] = 'Yes'\n                temp_func_list.remove(find_build_failure)\n                return False\n\n    return True", "code_tokens": ["def", "find_build_failure", "(", "each_line", ",", "temp_func_list", ")", ":", "global", "g_build_success", "global", "g_build_success_tests", "global", "g_failed_test_info_dict", "global", "g_failure_occurred", "global", "g_build_failed_message", "for", "ind", "in", "range", "(", "0", ",", "len", "(", "g_build_failed_message", ")", ")", ":", "if", "g_build_failed_message", "[", "ind", "]", "in", "each_line", ".", "lower", "(", ")", ":", "if", "(", "(", "ind", "==", "0", ")", "and", "(", "len", "(", "g_failed_jobs", ")", ">", "0", ")", ")", ":", "continue", "else", ":", "g_failure_occurred", "=", "True", "g_failed_test_info_dict", "[", "\"7.build_failure\"", "]", "=", "'Yes'", "temp_func_list", ".", "remove", "(", "find_build_failure", ")", "return", "False", "return", "True"], "docstring": "Find if a Jenkins job has failed to build.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will delete this particular\n    function handle off the temp_func_list as we do not need to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text", "docstring_tokens": ["Find", "if", "a", "Jenkins", "job", "has", "failed", "to", "build", ".", "It", "will", "save", "this", "information", "in", "g_failed_test_info_dict", ".", "In", "addition", "it", "will", "delete", "this", "particular", "function", "handle", "off", "the", "temp_func_list", "as", "we", "do", "not", "need", "to", "perform", "this", "action", "again", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L271-L304", "partition": "test", "index": 1518, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "find_build_id", "original_string": "def find_build_id(each_line,temp_func_list):\n    \"\"\"\n    Find the build id of a jenkins job.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will delete this particular\n    function handle off the temp_func_list as we do not need to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text\n    \"\"\"\n    global g_before_java_file\n    global g_java_filenames\n    global g_build_id_text\n    global g_jenkins_url\n    global g_output_filename\n    global g_output_pickle_filename\n\n\n    if g_build_id_text in each_line:\n        [startStr,found,endStr] = each_line.partition(g_build_id_text)\n        g_failed_test_info_dict[\"2.build_id\"] = endStr.strip()\n\n        temp_func_list.remove(find_build_id)\n        g_jenkins_url = os.path.join('http://',g_jenkins_url,'view',g_view_name,'job',g_failed_test_info_dict[\"1.jobName\"],g_failed_test_info_dict[\"2.build_id\"],'artifact')\n\n\n    return True", "language": "python", "code": "def find_build_id(each_line,temp_func_list):\n    \"\"\"\n    Find the build id of a jenkins job.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will delete this particular\n    function handle off the temp_func_list as we do not need to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text\n    \"\"\"\n    global g_before_java_file\n    global g_java_filenames\n    global g_build_id_text\n    global g_jenkins_url\n    global g_output_filename\n    global g_output_pickle_filename\n\n\n    if g_build_id_text in each_line:\n        [startStr,found,endStr] = each_line.partition(g_build_id_text)\n        g_failed_test_info_dict[\"2.build_id\"] = endStr.strip()\n\n        temp_func_list.remove(find_build_id)\n        g_jenkins_url = os.path.join('http://',g_jenkins_url,'view',g_view_name,'job',g_failed_test_info_dict[\"1.jobName\"],g_failed_test_info_dict[\"2.build_id\"],'artifact')\n\n\n    return True", "code_tokens": ["def", "find_build_id", "(", "each_line", ",", "temp_func_list", ")", ":", "global", "g_before_java_file", "global", "g_java_filenames", "global", "g_build_id_text", "global", "g_jenkins_url", "global", "g_output_filename", "global", "g_output_pickle_filename", "if", "g_build_id_text", "in", "each_line", ":", "[", "startStr", ",", "found", ",", "endStr", "]", "=", "each_line", ".", "partition", "(", "g_build_id_text", ")", "g_failed_test_info_dict", "[", "\"2.build_id\"", "]", "=", "endStr", ".", "strip", "(", ")", "temp_func_list", ".", "remove", "(", "find_build_id", ")", "g_jenkins_url", "=", "os", ".", "path", ".", "join", "(", "'http://'", ",", "g_jenkins_url", ",", "'view'", ",", "g_view_name", ",", "'job'", ",", "g_failed_test_info_dict", "[", "\"1.jobName\"", "]", ",", "g_failed_test_info_dict", "[", "\"2.build_id\"", "]", ",", "'artifact'", ")", "return", "True"], "docstring": "Find the build id of a jenkins job.  It will save this\n    information in g_failed_test_info_dict.  In addition, it will delete this particular\n    function handle off the temp_func_list as we do not need to perform this action again.\n\n    Parameters\n    ----------\n\n    each_line :  str\n        contains a line read in from jenkins console\n    temp_func_list :  list of Python function handles\n        contains a list of functions that we want to invoke to extract information from\n        the Jenkins console text.\n\n    :return: bool to determine if text mining should continue on the jenkins console text", "docstring_tokens": ["Find", "the", "build", "id", "of", "a", "jenkins", "job", ".", "It", "will", "save", "this", "information", "in", "g_failed_test_info_dict", ".", "In", "addition", "it", "will", "delete", "this", "particular", "function", "handle", "off", "the", "temp_func_list", "as", "we", "do", "not", "need", "to", "perform", "this", "action", "again", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L337-L370", "partition": "test", "index": 1519, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "extract_job_build_url", "original_string": "def extract_job_build_url(url_string):\n    \"\"\"\n    From user input, grab the jenkins job name and saved it in g_failed_test_info_dict.\n    In addition, it will grab the jenkins url and the view name into g_jenkins_url, and\n    g_view_name.\n\n    Parameters\n    ----------\n    url_string :  str\n        contains information on the jenkins job whose console output we are interested in.\n\n    :return: none\n    \"\"\"\n    global g_failed_test_info_dict\n    global g_jenkins_url\n    global g_view_name\n    \n    tempString = url_string.strip('/').split('/')\n\n    if len(tempString) < 6:\n        print \"Illegal URL resource address.\\n\"\n        sys.exit(1)\n        \n    g_failed_test_info_dict[\"1.jobName\"] = tempString[6]\n        \n    g_jenkins_url = tempString[2]\n    g_view_name = tempString[4]", "language": "python", "code": "def extract_job_build_url(url_string):\n    \"\"\"\n    From user input, grab the jenkins job name and saved it in g_failed_test_info_dict.\n    In addition, it will grab the jenkins url and the view name into g_jenkins_url, and\n    g_view_name.\n\n    Parameters\n    ----------\n    url_string :  str\n        contains information on the jenkins job whose console output we are interested in.\n\n    :return: none\n    \"\"\"\n    global g_failed_test_info_dict\n    global g_jenkins_url\n    global g_view_name\n    \n    tempString = url_string.strip('/').split('/')\n\n    if len(tempString) < 6:\n        print \"Illegal URL resource address.\\n\"\n        sys.exit(1)\n        \n    g_failed_test_info_dict[\"1.jobName\"] = tempString[6]\n        \n    g_jenkins_url = tempString[2]\n    g_view_name = tempString[4]", "code_tokens": ["def", "extract_job_build_url", "(", "url_string", ")", ":", "global", "g_failed_test_info_dict", "global", "g_jenkins_url", "global", "g_view_name", "tempString", "=", "url_string", ".", "strip", "(", "'/'", ")", ".", "split", "(", "'/'", ")", "if", "len", "(", "tempString", ")", "<", "6", ":", "print", "\"Illegal URL resource address.\\n\"", "sys", ".", "exit", "(", "1", ")", "g_failed_test_info_dict", "[", "\"1.jobName\"", "]", "=", "tempString", "[", "6", "]", "g_jenkins_url", "=", "tempString", "[", "2", "]", "g_view_name", "=", "tempString", "[", "4", "]"], "docstring": "From user input, grab the jenkins job name and saved it in g_failed_test_info_dict.\n    In addition, it will grab the jenkins url and the view name into g_jenkins_url, and\n    g_view_name.\n\n    Parameters\n    ----------\n    url_string :  str\n        contains information on the jenkins job whose console output we are interested in.\n\n    :return: none", "docstring_tokens": ["From", "user", "input", "grab", "the", "jenkins", "job", "name", "and", "saved", "it", "in", "g_failed_test_info_dict", ".", "In", "addition", "it", "will", "grab", "the", "jenkins", "url", "and", "the", "view", "name", "into", "g_jenkins_url", "and", "g_view_name", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L487-L513", "partition": "test", "index": 1520, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "grab_java_message", "original_string": "def grab_java_message():\n    \"\"\"scan through the java output text and extract the bad java messages that may or may not happened when\n    unit tests are run.  It will not record any bad java messages that are stored in g_ok_java_messages.\n\n    :return: none\n    \"\"\"\n\n    global g_temp_filename\n    global g_current_testname\n    global g_java_start_text\n    global g_ok_java_messages\n    global g_java_general_bad_messages  # store bad java messages not associated with running a unit test\n    global g_java_general_bad_message_types\n    global g_failure_occurred\n    global g_java_message_type\n    global g_all_java_message_type\n    global g_toContinue\n\n    java_messages = []      # store all bad java messages associated with running a unit test\n    java_message_types = [] # store all bad java message types associated with running a unit test\n\n    if os.path.isfile(g_temp_filename): # open temp file containing content of some java_*_0.out.txt\n        java_file = open(g_temp_filename,'r')\n\n        g_toContinue = False    # denote if a multi-line message starts\n\n        tempMessage = \"\"\n        messageType = \"\"\n\n        for each_line in java_file:\n\n            if (g_java_start_text in each_line):\n                startStr,found,endStr = each_line.partition(g_java_start_text)\n\n                if len(found) > 0:\n                    if len(g_current_testname) > 0: # a new unit test is being started.  Save old info and move on\n                        associate_test_with_java(g_current_testname,java_messages,java_message_types)\n        \n                    g_current_testname = endStr.strip() # record the test name\n                    \n                    java_messages = []\n                    java_message_types = []\n        \n            temp_strings = each_line.strip().split()\n\n            if (len(temp_strings) >= 6) and (temp_strings[5] in g_all_java_message_type):\n                if g_toContinue == True:    # at the end of last message fragment\n                    addJavaMessages(tempMessage,messageType,java_messages,java_message_types)\n                    tempMessage = \"\"\n                    messageType = \"\"\n\n                # start of new message fragment\n                g_toContinue = False\n            else: # non standard output.  Continuation of last java message, add it to bad java message list\n                if g_toContinue:\n\n                    tempMessage += each_line    # add more java message here\n                    # if len(g_current_testname) == 0:\n                    #     addJavaMessages(each_line.strip(),\"\",java_messages,java_message_types)\n                    # else:\n                    #     addJavaMessages(each_line.strip(),\"\",java_messages,java_message_types)\n\n            if ((len(temp_strings) > 5) and (temp_strings[5] in g_java_message_type)):  # find a bad java message\n                startStr,found,endStr = each_line.partition(temp_strings[5])    # can be WARN,ERRR,FATAL,TRACE\n\n                if found and (len(endStr.strip()) > 0):\n                    tempMessage += endStr\n                    messageType = temp_strings[5]\n#                    if (tempMessage not in g_ok_java_messages[\"general\"]):  # found new bad messages that cannot be ignored\n                    g_toContinue = True\n\n                        # add tempMessage to bad java message list\n#                        addJavaMessages(tempMessage,temp_strings[5],java_messages,java_message_types)\n        java_file.close()", "language": "python", "code": "def grab_java_message():\n    \"\"\"scan through the java output text and extract the bad java messages that may or may not happened when\n    unit tests are run.  It will not record any bad java messages that are stored in g_ok_java_messages.\n\n    :return: none\n    \"\"\"\n\n    global g_temp_filename\n    global g_current_testname\n    global g_java_start_text\n    global g_ok_java_messages\n    global g_java_general_bad_messages  # store bad java messages not associated with running a unit test\n    global g_java_general_bad_message_types\n    global g_failure_occurred\n    global g_java_message_type\n    global g_all_java_message_type\n    global g_toContinue\n\n    java_messages = []      # store all bad java messages associated with running a unit test\n    java_message_types = [] # store all bad java message types associated with running a unit test\n\n    if os.path.isfile(g_temp_filename): # open temp file containing content of some java_*_0.out.txt\n        java_file = open(g_temp_filename,'r')\n\n        g_toContinue = False    # denote if a multi-line message starts\n\n        tempMessage = \"\"\n        messageType = \"\"\n\n        for each_line in java_file:\n\n            if (g_java_start_text in each_line):\n                startStr,found,endStr = each_line.partition(g_java_start_text)\n\n                if len(found) > 0:\n                    if len(g_current_testname) > 0: # a new unit test is being started.  Save old info and move on\n                        associate_test_with_java(g_current_testname,java_messages,java_message_types)\n        \n                    g_current_testname = endStr.strip() # record the test name\n                    \n                    java_messages = []\n                    java_message_types = []\n        \n            temp_strings = each_line.strip().split()\n\n            if (len(temp_strings) >= 6) and (temp_strings[5] in g_all_java_message_type):\n                if g_toContinue == True:    # at the end of last message fragment\n                    addJavaMessages(tempMessage,messageType,java_messages,java_message_types)\n                    tempMessage = \"\"\n                    messageType = \"\"\n\n                # start of new message fragment\n                g_toContinue = False\n            else: # non standard output.  Continuation of last java message, add it to bad java message list\n                if g_toContinue:\n\n                    tempMessage += each_line    # add more java message here\n                    # if len(g_current_testname) == 0:\n                    #     addJavaMessages(each_line.strip(),\"\",java_messages,java_message_types)\n                    # else:\n                    #     addJavaMessages(each_line.strip(),\"\",java_messages,java_message_types)\n\n            if ((len(temp_strings) > 5) and (temp_strings[5] in g_java_message_type)):  # find a bad java message\n                startStr,found,endStr = each_line.partition(temp_strings[5])    # can be WARN,ERRR,FATAL,TRACE\n\n                if found and (len(endStr.strip()) > 0):\n                    tempMessage += endStr\n                    messageType = temp_strings[5]\n#                    if (tempMessage not in g_ok_java_messages[\"general\"]):  # found new bad messages that cannot be ignored\n                    g_toContinue = True\n\n                        # add tempMessage to bad java message list\n#                        addJavaMessages(tempMessage,temp_strings[5],java_messages,java_message_types)\n        java_file.close()", "code_tokens": ["def", "grab_java_message", "(", ")", ":", "global", "g_temp_filename", "global", "g_current_testname", "global", "g_java_start_text", "global", "g_ok_java_messages", "global", "g_java_general_bad_messages", "# store bad java messages not associated with running a unit test", "global", "g_java_general_bad_message_types", "global", "g_failure_occurred", "global", "g_java_message_type", "global", "g_all_java_message_type", "global", "g_toContinue", "java_messages", "=", "[", "]", "# store all bad java messages associated with running a unit test", "java_message_types", "=", "[", "]", "# store all bad java message types associated with running a unit test", "if", "os", ".", "path", ".", "isfile", "(", "g_temp_filename", ")", ":", "# open temp file containing content of some java_*_0.out.txt", "java_file", "=", "open", "(", "g_temp_filename", ",", "'r'", ")", "g_toContinue", "=", "False", "# denote if a multi-line message starts", "tempMessage", "=", "\"\"", "messageType", "=", "\"\"", "for", "each_line", "in", "java_file", ":", "if", "(", "g_java_start_text", "in", "each_line", ")", ":", "startStr", ",", "found", ",", "endStr", "=", "each_line", ".", "partition", "(", "g_java_start_text", ")", "if", "len", "(", "found", ")", ">", "0", ":", "if", "len", "(", "g_current_testname", ")", ">", "0", ":", "# a new unit test is being started.  Save old info and move on", "associate_test_with_java", "(", "g_current_testname", ",", "java_messages", ",", "java_message_types", ")", "g_current_testname", "=", "endStr", ".", "strip", "(", ")", "# record the test name", "java_messages", "=", "[", "]", "java_message_types", "=", "[", "]", "temp_strings", "=", "each_line", ".", "strip", "(", ")", ".", "split", "(", ")", "if", "(", "len", "(", "temp_strings", ")", ">=", "6", ")", "and", "(", "temp_strings", "[", "5", "]", "in", "g_all_java_message_type", ")", ":", "if", "g_toContinue", "==", "True", ":", "# at the end of last message fragment", "addJavaMessages", "(", "tempMessage", ",", "messageType", ",", "java_messages", ",", "java_message_types", ")", "tempMessage", "=", "\"\"", "messageType", "=", "\"\"", "# start of new message fragment", "g_toContinue", "=", "False", "else", ":", "# non standard output.  Continuation of last java message, add it to bad java message list", "if", "g_toContinue", ":", "tempMessage", "+=", "each_line", "# add more java message here", "# if len(g_current_testname) == 0:", "#     addJavaMessages(each_line.strip(),\"\",java_messages,java_message_types)", "# else:", "#     addJavaMessages(each_line.strip(),\"\",java_messages,java_message_types)", "if", "(", "(", "len", "(", "temp_strings", ")", ">", "5", ")", "and", "(", "temp_strings", "[", "5", "]", "in", "g_java_message_type", ")", ")", ":", "# find a bad java message", "startStr", ",", "found", ",", "endStr", "=", "each_line", ".", "partition", "(", "temp_strings", "[", "5", "]", ")", "# can be WARN,ERRR,FATAL,TRACE", "if", "found", "and", "(", "len", "(", "endStr", ".", "strip", "(", ")", ")", ">", "0", ")", ":", "tempMessage", "+=", "endStr", "messageType", "=", "temp_strings", "[", "5", "]", "#                    if (tempMessage not in g_ok_java_messages[\"general\"]):  # found new bad messages that cannot be ignored", "g_toContinue", "=", "True", "# add tempMessage to bad java message list", "#                        addJavaMessages(tempMessage,temp_strings[5],java_messages,java_message_types)", "java_file", ".", "close", "(", ")"], "docstring": "scan through the java output text and extract the bad java messages that may or may not happened when\n    unit tests are run.  It will not record any bad java messages that are stored in g_ok_java_messages.\n\n    :return: none", "docstring_tokens": ["scan", "through", "the", "java", "output", "text", "and", "extract", "the", "bad", "java", "messages", "that", "may", "or", "may", "not", "happened", "when", "unit", "tests", "are", "run", ".", "It", "will", "not", "record", "any", "bad", "java", "messages", "that", "are", "stored", "in", "g_ok_java_messages", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L516-L589", "partition": "test", "index": 1521, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "save_dict", "original_string": "def save_dict():\n    \"\"\"\n    Save the log scraping results into logs denoted by g_output_filename_failed_tests and\n    g_output_filename_passed_tests.\n\n    :return: none\n    \"\"\"\n\n    global g_test_root_dir\n    global g_output_filename_failed_tests\n    global g_output_filename_passed_tests\n    global g_output_pickle_filename\n    global g_failed_test_info_dict\n\n\n    # some build can fail really early that no buid id info is stored in the console text.\n    if \"2.build_id\" not in g_failed_test_info_dict.keys():\n        g_failed_test_info_dict[\"2.build_id\"] = \"unknown\"\n\n    build_id = g_failed_test_info_dict[\"2.build_id\"]\n\n    g_output_filename_failed_tests = g_output_filename_failed_tests+'_build_'+build_id+'_failed_tests.log'\n    g_output_filename_passed_tests = g_output_filename_passed_tests+'_build_'+build_id+'_passed_tests.log'\n    g_output_pickle_filename = g_output_pickle_filename+'_build_'+build_id+'.pickle'\n\n    allKeys = sorted(g_failed_test_info_dict.keys())\n\n    # write out the jenkins job info into log files.\n    with open(g_output_pickle_filename,'wb') as test_file:\n        pickle.dump(g_failed_test_info_dict,test_file)\n\n    # write out the failure report as text into a text file\n    text_file_failed_tests = open(g_output_filename_failed_tests,'w')\n    text_file_passed_tests = None\n    allKeys = sorted(g_failed_test_info_dict.keys())\n    write_passed_tests = False\n\n    if (\"passed_tests_info *********\" in allKeys):\n        text_file_passed_tests = open(g_output_filename_passed_tests,'w')\n        write_passed_tests = True\n\n    for keyName in allKeys:\n        val = g_failed_test_info_dict[keyName]\n        if isinstance(val,list):    # writing one of the job lists\n            if (len(val) == 3):     # it is a message for a test\n                if keyName == \"failed_tests_info *********\":\n                    write_test_java_message(keyName,val,text_file_failed_tests)\n\n                if keyName == \"passed_tests_info *********\":\n                    write_test_java_message(keyName,val,text_file_passed_tests)\n            elif (len(val) == 2):                   # it is a general bad java message\n                write_java_message(keyName,val,text_file_failed_tests)\n                if write_passed_tests:\n                    write_java_message(keyName,val,text_file_passed_tests)\n        else:\n            write_general_build_message(keyName,val,text_file_failed_tests)\n            if write_passed_tests:\n                write_general_build_message(keyName,val,text_file_passed_tests)\n\n    text_file_failed_tests.close()\n    if write_passed_tests:\n        text_file_passed_tests.close()", "language": "python", "code": "def save_dict():\n    \"\"\"\n    Save the log scraping results into logs denoted by g_output_filename_failed_tests and\n    g_output_filename_passed_tests.\n\n    :return: none\n    \"\"\"\n\n    global g_test_root_dir\n    global g_output_filename_failed_tests\n    global g_output_filename_passed_tests\n    global g_output_pickle_filename\n    global g_failed_test_info_dict\n\n\n    # some build can fail really early that no buid id info is stored in the console text.\n    if \"2.build_id\" not in g_failed_test_info_dict.keys():\n        g_failed_test_info_dict[\"2.build_id\"] = \"unknown\"\n\n    build_id = g_failed_test_info_dict[\"2.build_id\"]\n\n    g_output_filename_failed_tests = g_output_filename_failed_tests+'_build_'+build_id+'_failed_tests.log'\n    g_output_filename_passed_tests = g_output_filename_passed_tests+'_build_'+build_id+'_passed_tests.log'\n    g_output_pickle_filename = g_output_pickle_filename+'_build_'+build_id+'.pickle'\n\n    allKeys = sorted(g_failed_test_info_dict.keys())\n\n    # write out the jenkins job info into log files.\n    with open(g_output_pickle_filename,'wb') as test_file:\n        pickle.dump(g_failed_test_info_dict,test_file)\n\n    # write out the failure report as text into a text file\n    text_file_failed_tests = open(g_output_filename_failed_tests,'w')\n    text_file_passed_tests = None\n    allKeys = sorted(g_failed_test_info_dict.keys())\n    write_passed_tests = False\n\n    if (\"passed_tests_info *********\" in allKeys):\n        text_file_passed_tests = open(g_output_filename_passed_tests,'w')\n        write_passed_tests = True\n\n    for keyName in allKeys:\n        val = g_failed_test_info_dict[keyName]\n        if isinstance(val,list):    # writing one of the job lists\n            if (len(val) == 3):     # it is a message for a test\n                if keyName == \"failed_tests_info *********\":\n                    write_test_java_message(keyName,val,text_file_failed_tests)\n\n                if keyName == \"passed_tests_info *********\":\n                    write_test_java_message(keyName,val,text_file_passed_tests)\n            elif (len(val) == 2):                   # it is a general bad java message\n                write_java_message(keyName,val,text_file_failed_tests)\n                if write_passed_tests:\n                    write_java_message(keyName,val,text_file_passed_tests)\n        else:\n            write_general_build_message(keyName,val,text_file_failed_tests)\n            if write_passed_tests:\n                write_general_build_message(keyName,val,text_file_passed_tests)\n\n    text_file_failed_tests.close()\n    if write_passed_tests:\n        text_file_passed_tests.close()", "code_tokens": ["def", "save_dict", "(", ")", ":", "global", "g_test_root_dir", "global", "g_output_filename_failed_tests", "global", "g_output_filename_passed_tests", "global", "g_output_pickle_filename", "global", "g_failed_test_info_dict", "# some build can fail really early that no buid id info is stored in the console text.", "if", "\"2.build_id\"", "not", "in", "g_failed_test_info_dict", ".", "keys", "(", ")", ":", "g_failed_test_info_dict", "[", "\"2.build_id\"", "]", "=", "\"unknown\"", "build_id", "=", "g_failed_test_info_dict", "[", "\"2.build_id\"", "]", "g_output_filename_failed_tests", "=", "g_output_filename_failed_tests", "+", "'_build_'", "+", "build_id", "+", "'_failed_tests.log'", "g_output_filename_passed_tests", "=", "g_output_filename_passed_tests", "+", "'_build_'", "+", "build_id", "+", "'_passed_tests.log'", "g_output_pickle_filename", "=", "g_output_pickle_filename", "+", "'_build_'", "+", "build_id", "+", "'.pickle'", "allKeys", "=", "sorted", "(", "g_failed_test_info_dict", ".", "keys", "(", ")", ")", "# write out the jenkins job info into log files.", "with", "open", "(", "g_output_pickle_filename", ",", "'wb'", ")", "as", "test_file", ":", "pickle", ".", "dump", "(", "g_failed_test_info_dict", ",", "test_file", ")", "# write out the failure report as text into a text file", "text_file_failed_tests", "=", "open", "(", "g_output_filename_failed_tests", ",", "'w'", ")", "text_file_passed_tests", "=", "None", "allKeys", "=", "sorted", "(", "g_failed_test_info_dict", ".", "keys", "(", ")", ")", "write_passed_tests", "=", "False", "if", "(", "\"passed_tests_info *********\"", "in", "allKeys", ")", ":", "text_file_passed_tests", "=", "open", "(", "g_output_filename_passed_tests", ",", "'w'", ")", "write_passed_tests", "=", "True", "for", "keyName", "in", "allKeys", ":", "val", "=", "g_failed_test_info_dict", "[", "keyName", "]", "if", "isinstance", "(", "val", ",", "list", ")", ":", "# writing one of the job lists", "if", "(", "len", "(", "val", ")", "==", "3", ")", ":", "# it is a message for a test", "if", "keyName", "==", "\"failed_tests_info *********\"", ":", "write_test_java_message", "(", "keyName", ",", "val", ",", "text_file_failed_tests", ")", "if", "keyName", "==", "\"passed_tests_info *********\"", ":", "write_test_java_message", "(", "keyName", ",", "val", ",", "text_file_passed_tests", ")", "elif", "(", "len", "(", "val", ")", "==", "2", ")", ":", "# it is a general bad java message", "write_java_message", "(", "keyName", ",", "val", ",", "text_file_failed_tests", ")", "if", "write_passed_tests", ":", "write_java_message", "(", "keyName", ",", "val", ",", "text_file_passed_tests", ")", "else", ":", "write_general_build_message", "(", "keyName", ",", "val", ",", "text_file_failed_tests", ")", "if", "write_passed_tests", ":", "write_general_build_message", "(", "keyName", ",", "val", ",", "text_file_passed_tests", ")", "text_file_failed_tests", ".", "close", "(", ")", "if", "write_passed_tests", ":", "text_file_passed_tests", ".", "close", "(", ")"], "docstring": "Save the log scraping results into logs denoted by g_output_filename_failed_tests and\n    g_output_filename_passed_tests.\n\n    :return: none", "docstring_tokens": ["Save", "the", "log", "scraping", "results", "into", "logs", "denoted", "by", "g_output_filename_failed_tests", "and", "g_output_filename_passed_tests", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L722-L783", "partition": "test", "index": 1522, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "write_file_content", "original_string": "def write_file_content(fhandle,file2read):\n    \"\"\"\n    Write one log file into the summary text file.\n\n    Parameters\n    ----------\n    fhandle :  Python file handle\n        file handle to the summary text file\n    file2read : Python file handle\n        file handle to log file where we want to add its content to the summary text file.\n\n    :return: none\n    \"\"\"\n    if os.path.isfile(file2read):\n\n        # write summary of failed tests logs\n        with open(file2read,'r') as tfile:\n            fhandle.write('============ Content of '+ file2read)\n            fhandle.write('\\n')\n            fhandle.write(tfile.read())\n            fhandle.write('\\n\\n')", "language": "python", "code": "def write_file_content(fhandle,file2read):\n    \"\"\"\n    Write one log file into the summary text file.\n\n    Parameters\n    ----------\n    fhandle :  Python file handle\n        file handle to the summary text file\n    file2read : Python file handle\n        file handle to log file where we want to add its content to the summary text file.\n\n    :return: none\n    \"\"\"\n    if os.path.isfile(file2read):\n\n        # write summary of failed tests logs\n        with open(file2read,'r') as tfile:\n            fhandle.write('============ Content of '+ file2read)\n            fhandle.write('\\n')\n            fhandle.write(tfile.read())\n            fhandle.write('\\n\\n')", "code_tokens": ["def", "write_file_content", "(", "fhandle", ",", "file2read", ")", ":", "if", "os", ".", "path", ".", "isfile", "(", "file2read", ")", ":", "# write summary of failed tests logs", "with", "open", "(", "file2read", ",", "'r'", ")", "as", "tfile", ":", "fhandle", ".", "write", "(", "'============ Content of '", "+", "file2read", ")", "fhandle", ".", "write", "(", "'\\n'", ")", "fhandle", ".", "write", "(", "tfile", ".", "read", "(", ")", ")", "fhandle", ".", "write", "(", "'\\n\\n'", ")"], "docstring": "Write one log file into the summary text file.\n\n    Parameters\n    ----------\n    fhandle :  Python file handle\n        file handle to the summary text file\n    file2read : Python file handle\n        file handle to log file where we want to add its content to the summary text file.\n\n    :return: none", "docstring_tokens": ["Write", "one", "log", "file", "into", "the", "summary", "text", "file", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L861-L881", "partition": "test", "index": 1524, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/addjavamessage2ignore.py", "func_name": "load_dict", "original_string": "def load_dict():\n    \"\"\"\n    Load java messages that can be ignored pickle file into a dict structure g_ok_java_messages.\n\n    :return: none\n    \"\"\"\n    global g_load_java_message_filename\n    global g_ok_java_messages\n\n    if os.path.isfile(g_load_java_message_filename):\n            # only load dict from file if it exists.\n        with open(g_load_java_message_filename,'rb') as ofile:\n            g_ok_java_messages = pickle.load(ofile)\n    else:   # no previous java messages to be excluded are found\n        g_ok_java_messages[\"general\"] = []", "language": "python", "code": "def load_dict():\n    \"\"\"\n    Load java messages that can be ignored pickle file into a dict structure g_ok_java_messages.\n\n    :return: none\n    \"\"\"\n    global g_load_java_message_filename\n    global g_ok_java_messages\n\n    if os.path.isfile(g_load_java_message_filename):\n            # only load dict from file if it exists.\n        with open(g_load_java_message_filename,'rb') as ofile:\n            g_ok_java_messages = pickle.load(ofile)\n    else:   # no previous java messages to be excluded are found\n        g_ok_java_messages[\"general\"] = []", "code_tokens": ["def", "load_dict", "(", ")", ":", "global", "g_load_java_message_filename", "global", "g_ok_java_messages", "if", "os", ".", "path", ".", "isfile", "(", "g_load_java_message_filename", ")", ":", "# only load dict from file if it exists.", "with", "open", "(", "g_load_java_message_filename", ",", "'rb'", ")", "as", "ofile", ":", "g_ok_java_messages", "=", "pickle", ".", "load", "(", "ofile", ")", "else", ":", "# no previous java messages to be excluded are found", "g_ok_java_messages", "[", "\"general\"", "]", "=", "[", "]"], "docstring": "Load java messages that can be ignored pickle file into a dict structure g_ok_java_messages.\n\n    :return: none", "docstring_tokens": ["Load", "java", "messages", "that", "can", "be", "ignored", "pickle", "file", "into", "a", "dict", "structure", "g_ok_java_messages", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/addjavamessage2ignore.py#L87-L101", "partition": "test", "index": 1565, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/addjavamessage2ignore.py", "func_name": "add_new_message", "original_string": "def add_new_message():\n    \"\"\"\n    Add new java messages to ignore from user text file.  It first reads in the new java ignored messages\n    from the user text file and generate a dict structure to out of the new java ignored messages.  This\n    is achieved by function extract_message_to_dict.  Next, new java messages will be added to the original\n    ignored java messages dict g_ok_java_messages.  Again, this is achieved by function update_message_dict.\n\n    :return: none\n    \"\"\"\n    global g_new_messages_to_exclude    # filename containing text file from user containing new java ignored messages\n    global g_dict_changed               # True if new ignored java messages are added.\n\n    new_message_dict = extract_message_to_dict(g_new_messages_to_exclude)\n\n    if new_message_dict:\n        g_dict_changed = True\n        update_message_dict(new_message_dict,1)", "language": "python", "code": "def add_new_message():\n    \"\"\"\n    Add new java messages to ignore from user text file.  It first reads in the new java ignored messages\n    from the user text file and generate a dict structure to out of the new java ignored messages.  This\n    is achieved by function extract_message_to_dict.  Next, new java messages will be added to the original\n    ignored java messages dict g_ok_java_messages.  Again, this is achieved by function update_message_dict.\n\n    :return: none\n    \"\"\"\n    global g_new_messages_to_exclude    # filename containing text file from user containing new java ignored messages\n    global g_dict_changed               # True if new ignored java messages are added.\n\n    new_message_dict = extract_message_to_dict(g_new_messages_to_exclude)\n\n    if new_message_dict:\n        g_dict_changed = True\n        update_message_dict(new_message_dict,1)", "code_tokens": ["def", "add_new_message", "(", ")", ":", "global", "g_new_messages_to_exclude", "# filename containing text file from user containing new java ignored messages", "global", "g_dict_changed", "# True if new ignored java messages are added.", "new_message_dict", "=", "extract_message_to_dict", "(", "g_new_messages_to_exclude", ")", "if", "new_message_dict", ":", "g_dict_changed", "=", "True", "update_message_dict", "(", "new_message_dict", ",", "1", ")"], "docstring": "Add new java messages to ignore from user text file.  It first reads in the new java ignored messages\n    from the user text file and generate a dict structure to out of the new java ignored messages.  This\n    is achieved by function extract_message_to_dict.  Next, new java messages will be added to the original\n    ignored java messages dict g_ok_java_messages.  Again, this is achieved by function update_message_dict.\n\n    :return: none", "docstring_tokens": ["Add", "new", "java", "messages", "to", "ignore", "from", "user", "text", "file", ".", "It", "first", "reads", "in", "the", "new", "java", "ignored", "messages", "from", "the", "user", "text", "file", "and", "generate", "a", "dict", "structure", "to", "out", "of", "the", "new", "java", "ignored", "messages", ".", "This", "is", "achieved", "by", "function", "extract_message_to_dict", ".", "Next", "new", "java", "messages", "will", "be", "added", "to", "the", "original", "ignored", "java", "messages", "dict", "g_ok_java_messages", ".", "Again", "this", "is", "achieved", "by", "function", "update_message_dict", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/addjavamessage2ignore.py#L103-L119", "partition": "test", "index": 1566, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "write_java_message", "original_string": "def write_java_message(key,val,text_file):\n    \"\"\"\n    Loop through all java messages that are not associated with a unit test and\n    write them into a log file.\n\n    Parameters\n    ----------\n    key :  str\n        9.general_bad_java_messages\n    val : list of list of str\n        contains the bad java messages and the message types.\n\n\n    :return: none\n    \"\"\"\n\n    text_file.write(key)\n    text_file.write('\\n')\n\n    if (len(val[0]) > 0) and (len(val) >= 3):\n        for index in range(len(val[0])):\n            text_file.write(\"Java Message Type: \")\n            text_file.write(val[1][index])\n            text_file.write('\\n')\n\n            text_file.write(\"Java Message: \")\n\n            for jmess in val[2][index]:\n                text_file.write(jmess)\n                text_file.write('\\n')\n\n        text_file.write('\\n \\n')", "language": "python", "code": "def write_java_message(key,val,text_file):\n    \"\"\"\n    Loop through all java messages that are not associated with a unit test and\n    write them into a log file.\n\n    Parameters\n    ----------\n    key :  str\n        9.general_bad_java_messages\n    val : list of list of str\n        contains the bad java messages and the message types.\n\n\n    :return: none\n    \"\"\"\n\n    text_file.write(key)\n    text_file.write('\\n')\n\n    if (len(val[0]) > 0) and (len(val) >= 3):\n        for index in range(len(val[0])):\n            text_file.write(\"Java Message Type: \")\n            text_file.write(val[1][index])\n            text_file.write('\\n')\n\n            text_file.write(\"Java Message: \")\n\n            for jmess in val[2][index]:\n                text_file.write(jmess)\n                text_file.write('\\n')\n\n        text_file.write('\\n \\n')", "code_tokens": ["def", "write_java_message", "(", "key", ",", "val", ",", "text_file", ")", ":", "text_file", ".", "write", "(", "key", ")", "text_file", ".", "write", "(", "'\\n'", ")", "if", "(", "len", "(", "val", "[", "0", "]", ")", ">", "0", ")", "and", "(", "len", "(", "val", ")", ">=", "3", ")", ":", "for", "index", "in", "range", "(", "len", "(", "val", "[", "0", "]", ")", ")", ":", "text_file", ".", "write", "(", "\"Java Message Type: \"", ")", "text_file", ".", "write", "(", "val", "[", "1", "]", "[", "index", "]", ")", "text_file", ".", "write", "(", "'\\n'", ")", "text_file", ".", "write", "(", "\"Java Message: \"", ")", "for", "jmess", "in", "val", "[", "2", "]", "[", "index", "]", ":", "text_file", ".", "write", "(", "jmess", ")", "text_file", ".", "write", "(", "'\\n'", ")", "text_file", ".", "write", "(", "'\\n \\n'", ")"], "docstring": "Loop through all java messages that are not associated with a unit test and\n    write them into a log file.\n\n    Parameters\n    ----------\n    key :  str\n        9.general_bad_java_messages\n    val : list of list of str\n        contains the bad java messages and the message types.\n\n\n    :return: none", "docstring_tokens": ["Loop", "through", "all", "java", "messages", "that", "are", "not", "associated", "with", "a", "unit", "test", "and", "write", "them", "into", "a", "log", "file", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L885-L916", "partition": "test", "index": 1525, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/logscrapedaily.py", "func_name": "load_java_messages_to_ignore", "original_string": "def load_java_messages_to_ignore():\n    \"\"\"\n    Load in pickle file that contains dict structure with bad java messages to ignore per unit test\n    or for all cases.  The ignored bad java info is stored in g_ok_java_messages dict.\n\n    :return:\n    \"\"\"\n    global g_ok_java_messages\n    global g_java_message_pickle_filename\n\n    if os.path.isfile(g_java_message_pickle_filename):\n        with open(g_java_message_pickle_filename,'rb') as tfile:\n            g_ok_java_messages = pickle.load(tfile)\n    else:\n        g_ok_java_messages[\"general\"] = []", "language": "python", "code": "def load_java_messages_to_ignore():\n    \"\"\"\n    Load in pickle file that contains dict structure with bad java messages to ignore per unit test\n    or for all cases.  The ignored bad java info is stored in g_ok_java_messages dict.\n\n    :return:\n    \"\"\"\n    global g_ok_java_messages\n    global g_java_message_pickle_filename\n\n    if os.path.isfile(g_java_message_pickle_filename):\n        with open(g_java_message_pickle_filename,'rb') as tfile:\n            g_ok_java_messages = pickle.load(tfile)\n    else:\n        g_ok_java_messages[\"general\"] = []", "code_tokens": ["def", "load_java_messages_to_ignore", "(", ")", ":", "global", "g_ok_java_messages", "global", "g_java_message_pickle_filename", "if", "os", ".", "path", ".", "isfile", "(", "g_java_message_pickle_filename", ")", ":", "with", "open", "(", "g_java_message_pickle_filename", ",", "'rb'", ")", "as", "tfile", ":", "g_ok_java_messages", "=", "pickle", ".", "load", "(", "tfile", ")", "else", ":", "g_ok_java_messages", "[", "\"general\"", "]", "=", "[", "]"], "docstring": "Load in pickle file that contains dict structure with bad java messages to ignore per unit test\n    or for all cases.  The ignored bad java info is stored in g_ok_java_messages dict.\n\n    :return:", "docstring_tokens": ["Load", "in", "pickle", "file", "that", "contains", "dict", "structure", "with", "bad", "java", "messages", "to", "ignore", "per", "unit", "test", "or", "for", "all", "cases", ".", "The", "ignored", "bad", "java", "info", "is", "stored", "in", "g_ok_java_messages", "dict", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L919-L933", "partition": "test", "index": 1526, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/addjavamessage2ignore.py", "func_name": "usage", "original_string": "def usage():\n    \"\"\"\n    Illustrate what the various input flags are and the options should be.\n\n    :return: none\n    \"\"\"\n    global g_script_name    # name of the script being run.\n\n    print(\"\")\n    print(\"Usage:  \" + g_script_name + \" [...options...]\")\n    print(\"\")\n    print(\"     --help print out this help menu and show all the valid flags and inputs.\")\n    print(\"\")\n    print(\"    --inputfileadd filename where the new java messages to ignore are stored in.\")\n    print(\"\")\n    print(\"    --inputfilerm filename where the java messages are removed from the ignored list.\")\n    print(\"\")\n    print(\"    --loadjavamessage filename pickle file that stores the dict structure containing java messages to include.\")\n    print(\"\")\n    print(\"    --savejavamessage filename pickle file that saves the final dict structure after update.\")\n    print(\"\")\n    print(\"    --printjavamessage filename print java ignored java messages stored in pickle file filenam onto console and save into a text file.\")\n    print(\"\")\n    sys.exit(1)", "language": "python", "code": "def usage():\n    \"\"\"\n    Illustrate what the various input flags are and the options should be.\n\n    :return: none\n    \"\"\"\n    global g_script_name    # name of the script being run.\n\n    print(\"\")\n    print(\"Usage:  \" + g_script_name + \" [...options...]\")\n    print(\"\")\n    print(\"     --help print out this help menu and show all the valid flags and inputs.\")\n    print(\"\")\n    print(\"    --inputfileadd filename where the new java messages to ignore are stored in.\")\n    print(\"\")\n    print(\"    --inputfilerm filename where the java messages are removed from the ignored list.\")\n    print(\"\")\n    print(\"    --loadjavamessage filename pickle file that stores the dict structure containing java messages to include.\")\n    print(\"\")\n    print(\"    --savejavamessage filename pickle file that saves the final dict structure after update.\")\n    print(\"\")\n    print(\"    --printjavamessage filename print java ignored java messages stored in pickle file filenam onto console and save into a text file.\")\n    print(\"\")\n    sys.exit(1)", "code_tokens": ["def", "usage", "(", ")", ":", "global", "g_script_name", "# name of the script being run.", "print", "(", "\"\"", ")", "print", "(", "\"Usage:  \"", "+", "g_script_name", "+", "\" [...options...]\"", ")", "print", "(", "\"\"", ")", "print", "(", "\"     --help print out this help menu and show all the valid flags and inputs.\"", ")", "print", "(", "\"\"", ")", "print", "(", "\"    --inputfileadd filename where the new java messages to ignore are stored in.\"", ")", "print", "(", "\"\"", ")", "print", "(", "\"    --inputfilerm filename where the java messages are removed from the ignored list.\"", ")", "print", "(", "\"\"", ")", "print", "(", "\"    --loadjavamessage filename pickle file that stores the dict structure containing java messages to include.\"", ")", "print", "(", "\"\"", ")", "print", "(", "\"    --savejavamessage filename pickle file that saves the final dict structure after update.\"", ")", "print", "(", "\"\"", ")", "print", "(", "\"    --printjavamessage filename print java ignored java messages stored in pickle file filenam onto console and save into a text file.\"", ")", "print", "(", "\"\"", ")", "sys", ".", "exit", "(", "1", ")"], "docstring": "Illustrate what the various input flags are and the options should be.\n\n    :return: none", "docstring_tokens": ["Illustrate", "what", "the", "various", "input", "flags", "are", "and", "the", "options", "should", "be", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/addjavamessage2ignore.py#L370-L393", "partition": "test", "index": 1572, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/addjavamessage2ignore.py", "func_name": "parse_args", "original_string": "def parse_args(argv):\n    \"\"\"\n    Parse user inputs and set the corresponing global variables to perform the\n    necessary tasks.\n\n    Parameters\n    ----------\n\n    argv : string array\n        contains flags and input options from users\n\n    :return:\n    \"\"\"\n    global g_new_messages_to_exclude\n    global g_old_messages_to_remove\n    global g_load_java_message_filename\n    global g_save_java_message_filename\n    global g_print_java_messages\n\n\n    if len(argv) < 2:   # print out help menu if user did not enter any arguments.\n        usage()\n\n    i = 1\n    while (i < len(argv)):\n        s = argv[i]\n\n        if (s == \"--inputfileadd\"):         # input text file where new java messages are stored\n            i += 1\n            if (i > len(argv)):\n                usage()\n            g_new_messages_to_exclude = argv[i]\n        elif (s == \"--inputfilerm\"):        # input text file containing java messages to be removed from the ignored list\n            i += 1\n            if (i > len(argv)):\n                usage()\n            g_old_messages_to_remove = argv[i]\n        elif (s == \"--loadjavamessage\"):    # load previously saved java message pickle file from file other than\n            i += 1                          # the default one before performing update\n            if i > len(argv):\n                usage()\n            g_load_java_message_filename = argv[i]\n        elif (s == \"--savejavamessage\"):    # save updated java message in this file instead of default file\n            i += 1\n            if (i > len(argv)):\n                usage()\n            g_save_java_message_filename = argv[i]\n        elif (s == '--printjavamessage'):   # will print java message out to console and save in a text file\n            i += 1\n            g_print_java_messages = True\n            g_load_java_message_filename = argv[i]\n        elif (s == '--help'):               # print help menu and exit\n            usage()\n        else:\n            unknown_arg(s)\n\n        i += 1", "language": "python", "code": "def parse_args(argv):\n    \"\"\"\n    Parse user inputs and set the corresponing global variables to perform the\n    necessary tasks.\n\n    Parameters\n    ----------\n\n    argv : string array\n        contains flags and input options from users\n\n    :return:\n    \"\"\"\n    global g_new_messages_to_exclude\n    global g_old_messages_to_remove\n    global g_load_java_message_filename\n    global g_save_java_message_filename\n    global g_print_java_messages\n\n\n    if len(argv) < 2:   # print out help menu if user did not enter any arguments.\n        usage()\n\n    i = 1\n    while (i < len(argv)):\n        s = argv[i]\n\n        if (s == \"--inputfileadd\"):         # input text file where new java messages are stored\n            i += 1\n            if (i > len(argv)):\n                usage()\n            g_new_messages_to_exclude = argv[i]\n        elif (s == \"--inputfilerm\"):        # input text file containing java messages to be removed from the ignored list\n            i += 1\n            if (i > len(argv)):\n                usage()\n            g_old_messages_to_remove = argv[i]\n        elif (s == \"--loadjavamessage\"):    # load previously saved java message pickle file from file other than\n            i += 1                          # the default one before performing update\n            if i > len(argv):\n                usage()\n            g_load_java_message_filename = argv[i]\n        elif (s == \"--savejavamessage\"):    # save updated java message in this file instead of default file\n            i += 1\n            if (i > len(argv)):\n                usage()\n            g_save_java_message_filename = argv[i]\n        elif (s == '--printjavamessage'):   # will print java message out to console and save in a text file\n            i += 1\n            g_print_java_messages = True\n            g_load_java_message_filename = argv[i]\n        elif (s == '--help'):               # print help menu and exit\n            usage()\n        else:\n            unknown_arg(s)\n\n        i += 1", "code_tokens": ["def", "parse_args", "(", "argv", ")", ":", "global", "g_new_messages_to_exclude", "global", "g_old_messages_to_remove", "global", "g_load_java_message_filename", "global", "g_save_java_message_filename", "global", "g_print_java_messages", "if", "len", "(", "argv", ")", "<", "2", ":", "# print out help menu if user did not enter any arguments.", "usage", "(", ")", "i", "=", "1", "while", "(", "i", "<", "len", "(", "argv", ")", ")", ":", "s", "=", "argv", "[", "i", "]", "if", "(", "s", "==", "\"--inputfileadd\"", ")", ":", "# input text file where new java messages are stored", "i", "+=", "1", "if", "(", "i", ">", "len", "(", "argv", ")", ")", ":", "usage", "(", ")", "g_new_messages_to_exclude", "=", "argv", "[", "i", "]", "elif", "(", "s", "==", "\"--inputfilerm\"", ")", ":", "# input text file containing java messages to be removed from the ignored list", "i", "+=", "1", "if", "(", "i", ">", "len", "(", "argv", ")", ")", ":", "usage", "(", ")", "g_old_messages_to_remove", "=", "argv", "[", "i", "]", "elif", "(", "s", "==", "\"--loadjavamessage\"", ")", ":", "# load previously saved java message pickle file from file other than", "i", "+=", "1", "# the default one before performing update", "if", "i", ">", "len", "(", "argv", ")", ":", "usage", "(", ")", "g_load_java_message_filename", "=", "argv", "[", "i", "]", "elif", "(", "s", "==", "\"--savejavamessage\"", ")", ":", "# save updated java message in this file instead of default file", "i", "+=", "1", "if", "(", "i", ">", "len", "(", "argv", ")", ")", ":", "usage", "(", ")", "g_save_java_message_filename", "=", "argv", "[", "i", "]", "elif", "(", "s", "==", "'--printjavamessage'", ")", ":", "# will print java message out to console and save in a text file", "i", "+=", "1", "g_print_java_messages", "=", "True", "g_load_java_message_filename", "=", "argv", "[", "i", "]", "elif", "(", "s", "==", "'--help'", ")", ":", "# print help menu and exit", "usage", "(", ")", "else", ":", "unknown_arg", "(", "s", ")", "i", "+=", "1"], "docstring": "Parse user inputs and set the corresponing global variables to perform the\n    necessary tasks.\n\n    Parameters\n    ----------\n\n    argv : string array\n        contains flags and input options from users\n\n    :return:", "docstring_tokens": ["Parse", "user", "inputs", "and", "set", "the", "corresponing", "global", "variables", "to", "perform", "the", "necessary", "tasks", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/addjavamessage2ignore.py#L311-L367", "partition": "test", "index": 1571, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/addjavamessage2ignore.py", "func_name": "print_dict", "original_string": "def print_dict():\n    \"\"\"\n    Write the java ignored messages in g_ok_java_messages into a text file for humans to read.\n\n    :return: none\n    \"\"\"\n    global g_ok_java_messages\n    global g_java_messages_to_ignore_text_filename\n\n    allKeys = sorted(g_ok_java_messages.keys())\n\n    with open(g_java_messages_to_ignore_text_filename,'w') as ofile:\n        for key in allKeys:\n\n            for mess in g_ok_java_messages[key]:\n                ofile.write('KeyName: '+key+'\\n')\n                ofile.write('IgnoredMessage: '+mess+'\\n')\n\n            print('KeyName: ',key)\n            print('IgnoredMessage: ',g_ok_java_messages[key])\n            print('\\n')", "language": "python", "code": "def print_dict():\n    \"\"\"\n    Write the java ignored messages in g_ok_java_messages into a text file for humans to read.\n\n    :return: none\n    \"\"\"\n    global g_ok_java_messages\n    global g_java_messages_to_ignore_text_filename\n\n    allKeys = sorted(g_ok_java_messages.keys())\n\n    with open(g_java_messages_to_ignore_text_filename,'w') as ofile:\n        for key in allKeys:\n\n            for mess in g_ok_java_messages[key]:\n                ofile.write('KeyName: '+key+'\\n')\n                ofile.write('IgnoredMessage: '+mess+'\\n')\n\n            print('KeyName: ',key)\n            print('IgnoredMessage: ',g_ok_java_messages[key])\n            print('\\n')", "code_tokens": ["def", "print_dict", "(", ")", ":", "global", "g_ok_java_messages", "global", "g_java_messages_to_ignore_text_filename", "allKeys", "=", "sorted", "(", "g_ok_java_messages", ".", "keys", "(", ")", ")", "with", "open", "(", "g_java_messages_to_ignore_text_filename", ",", "'w'", ")", "as", "ofile", ":", "for", "key", "in", "allKeys", ":", "for", "mess", "in", "g_ok_java_messages", "[", "key", "]", ":", "ofile", ".", "write", "(", "'KeyName: '", "+", "key", "+", "'\\n'", ")", "ofile", ".", "write", "(", "'IgnoredMessage: '", "+", "mess", "+", "'\\n'", ")", "print", "(", "'KeyName: '", ",", "key", ")", "print", "(", "'IgnoredMessage: '", ",", "g_ok_java_messages", "[", "key", "]", ")", "print", "(", "'\\n'", ")"], "docstring": "Write the java ignored messages in g_ok_java_messages into a text file for humans to read.\n\n    :return: none", "docstring_tokens": ["Write", "the", "java", "ignored", "messages", "in", "g_ok_java_messages", "into", "a", "text", "file", "for", "humans", "to", "read", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/addjavamessage2ignore.py#L287-L307", "partition": "test", "index": 1570, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/addjavamessage2ignore.py", "func_name": "save_dict", "original_string": "def save_dict():\n    \"\"\"\n    Save the ignored java message dict stored in g_ok_java_messages into a pickle file for future use.\n\n    :return: none\n    \"\"\"\n    global g_ok_java_messages\n    global g_save_java_message_filename\n    global g_dict_changed\n\n    if g_dict_changed:\n        with open(g_save_java_message_filename,'wb') as ofile:\n            pickle.dump(g_ok_java_messages,ofile)", "language": "python", "code": "def save_dict():\n    \"\"\"\n    Save the ignored java message dict stored in g_ok_java_messages into a pickle file for future use.\n\n    :return: none\n    \"\"\"\n    global g_ok_java_messages\n    global g_save_java_message_filename\n    global g_dict_changed\n\n    if g_dict_changed:\n        with open(g_save_java_message_filename,'wb') as ofile:\n            pickle.dump(g_ok_java_messages,ofile)", "code_tokens": ["def", "save_dict", "(", ")", ":", "global", "g_ok_java_messages", "global", "g_save_java_message_filename", "global", "g_dict_changed", "if", "g_dict_changed", ":", "with", "open", "(", "g_save_java_message_filename", ",", "'wb'", ")", "as", "ofile", ":", "pickle", ".", "dump", "(", "g_ok_java_messages", ",", "ofile", ")"], "docstring": "Save the ignored java message dict stored in g_ok_java_messages into a pickle file for future use.\n\n    :return: none", "docstring_tokens": ["Save", "the", "ignored", "java", "message", "dict", "stored", "in", "g_ok_java_messages", "into", "a", "pickle", "file", "for", "future", "use", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/addjavamessage2ignore.py#L273-L285", "partition": "test", "index": 1569, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/addjavamessage2ignore.py", "func_name": "extract_message_to_dict", "original_string": "def extract_message_to_dict(filename):\n    \"\"\"\n    Read in a text file that java messages to be ignored and generate a dictionary structure out of\n    it with key and value pairs.  The keys are test names and the values are lists of java message\n    strings associated with that test name where we are either going to add to the existing java messages\n    to ignore or remove them from g_ok_java_messages.\n\n    Parameters\n    ----------\n\n    filename :  Str\n       filename that contains ignored java messages.  The text file shall contain something like this:\n        keyName = general\n        Message = nfolds: nfolds cannot be larger than the number of rows (406).\n        KeyName = pyunit_cv_cars_gbm.py\n        Message = Caught exception: Illegal argument(s) for GBM model: GBM_model_python_1452503348770_2586.  \\\n            Details: ERRR on field: _nfolds: nfolds must be either 0 or >1.\n        ...\n\n    :return:\n    message_dict : dict\n        contains java message to be ignored with key as unit test name or \"general\" and values as list of ignored java\n        messages.\n    \"\"\"\n    message_dict = {}\n\n    if os.path.isfile(filename):\n        # open file to read in new exclude messages if it exists\n        with open(filename,'r') as wfile:\n\n            key = \"\"\n            val = \"\"\n            startMess = False\n\n            while 1:\n                each_line = wfile.readline()\n\n                if not each_line:   # reached EOF\n                    if startMess:\n                        add_to_dict(val.strip(),key,message_dict)\n                    break\n\n                # found a test name or general with values to follow\n                if \"keyname\" in each_line.lower():  # name of test file or the word \"general\"\n                    temp_strings = each_line.strip().split('=')\n\n                    if (len(temp_strings) > 1): # make sure the line is formatted sort of correctly\n                        if startMess:   # this is the start of a new key/value pair\n                            add_to_dict(val.strip(),key,message_dict)\n                            val = \"\"\n\n                        key = temp_strings[1].strip()\n                        startMess = False\n\n                if (len(each_line) > 1) and startMess:\n                    val += each_line\n\n                if \"ignoredmessage\" in each_line.lower():\n                    startMess = True    # start of a Java message.\n                    temp_mess = each_line.split('=')\n\n                    if (len(temp_mess) > 1):\n                        val = temp_mess[1]\n\n\n\n    return message_dict", "language": "python", "code": "def extract_message_to_dict(filename):\n    \"\"\"\n    Read in a text file that java messages to be ignored and generate a dictionary structure out of\n    it with key and value pairs.  The keys are test names and the values are lists of java message\n    strings associated with that test name where we are either going to add to the existing java messages\n    to ignore or remove them from g_ok_java_messages.\n\n    Parameters\n    ----------\n\n    filename :  Str\n       filename that contains ignored java messages.  The text file shall contain something like this:\n        keyName = general\n        Message = nfolds: nfolds cannot be larger than the number of rows (406).\n        KeyName = pyunit_cv_cars_gbm.py\n        Message = Caught exception: Illegal argument(s) for GBM model: GBM_model_python_1452503348770_2586.  \\\n            Details: ERRR on field: _nfolds: nfolds must be either 0 or >1.\n        ...\n\n    :return:\n    message_dict : dict\n        contains java message to be ignored with key as unit test name or \"general\" and values as list of ignored java\n        messages.\n    \"\"\"\n    message_dict = {}\n\n    if os.path.isfile(filename):\n        # open file to read in new exclude messages if it exists\n        with open(filename,'r') as wfile:\n\n            key = \"\"\n            val = \"\"\n            startMess = False\n\n            while 1:\n                each_line = wfile.readline()\n\n                if not each_line:   # reached EOF\n                    if startMess:\n                        add_to_dict(val.strip(),key,message_dict)\n                    break\n\n                # found a test name or general with values to follow\n                if \"keyname\" in each_line.lower():  # name of test file or the word \"general\"\n                    temp_strings = each_line.strip().split('=')\n\n                    if (len(temp_strings) > 1): # make sure the line is formatted sort of correctly\n                        if startMess:   # this is the start of a new key/value pair\n                            add_to_dict(val.strip(),key,message_dict)\n                            val = \"\"\n\n                        key = temp_strings[1].strip()\n                        startMess = False\n\n                if (len(each_line) > 1) and startMess:\n                    val += each_line\n\n                if \"ignoredmessage\" in each_line.lower():\n                    startMess = True    # start of a Java message.\n                    temp_mess = each_line.split('=')\n\n                    if (len(temp_mess) > 1):\n                        val = temp_mess[1]\n\n\n\n    return message_dict", "code_tokens": ["def", "extract_message_to_dict", "(", "filename", ")", ":", "message_dict", "=", "{", "}", "if", "os", ".", "path", ".", "isfile", "(", "filename", ")", ":", "# open file to read in new exclude messages if it exists", "with", "open", "(", "filename", ",", "'r'", ")", "as", "wfile", ":", "key", "=", "\"\"", "val", "=", "\"\"", "startMess", "=", "False", "while", "1", ":", "each_line", "=", "wfile", ".", "readline", "(", ")", "if", "not", "each_line", ":", "# reached EOF", "if", "startMess", ":", "add_to_dict", "(", "val", ".", "strip", "(", ")", ",", "key", ",", "message_dict", ")", "break", "# found a test name or general with values to follow", "if", "\"keyname\"", "in", "each_line", ".", "lower", "(", ")", ":", "# name of test file or the word \"general\"", "temp_strings", "=", "each_line", ".", "strip", "(", ")", ".", "split", "(", "'='", ")", "if", "(", "len", "(", "temp_strings", ")", ">", "1", ")", ":", "# make sure the line is formatted sort of correctly", "if", "startMess", ":", "# this is the start of a new key/value pair", "add_to_dict", "(", "val", ".", "strip", "(", ")", ",", "key", ",", "message_dict", ")", "val", "=", "\"\"", "key", "=", "temp_strings", "[", "1", "]", ".", "strip", "(", ")", "startMess", "=", "False", "if", "(", "len", "(", "each_line", ")", ">", "1", ")", "and", "startMess", ":", "val", "+=", "each_line", "if", "\"ignoredmessage\"", "in", "each_line", ".", "lower", "(", ")", ":", "startMess", "=", "True", "# start of a Java message.", "temp_mess", "=", "each_line", ".", "split", "(", "'='", ")", "if", "(", "len", "(", "temp_mess", ")", ">", "1", ")", ":", "val", "=", "temp_mess", "[", "1", "]", "return", "message_dict"], "docstring": "Read in a text file that java messages to be ignored and generate a dictionary structure out of\n    it with key and value pairs.  The keys are test names and the values are lists of java message\n    strings associated with that test name where we are either going to add to the existing java messages\n    to ignore or remove them from g_ok_java_messages.\n\n    Parameters\n    ----------\n\n    filename :  Str\n       filename that contains ignored java messages.  The text file shall contain something like this:\n        keyName = general\n        Message = nfolds: nfolds cannot be larger than the number of rows (406).\n        KeyName = pyunit_cv_cars_gbm.py\n        Message = Caught exception: Illegal argument(s) for GBM model: GBM_model_python_1452503348770_2586.  \\\n            Details: ERRR on field: _nfolds: nfolds must be either 0 or >1.\n        ...\n\n    :return:\n    message_dict : dict\n        contains java message to be ignored with key as unit test name or \"general\" and values as list of ignored java\n        messages.", "docstring_tokens": ["Read", "in", "a", "text", "file", "that", "java", "messages", "to", "be", "ignored", "and", "generate", "a", "dictionary", "structure", "out", "of", "it", "with", "key", "and", "value", "pairs", ".", "The", "keys", "are", "test", "names", "and", "the", "values", "are", "lists", "of", "java", "message", "strings", "associated", "with", "that", "test", "name", "where", "we", "are", "either", "going", "to", "add", "to", "the", "existing", "java", "messages", "to", "ignore", "or", "remove", "them", "from", "g_ok_java_messages", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/addjavamessage2ignore.py#L179-L245", "partition": "test", "index": 1568, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/addjavamessage2ignore.py", "func_name": "update_message_dict", "original_string": "def update_message_dict(message_dict,action):\n    \"\"\"\n    Update the g_ok_java_messages dict structure by\n    1. add the new java ignored messages stored in message_dict if action == 1\n    2. remove the java ignored messages stired in message_dict if action == 2.\n\n    Parameters\n    ----------\n\n    message_dict :  Python dict\n      key: unit test name or \"general\"\n      value: list of java messages that are to be ignored if they are found when running the test stored as the key.  If\n        the key is \"general\", the list of java messages are to be ignored when running all tests.\n    action : int\n      if 1: add java ignored messages stored in message_dict to g_ok_java_messages dict;\n      if 2: remove java ignored messages stored in message_dict from g_ok_java_messages dict.\n\n    :return: none\n    \"\"\"\n    global g_ok_java_messages\n\n    allKeys = g_ok_java_messages.keys()\n\n    for key in message_dict.keys():\n        if key in allKeys:  # key already exists, just add to it\n            for message in message_dict[key]:\n\n                if action == 1:\n                    if message not in g_ok_java_messages[key]:\n                        g_ok_java_messages[key].append(message)\n\n                if action == 2:\n                    if message in g_ok_java_messages[key]:\n                        g_ok_java_messages[key].remove(message)\n        else:   # new key here.  Can only add and cannot remove\n            if action == 1:\n                g_ok_java_messages[key] = message_dict[key]", "language": "python", "code": "def update_message_dict(message_dict,action):\n    \"\"\"\n    Update the g_ok_java_messages dict structure by\n    1. add the new java ignored messages stored in message_dict if action == 1\n    2. remove the java ignored messages stired in message_dict if action == 2.\n\n    Parameters\n    ----------\n\n    message_dict :  Python dict\n      key: unit test name or \"general\"\n      value: list of java messages that are to be ignored if they are found when running the test stored as the key.  If\n        the key is \"general\", the list of java messages are to be ignored when running all tests.\n    action : int\n      if 1: add java ignored messages stored in message_dict to g_ok_java_messages dict;\n      if 2: remove java ignored messages stored in message_dict from g_ok_java_messages dict.\n\n    :return: none\n    \"\"\"\n    global g_ok_java_messages\n\n    allKeys = g_ok_java_messages.keys()\n\n    for key in message_dict.keys():\n        if key in allKeys:  # key already exists, just add to it\n            for message in message_dict[key]:\n\n                if action == 1:\n                    if message not in g_ok_java_messages[key]:\n                        g_ok_java_messages[key].append(message)\n\n                if action == 2:\n                    if message in g_ok_java_messages[key]:\n                        g_ok_java_messages[key].remove(message)\n        else:   # new key here.  Can only add and cannot remove\n            if action == 1:\n                g_ok_java_messages[key] = message_dict[key]", "code_tokens": ["def", "update_message_dict", "(", "message_dict", ",", "action", ")", ":", "global", "g_ok_java_messages", "allKeys", "=", "g_ok_java_messages", ".", "keys", "(", ")", "for", "key", "in", "message_dict", ".", "keys", "(", ")", ":", "if", "key", "in", "allKeys", ":", "# key already exists, just add to it", "for", "message", "in", "message_dict", "[", "key", "]", ":", "if", "action", "==", "1", ":", "if", "message", "not", "in", "g_ok_java_messages", "[", "key", "]", ":", "g_ok_java_messages", "[", "key", "]", ".", "append", "(", "message", ")", "if", "action", "==", "2", ":", "if", "message", "in", "g_ok_java_messages", "[", "key", "]", ":", "g_ok_java_messages", "[", "key", "]", ".", "remove", "(", "message", ")", "else", ":", "# new key here.  Can only add and cannot remove", "if", "action", "==", "1", ":", "g_ok_java_messages", "[", "key", "]", "=", "message_dict", "[", "key", "]"], "docstring": "Update the g_ok_java_messages dict structure by\n    1. add the new java ignored messages stored in message_dict if action == 1\n    2. remove the java ignored messages stired in message_dict if action == 2.\n\n    Parameters\n    ----------\n\n    message_dict :  Python dict\n      key: unit test name or \"general\"\n      value: list of java messages that are to be ignored if they are found when running the test stored as the key.  If\n        the key is \"general\", the list of java messages are to be ignored when running all tests.\n    action : int\n      if 1: add java ignored messages stored in message_dict to g_ok_java_messages dict;\n      if 2: remove java ignored messages stored in message_dict from g_ok_java_messages dict.\n\n    :return: none", "docstring_tokens": ["Update", "the", "g_ok_java_messages", "dict", "structure", "by", "1", ".", "add", "the", "new", "java", "ignored", "messages", "stored", "in", "message_dict", "if", "action", "==", "1", "2", ".", "remove", "the", "java", "ignored", "messages", "stired", "in", "message_dict", "if", "action", "==", "2", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/addjavamessage2ignore.py#L140-L176", "partition": "test", "index": 1567, "time": "2016-02-25 13:51:40"}
{"repo": "h2oai/h2o-3", "path": "scripts/run.py", "func_name": "remove_sandbox", "original_string": "def remove_sandbox(parent_dir, dir_name):\n    \"\"\"\n    This function is written to remove sandbox directories if they exist under the\n    parent_dir.\n\n    :param parent_dir: string denoting full parent directory path\n    :param dir_name: string denoting directory path which could be a sandbox\n    :return: None\n    \"\"\"\n    if \"Rsandbox\" in dir_name:\n        rsandbox_dir = os.path.join(parent_dir, dir_name)\n        try:\n            if sys.platform == \"win32\":\n                os.system(r'C:/cygwin64/bin/rm.exe -r -f \"{0}\"'.format(rsandbox_dir))\n            else:\n                shutil.rmtree(rsandbox_dir)\n        except OSError as e:\n            print(\"\")\n            print(\"ERROR: Removing RSandbox directory failed: \" + rsandbox_dir)\n            print(\"       (errno {0}): {1}\".format(e.errno, e.strerror))\n            print(\"\")\n            sys.exit(1)", "language": "python", "code": "def remove_sandbox(parent_dir, dir_name):\n    \"\"\"\n    This function is written to remove sandbox directories if they exist under the\n    parent_dir.\n\n    :param parent_dir: string denoting full parent directory path\n    :param dir_name: string denoting directory path which could be a sandbox\n    :return: None\n    \"\"\"\n    if \"Rsandbox\" in dir_name:\n        rsandbox_dir = os.path.join(parent_dir, dir_name)\n        try:\n            if sys.platform == \"win32\":\n                os.system(r'C:/cygwin64/bin/rm.exe -r -f \"{0}\"'.format(rsandbox_dir))\n            else:\n                shutil.rmtree(rsandbox_dir)\n        except OSError as e:\n            print(\"\")\n            print(\"ERROR: Removing RSandbox directory failed: \" + rsandbox_dir)\n            print(\"       (errno {0}): {1}\".format(e.errno, e.strerror))\n            print(\"\")\n            sys.exit(1)", "code_tokens": ["def", "remove_sandbox", "(", "parent_dir", ",", "dir_name", ")", ":", "if", "\"Rsandbox\"", "in", "dir_name", ":", "rsandbox_dir", "=", "os", ".", "path", ".", "join", "(", "parent_dir", ",", "dir_name", ")", "try", ":", "if", "sys", ".", "platform", "==", "\"win32\"", ":", "os", ".", "system", "(", "r'C:/cygwin64/bin/rm.exe -r -f \"{0}\"'", ".", "format", "(", "rsandbox_dir", ")", ")", "else", ":", "shutil", ".", "rmtree", "(", "rsandbox_dir", ")", "except", "OSError", "as", "e", ":", "print", "(", "\"\"", ")", "print", "(", "\"ERROR: Removing RSandbox directory failed: \"", "+", "rsandbox_dir", ")", "print", "(", "\"       (errno {0}): {1}\"", ".", "format", "(", "e", ".", "errno", ",", "e", ".", "strerror", ")", ")", "print", "(", "\"\"", ")", "sys", ".", "exit", "(", "1", ")"], "docstring": "This function is written to remove sandbox directories if they exist under the\n    parent_dir.\n\n    :param parent_dir: string denoting full parent directory path\n    :param dir_name: string denoting directory path which could be a sandbox\n    :return: None", "docstring_tokens": ["This", "function", "is", "written", "to", "remove", "sandbox", "directories", "if", "they", "exist", "under", "the", "parent_dir", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/run.py#L2590-L2611", "partition": "test", "index": 1351, "time": "2016-03-03 13:20:17"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "download_pojo", "original_string": "def download_pojo(model, path=\"\", get_jar=True, jar_name=\"\"):\n    \"\"\"\n    Download the POJO for this model to the directory specified by path; if path is \"\", then dump to screen.\n\n    :param model: the model whose scoring POJO should be retrieved.\n    :param path: an absolute path to the directory where POJO should be saved.\n    :param get_jar: retrieve the h2o-genmodel.jar also (will be saved to the same folder ``path``).\n    :param jar_name: Custom name of genmodel jar.\n    :returns: location of the downloaded POJO file.\n    \"\"\"\n    assert_is_type(model, ModelBase)\n    assert_is_type(path, str)\n    assert_is_type(get_jar, bool)\n\n    if not model.have_pojo:\n        raise H2OValueError(\"Export to POJO not supported\")\n\n    if path == \"\":\n        java_code = api(\"GET /3/Models.java/%s\" % model.model_id)\n        print(java_code)\n        return None\n    else:\n        filename = api(\"GET /3/Models.java/%s\" % model.model_id, save_to=path)\n        if get_jar:\n            if jar_name == \"\":\n                api(\"GET /3/h2o-genmodel.jar\", save_to=os.path.join(path, \"h2o-genmodel.jar\"))\n            else:\n                api(\"GET /3/h2o-genmodel.jar\", save_to=os.path.join(path, jar_name))\n        return filename", "language": "python", "code": "def download_pojo(model, path=\"\", get_jar=True, jar_name=\"\"):\n    \"\"\"\n    Download the POJO for this model to the directory specified by path; if path is \"\", then dump to screen.\n\n    :param model: the model whose scoring POJO should be retrieved.\n    :param path: an absolute path to the directory where POJO should be saved.\n    :param get_jar: retrieve the h2o-genmodel.jar also (will be saved to the same folder ``path``).\n    :param jar_name: Custom name of genmodel jar.\n    :returns: location of the downloaded POJO file.\n    \"\"\"\n    assert_is_type(model, ModelBase)\n    assert_is_type(path, str)\n    assert_is_type(get_jar, bool)\n\n    if not model.have_pojo:\n        raise H2OValueError(\"Export to POJO not supported\")\n\n    if path == \"\":\n        java_code = api(\"GET /3/Models.java/%s\" % model.model_id)\n        print(java_code)\n        return None\n    else:\n        filename = api(\"GET /3/Models.java/%s\" % model.model_id, save_to=path)\n        if get_jar:\n            if jar_name == \"\":\n                api(\"GET /3/h2o-genmodel.jar\", save_to=os.path.join(path, \"h2o-genmodel.jar\"))\n            else:\n                api(\"GET /3/h2o-genmodel.jar\", save_to=os.path.join(path, jar_name))\n        return filename", "code_tokens": ["def", "download_pojo", "(", "model", ",", "path", "=", "\"\"", ",", "get_jar", "=", "True", ",", "jar_name", "=", "\"\"", ")", ":", "assert_is_type", "(", "model", ",", "ModelBase", ")", "assert_is_type", "(", "path", ",", "str", ")", "assert_is_type", "(", "get_jar", ",", "bool", ")", "if", "not", "model", ".", "have_pojo", ":", "raise", "H2OValueError", "(", "\"Export to POJO not supported\"", ")", "if", "path", "==", "\"\"", ":", "java_code", "=", "api", "(", "\"GET /3/Models.java/%s\"", "%", "model", ".", "model_id", ")", "print", "(", "java_code", ")", "return", "None", "else", ":", "filename", "=", "api", "(", "\"GET /3/Models.java/%s\"", "%", "model", ".", "model_id", ",", "save_to", "=", "path", ")", "if", "get_jar", ":", "if", "jar_name", "==", "\"\"", ":", "api", "(", "\"GET /3/h2o-genmodel.jar\"", ",", "save_to", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"h2o-genmodel.jar\"", ")", ")", "else", ":", "api", "(", "\"GET /3/h2o-genmodel.jar\"", ",", "save_to", "=", "os", ".", "path", ".", "join", "(", "path", ",", "jar_name", ")", ")", "return", "filename"], "docstring": "Download the POJO for this model to the directory specified by path; if path is \"\", then dump to screen.\n\n    :param model: the model whose scoring POJO should be retrieved.\n    :param path: an absolute path to the directory where POJO should be saved.\n    :param get_jar: retrieve the h2o-genmodel.jar also (will be saved to the same folder ``path``).\n    :param jar_name: Custom name of genmodel jar.\n    :returns: location of the downloaded POJO file.", "docstring_tokens": ["Download", "the", "POJO", "for", "this", "model", "to", "the", "directory", "specified", "by", "path", ";", "if", "path", "is", "then", "dump", "to", "screen", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L978-L1006", "partition": "test", "index": 1466, "time": "2016-03-08 15:51:27"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "import_file", "original_string": "def import_file(path=None, destination_frame=None, parse=True, header=0, sep=None, col_names=None, col_types=None,\n                na_strings=None, pattern=None, skipped_columns=None, custom_non_data_line_markers = None):\n    \"\"\"\n    Import a dataset that is already on the cluster.\n\n    The path to the data must be a valid path for each node in the H2O cluster. If some node in the H2O cluster\n    cannot see the file, then an exception will be thrown by the H2O cluster. Does a parallel/distributed\n    multi-threaded pull of the data. The main difference between this method and :func:`upload_file` is that\n    the latter works with local files, whereas this method imports remote files (i.e. files local to the server).\n    If you running H2O server on your own maching, then both methods behave the same.\n\n    :param path: path(s) specifying the location of the data to import or a path to a directory of files to import\n    :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will be\n        automatically generated.\n    :param parse: If True, the file should be parsed after import. If False, then a list is returned containing the file path.\n    :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n    :param sep: The field separator character. Values on each line of the file are separated by\n        this character. If not provided, the parser will automatically detect the separator.\n    :param col_names: A list of column names for the file.\n    :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n        should be forced to a certain type upon import parsing. If a list, the types for elements that are\n        one will be guessed. The possible types a column may have are:\n\n        - \"unknown\" - this will force the column to be parsed as all NA\n        - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n        - \"string\"  - force the column to be parsed as a string\n        - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n          data in the optimal manner.\n        - \"enum\"    - force the column to be parsed as a categorical column.\n        - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n          list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n          \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n          Times can also contain \"AM\" or \"PM\".\n    :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n        of column names to strings which are to be interpreted as missing values.\n    :param pattern: Character string containing a regular expression to match file(s) in the folder if `path` is a\n        directory.\n    :param skipped_columns: an integer list of column indices to skip and not parsed into the final frame from the import file.\n    :param custom_non_data_line_markers: If a line in imported file starts with any character in given string it will NOT be imported. Empty string means all lines are imported, None means that default behaviour for given format will be used\n\n    :returns: a new :class:`H2OFrame` instance.\n\n    :examples:\n        >>> # Single file import\n        >>> iris = import_file(\"h2o-3/smalldata/iris.csv\")\n        >>> # Return all files in the folder iris/ matching the regex r\"iris_.*\\.csv\"\n        >>> iris_pattern = h2o.import_file(path = \"h2o-3/smalldata/iris\",\n        ...                                pattern = \"iris_.*\\.csv\")\n    \"\"\"\n    coltype = U(None, \"unknown\", \"uuid\", \"string\", \"float\", \"real\", \"double\", \"int\", \"numeric\",\n                \"categorical\", \"factor\", \"enum\", \"time\")\n    natype = U(str, [str])\n    assert_is_type(path, str, [str])\n    assert_is_type(pattern, str, None)\n    assert_is_type(destination_frame, str, None)\n    assert_is_type(parse, bool)\n    assert_is_type(header, -1, 0, 1)\n    assert_is_type(sep, None, I(str, lambda s: len(s) == 1))\n    assert_is_type(col_names, [str], None)\n    assert_is_type(col_types, [coltype], {str: coltype}, None)\n    assert_is_type(na_strings, [natype], {str: natype}, None)\n    assert isinstance(skipped_columns, (type(None), list)), \"The skipped_columns should be an list of column names!\"\n    check_frame_id(destination_frame)\n    patharr = path if isinstance(path, list) else [path]\n    if any(os.path.split(p)[0] == \"~\" for p in patharr):\n        raise H2OValueError(\"Paths relative to a current user (~) are not valid in the server environment. \"\n                            \"Please use absolute paths if possible.\")\n    if not parse:\n        return lazy_import(path, pattern)\n    else:\n        return H2OFrame()._import_parse(path, pattern, destination_frame, header, sep, col_names, col_types, na_strings,\n                                        skipped_columns, custom_non_data_line_markers)", "language": "python", "code": "def import_file(path=None, destination_frame=None, parse=True, header=0, sep=None, col_names=None, col_types=None,\n                na_strings=None, pattern=None, skipped_columns=None, custom_non_data_line_markers = None):\n    \"\"\"\n    Import a dataset that is already on the cluster.\n\n    The path to the data must be a valid path for each node in the H2O cluster. If some node in the H2O cluster\n    cannot see the file, then an exception will be thrown by the H2O cluster. Does a parallel/distributed\n    multi-threaded pull of the data. The main difference between this method and :func:`upload_file` is that\n    the latter works with local files, whereas this method imports remote files (i.e. files local to the server).\n    If you running H2O server on your own maching, then both methods behave the same.\n\n    :param path: path(s) specifying the location of the data to import or a path to a directory of files to import\n    :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will be\n        automatically generated.\n    :param parse: If True, the file should be parsed after import. If False, then a list is returned containing the file path.\n    :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n    :param sep: The field separator character. Values on each line of the file are separated by\n        this character. If not provided, the parser will automatically detect the separator.\n    :param col_names: A list of column names for the file.\n    :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n        should be forced to a certain type upon import parsing. If a list, the types for elements that are\n        one will be guessed. The possible types a column may have are:\n\n        - \"unknown\" - this will force the column to be parsed as all NA\n        - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n        - \"string\"  - force the column to be parsed as a string\n        - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n          data in the optimal manner.\n        - \"enum\"    - force the column to be parsed as a categorical column.\n        - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n          list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n          \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n          Times can also contain \"AM\" or \"PM\".\n    :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n        of column names to strings which are to be interpreted as missing values.\n    :param pattern: Character string containing a regular expression to match file(s) in the folder if `path` is a\n        directory.\n    :param skipped_columns: an integer list of column indices to skip and not parsed into the final frame from the import file.\n    :param custom_non_data_line_markers: If a line in imported file starts with any character in given string it will NOT be imported. Empty string means all lines are imported, None means that default behaviour for given format will be used\n\n    :returns: a new :class:`H2OFrame` instance.\n\n    :examples:\n        >>> # Single file import\n        >>> iris = import_file(\"h2o-3/smalldata/iris.csv\")\n        >>> # Return all files in the folder iris/ matching the regex r\"iris_.*\\.csv\"\n        >>> iris_pattern = h2o.import_file(path = \"h2o-3/smalldata/iris\",\n        ...                                pattern = \"iris_.*\\.csv\")\n    \"\"\"\n    coltype = U(None, \"unknown\", \"uuid\", \"string\", \"float\", \"real\", \"double\", \"int\", \"numeric\",\n                \"categorical\", \"factor\", \"enum\", \"time\")\n    natype = U(str, [str])\n    assert_is_type(path, str, [str])\n    assert_is_type(pattern, str, None)\n    assert_is_type(destination_frame, str, None)\n    assert_is_type(parse, bool)\n    assert_is_type(header, -1, 0, 1)\n    assert_is_type(sep, None, I(str, lambda s: len(s) == 1))\n    assert_is_type(col_names, [str], None)\n    assert_is_type(col_types, [coltype], {str: coltype}, None)\n    assert_is_type(na_strings, [natype], {str: natype}, None)\n    assert isinstance(skipped_columns, (type(None), list)), \"The skipped_columns should be an list of column names!\"\n    check_frame_id(destination_frame)\n    patharr = path if isinstance(path, list) else [path]\n    if any(os.path.split(p)[0] == \"~\" for p in patharr):\n        raise H2OValueError(\"Paths relative to a current user (~) are not valid in the server environment. \"\n                            \"Please use absolute paths if possible.\")\n    if not parse:\n        return lazy_import(path, pattern)\n    else:\n        return H2OFrame()._import_parse(path, pattern, destination_frame, header, sep, col_names, col_types, na_strings,\n                                        skipped_columns, custom_non_data_line_markers)", "code_tokens": ["def", "import_file", "(", "path", "=", "None", ",", "destination_frame", "=", "None", ",", "parse", "=", "True", ",", "header", "=", "0", ",", "sep", "=", "None", ",", "col_names", "=", "None", ",", "col_types", "=", "None", ",", "na_strings", "=", "None", ",", "pattern", "=", "None", ",", "skipped_columns", "=", "None", ",", "custom_non_data_line_markers", "=", "None", ")", ":", "coltype", "=", "U", "(", "None", ",", "\"unknown\"", ",", "\"uuid\"", ",", "\"string\"", ",", "\"float\"", ",", "\"real\"", ",", "\"double\"", ",", "\"int\"", ",", "\"numeric\"", ",", "\"categorical\"", ",", "\"factor\"", ",", "\"enum\"", ",", "\"time\"", ")", "natype", "=", "U", "(", "str", ",", "[", "str", "]", ")", "assert_is_type", "(", "path", ",", "str", ",", "[", "str", "]", ")", "assert_is_type", "(", "pattern", ",", "str", ",", "None", ")", "assert_is_type", "(", "destination_frame", ",", "str", ",", "None", ")", "assert_is_type", "(", "parse", ",", "bool", ")", "assert_is_type", "(", "header", ",", "-", "1", ",", "0", ",", "1", ")", "assert_is_type", "(", "sep", ",", "None", ",", "I", "(", "str", ",", "lambda", "s", ":", "len", "(", "s", ")", "==", "1", ")", ")", "assert_is_type", "(", "col_names", ",", "[", "str", "]", ",", "None", ")", "assert_is_type", "(", "col_types", ",", "[", "coltype", "]", ",", "{", "str", ":", "coltype", "}", ",", "None", ")", "assert_is_type", "(", "na_strings", ",", "[", "natype", "]", ",", "{", "str", ":", "natype", "}", ",", "None", ")", "assert", "isinstance", "(", "skipped_columns", ",", "(", "type", "(", "None", ")", ",", "list", ")", ")", ",", "\"The skipped_columns should be an list of column names!\"", "check_frame_id", "(", "destination_frame", ")", "patharr", "=", "path", "if", "isinstance", "(", "path", ",", "list", ")", "else", "[", "path", "]", "if", "any", "(", "os", ".", "path", ".", "split", "(", "p", ")", "[", "0", "]", "==", "\"~\"", "for", "p", "in", "patharr", ")", ":", "raise", "H2OValueError", "(", "\"Paths relative to a current user (~) are not valid in the server environment. \"", "\"Please use absolute paths if possible.\"", ")", "if", "not", "parse", ":", "return", "lazy_import", "(", "path", ",", "pattern", ")", "else", ":", "return", "H2OFrame", "(", ")", ".", "_import_parse", "(", "path", ",", "pattern", ",", "destination_frame", ",", "header", ",", "sep", ",", "col_names", ",", "col_types", ",", "na_strings", ",", "skipped_columns", ",", "custom_non_data_line_markers", ")"], "docstring": "Import a dataset that is already on the cluster.\n\n    The path to the data must be a valid path for each node in the H2O cluster. If some node in the H2O cluster\n    cannot see the file, then an exception will be thrown by the H2O cluster. Does a parallel/distributed\n    multi-threaded pull of the data. The main difference between this method and :func:`upload_file` is that\n    the latter works with local files, whereas this method imports remote files (i.e. files local to the server).\n    If you running H2O server on your own maching, then both methods behave the same.\n\n    :param path: path(s) specifying the location of the data to import or a path to a directory of files to import\n    :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will be\n        automatically generated.\n    :param parse: If True, the file should be parsed after import. If False, then a list is returned containing the file path.\n    :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n    :param sep: The field separator character. Values on each line of the file are separated by\n        this character. If not provided, the parser will automatically detect the separator.\n    :param col_names: A list of column names for the file.\n    :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n        should be forced to a certain type upon import parsing. If a list, the types for elements that are\n        one will be guessed. The possible types a column may have are:\n\n        - \"unknown\" - this will force the column to be parsed as all NA\n        - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n        - \"string\"  - force the column to be parsed as a string\n        - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n          data in the optimal manner.\n        - \"enum\"    - force the column to be parsed as a categorical column.\n        - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n          list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n          \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n          Times can also contain \"AM\" or \"PM\".\n    :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n        of column names to strings which are to be interpreted as missing values.\n    :param pattern: Character string containing a regular expression to match file(s) in the folder if `path` is a\n        directory.\n    :param skipped_columns: an integer list of column indices to skip and not parsed into the final frame from the import file.\n    :param custom_non_data_line_markers: If a line in imported file starts with any character in given string it will NOT be imported. Empty string means all lines are imported, None means that default behaviour for given format will be used\n\n    :returns: a new :class:`H2OFrame` instance.\n\n    :examples:\n        >>> # Single file import\n        >>> iris = import_file(\"h2o-3/smalldata/iris.csv\")\n        >>> # Return all files in the folder iris/ matching the regex r\"iris_.*\\.csv\"\n        >>> iris_pattern = h2o.import_file(path = \"h2o-3/smalldata/iris\",\n        ...                                pattern = \"iris_.*\\.csv\")", "docstring_tokens": ["Import", "a", "dataset", "that", "is", "already", "on", "the", "cluster", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L366-L437", "partition": "test", "index": 1457, "time": "2016-03-08 15:51:27"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "get_grid", "original_string": "def get_grid(grid_id):\n    \"\"\"\n    Return the specified grid.\n\n    :param grid_id: The grid identification in h2o\n\n    :returns: an :class:`H2OGridSearch` instance.\n    \"\"\"\n    assert_is_type(grid_id, str)\n    grid_json = api(\"GET /99/Grids/%s\" % grid_id)\n    models = [get_model(key[\"name\"]) for key in grid_json[\"model_ids\"]]\n    # get first model returned in list of models from grid search to get model class (binomial, multinomial, etc)\n    first_model_json = api(\"GET /3/Models/%s\" % grid_json[\"model_ids\"][0][\"name\"])[\"models\"][0]\n    gs = H2OGridSearch(None, {}, grid_id)\n    gs._resolve_grid(grid_id, grid_json, first_model_json)\n    gs.models = models\n    hyper_params = {param: set() for param in gs.hyper_names}\n    for param in gs.hyper_names:\n        for model in models:\n            if isinstance(model.full_parameters[param][\"actual_value\"], list):\n                hyper_params[param].add(model.full_parameters[param][\"actual_value\"][0])\n            else:\n                hyper_params[param].add(model.full_parameters[param][\"actual_value\"])\n\n    hyper_params = {str(param): list(vals) for param, vals in hyper_params.items()}\n    gs.hyper_params = hyper_params\n    gs.model = model.__class__()\n    return gs", "language": "python", "code": "def get_grid(grid_id):\n    \"\"\"\n    Return the specified grid.\n\n    :param grid_id: The grid identification in h2o\n\n    :returns: an :class:`H2OGridSearch` instance.\n    \"\"\"\n    assert_is_type(grid_id, str)\n    grid_json = api(\"GET /99/Grids/%s\" % grid_id)\n    models = [get_model(key[\"name\"]) for key in grid_json[\"model_ids\"]]\n    # get first model returned in list of models from grid search to get model class (binomial, multinomial, etc)\n    first_model_json = api(\"GET /3/Models/%s\" % grid_json[\"model_ids\"][0][\"name\"])[\"models\"][0]\n    gs = H2OGridSearch(None, {}, grid_id)\n    gs._resolve_grid(grid_id, grid_json, first_model_json)\n    gs.models = models\n    hyper_params = {param: set() for param in gs.hyper_names}\n    for param in gs.hyper_names:\n        for model in models:\n            if isinstance(model.full_parameters[param][\"actual_value\"], list):\n                hyper_params[param].add(model.full_parameters[param][\"actual_value\"][0])\n            else:\n                hyper_params[param].add(model.full_parameters[param][\"actual_value\"])\n\n    hyper_params = {str(param): list(vals) for param, vals in hyper_params.items()}\n    gs.hyper_params = hyper_params\n    gs.model = model.__class__()\n    return gs", "code_tokens": ["def", "get_grid", "(", "grid_id", ")", ":", "assert_is_type", "(", "grid_id", ",", "str", ")", "grid_json", "=", "api", "(", "\"GET /99/Grids/%s\"", "%", "grid_id", ")", "models", "=", "[", "get_model", "(", "key", "[", "\"name\"", "]", ")", "for", "key", "in", "grid_json", "[", "\"model_ids\"", "]", "]", "# get first model returned in list of models from grid search to get model class (binomial, multinomial, etc)", "first_model_json", "=", "api", "(", "\"GET /3/Models/%s\"", "%", "grid_json", "[", "\"model_ids\"", "]", "[", "0", "]", "[", "\"name\"", "]", ")", "[", "\"models\"", "]", "[", "0", "]", "gs", "=", "H2OGridSearch", "(", "None", ",", "{", "}", ",", "grid_id", ")", "gs", ".", "_resolve_grid", "(", "grid_id", ",", "grid_json", ",", "first_model_json", ")", "gs", ".", "models", "=", "models", "hyper_params", "=", "{", "param", ":", "set", "(", ")", "for", "param", "in", "gs", ".", "hyper_names", "}", "for", "param", "in", "gs", ".", "hyper_names", ":", "for", "model", "in", "models", ":", "if", "isinstance", "(", "model", ".", "full_parameters", "[", "param", "]", "[", "\"actual_value\"", "]", ",", "list", ")", ":", "hyper_params", "[", "param", "]", ".", "add", "(", "model", ".", "full_parameters", "[", "param", "]", "[", "\"actual_value\"", "]", "[", "0", "]", ")", "else", ":", "hyper_params", "[", "param", "]", ".", "add", "(", "model", ".", "full_parameters", "[", "param", "]", "[", "\"actual_value\"", "]", ")", "hyper_params", "=", "{", "str", "(", "param", ")", ":", "list", "(", "vals", ")", "for", "param", ",", "vals", "in", "hyper_params", ".", "items", "(", ")", "}", "gs", ".", "hyper_params", "=", "hyper_params", "gs", ".", "model", "=", "model", ".", "__class__", "(", ")", "return", "gs"], "docstring": "Return the specified grid.\n\n    :param grid_id: The grid identification in h2o\n\n    :returns: an :class:`H2OGridSearch` instance.", "docstring_tokens": ["Return", "the", "specified", "grid", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L828-L855", "partition": "test", "index": 1464, "time": "2016-04-09 06:05:41"}
{"repo": "h2oai/h2o-3", "path": "h2o-docs/src/product/sphinxext/apigen.py", "func_name": "ApiDocWriter.discover_modules", "original_string": "def discover_modules(self):\n        ''' Return module sequence discovered from ``self.package_name`` \n\n\n        Parameters\n        ----------\n        None\n\n        Returns\n        -------\n        mods : sequence\n            Sequence of module names within ``self.package_name``\n\n        Examples\n        --------\n        >>> dw = ApiDocWriter('sphinx')\n        >>> mods = dw.discover_modules()\n        >>> 'sphinx.util' in mods\n        True\n        >>> dw.package_skip_patterns.append('\\.util$')\n        >>> 'sphinx.util' in dw.discover_modules()\n        False\n        >>> \n        '''\n        modules = [self.package_name]\n        # raw directory parsing\n        for dirpath, dirnames, filenames in os.walk(self.root_path):\n            # Check directory names for packages\n            root_uri = self._path2uri(os.path.join(self.root_path,\n                                                   dirpath))\n            for dirname in dirnames[:]: # copy list - we modify inplace\n                package_uri = '.'.join((root_uri, dirname))\n                if (self._uri2path(package_uri) and\n                    self._survives_exclude(package_uri, 'package')):\n                    modules.append(package_uri)\n                else:\n                    dirnames.remove(dirname)\n            # Check filenames for modules\n            for filename in filenames:\n                module_name = filename[:-3]\n                module_uri = '.'.join((root_uri, module_name))\n                if (self._uri2path(module_uri) and\n                    self._survives_exclude(module_uri, 'module')):\n                    modules.append(module_uri)\n        return sorted(modules)", "language": "python", "code": "def discover_modules(self):\n        ''' Return module sequence discovered from ``self.package_name`` \n\n\n        Parameters\n        ----------\n        None\n\n        Returns\n        -------\n        mods : sequence\n            Sequence of module names within ``self.package_name``\n\n        Examples\n        --------\n        >>> dw = ApiDocWriter('sphinx')\n        >>> mods = dw.discover_modules()\n        >>> 'sphinx.util' in mods\n        True\n        >>> dw.package_skip_patterns.append('\\.util$')\n        >>> 'sphinx.util' in dw.discover_modules()\n        False\n        >>> \n        '''\n        modules = [self.package_name]\n        # raw directory parsing\n        for dirpath, dirnames, filenames in os.walk(self.root_path):\n            # Check directory names for packages\n            root_uri = self._path2uri(os.path.join(self.root_path,\n                                                   dirpath))\n            for dirname in dirnames[:]: # copy list - we modify inplace\n                package_uri = '.'.join((root_uri, dirname))\n                if (self._uri2path(package_uri) and\n                    self._survives_exclude(package_uri, 'package')):\n                    modules.append(package_uri)\n                else:\n                    dirnames.remove(dirname)\n            # Check filenames for modules\n            for filename in filenames:\n                module_name = filename[:-3]\n                module_uri = '.'.join((root_uri, module_name))\n                if (self._uri2path(module_uri) and\n                    self._survives_exclude(module_uri, 'module')):\n                    modules.append(module_uri)\n        return sorted(modules)", "code_tokens": ["def", "discover_modules", "(", "self", ")", ":", "modules", "=", "[", "self", ".", "package_name", "]", "# raw directory parsing", "for", "dirpath", ",", "dirnames", ",", "filenames", "in", "os", ".", "walk", "(", "self", ".", "root_path", ")", ":", "# Check directory names for packages", "root_uri", "=", "self", ".", "_path2uri", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "dirpath", ")", ")", "for", "dirname", "in", "dirnames", "[", ":", "]", ":", "# copy list - we modify inplace", "package_uri", "=", "'.'", ".", "join", "(", "(", "root_uri", ",", "dirname", ")", ")", "if", "(", "self", ".", "_uri2path", "(", "package_uri", ")", "and", "self", ".", "_survives_exclude", "(", "package_uri", ",", "'package'", ")", ")", ":", "modules", ".", "append", "(", "package_uri", ")", "else", ":", "dirnames", ".", "remove", "(", "dirname", ")", "# Check filenames for modules", "for", "filename", "in", "filenames", ":", "module_name", "=", "filename", "[", ":", "-", "3", "]", "module_uri", "=", "'.'", ".", "join", "(", "(", "root_uri", ",", "module_name", ")", ")", "if", "(", "self", ".", "_uri2path", "(", "module_uri", ")", "and", "self", ".", "_survives_exclude", "(", "module_uri", ",", "'module'", ")", ")", ":", "modules", ".", "append", "(", "module_uri", ")", "return", "sorted", "(", "modules", ")"], "docstring": "Return module sequence discovered from ``self.package_name`` \n\n\n        Parameters\n        ----------\n        None\n\n        Returns\n        -------\n        mods : sequence\n            Sequence of module names within ``self.package_name``\n\n        Examples\n        --------\n        >>> dw = ApiDocWriter('sphinx')\n        >>> mods = dw.discover_modules()\n        >>> 'sphinx.util' in mods\n        True\n        >>> dw.package_skip_patterns.append('\\.util$')\n        >>> 'sphinx.util' in dw.discover_modules()\n        False\n        >>>", "docstring_tokens": ["Return", "module", "sequence", "discovered", "from", "self", ".", "package_name"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-docs/src/product/sphinxext/apigen.py#L309-L353", "partition": "test", "index": 1561, "time": "2016-05-04 08:57:54"}
{"repo": "h2oai/h2o-3", "path": "h2o-docs/src/product/sphinxext/apigen.py", "func_name": "ApiDocWriter.write_api_docs", "original_string": "def write_api_docs(self, outdir):\n        \"\"\"Generate API reST files.\n\n        Parameters\n        ----------\n        outdir : string\n            Directory name in which to store files\n            We create automatic filenames for each module\n            \n        Returns\n        -------\n        None\n\n        Notes\n        -----\n        Sets self.written_modules to list of written modules\n        \"\"\"\n        if not os.path.exists(outdir):\n            os.mkdir(outdir)\n        # compose list of modules\n        modules = self.discover_modules()\n        self.write_modules_api(modules,outdir)", "language": "python", "code": "def write_api_docs(self, outdir):\n        \"\"\"Generate API reST files.\n\n        Parameters\n        ----------\n        outdir : string\n            Directory name in which to store files\n            We create automatic filenames for each module\n            \n        Returns\n        -------\n        None\n\n        Notes\n        -----\n        Sets self.written_modules to list of written modules\n        \"\"\"\n        if not os.path.exists(outdir):\n            os.mkdir(outdir)\n        # compose list of modules\n        modules = self.discover_modules()\n        self.write_modules_api(modules,outdir)", "code_tokens": ["def", "write_api_docs", "(", "self", ",", "outdir", ")", ":", "if", "not", "os", ".", "path", ".", "exists", "(", "outdir", ")", ":", "os", ".", "mkdir", "(", "outdir", ")", "# compose list of modules", "modules", "=", "self", ".", "discover_modules", "(", ")", "self", ".", "write_modules_api", "(", "modules", ",", "outdir", ")"], "docstring": "Generate API reST files.\n\n        Parameters\n        ----------\n        outdir : string\n            Directory name in which to store files\n            We create automatic filenames for each module\n            \n        Returns\n        -------\n        None\n\n        Notes\n        -----\n        Sets self.written_modules to list of written modules", "docstring_tokens": ["Generate", "API", "reST", "files", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-docs/src/product/sphinxext/apigen.py#L371-L392", "partition": "test", "index": 1562, "time": "2016-05-04 08:57:54"}
{"repo": "h2oai/h2o-3", "path": "h2o-docs/src/product/sphinxext/apigen.py", "func_name": "ApiDocWriter.write_index", "original_string": "def write_index(self, outdir, froot='gen', relative_to=None):\n        \"\"\"Make a reST API index file from written files\n\n        Parameters\n        ----------\n        path : string\n            Filename to write index to\n        outdir : string\n            Directory to which to write generated index file\n        froot : string, optional\n            root (filename without extension) of filename to write to\n            Defaults to 'gen'.  We add ``self.rst_extension``.\n        relative_to : string\n            path to which written filenames are relative.  This\n            component of the written file path will be removed from\n            outdir, in the generated index.  Default is None, meaning,\n            leave path as it is.\n        \"\"\"\n        if self.written_modules is None:\n            raise ValueError('No modules written')\n        # Get full filename path\n        path = os.path.join(outdir, froot+self.rst_extension)\n        # Path written into index is relative to rootpath\n        if relative_to is not None:\n            relpath = outdir.replace(relative_to + os.path.sep, '')\n        else:\n            relpath = outdir\n        idx = open(path,'wt')\n        w = idx.write\n        w('.. AUTO-GENERATED FILE -- DO NOT EDIT!\\n\\n')\n        w('.. toctree::\\n\\n')\n        for f in self.written_modules:\n            w('   %s\\n' % os.path.join(relpath,f))\n        idx.close()", "language": "python", "code": "def write_index(self, outdir, froot='gen', relative_to=None):\n        \"\"\"Make a reST API index file from written files\n\n        Parameters\n        ----------\n        path : string\n            Filename to write index to\n        outdir : string\n            Directory to which to write generated index file\n        froot : string, optional\n            root (filename without extension) of filename to write to\n            Defaults to 'gen'.  We add ``self.rst_extension``.\n        relative_to : string\n            path to which written filenames are relative.  This\n            component of the written file path will be removed from\n            outdir, in the generated index.  Default is None, meaning,\n            leave path as it is.\n        \"\"\"\n        if self.written_modules is None:\n            raise ValueError('No modules written')\n        # Get full filename path\n        path = os.path.join(outdir, froot+self.rst_extension)\n        # Path written into index is relative to rootpath\n        if relative_to is not None:\n            relpath = outdir.replace(relative_to + os.path.sep, '')\n        else:\n            relpath = outdir\n        idx = open(path,'wt')\n        w = idx.write\n        w('.. AUTO-GENERATED FILE -- DO NOT EDIT!\\n\\n')\n        w('.. toctree::\\n\\n')\n        for f in self.written_modules:\n            w('   %s\\n' % os.path.join(relpath,f))\n        idx.close()", "code_tokens": ["def", "write_index", "(", "self", ",", "outdir", ",", "froot", "=", "'gen'", ",", "relative_to", "=", "None", ")", ":", "if", "self", ".", "written_modules", "is", "None", ":", "raise", "ValueError", "(", "'No modules written'", ")", "# Get full filename path", "path", "=", "os", ".", "path", ".", "join", "(", "outdir", ",", "froot", "+", "self", ".", "rst_extension", ")", "# Path written into index is relative to rootpath", "if", "relative_to", "is", "not", "None", ":", "relpath", "=", "outdir", ".", "replace", "(", "relative_to", "+", "os", ".", "path", ".", "sep", ",", "''", ")", "else", ":", "relpath", "=", "outdir", "idx", "=", "open", "(", "path", ",", "'wt'", ")", "w", "=", "idx", ".", "write", "w", "(", "'.. AUTO-GENERATED FILE -- DO NOT EDIT!\\n\\n'", ")", "w", "(", "'.. toctree::\\n\\n'", ")", "for", "f", "in", "self", ".", "written_modules", ":", "w", "(", "'   %s\\n'", "%", "os", ".", "path", ".", "join", "(", "relpath", ",", "f", ")", ")", "idx", ".", "close", "(", ")"], "docstring": "Make a reST API index file from written files\n\n        Parameters\n        ----------\n        path : string\n            Filename to write index to\n        outdir : string\n            Directory to which to write generated index file\n        froot : string, optional\n            root (filename without extension) of filename to write to\n            Defaults to 'gen'.  We add ``self.rst_extension``.\n        relative_to : string\n            path to which written filenames are relative.  This\n            component of the written file path will be removed from\n            outdir, in the generated index.  Default is None, meaning,\n            leave path as it is.", "docstring_tokens": ["Make", "a", "reST", "API", "index", "file", "from", "written", "files"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-docs/src/product/sphinxext/apigen.py#L394-L427", "partition": "test", "index": 1563, "time": "2016-05-04 08:57:54"}
{"repo": "h2oai/h2o-3", "path": "h2o-docs/src/product/sphinxext/apigen.py", "func_name": "ApiDocWriter._uri2path", "original_string": "def _uri2path(self, uri):\n        ''' Convert uri to absolute filepath\n\n        Parameters\n        ----------\n        uri : string\n            URI of python module to return path for\n\n        Returns\n        -------\n        path : None or string\n            Returns None if there is no valid path for this URI\n            Otherwise returns absolute file system path for URI\n\n        Examples\n        --------\n        >>> docwriter = ApiDocWriter('sphinx')\n        >>> import sphinx\n        >>> modpath = sphinx.__path__[0]\n        >>> res = docwriter._uri2path('sphinx.builder')\n        >>> res == os.path.join(modpath, 'builder.py')\n        True\n        >>> res = docwriter._uri2path('sphinx')\n        >>> res == os.path.join(modpath, '__init__.py')\n        True\n        >>> docwriter._uri2path('sphinx.does_not_exist')\n\n        '''\n        if uri == self.package_name:\n            return os.path.join(self.root_path, '__init__.py')\n        path = uri.replace('.', os.path.sep)\n        path = path.replace(self.package_name + os.path.sep, '')\n        path = os.path.join(self.root_path, path)\n        # XXX maybe check for extensions as well?\n        if os.path.exists(path + '.py'): # file\n            path += '.py'\n        elif os.path.exists(os.path.join(path, '__init__.py')):\n            path = os.path.join(path, '__init__.py')\n        else:\n            return None\n        return path", "language": "python", "code": "def _uri2path(self, uri):\n        ''' Convert uri to absolute filepath\n\n        Parameters\n        ----------\n        uri : string\n            URI of python module to return path for\n\n        Returns\n        -------\n        path : None or string\n            Returns None if there is no valid path for this URI\n            Otherwise returns absolute file system path for URI\n\n        Examples\n        --------\n        >>> docwriter = ApiDocWriter('sphinx')\n        >>> import sphinx\n        >>> modpath = sphinx.__path__[0]\n        >>> res = docwriter._uri2path('sphinx.builder')\n        >>> res == os.path.join(modpath, 'builder.py')\n        True\n        >>> res = docwriter._uri2path('sphinx')\n        >>> res == os.path.join(modpath, '__init__.py')\n        True\n        >>> docwriter._uri2path('sphinx.does_not_exist')\n\n        '''\n        if uri == self.package_name:\n            return os.path.join(self.root_path, '__init__.py')\n        path = uri.replace('.', os.path.sep)\n        path = path.replace(self.package_name + os.path.sep, '')\n        path = os.path.join(self.root_path, path)\n        # XXX maybe check for extensions as well?\n        if os.path.exists(path + '.py'): # file\n            path += '.py'\n        elif os.path.exists(os.path.join(path, '__init__.py')):\n            path = os.path.join(path, '__init__.py')\n        else:\n            return None\n        return path", "code_tokens": ["def", "_uri2path", "(", "self", ",", "uri", ")", ":", "if", "uri", "==", "self", ".", "package_name", ":", "return", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "'__init__.py'", ")", "path", "=", "uri", ".", "replace", "(", "'.'", ",", "os", ".", "path", ".", "sep", ")", "path", "=", "path", ".", "replace", "(", "self", ".", "package_name", "+", "os", ".", "path", ".", "sep", ",", "''", ")", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "path", ")", "# XXX maybe check for extensions as well?", "if", "os", ".", "path", ".", "exists", "(", "path", "+", "'.py'", ")", ":", "# file", "path", "+=", "'.py'", "elif", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'__init__.py'", ")", ")", ":", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'__init__.py'", ")", "else", ":", "return", "None", "return", "path"], "docstring": "Convert uri to absolute filepath\n\n        Parameters\n        ----------\n        uri : string\n            URI of python module to return path for\n\n        Returns\n        -------\n        path : None or string\n            Returns None if there is no valid path for this URI\n            Otherwise returns absolute file system path for URI\n\n        Examples\n        --------\n        >>> docwriter = ApiDocWriter('sphinx')\n        >>> import sphinx\n        >>> modpath = sphinx.__path__[0]\n        >>> res = docwriter._uri2path('sphinx.builder')\n        >>> res == os.path.join(modpath, 'builder.py')\n        True\n        >>> res = docwriter._uri2path('sphinx')\n        >>> res == os.path.join(modpath, '__init__.py')\n        True\n        >>> docwriter._uri2path('sphinx.does_not_exist')", "docstring_tokens": ["Convert", "uri", "to", "absolute", "filepath"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-docs/src/product/sphinxext/apigen.py#L112-L152", "partition": "test", "index": 1557, "time": "2016-05-04 08:57:54"}
{"repo": "h2oai/h2o-3", "path": "h2o-docs/src/product/sphinxext/apigen.py", "func_name": "ApiDocWriter._path2uri", "original_string": "def _path2uri(self, dirpath):\n        ''' Convert directory path to uri '''\n        relpath = dirpath.replace(self.root_path, self.package_name)\n        if relpath.startswith(os.path.sep):\n            relpath = relpath[1:]\n        return relpath.replace(os.path.sep, '.')", "language": "python", "code": "def _path2uri(self, dirpath):\n        ''' Convert directory path to uri '''\n        relpath = dirpath.replace(self.root_path, self.package_name)\n        if relpath.startswith(os.path.sep):\n            relpath = relpath[1:]\n        return relpath.replace(os.path.sep, '.')", "code_tokens": ["def", "_path2uri", "(", "self", ",", "dirpath", ")", ":", "relpath", "=", "dirpath", ".", "replace", "(", "self", ".", "root_path", ",", "self", ".", "package_name", ")", "if", "relpath", ".", "startswith", "(", "os", ".", "path", ".", "sep", ")", ":", "relpath", "=", "relpath", "[", "1", ":", "]", "return", "relpath", ".", "replace", "(", "os", ".", "path", ".", "sep", ",", "'.'", ")"], "docstring": "Convert directory path to uri", "docstring_tokens": ["Convert", "directory", "path", "to", "uri"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-docs/src/product/sphinxext/apigen.py#L154-L159", "partition": "test", "index": 1558, "time": "2016-05-04 08:57:54"}
{"repo": "h2oai/h2o-3", "path": "h2o-docs/src/product/sphinxext/apigen.py", "func_name": "ApiDocWriter._parse_lines", "original_string": "def _parse_lines(self, linesource):\n        ''' Parse lines of text for functions and classes '''\n        functions = []\n        classes = []\n        for line in linesource:\n            if line.startswith('def ') and line.count('('):\n                # exclude private stuff\n                name = self._get_object_name(line)\n                if not name.startswith('_'):\n                    functions.append(name)\n            elif line.startswith('class '):\n                # exclude private stuff\n                name = self._get_object_name(line)\n                if not name.startswith('_'):\n                    classes.append(name)\n            else:\n                pass\n        functions.sort()\n        classes.sort()\n        return functions, classes", "language": "python", "code": "def _parse_lines(self, linesource):\n        ''' Parse lines of text for functions and classes '''\n        functions = []\n        classes = []\n        for line in linesource:\n            if line.startswith('def ') and line.count('('):\n                # exclude private stuff\n                name = self._get_object_name(line)\n                if not name.startswith('_'):\n                    functions.append(name)\n            elif line.startswith('class '):\n                # exclude private stuff\n                name = self._get_object_name(line)\n                if not name.startswith('_'):\n                    classes.append(name)\n            else:\n                pass\n        functions.sort()\n        classes.sort()\n        return functions, classes", "code_tokens": ["def", "_parse_lines", "(", "self", ",", "linesource", ")", ":", "functions", "=", "[", "]", "classes", "=", "[", "]", "for", "line", "in", "linesource", ":", "if", "line", ".", "startswith", "(", "'def '", ")", "and", "line", ".", "count", "(", "'('", ")", ":", "# exclude private stuff", "name", "=", "self", ".", "_get_object_name", "(", "line", ")", "if", "not", "name", ".", "startswith", "(", "'_'", ")", ":", "functions", ".", "append", "(", "name", ")", "elif", "line", ".", "startswith", "(", "'class '", ")", ":", "# exclude private stuff", "name", "=", "self", ".", "_get_object_name", "(", "line", ")", "if", "not", "name", ".", "startswith", "(", "'_'", ")", ":", "classes", ".", "append", "(", "name", ")", "else", ":", "pass", "functions", ".", "sort", "(", ")", "classes", ".", "sort", "(", ")", "return", "functions", ",", "classes"], "docstring": "Parse lines of text for functions and classes", "docstring_tokens": ["Parse", "lines", "of", "text", "for", "functions", "and", "classes"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-docs/src/product/sphinxext/apigen.py#L172-L191", "partition": "test", "index": 1559, "time": "2016-05-04 08:57:54"}
{"repo": "h2oai/h2o-3", "path": "h2o-docs/src/product/sphinxext/apigen.py", "func_name": "ApiDocWriter.generate_api_doc", "original_string": "def generate_api_doc(self, uri):\n        '''Make autodoc documentation template string for a module\n\n        Parameters\n        ----------\n        uri : string\n            python location of module - e.g 'sphinx.builder'\n\n        Returns\n        -------\n        S : string\n            Contents of API doc\n        '''\n        # get the names of all classes and functions\n        functions, classes = self._parse_module(uri)\n        if not len(functions) and not len(classes):\n            print 'WARNING: Empty -',uri  # dbg\n            return ''\n\n        # Make a shorter version of the uri that omits the package name for\n        # titles \n        uri_short = re.sub(r'^%s\\.' % self.package_name,'',uri)\n        \n        ad = '.. AUTO-GENERATED FILE -- DO NOT EDIT!\\n\\n'\n\n        chap_title = uri_short\n        ad += (chap_title+'\\n'+ self.rst_section_levels[1] * len(chap_title)\n               + '\\n\\n')\n\n        # Set the chapter title to read 'module' for all modules except for the\n        # main packages\n        if '.' in uri:\n            title = 'Module: :mod:`' + uri_short + '`'\n        else:\n            title = ':mod:`' + uri_short + '`'\n        ad += title + '\\n' + self.rst_section_levels[2] * len(title)\n\n        if len(classes):\n            ad += '\\nInheritance diagram for ``%s``:\\n\\n' % uri\n            ad += '.. inheritance-diagram:: %s \\n' % uri\n            ad += '   :parts: 3\\n'\n\n        ad += '\\n.. automodule:: ' + uri + '\\n'\n        ad += '\\n.. currentmodule:: ' + uri + '\\n'\n        multi_class = len(classes) > 1\n        multi_fx = len(functions) > 1\n        if multi_class:\n            ad += '\\n' + 'Classes' + '\\n' + \\\n                  self.rst_section_levels[2] * 7 + '\\n'\n        elif len(classes) and multi_fx:\n            ad += '\\n' + 'Class' + '\\n' + \\\n                  self.rst_section_levels[2] * 5 + '\\n'\n        for c in classes:\n            ad += '\\n:class:`' + c + '`\\n' \\\n                  + self.rst_section_levels[multi_class + 2 ] * \\\n                  (len(c)+9) + '\\n\\n'\n            ad += '\\n.. autoclass:: ' + c + '\\n'\n            # must NOT exclude from index to keep cross-refs working\n            ad += '  :members:\\n' \\\n                  '  :undoc-members:\\n' \\\n                  '  :show-inheritance:\\n' \\\n                  '  :inherited-members:\\n' \\\n                  '\\n' \\\n                  '  .. automethod:: __init__\\n'\n        if multi_fx:\n            ad += '\\n' + 'Functions' + '\\n' + \\\n                  self.rst_section_levels[2] * 9 + '\\n\\n'\n        elif len(functions) and multi_class:\n            ad += '\\n' + 'Function' + '\\n' + \\\n                  self.rst_section_levels[2] * 8 + '\\n\\n'\n        for f in functions:\n            # must NOT exclude from index to keep cross-refs working\n            ad += '\\n.. autofunction:: ' + uri + '.' + f + '\\n\\n'\n        return ad", "language": "python", "code": "def generate_api_doc(self, uri):\n        '''Make autodoc documentation template string for a module\n\n        Parameters\n        ----------\n        uri : string\n            python location of module - e.g 'sphinx.builder'\n\n        Returns\n        -------\n        S : string\n            Contents of API doc\n        '''\n        # get the names of all classes and functions\n        functions, classes = self._parse_module(uri)\n        if not len(functions) and not len(classes):\n            print 'WARNING: Empty -',uri  # dbg\n            return ''\n\n        # Make a shorter version of the uri that omits the package name for\n        # titles \n        uri_short = re.sub(r'^%s\\.' % self.package_name,'',uri)\n        \n        ad = '.. AUTO-GENERATED FILE -- DO NOT EDIT!\\n\\n'\n\n        chap_title = uri_short\n        ad += (chap_title+'\\n'+ self.rst_section_levels[1] * len(chap_title)\n               + '\\n\\n')\n\n        # Set the chapter title to read 'module' for all modules except for the\n        # main packages\n        if '.' in uri:\n            title = 'Module: :mod:`' + uri_short + '`'\n        else:\n            title = ':mod:`' + uri_short + '`'\n        ad += title + '\\n' + self.rst_section_levels[2] * len(title)\n\n        if len(classes):\n            ad += '\\nInheritance diagram for ``%s``:\\n\\n' % uri\n            ad += '.. inheritance-diagram:: %s \\n' % uri\n            ad += '   :parts: 3\\n'\n\n        ad += '\\n.. automodule:: ' + uri + '\\n'\n        ad += '\\n.. currentmodule:: ' + uri + '\\n'\n        multi_class = len(classes) > 1\n        multi_fx = len(functions) > 1\n        if multi_class:\n            ad += '\\n' + 'Classes' + '\\n' + \\\n                  self.rst_section_levels[2] * 7 + '\\n'\n        elif len(classes) and multi_fx:\n            ad += '\\n' + 'Class' + '\\n' + \\\n                  self.rst_section_levels[2] * 5 + '\\n'\n        for c in classes:\n            ad += '\\n:class:`' + c + '`\\n' \\\n                  + self.rst_section_levels[multi_class + 2 ] * \\\n                  (len(c)+9) + '\\n\\n'\n            ad += '\\n.. autoclass:: ' + c + '\\n'\n            # must NOT exclude from index to keep cross-refs working\n            ad += '  :members:\\n' \\\n                  '  :undoc-members:\\n' \\\n                  '  :show-inheritance:\\n' \\\n                  '  :inherited-members:\\n' \\\n                  '\\n' \\\n                  '  .. automethod:: __init__\\n'\n        if multi_fx:\n            ad += '\\n' + 'Functions' + '\\n' + \\\n                  self.rst_section_levels[2] * 9 + '\\n\\n'\n        elif len(functions) and multi_class:\n            ad += '\\n' + 'Function' + '\\n' + \\\n                  self.rst_section_levels[2] * 8 + '\\n\\n'\n        for f in functions:\n            # must NOT exclude from index to keep cross-refs working\n            ad += '\\n.. autofunction:: ' + uri + '.' + f + '\\n\\n'\n        return ad", "code_tokens": ["def", "generate_api_doc", "(", "self", ",", "uri", ")", ":", "# get the names of all classes and functions", "functions", ",", "classes", "=", "self", ".", "_parse_module", "(", "uri", ")", "if", "not", "len", "(", "functions", ")", "and", "not", "len", "(", "classes", ")", ":", "print", "'WARNING: Empty -'", ",", "uri", "# dbg", "return", "''", "# Make a shorter version of the uri that omits the package name for", "# titles ", "uri_short", "=", "re", ".", "sub", "(", "r'^%s\\.'", "%", "self", ".", "package_name", ",", "''", ",", "uri", ")", "ad", "=", "'.. AUTO-GENERATED FILE -- DO NOT EDIT!\\n\\n'", "chap_title", "=", "uri_short", "ad", "+=", "(", "chap_title", "+", "'\\n'", "+", "self", ".", "rst_section_levels", "[", "1", "]", "*", "len", "(", "chap_title", ")", "+", "'\\n\\n'", ")", "# Set the chapter title to read 'module' for all modules except for the", "# main packages", "if", "'.'", "in", "uri", ":", "title", "=", "'Module: :mod:`'", "+", "uri_short", "+", "'`'", "else", ":", "title", "=", "':mod:`'", "+", "uri_short", "+", "'`'", "ad", "+=", "title", "+", "'\\n'", "+", "self", ".", "rst_section_levels", "[", "2", "]", "*", "len", "(", "title", ")", "if", "len", "(", "classes", ")", ":", "ad", "+=", "'\\nInheritance diagram for ``%s``:\\n\\n'", "%", "uri", "ad", "+=", "'.. inheritance-diagram:: %s \\n'", "%", "uri", "ad", "+=", "'   :parts: 3\\n'", "ad", "+=", "'\\n.. automodule:: '", "+", "uri", "+", "'\\n'", "ad", "+=", "'\\n.. currentmodule:: '", "+", "uri", "+", "'\\n'", "multi_class", "=", "len", "(", "classes", ")", ">", "1", "multi_fx", "=", "len", "(", "functions", ")", ">", "1", "if", "multi_class", ":", "ad", "+=", "'\\n'", "+", "'Classes'", "+", "'\\n'", "+", "self", ".", "rst_section_levels", "[", "2", "]", "*", "7", "+", "'\\n'", "elif", "len", "(", "classes", ")", "and", "multi_fx", ":", "ad", "+=", "'\\n'", "+", "'Class'", "+", "'\\n'", "+", "self", ".", "rst_section_levels", "[", "2", "]", "*", "5", "+", "'\\n'", "for", "c", "in", "classes", ":", "ad", "+=", "'\\n:class:`'", "+", "c", "+", "'`\\n'", "+", "self", ".", "rst_section_levels", "[", "multi_class", "+", "2", "]", "*", "(", "len", "(", "c", ")", "+", "9", ")", "+", "'\\n\\n'", "ad", "+=", "'\\n.. autoclass:: '", "+", "c", "+", "'\\n'", "# must NOT exclude from index to keep cross-refs working", "ad", "+=", "'  :members:\\n'", "'  :undoc-members:\\n'", "'  :show-inheritance:\\n'", "'  :inherited-members:\\n'", "'\\n'", "'  .. automethod:: __init__\\n'", "if", "multi_fx", ":", "ad", "+=", "'\\n'", "+", "'Functions'", "+", "'\\n'", "+", "self", ".", "rst_section_levels", "[", "2", "]", "*", "9", "+", "'\\n\\n'", "elif", "len", "(", "functions", ")", "and", "multi_class", ":", "ad", "+=", "'\\n'", "+", "'Function'", "+", "'\\n'", "+", "self", ".", "rst_section_levels", "[", "2", "]", "*", "8", "+", "'\\n\\n'", "for", "f", "in", "functions", ":", "# must NOT exclude from index to keep cross-refs working", "ad", "+=", "'\\n.. autofunction:: '", "+", "uri", "+", "'.'", "+", "f", "+", "'\\n\\n'", "return", "ad"], "docstring": "Make autodoc documentation template string for a module\n\n        Parameters\n        ----------\n        uri : string\n            python location of module - e.g 'sphinx.builder'\n\n        Returns\n        -------\n        S : string\n            Contents of API doc", "docstring_tokens": ["Make", "autodoc", "documentation", "template", "string", "for", "a", "module"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-docs/src/product/sphinxext/apigen.py#L193-L266", "partition": "test", "index": 1560, "time": "2016-05-04 08:57:54"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/bindings.py", "func_name": "endpoint_groups", "original_string": "def endpoint_groups():\n    \"\"\"Return endpoints, grouped by the class which handles them.\"\"\"\n    groups = defaultdict(list)\n    for e in endpoints():\n        groups[e[\"class_name\"]].append(e)\n    return groups", "language": "python", "code": "def endpoint_groups():\n    \"\"\"Return endpoints, grouped by the class which handles them.\"\"\"\n    groups = defaultdict(list)\n    for e in endpoints():\n        groups[e[\"class_name\"]].append(e)\n    return groups", "code_tokens": ["def", "endpoint_groups", "(", ")", ":", "groups", "=", "defaultdict", "(", "list", ")", "for", "e", "in", "endpoints", "(", ")", ":", "groups", "[", "e", "[", "\"class_name\"", "]", "]", ".", "append", "(", "e", ")", "return", "groups"], "docstring": "Return endpoints, grouped by the class which handles them.", "docstring_tokens": ["Return", "endpoints", "grouped", "by", "the", "class", "which", "handles", "them", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/bindings.py#L298-L303", "partition": "test", "index": 1583, "time": "2016-05-31 16:19:02"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/gen_java.py", "func_name": "translate_name", "original_string": "def translate_name(name):\n    \"\"\"\n    Convert names with underscores into camelcase.\n\n    For example:\n        \"num_rows\" => \"numRows\"\n        \"very_long_json_name\" => \"veryLongJsonName\"\n        \"build_GBM_model\" => \"buildGbmModel\"\n        \"KEY\" => \"key\"\n        \"middle___underscores\" => \"middleUnderscores\"\n        \"_exclude_fields\" => \"_excludeFields\" (retain initial/trailing underscores)\n        \"__http_status__\" => \"__httpStatus__\"\n\n    :param name: name to be converted\n    \"\"\"\n    parts = name.split(\"_\")\n    i = 0\n    while parts[i] == \"\":\n        parts[i] = \"_\"\n        i += 1\n    parts[i] = parts[i].lower()\n    for j in range(i + 1, len(parts)):\n        parts[j] = parts[j].capitalize()\n    i = len(parts) - 1\n    while parts[i] == \"\":\n        parts[i] = \"_\"\n        i -= 1\n    return \"\".join(parts)", "language": "python", "code": "def translate_name(name):\n    \"\"\"\n    Convert names with underscores into camelcase.\n\n    For example:\n        \"num_rows\" => \"numRows\"\n        \"very_long_json_name\" => \"veryLongJsonName\"\n        \"build_GBM_model\" => \"buildGbmModel\"\n        \"KEY\" => \"key\"\n        \"middle___underscores\" => \"middleUnderscores\"\n        \"_exclude_fields\" => \"_excludeFields\" (retain initial/trailing underscores)\n        \"__http_status__\" => \"__httpStatus__\"\n\n    :param name: name to be converted\n    \"\"\"\n    parts = name.split(\"_\")\n    i = 0\n    while parts[i] == \"\":\n        parts[i] = \"_\"\n        i += 1\n    parts[i] = parts[i].lower()\n    for j in range(i + 1, len(parts)):\n        parts[j] = parts[j].capitalize()\n    i = len(parts) - 1\n    while parts[i] == \"\":\n        parts[i] = \"_\"\n        i -= 1\n    return \"\".join(parts)", "code_tokens": ["def", "translate_name", "(", "name", ")", ":", "parts", "=", "name", ".", "split", "(", "\"_\"", ")", "i", "=", "0", "while", "parts", "[", "i", "]", "==", "\"\"", ":", "parts", "[", "i", "]", "=", "\"_\"", "i", "+=", "1", "parts", "[", "i", "]", "=", "parts", "[", "i", "]", ".", "lower", "(", ")", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "parts", ")", ")", ":", "parts", "[", "j", "]", "=", "parts", "[", "j", "]", ".", "capitalize", "(", ")", "i", "=", "len", "(", "parts", ")", "-", "1", "while", "parts", "[", "i", "]", "==", "\"\"", ":", "parts", "[", "i", "]", "=", "\"_\"", "i", "-=", "1", "return", "\"\"", ".", "join", "(", "parts", ")"], "docstring": "Convert names with underscores into camelcase.\n\n    For example:\n        \"num_rows\" => \"numRows\"\n        \"very_long_json_name\" => \"veryLongJsonName\"\n        \"build_GBM_model\" => \"buildGbmModel\"\n        \"KEY\" => \"key\"\n        \"middle___underscores\" => \"middleUnderscores\"\n        \"_exclude_fields\" => \"_excludeFields\" (retain initial/trailing underscores)\n        \"__http_status__\" => \"__httpStatus__\"\n\n    :param name: name to be converted", "docstring_tokens": ["Convert", "names", "with", "underscores", "into", "camelcase", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/gen_java.py#L42-L69", "partition": "test", "index": 1494, "time": "2016-06-02 17:10:45"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/estimators/glm.py", "func_name": "H2OGeneralizedLinearEstimator.getGLMRegularizationPath", "original_string": "def getGLMRegularizationPath(model):\n        \"\"\"\n        Extract full regularization path explored during lambda search from glm model.\n\n        :param model: source lambda search model\n        \"\"\"\n        x = h2o.api(\"GET /3/GetGLMRegPath\", data={\"model\": model._model_json[\"model_id\"][\"name\"]})\n        ns = x.pop(\"coefficient_names\")\n        res = {\n            \"lambdas\": x[\"lambdas\"],\n            \"explained_deviance_train\": x[\"explained_deviance_train\"],\n            \"explained_deviance_valid\": x[\"explained_deviance_valid\"],\n            \"coefficients\": [dict(zip(ns, y)) for y in x[\"coefficients\"]],\n        }\n        if \"coefficients_std\" in x:\n            res[\"coefficients_std\"] = [dict(zip(ns, y)) for y in x[\"coefficients_std\"]]\n        return res", "language": "python", "code": "def getGLMRegularizationPath(model):\n        \"\"\"\n        Extract full regularization path explored during lambda search from glm model.\n\n        :param model: source lambda search model\n        \"\"\"\n        x = h2o.api(\"GET /3/GetGLMRegPath\", data={\"model\": model._model_json[\"model_id\"][\"name\"]})\n        ns = x.pop(\"coefficient_names\")\n        res = {\n            \"lambdas\": x[\"lambdas\"],\n            \"explained_deviance_train\": x[\"explained_deviance_train\"],\n            \"explained_deviance_valid\": x[\"explained_deviance_valid\"],\n            \"coefficients\": [dict(zip(ns, y)) for y in x[\"coefficients\"]],\n        }\n        if \"coefficients_std\" in x:\n            res[\"coefficients_std\"] = [dict(zip(ns, y)) for y in x[\"coefficients_std\"]]\n        return res", "code_tokens": ["def", "getGLMRegularizationPath", "(", "model", ")", ":", "x", "=", "h2o", ".", "api", "(", "\"GET /3/GetGLMRegPath\"", ",", "data", "=", "{", "\"model\"", ":", "model", ".", "_model_json", "[", "\"model_id\"", "]", "[", "\"name\"", "]", "}", ")", "ns", "=", "x", ".", "pop", "(", "\"coefficient_names\"", ")", "res", "=", "{", "\"lambdas\"", ":", "x", "[", "\"lambdas\"", "]", ",", "\"explained_deviance_train\"", ":", "x", "[", "\"explained_deviance_train\"", "]", ",", "\"explained_deviance_valid\"", ":", "x", "[", "\"explained_deviance_valid\"", "]", ",", "\"coefficients\"", ":", "[", "dict", "(", "zip", "(", "ns", ",", "y", ")", ")", "for", "y", "in", "x", "[", "\"coefficients\"", "]", "]", ",", "}", "if", "\"coefficients_std\"", "in", "x", ":", "res", "[", "\"coefficients_std\"", "]", "=", "[", "dict", "(", "zip", "(", "ns", ",", "y", ")", ")", "for", "y", "in", "x", "[", "\"coefficients_std\"", "]", "]", "return", "res"], "docstring": "Extract full regularization path explored during lambda search from glm model.\n\n        :param model: source lambda search model", "docstring_tokens": ["Extract", "full", "regularization", "path", "explored", "during", "lambda", "search", "from", "glm", "model", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/estimators/glm.py#L860-L876", "partition": "test", "index": 1316, "time": "2016-06-27 17:49:05"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/estimators/glm.py", "func_name": "H2OGeneralizedLinearEstimator.makeGLMModel", "original_string": "def makeGLMModel(model, coefs, threshold=.5):\n        \"\"\"\n        Create a custom GLM model using the given coefficients.\n\n        Needs to be passed source model trained on the dataset to extract the dataset information from.\n\n        :param model: source model, used for extracting dataset information\n        :param coefs: dictionary containing model coefficients\n        :param threshold: (optional, only for binomial) decision threshold used for classification\n        \"\"\"\n        model_json = h2o.api(\n            \"POST /3/MakeGLMModel\",\n            data={\"model\": model._model_json[\"model_id\"][\"name\"],\n                  \"names\": list(coefs.keys()),\n                  \"beta\": list(coefs.values()),\n                  \"threshold\": threshold}\n        )\n        m = H2OGeneralizedLinearEstimator()\n        m._resolve_model(model_json[\"model_id\"][\"name\"], model_json)\n        return m", "language": "python", "code": "def makeGLMModel(model, coefs, threshold=.5):\n        \"\"\"\n        Create a custom GLM model using the given coefficients.\n\n        Needs to be passed source model trained on the dataset to extract the dataset information from.\n\n        :param model: source model, used for extracting dataset information\n        :param coefs: dictionary containing model coefficients\n        :param threshold: (optional, only for binomial) decision threshold used for classification\n        \"\"\"\n        model_json = h2o.api(\n            \"POST /3/MakeGLMModel\",\n            data={\"model\": model._model_json[\"model_id\"][\"name\"],\n                  \"names\": list(coefs.keys()),\n                  \"beta\": list(coefs.values()),\n                  \"threshold\": threshold}\n        )\n        m = H2OGeneralizedLinearEstimator()\n        m._resolve_model(model_json[\"model_id\"][\"name\"], model_json)\n        return m", "code_tokens": ["def", "makeGLMModel", "(", "model", ",", "coefs", ",", "threshold", "=", ".5", ")", ":", "model_json", "=", "h2o", ".", "api", "(", "\"POST /3/MakeGLMModel\"", ",", "data", "=", "{", "\"model\"", ":", "model", ".", "_model_json", "[", "\"model_id\"", "]", "[", "\"name\"", "]", ",", "\"names\"", ":", "list", "(", "coefs", ".", "keys", "(", ")", ")", ",", "\"beta\"", ":", "list", "(", "coefs", ".", "values", "(", ")", ")", ",", "\"threshold\"", ":", "threshold", "}", ")", "m", "=", "H2OGeneralizedLinearEstimator", "(", ")", "m", ".", "_resolve_model", "(", "model_json", "[", "\"model_id\"", "]", "[", "\"name\"", "]", ",", "model_json", ")", "return", "m"], "docstring": "Create a custom GLM model using the given coefficients.\n\n        Needs to be passed source model trained on the dataset to extract the dataset information from.\n\n        :param model: source model, used for extracting dataset information\n        :param coefs: dictionary containing model coefficients\n        :param threshold: (optional, only for binomial) decision threshold used for classification", "docstring_tokens": ["Create", "a", "custom", "GLM", "model", "using", "the", "given", "coefficients", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/estimators/glm.py#L879-L898", "partition": "test", "index": 1317, "time": "2016-06-27 17:49:05"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "import_sql_table", "original_string": "def import_sql_table(connection_url, table, username, password, columns=None, optimize=True, fetch_mode=None):\n    \"\"\"\n    Import SQL table to H2OFrame in memory.\n\n    Assumes that the SQL table is not being updated and is stable.\n    Runs multiple SELECT SQL queries concurrently for parallel ingestion.\n    Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n\n        java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n\n    Also see :func:`import_sql_select`.\n    Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, Hive, Oracle and Microsoft SQL.\n\n    :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n        Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n    :param table: name of SQL table\n    :param columns: a list of column names to import from SQL table. Default is to import all columns.\n    :param username: username for SQL server\n    :param password: password for SQL server\n    :param optimize: DEPRECATED. Ignored - use fetch_mode instead. Optimize import of SQL table for faster imports.\n    :param fetch_mode: Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read by a single node\n        from the database.\n\n    :returns: an :class:`H2OFrame` containing data of the specified SQL table.\n\n    :examples:\n        >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n        >>> table = \"citibike20k\"\n        >>> username = \"root\"\n        >>> password = \"abc123\"\n        >>> my_citibike_data = h2o.import_sql_table(conn_url, table, username, password)\n    \"\"\"\n    assert_is_type(connection_url, str)\n    assert_is_type(table, str)\n    assert_is_type(username, str)\n    assert_is_type(password, str)\n    assert_is_type(columns, [str], None)\n    assert_is_type(optimize, bool)\n    assert_is_type(fetch_mode, str, None)\n    p = {\"connection_url\": connection_url, \"table\": table, \"username\": username, \"password\": password,\n         \"fetch_mode\": fetch_mode}\n    if columns:\n        p[\"columns\"] = \", \".join(columns)\n    j = H2OJob(api(\"POST /99/ImportSQLTable\", data=p), \"Import SQL Table\").poll()\n    return get_frame(j.dest_key)", "language": "python", "code": "def import_sql_table(connection_url, table, username, password, columns=None, optimize=True, fetch_mode=None):\n    \"\"\"\n    Import SQL table to H2OFrame in memory.\n\n    Assumes that the SQL table is not being updated and is stable.\n    Runs multiple SELECT SQL queries concurrently for parallel ingestion.\n    Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n\n        java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n\n    Also see :func:`import_sql_select`.\n    Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, Hive, Oracle and Microsoft SQL.\n\n    :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n        Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n    :param table: name of SQL table\n    :param columns: a list of column names to import from SQL table. Default is to import all columns.\n    :param username: username for SQL server\n    :param password: password for SQL server\n    :param optimize: DEPRECATED. Ignored - use fetch_mode instead. Optimize import of SQL table for faster imports.\n    :param fetch_mode: Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read by a single node\n        from the database.\n\n    :returns: an :class:`H2OFrame` containing data of the specified SQL table.\n\n    :examples:\n        >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n        >>> table = \"citibike20k\"\n        >>> username = \"root\"\n        >>> password = \"abc123\"\n        >>> my_citibike_data = h2o.import_sql_table(conn_url, table, username, password)\n    \"\"\"\n    assert_is_type(connection_url, str)\n    assert_is_type(table, str)\n    assert_is_type(username, str)\n    assert_is_type(password, str)\n    assert_is_type(columns, [str], None)\n    assert_is_type(optimize, bool)\n    assert_is_type(fetch_mode, str, None)\n    p = {\"connection_url\": connection_url, \"table\": table, \"username\": username, \"password\": password,\n         \"fetch_mode\": fetch_mode}\n    if columns:\n        p[\"columns\"] = \", \".join(columns)\n    j = H2OJob(api(\"POST /99/ImportSQLTable\", data=p), \"Import SQL Table\").poll()\n    return get_frame(j.dest_key)", "code_tokens": ["def", "import_sql_table", "(", "connection_url", ",", "table", ",", "username", ",", "password", ",", "columns", "=", "None", ",", "optimize", "=", "True", ",", "fetch_mode", "=", "None", ")", ":", "assert_is_type", "(", "connection_url", ",", "str", ")", "assert_is_type", "(", "table", ",", "str", ")", "assert_is_type", "(", "username", ",", "str", ")", "assert_is_type", "(", "password", ",", "str", ")", "assert_is_type", "(", "columns", ",", "[", "str", "]", ",", "None", ")", "assert_is_type", "(", "optimize", ",", "bool", ")", "assert_is_type", "(", "fetch_mode", ",", "str", ",", "None", ")", "p", "=", "{", "\"connection_url\"", ":", "connection_url", ",", "\"table\"", ":", "table", ",", "\"username\"", ":", "username", ",", "\"password\"", ":", "password", ",", "\"fetch_mode\"", ":", "fetch_mode", "}", "if", "columns", ":", "p", "[", "\"columns\"", "]", "=", "\", \"", ".", "join", "(", "columns", ")", "j", "=", "H2OJob", "(", "api", "(", "\"POST /99/ImportSQLTable\"", ",", "data", "=", "p", ")", ",", "\"Import SQL Table\"", ")", ".", "poll", "(", ")", "return", "get_frame", "(", "j", ".", "dest_key", ")"], "docstring": "Import SQL table to H2OFrame in memory.\n\n    Assumes that the SQL table is not being updated and is stable.\n    Runs multiple SELECT SQL queries concurrently for parallel ingestion.\n    Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n\n        java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n\n    Also see :func:`import_sql_select`.\n    Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, Hive, Oracle and Microsoft SQL.\n\n    :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n        Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n    :param table: name of SQL table\n    :param columns: a list of column names to import from SQL table. Default is to import all columns.\n    :param username: username for SQL server\n    :param password: password for SQL server\n    :param optimize: DEPRECATED. Ignored - use fetch_mode instead. Optimize import of SQL table for faster imports.\n    :param fetch_mode: Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read by a single node\n        from the database.\n\n    :returns: an :class:`H2OFrame` containing data of the specified SQL table.\n\n    :examples:\n        >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n        >>> table = \"citibike20k\"\n        >>> username = \"root\"\n        >>> password = \"abc123\"\n        >>> my_citibike_data = h2o.import_sql_table(conn_url, table, username, password)", "docstring_tokens": ["Import", "SQL", "table", "to", "H2OFrame", "in", "memory", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L464-L508", "partition": "test", "index": 1459, "time": "2016-07-01 13:16:04"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "parse_raw", "original_string": "def parse_raw(setup, id=None, first_line_is_header=0):\n    \"\"\"\n    Parse dataset using the parse setup structure.\n\n    :param setup: Result of ``h2o.parse_setup()``\n    :param id: an id for the frame.\n    :param first_line_is_header: -1, 0, 1 if the first line is to be used as the header\n\n    :returns: an :class:`H2OFrame` object.\n    \"\"\"\n    assert_is_type(setup, dict)\n    assert_is_type(id, str, None)\n    assert_is_type(first_line_is_header, -1, 0, 1)\n    check_frame_id(id)\n    if id:\n        setup[\"destination_frame\"] = id\n    if first_line_is_header != (-1, 0, 1):\n        if first_line_is_header not in (-1, 0, 1): raise ValueError(\"first_line_is_header should be -1, 0, or 1\")\n        setup[\"check_header\"] = first_line_is_header\n    fr = H2OFrame()\n    fr._parse_raw(setup)\n    return fr", "language": "python", "code": "def parse_raw(setup, id=None, first_line_is_header=0):\n    \"\"\"\n    Parse dataset using the parse setup structure.\n\n    :param setup: Result of ``h2o.parse_setup()``\n    :param id: an id for the frame.\n    :param first_line_is_header: -1, 0, 1 if the first line is to be used as the header\n\n    :returns: an :class:`H2OFrame` object.\n    \"\"\"\n    assert_is_type(setup, dict)\n    assert_is_type(id, str, None)\n    assert_is_type(first_line_is_header, -1, 0, 1)\n    check_frame_id(id)\n    if id:\n        setup[\"destination_frame\"] = id\n    if first_line_is_header != (-1, 0, 1):\n        if first_line_is_header not in (-1, 0, 1): raise ValueError(\"first_line_is_header should be -1, 0, or 1\")\n        setup[\"check_header\"] = first_line_is_header\n    fr = H2OFrame()\n    fr._parse_raw(setup)\n    return fr", "code_tokens": ["def", "parse_raw", "(", "setup", ",", "id", "=", "None", ",", "first_line_is_header", "=", "0", ")", ":", "assert_is_type", "(", "setup", ",", "dict", ")", "assert_is_type", "(", "id", ",", "str", ",", "None", ")", "assert_is_type", "(", "first_line_is_header", ",", "-", "1", ",", "0", ",", "1", ")", "check_frame_id", "(", "id", ")", "if", "id", ":", "setup", "[", "\"destination_frame\"", "]", "=", "id", "if", "first_line_is_header", "!=", "(", "-", "1", ",", "0", ",", "1", ")", ":", "if", "first_line_is_header", "not", "in", "(", "-", "1", ",", "0", ",", "1", ")", ":", "raise", "ValueError", "(", "\"first_line_is_header should be -1, 0, or 1\"", ")", "setup", "[", "\"check_header\"", "]", "=", "first_line_is_header", "fr", "=", "H2OFrame", "(", ")", "fr", ".", "_parse_raw", "(", "setup", ")", "return", "fr"], "docstring": "Parse dataset using the parse setup structure.\n\n    :param setup: Result of ``h2o.parse_setup()``\n    :param id: an id for the frame.\n    :param first_line_is_header: -1, 0, 1 if the first line is to be used as the header\n\n    :returns: an :class:`H2OFrame` object.", "docstring_tokens": ["Parse", "dataset", "using", "the", "parse", "setup", "structure", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L731-L752", "partition": "test", "index": 1461, "time": "2016-07-01 13:16:04"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "export_file", "original_string": "def export_file(frame, path, force=False, parts=1):\n    \"\"\"\n    Export a given H2OFrame to a path on the machine this python session is currently connected to.\n\n    :param frame: the Frame to save to disk.\n    :param path: the path to the save point on disk.\n    :param force: if True, overwrite any preexisting file with the same path\n    :param parts: enables export to multiple 'part' files instead of just a single file.\n        Convenient for large datasets that take too long to store in a single file.\n        Use parts=-1 to instruct H2O to determine the optimal number of part files or\n        specify your desired maximum number of part files. Path needs to be a directory\n        when exporting to multiple files, also that directory must be empty.\n        Default is ``parts = 1``, which is to export to a single file.\n    \"\"\"\n    assert_is_type(frame, H2OFrame)\n    assert_is_type(path, str)\n    assert_is_type(force, bool)\n    assert_is_type(parts, int)\n    H2OJob(api(\"POST /3/Frames/%s/export\" % (frame.frame_id), data={\"path\": path, \"num_parts\": parts, \"force\": force}),\n           \"Export File\").poll()", "language": "python", "code": "def export_file(frame, path, force=False, parts=1):\n    \"\"\"\n    Export a given H2OFrame to a path on the machine this python session is currently connected to.\n\n    :param frame: the Frame to save to disk.\n    :param path: the path to the save point on disk.\n    :param force: if True, overwrite any preexisting file with the same path\n    :param parts: enables export to multiple 'part' files instead of just a single file.\n        Convenient for large datasets that take too long to store in a single file.\n        Use parts=-1 to instruct H2O to determine the optimal number of part files or\n        specify your desired maximum number of part files. Path needs to be a directory\n        when exporting to multiple files, also that directory must be empty.\n        Default is ``parts = 1``, which is to export to a single file.\n    \"\"\"\n    assert_is_type(frame, H2OFrame)\n    assert_is_type(path, str)\n    assert_is_type(force, bool)\n    assert_is_type(parts, int)\n    H2OJob(api(\"POST /3/Frames/%s/export\" % (frame.frame_id), data={\"path\": path, \"num_parts\": parts, \"force\": force}),\n           \"Export File\").poll()", "code_tokens": ["def", "export_file", "(", "frame", ",", "path", ",", "force", "=", "False", ",", "parts", "=", "1", ")", ":", "assert_is_type", "(", "frame", ",", "H2OFrame", ")", "assert_is_type", "(", "path", ",", "str", ")", "assert_is_type", "(", "force", ",", "bool", ")", "assert_is_type", "(", "parts", ",", "int", ")", "H2OJob", "(", "api", "(", "\"POST /3/Frames/%s/export\"", "%", "(", "frame", ".", "frame_id", ")", ",", "data", "=", "{", "\"path\"", ":", "path", ",", "\"num_parts\"", ":", "parts", ",", "\"force\"", ":", "force", "}", ")", ",", "\"Export File\"", ")", ".", "poll", "(", ")"], "docstring": "Export a given H2OFrame to a path on the machine this python session is currently connected to.\n\n    :param frame: the Frame to save to disk.\n    :param path: the path to the save point on disk.\n    :param force: if True, overwrite any preexisting file with the same path\n    :param parts: enables export to multiple 'part' files instead of just a single file.\n        Convenient for large datasets that take too long to store in a single file.\n        Use parts=-1 to instruct H2O to determine the optimal number of part files or\n        specify your desired maximum number of part files. Path needs to be a directory\n        when exporting to multiple files, also that directory must be empty.\n        Default is ``parts = 1``, which is to export to a single file.", "docstring_tokens": ["Export", "a", "given", "H2OFrame", "to", "a", "path", "on", "the", "machine", "this", "python", "session", "is", "currently", "connected", "to", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L1102-L1121", "partition": "test", "index": 1469, "time": "2016-07-01 13:16:04"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/connection.py", "func_name": "H2OConnection._prepare_data_payload", "original_string": "def _prepare_data_payload(data):\n        \"\"\"\n        Make a copy of the `data` object, preparing it to be sent to the server.\n\n        The data will be sent via x-www-form-urlencoded or multipart/form-data mechanisms. Both of them work with\n        plain lists of key/value pairs, so this method converts the data into such format.\n        \"\"\"\n        if not data: return None\n        res = {}\n        for key, value in viewitems(data):\n            if value is None: continue  # don't send args set to None so backend defaults take precedence\n            if isinstance(value, list):\n                value = stringify_list(value)\n            elif isinstance(value, dict):\n                if \"__meta\" in value and value[\"__meta\"][\"schema_name\"].endswith(\"KeyV3\"):\n                    value = value[\"name\"]\n                else:\n                    value = stringify_dict(value)\n            else:\n                value = str(value)\n            res[key] = value\n        return res", "language": "python", "code": "def _prepare_data_payload(data):\n        \"\"\"\n        Make a copy of the `data` object, preparing it to be sent to the server.\n\n        The data will be sent via x-www-form-urlencoded or multipart/form-data mechanisms. Both of them work with\n        plain lists of key/value pairs, so this method converts the data into such format.\n        \"\"\"\n        if not data: return None\n        res = {}\n        for key, value in viewitems(data):\n            if value is None: continue  # don't send args set to None so backend defaults take precedence\n            if isinstance(value, list):\n                value = stringify_list(value)\n            elif isinstance(value, dict):\n                if \"__meta\" in value and value[\"__meta\"][\"schema_name\"].endswith(\"KeyV3\"):\n                    value = value[\"name\"]\n                else:\n                    value = stringify_dict(value)\n            else:\n                value = str(value)\n            res[key] = value\n        return res", "code_tokens": ["def", "_prepare_data_payload", "(", "data", ")", ":", "if", "not", "data", ":", "return", "None", "res", "=", "{", "}", "for", "key", ",", "value", "in", "viewitems", "(", "data", ")", ":", "if", "value", "is", "None", ":", "continue", "# don't send args set to None so backend defaults take precedence", "if", "isinstance", "(", "value", ",", "list", ")", ":", "value", "=", "stringify_list", "(", "value", ")", "elif", "isinstance", "(", "value", ",", "dict", ")", ":", "if", "\"__meta\"", "in", "value", "and", "value", "[", "\"__meta\"", "]", "[", "\"schema_name\"", "]", ".", "endswith", "(", "\"KeyV3\"", ")", ":", "value", "=", "value", "[", "\"name\"", "]", "else", ":", "value", "=", "stringify_dict", "(", "value", ")", "else", ":", "value", "=", "str", "(", "value", ")", "res", "[", "key", "]", "=", "value", "return", "res"], "docstring": "Make a copy of the `data` object, preparing it to be sent to the server.\n\n        The data will be sent via x-www-form-urlencoded or multipart/form-data mechanisms. Both of them work with\n        plain lists of key/value pairs, so this method converts the data into such format.", "docstring_tokens": ["Make", "a", "copy", "of", "the", "data", "object", "preparing", "it", "to", "be", "sent", "to", "the", "server", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L607-L628", "partition": "test", "index": 1501, "time": "2016-07-01 13:16:04"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/connection.py", "func_name": "H2OConnection.close", "original_string": "def close(self):\n        \"\"\"\n        Close an existing connection; once closed it cannot be used again.\n\n        Strictly speaking it is not necessary to close all connection that you opened -- we have several mechanisms\n        in place that will do so automatically (__del__(), __exit__() and atexit() handlers), however there is also\n        no good reason to make this method private.\n        \"\"\"\n        if self._session_id:\n            try:\n                # If the server gone bad, we don't want to wait forever...\n                if self._timeout is None: self._timeout = 1\n                self.request(\"DELETE /4/sessions/%s\" % self._session_id)\n                self._print(\"H2O session %s closed.\" % self._session_id)\n            except Exception:\n                pass\n            self._session_id = None\n        self._stage = -1", "language": "python", "code": "def close(self):\n        \"\"\"\n        Close an existing connection; once closed it cannot be used again.\n\n        Strictly speaking it is not necessary to close all connection that you opened -- we have several mechanisms\n        in place that will do so automatically (__del__(), __exit__() and atexit() handlers), however there is also\n        no good reason to make this method private.\n        \"\"\"\n        if self._session_id:\n            try:\n                # If the server gone bad, we don't want to wait forever...\n                if self._timeout is None: self._timeout = 1\n                self.request(\"DELETE /4/sessions/%s\" % self._session_id)\n                self._print(\"H2O session %s closed.\" % self._session_id)\n            except Exception:\n                pass\n            self._session_id = None\n        self._stage = -1", "code_tokens": ["def", "close", "(", "self", ")", ":", "if", "self", ".", "_session_id", ":", "try", ":", "# If the server gone bad, we don't want to wait forever...", "if", "self", ".", "_timeout", "is", "None", ":", "self", ".", "_timeout", "=", "1", "self", ".", "request", "(", "\"DELETE /4/sessions/%s\"", "%", "self", ".", "_session_id", ")", "self", ".", "_print", "(", "\"H2O session %s closed.\"", "%", "self", ".", "_session_id", ")", "except", "Exception", ":", "pass", "self", ".", "_session_id", "=", "None", "self", ".", "_stage", "=", "-", "1"], "docstring": "Close an existing connection; once closed it cannot be used again.\n\n        Strictly speaking it is not necessary to close all connection that you opened -- we have several mechanisms\n        in place that will do so automatically (__del__(), __exit__() and atexit() handlers), however there is also\n        no good reason to make this method private.", "docstring_tokens": ["Close", "an", "existing", "connection", ";", "once", "closed", "it", "cannot", "be", "used", "again", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L427-L444", "partition": "test", "index": 1498, "time": "2016-07-01 13:16:04"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/connection.py", "func_name": "H2OConnection._process_response", "original_string": "def _process_response(response, save_to):\n        \"\"\"\n        Given a response object, prepare it to be handed over to the external caller.\n\n        Preparation steps include:\n           * detect if the response has error status, and convert it to an appropriate exception;\n           * detect Content-Type, and based on that either parse the response as JSON or return as plain text.\n        \"\"\"\n        status_code = response.status_code\n        if status_code == 200 and save_to:\n            if save_to.startswith(\"~\"): save_to = os.path.expanduser(save_to)\n            if os.path.isdir(save_to) or save_to.endswith(os.path.sep):\n                dirname = os.path.abspath(save_to)\n                filename = H2OConnection._find_file_name(response)\n            else:\n                dirname, filename = os.path.split(os.path.abspath(save_to))\n            fullname = os.path.join(dirname, filename)\n            try:\n                if not os.path.exists(dirname):\n                    os.makedirs(dirname)\n                with open(fullname, \"wb\") as f:\n                    for chunk in response.iter_content(chunk_size=65536):\n                        if chunk:  # Empty chunks may occasionally happen\n                            f.write(chunk)\n            except OSError as e:\n                raise H2OValueError(\"Cannot write to file %s: %s\" % (fullname, e))\n            return fullname\n\n        content_type = response.headers.get(\"Content-Type\", \"\")\n        if \";\" in content_type:  # Remove a \";charset=...\" part\n            content_type = content_type[:content_type.index(\";\")]\n\n        # Auto-detect response type by its content-type. Decode JSON, all other responses pass as-is.\n        if content_type == \"application/json\":\n            try:\n                data = response.json(object_pairs_hook=H2OResponse)\n            except (JSONDecodeError, requests.exceptions.ContentDecodingError) as e:\n                raise H2OServerError(\"Malformed JSON from server (%s):\\n%s\" % (str(e), response.text))\n        else:\n            data = response.text\n\n        # Success (200 = \"Ok\", 201 = \"Created\", 202 = \"Accepted\", 204 = \"No Content\")\n        if status_code in {200, 201, 202, 204}:\n            return data\n\n        # Client errors (400 = \"Bad Request\", 404 = \"Not Found\", 412 = \"Precondition Failed\")\n        if status_code in {400, 404, 412} and isinstance(data, (H2OErrorV3, H2OModelBuilderErrorV3)):\n            raise H2OResponseError(data)\n\n        # Server errors (notably 500 = \"Server Error\")\n        # Note that it is possible to receive valid H2OErrorV3 object in this case, however it merely means the server\n        # did not provide the correct status code.\n        raise H2OServerError(\"HTTP %d %s:\\n%r\" % (status_code, response.reason, data))", "language": "python", "code": "def _process_response(response, save_to):\n        \"\"\"\n        Given a response object, prepare it to be handed over to the external caller.\n\n        Preparation steps include:\n           * detect if the response has error status, and convert it to an appropriate exception;\n           * detect Content-Type, and based on that either parse the response as JSON or return as plain text.\n        \"\"\"\n        status_code = response.status_code\n        if status_code == 200 and save_to:\n            if save_to.startswith(\"~\"): save_to = os.path.expanduser(save_to)\n            if os.path.isdir(save_to) or save_to.endswith(os.path.sep):\n                dirname = os.path.abspath(save_to)\n                filename = H2OConnection._find_file_name(response)\n            else:\n                dirname, filename = os.path.split(os.path.abspath(save_to))\n            fullname = os.path.join(dirname, filename)\n            try:\n                if not os.path.exists(dirname):\n                    os.makedirs(dirname)\n                with open(fullname, \"wb\") as f:\n                    for chunk in response.iter_content(chunk_size=65536):\n                        if chunk:  # Empty chunks may occasionally happen\n                            f.write(chunk)\n            except OSError as e:\n                raise H2OValueError(\"Cannot write to file %s: %s\" % (fullname, e))\n            return fullname\n\n        content_type = response.headers.get(\"Content-Type\", \"\")\n        if \";\" in content_type:  # Remove a \";charset=...\" part\n            content_type = content_type[:content_type.index(\";\")]\n\n        # Auto-detect response type by its content-type. Decode JSON, all other responses pass as-is.\n        if content_type == \"application/json\":\n            try:\n                data = response.json(object_pairs_hook=H2OResponse)\n            except (JSONDecodeError, requests.exceptions.ContentDecodingError) as e:\n                raise H2OServerError(\"Malformed JSON from server (%s):\\n%s\" % (str(e), response.text))\n        else:\n            data = response.text\n\n        # Success (200 = \"Ok\", 201 = \"Created\", 202 = \"Accepted\", 204 = \"No Content\")\n        if status_code in {200, 201, 202, 204}:\n            return data\n\n        # Client errors (400 = \"Bad Request\", 404 = \"Not Found\", 412 = \"Precondition Failed\")\n        if status_code in {400, 404, 412} and isinstance(data, (H2OErrorV3, H2OModelBuilderErrorV3)):\n            raise H2OResponseError(data)\n\n        # Server errors (notably 500 = \"Server Error\")\n        # Note that it is possible to receive valid H2OErrorV3 object in this case, however it merely means the server\n        # did not provide the correct status code.\n        raise H2OServerError(\"HTTP %d %s:\\n%r\" % (status_code, response.reason, data))", "code_tokens": ["def", "_process_response", "(", "response", ",", "save_to", ")", ":", "status_code", "=", "response", ".", "status_code", "if", "status_code", "==", "200", "and", "save_to", ":", "if", "save_to", ".", "startswith", "(", "\"~\"", ")", ":", "save_to", "=", "os", ".", "path", ".", "expanduser", "(", "save_to", ")", "if", "os", ".", "path", ".", "isdir", "(", "save_to", ")", "or", "save_to", ".", "endswith", "(", "os", ".", "path", ".", "sep", ")", ":", "dirname", "=", "os", ".", "path", ".", "abspath", "(", "save_to", ")", "filename", "=", "H2OConnection", ".", "_find_file_name", "(", "response", ")", "else", ":", "dirname", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "abspath", "(", "save_to", ")", ")", "fullname", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "filename", ")", "try", ":", "if", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "os", ".", "makedirs", "(", "dirname", ")", "with", "open", "(", "fullname", ",", "\"wb\"", ")", "as", "f", ":", "for", "chunk", "in", "response", ".", "iter_content", "(", "chunk_size", "=", "65536", ")", ":", "if", "chunk", ":", "# Empty chunks may occasionally happen", "f", ".", "write", "(", "chunk", ")", "except", "OSError", "as", "e", ":", "raise", "H2OValueError", "(", "\"Cannot write to file %s: %s\"", "%", "(", "fullname", ",", "e", ")", ")", "return", "fullname", "content_type", "=", "response", ".", "headers", ".", "get", "(", "\"Content-Type\"", ",", "\"\"", ")", "if", "\";\"", "in", "content_type", ":", "# Remove a \";charset=...\" part", "content_type", "=", "content_type", "[", ":", "content_type", ".", "index", "(", "\";\"", ")", "]", "# Auto-detect response type by its content-type. Decode JSON, all other responses pass as-is.", "if", "content_type", "==", "\"application/json\"", ":", "try", ":", "data", "=", "response", ".", "json", "(", "object_pairs_hook", "=", "H2OResponse", ")", "except", "(", "JSONDecodeError", ",", "requests", ".", "exceptions", ".", "ContentDecodingError", ")", "as", "e", ":", "raise", "H2OServerError", "(", "\"Malformed JSON from server (%s):\\n%s\"", "%", "(", "str", "(", "e", ")", ",", "response", ".", "text", ")", ")", "else", ":", "data", "=", "response", ".", "text", "# Success (200 = \"Ok\", 201 = \"Created\", 202 = \"Accepted\", 204 = \"No Content\")", "if", "status_code", "in", "{", "200", ",", "201", ",", "202", ",", "204", "}", ":", "return", "data", "# Client errors (400 = \"Bad Request\", 404 = \"Not Found\", 412 = \"Precondition Failed\")", "if", "status_code", "in", "{", "400", ",", "404", ",", "412", "}", "and", "isinstance", "(", "data", ",", "(", "H2OErrorV3", ",", "H2OModelBuilderErrorV3", ")", ")", ":", "raise", "H2OResponseError", "(", "data", ")", "# Server errors (notably 500 = \"Server Error\")", "# Note that it is possible to receive valid H2OErrorV3 object in this case, however it merely means the server", "# did not provide the correct status code.", "raise", "H2OServerError", "(", "\"HTTP %d %s:\\n%r\"", "%", "(", "status_code", ",", "response", ".", "reason", ",", "data", ")", ")"], "docstring": "Given a response object, prepare it to be handed over to the external caller.\n\n        Preparation steps include:\n           * detect if the response has error status, and convert it to an appropriate exception;\n           * detect Content-Type, and based on that either parse the response as JSON or return as plain text.", "docstring_tokens": ["Given", "a", "response", "object", "prepare", "it", "to", "be", "handed", "over", "to", "the", "external", "caller", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L696-L748", "partition": "test", "index": 1506, "time": "2016-07-01 13:16:04"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/shared_utils.py", "func_name": "get_human_readable_bytes", "original_string": "def get_human_readable_bytes(size):\n    \"\"\"\n    Convert given number of bytes into a human readable representation, i.e. add prefix such as kb, Mb, Gb,\n    etc. The `size` argument must be a non-negative integer.\n\n    :param size: integer representing byte size of something\n    :return: string representation of the size, in human-readable form\n    \"\"\"\n    if size == 0: return \"0\"\n    if size is None: return \"\"\n    assert_is_type(size, int)\n    assert size >= 0, \"`size` cannot be negative, got %d\" % size\n    suffixes = \"PTGMk\"\n    maxl = len(suffixes)\n    for i in range(maxl + 1):\n        shift = (maxl - i) * 10\n        if size >> shift == 0: continue\n        ndigits = 0\n        for nd in [3, 2, 1]:\n            if size >> (shift + 12 - nd * 3) == 0:\n                ndigits = nd\n                break\n        if ndigits == 0 or size == (size >> shift) << shift:\n            rounded_val = str(size >> shift)\n        else:\n            rounded_val = \"%.*f\" % (ndigits, size / (1 << shift))\n        return \"%s %sb\" % (rounded_val, suffixes[i] if i < maxl else \"\")", "language": "python", "code": "def get_human_readable_bytes(size):\n    \"\"\"\n    Convert given number of bytes into a human readable representation, i.e. add prefix such as kb, Mb, Gb,\n    etc. The `size` argument must be a non-negative integer.\n\n    :param size: integer representing byte size of something\n    :return: string representation of the size, in human-readable form\n    \"\"\"\n    if size == 0: return \"0\"\n    if size is None: return \"\"\n    assert_is_type(size, int)\n    assert size >= 0, \"`size` cannot be negative, got %d\" % size\n    suffixes = \"PTGMk\"\n    maxl = len(suffixes)\n    for i in range(maxl + 1):\n        shift = (maxl - i) * 10\n        if size >> shift == 0: continue\n        ndigits = 0\n        for nd in [3, 2, 1]:\n            if size >> (shift + 12 - nd * 3) == 0:\n                ndigits = nd\n                break\n        if ndigits == 0 or size == (size >> shift) << shift:\n            rounded_val = str(size >> shift)\n        else:\n            rounded_val = \"%.*f\" % (ndigits, size / (1 << shift))\n        return \"%s %sb\" % (rounded_val, suffixes[i] if i < maxl else \"\")", "code_tokens": ["def", "get_human_readable_bytes", "(", "size", ")", ":", "if", "size", "==", "0", ":", "return", "\"0\"", "if", "size", "is", "None", ":", "return", "\"\"", "assert_is_type", "(", "size", ",", "int", ")", "assert", "size", ">=", "0", ",", "\"`size` cannot be negative, got %d\"", "%", "size", "suffixes", "=", "\"PTGMk\"", "maxl", "=", "len", "(", "suffixes", ")", "for", "i", "in", "range", "(", "maxl", "+", "1", ")", ":", "shift", "=", "(", "maxl", "-", "i", ")", "*", "10", "if", "size", ">>", "shift", "==", "0", ":", "continue", "ndigits", "=", "0", "for", "nd", "in", "[", "3", ",", "2", ",", "1", "]", ":", "if", "size", ">>", "(", "shift", "+", "12", "-", "nd", "*", "3", ")", "==", "0", ":", "ndigits", "=", "nd", "break", "if", "ndigits", "==", "0", "or", "size", "==", "(", "size", ">>", "shift", ")", "<<", "shift", ":", "rounded_val", "=", "str", "(", "size", ">>", "shift", ")", "else", ":", "rounded_val", "=", "\"%.*f\"", "%", "(", "ndigits", ",", "size", "/", "(", "1", "<<", "shift", ")", ")", "return", "\"%s %sb\"", "%", "(", "rounded_val", ",", "suffixes", "[", "i", "]", "if", "i", "<", "maxl", "else", "\"\"", ")"], "docstring": "Convert given number of bytes into a human readable representation, i.e. add prefix such as kb, Mb, Gb,\n    etc. The `size` argument must be a non-negative integer.\n\n    :param size: integer representing byte size of something\n    :return: string representation of the size, in human-readable form", "docstring_tokens": ["Convert", "given", "number", "of", "bytes", "into", "a", "human", "readable", "representation", "i", ".", "e", ".", "add", "prefix", "such", "as", "kb", "Mb", "Gb", "etc", ".", "The", "size", "argument", "must", "be", "a", "non", "-", "negative", "integer", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/shared_utils.py#L253-L279", "partition": "test", "index": 1477, "time": "2016-07-06 18:09:41"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/connection.py", "func_name": "H2OConnection._log_start_transaction", "original_string": "def _log_start_transaction(self, endpoint, data, json, files, params):\n        \"\"\"Log the beginning of an API request.\"\"\"\n        # TODO: add information about the caller, i.e. which module + line of code called the .request() method\n        #       This can be done by fetching current traceback and then traversing it until we find the request function\n        self._requests_counter += 1\n        if not self._is_logging: return\n        msg = \"\\n---- %d --------------------------------------------------------\\n\" % self._requests_counter\n        msg += \"[%s] %s\\n\" % (time.strftime(\"%H:%M:%S\"), endpoint)\n        if params is not None: msg += \"     params: {%s}\\n\" % \", \".join(\"%s:%s\" % item for item in viewitems(params))\n        if data is not None:   msg += \"     body: {%s}\\n\" % \", \".join(\"%s:%s\" % item for item in viewitems(data))\n        if json is not None:\n            import json as j\n            msg += \"     json: %s\\n\" % j.dumps(json)\n        if files is not None:  msg += \"     file: %s\\n\" % \", \".join(f.name for f in viewvalues(files))\n        self._log_message(msg + \"\\n\")", "language": "python", "code": "def _log_start_transaction(self, endpoint, data, json, files, params):\n        \"\"\"Log the beginning of an API request.\"\"\"\n        # TODO: add information about the caller, i.e. which module + line of code called the .request() method\n        #       This can be done by fetching current traceback and then traversing it until we find the request function\n        self._requests_counter += 1\n        if not self._is_logging: return\n        msg = \"\\n---- %d --------------------------------------------------------\\n\" % self._requests_counter\n        msg += \"[%s] %s\\n\" % (time.strftime(\"%H:%M:%S\"), endpoint)\n        if params is not None: msg += \"     params: {%s}\\n\" % \", \".join(\"%s:%s\" % item for item in viewitems(params))\n        if data is not None:   msg += \"     body: {%s}\\n\" % \", \".join(\"%s:%s\" % item for item in viewitems(data))\n        if json is not None:\n            import json as j\n            msg += \"     json: %s\\n\" % j.dumps(json)\n        if files is not None:  msg += \"     file: %s\\n\" % \", \".join(f.name for f in viewvalues(files))\n        self._log_message(msg + \"\\n\")", "code_tokens": ["def", "_log_start_transaction", "(", "self", ",", "endpoint", ",", "data", ",", "json", ",", "files", ",", "params", ")", ":", "# TODO: add information about the caller, i.e. which module + line of code called the .request() method", "#       This can be done by fetching current traceback and then traversing it until we find the request function", "self", ".", "_requests_counter", "+=", "1", "if", "not", "self", ".", "_is_logging", ":", "return", "msg", "=", "\"\\n---- %d --------------------------------------------------------\\n\"", "%", "self", ".", "_requests_counter", "msg", "+=", "\"[%s] %s\\n\"", "%", "(", "time", ".", "strftime", "(", "\"%H:%M:%S\"", ")", ",", "endpoint", ")", "if", "params", "is", "not", "None", ":", "msg", "+=", "\"     params: {%s}\\n\"", "%", "\", \"", ".", "join", "(", "\"%s:%s\"", "%", "item", "for", "item", "in", "viewitems", "(", "params", ")", ")", "if", "data", "is", "not", "None", ":", "msg", "+=", "\"     body: {%s}\\n\"", "%", "\", \"", ".", "join", "(", "\"%s:%s\"", "%", "item", "for", "item", "in", "viewitems", "(", "data", ")", ")", "if", "json", "is", "not", "None", ":", "import", "json", "as", "j", "msg", "+=", "\"     json: %s\\n\"", "%", "j", ".", "dumps", "(", "json", ")", "if", "files", "is", "not", "None", ":", "msg", "+=", "\"     file: %s\\n\"", "%", "\", \"", ".", "join", "(", "f", ".", "name", "for", "f", "in", "viewvalues", "(", "files", ")", ")", "self", ".", "_log_message", "(", "msg", "+", "\"\\n\"", ")"], "docstring": "Log the beginning of an API request.", "docstring_tokens": ["Log", "the", "beginning", "of", "an", "API", "request", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L646-L660", "partition": "test", "index": 1503, "time": "2016-07-12 18:35:49"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "connect", "original_string": "def connect(server=None, url=None, ip=None, port=None, https=None, verify_ssl_certificates=None, auth=None,\n            proxy=None, cookies=None, verbose=True, config=None):\n    \"\"\"\n    Connect to an existing H2O server, remote or local.\n\n    There are two ways to connect to a server: either pass a `server` parameter containing an instance of\n    an H2OLocalServer, or specify `ip` and `port` of the server that you want to connect to.\n\n    :param server: An H2OLocalServer instance to connect to (optional).\n    :param url: Full URL of the server to connect to (can be used instead of `ip` + `port` + `https`).\n    :param ip: The ip address (or host name) of the server where H2O is running.\n    :param port: Port number that H2O service is listening to.\n    :param https: Set to True to connect via https:// instead of http://.\n    :param verify_ssl_certificates: When using https, setting this to False will disable SSL certificates verification.\n    :param auth: Either a (username, password) pair for basic authentication, an instance of h2o.auth.SpnegoAuth\n                 or one of the requests.auth authenticator objects.\n    :param proxy: Proxy server address.\n    :param cookies: Cookie (or list of) to add to request\n    :param verbose: Set to False to disable printing connection status messages.\n    :param connection_conf: Connection configuration object encapsulating connection parameters.\n    :returns: the new :class:`H2OConnection` object.\n    \"\"\"\n    global h2oconn\n    if config:\n        if \"connect_params\" in config:\n            h2oconn = _connect_with_conf(config[\"connect_params\"])\n        else:\n            h2oconn = _connect_with_conf(config)\n    else:\n        h2oconn = H2OConnection.open(server=server, url=url, ip=ip, port=port, https=https,\n                                     auth=auth, verify_ssl_certificates=verify_ssl_certificates,\n                                     proxy=proxy, cookies=cookies,\n                                     verbose=verbose)\n        if verbose:\n            h2oconn.cluster.show_status()\n    return h2oconn", "language": "python", "code": "def connect(server=None, url=None, ip=None, port=None, https=None, verify_ssl_certificates=None, auth=None,\n            proxy=None, cookies=None, verbose=True, config=None):\n    \"\"\"\n    Connect to an existing H2O server, remote or local.\n\n    There are two ways to connect to a server: either pass a `server` parameter containing an instance of\n    an H2OLocalServer, or specify `ip` and `port` of the server that you want to connect to.\n\n    :param server: An H2OLocalServer instance to connect to (optional).\n    :param url: Full URL of the server to connect to (can be used instead of `ip` + `port` + `https`).\n    :param ip: The ip address (or host name) of the server where H2O is running.\n    :param port: Port number that H2O service is listening to.\n    :param https: Set to True to connect via https:// instead of http://.\n    :param verify_ssl_certificates: When using https, setting this to False will disable SSL certificates verification.\n    :param auth: Either a (username, password) pair for basic authentication, an instance of h2o.auth.SpnegoAuth\n                 or one of the requests.auth authenticator objects.\n    :param proxy: Proxy server address.\n    :param cookies: Cookie (or list of) to add to request\n    :param verbose: Set to False to disable printing connection status messages.\n    :param connection_conf: Connection configuration object encapsulating connection parameters.\n    :returns: the new :class:`H2OConnection` object.\n    \"\"\"\n    global h2oconn\n    if config:\n        if \"connect_params\" in config:\n            h2oconn = _connect_with_conf(config[\"connect_params\"])\n        else:\n            h2oconn = _connect_with_conf(config)\n    else:\n        h2oconn = H2OConnection.open(server=server, url=url, ip=ip, port=port, https=https,\n                                     auth=auth, verify_ssl_certificates=verify_ssl_certificates,\n                                     proxy=proxy, cookies=cookies,\n                                     verbose=verbose)\n        if verbose:\n            h2oconn.cluster.show_status()\n    return h2oconn", "code_tokens": ["def", "connect", "(", "server", "=", "None", ",", "url", "=", "None", ",", "ip", "=", "None", ",", "port", "=", "None", ",", "https", "=", "None", ",", "verify_ssl_certificates", "=", "None", ",", "auth", "=", "None", ",", "proxy", "=", "None", ",", "cookies", "=", "None", ",", "verbose", "=", "True", ",", "config", "=", "None", ")", ":", "global", "h2oconn", "if", "config", ":", "if", "\"connect_params\"", "in", "config", ":", "h2oconn", "=", "_connect_with_conf", "(", "config", "[", "\"connect_params\"", "]", ")", "else", ":", "h2oconn", "=", "_connect_with_conf", "(", "config", ")", "else", ":", "h2oconn", "=", "H2OConnection", ".", "open", "(", "server", "=", "server", ",", "url", "=", "url", ",", "ip", "=", "ip", ",", "port", "=", "port", ",", "https", "=", "https", ",", "auth", "=", "auth", ",", "verify_ssl_certificates", "=", "verify_ssl_certificates", ",", "proxy", "=", "proxy", ",", "cookies", "=", "cookies", ",", "verbose", "=", "verbose", ")", "if", "verbose", ":", "h2oconn", ".", "cluster", ".", "show_status", "(", ")", "return", "h2oconn"], "docstring": "Connect to an existing H2O server, remote or local.\n\n    There are two ways to connect to a server: either pass a `server` parameter containing an instance of\n    an H2OLocalServer, or specify `ip` and `port` of the server that you want to connect to.\n\n    :param server: An H2OLocalServer instance to connect to (optional).\n    :param url: Full URL of the server to connect to (can be used instead of `ip` + `port` + `https`).\n    :param ip: The ip address (or host name) of the server where H2O is running.\n    :param port: Port number that H2O service is listening to.\n    :param https: Set to True to connect via https:// instead of http://.\n    :param verify_ssl_certificates: When using https, setting this to False will disable SSL certificates verification.\n    :param auth: Either a (username, password) pair for basic authentication, an instance of h2o.auth.SpnegoAuth\n                 or one of the requests.auth authenticator objects.\n    :param proxy: Proxy server address.\n    :param cookies: Cookie (or list of) to add to request\n    :param verbose: Set to False to disable printing connection status messages.\n    :param connection_conf: Connection configuration object encapsulating connection parameters.\n    :returns: the new :class:`H2OConnection` object.", "docstring_tokens": ["Connect", "to", "an", "existing", "H2O", "server", "remote", "or", "local", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L59-L94", "partition": "test", "index": 1452, "time": "2016-07-12 18:35:49"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "version_check", "original_string": "def version_check():\n    \"\"\"Used to verify that h2o-python module and the H2O server are compatible with each other.\"\"\"\n    from .__init__ import __version__ as ver_pkg\n    ci = h2oconn.cluster\n    if not ci:\n        raise H2OConnectionError(\"Connection not initialized. Did you run h2o.connect()?\")\n    ver_h2o = ci.version\n    if ver_pkg == \"SUBST_PROJECT_VERSION\": ver_pkg = \"UNKNOWN\"\n    if str(ver_h2o) != str(ver_pkg):\n        branch_name_h2o = ci.branch_name\n        build_number_h2o = ci.build_number\n        if build_number_h2o is None or build_number_h2o == \"unknown\":\n            raise H2OConnectionError(\n                \"Version mismatch. H2O is version {0}, but the h2o-python package is version {1}. \"\n                \"Upgrade H2O and h2o-Python to latest stable version - \"\n                \"http://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\"\n                \"\".format(ver_h2o, ver_pkg))\n        elif build_number_h2o == \"99999\":\n            raise H2OConnectionError(\n                \"Version mismatch. H2O is version {0}, but the h2o-python package is version {1}. \"\n                \"This is a developer build, please contact your developer.\"\n                \"\".format(ver_h2o, ver_pkg))\n        else:\n            raise H2OConnectionError(\n                \"Version mismatch. H2O is version {0}, but the h2o-python package is version {1}. \"\n                \"Install the matching h2o-Python version from - \"\n                \"http://h2o-release.s3.amazonaws.com/h2o/{2}/{3}/index.html.\"\n                \"\".format(ver_h2o, ver_pkg, branch_name_h2o, build_number_h2o))\n    # Check age of the install\n    if ci.build_too_old:\n        print(\"Warning: Your H2O cluster version is too old ({})! Please download and install the latest \"\n              \"version from http://h2o.ai/download/\".format(ci.build_age))", "language": "python", "code": "def version_check():\n    \"\"\"Used to verify that h2o-python module and the H2O server are compatible with each other.\"\"\"\n    from .__init__ import __version__ as ver_pkg\n    ci = h2oconn.cluster\n    if not ci:\n        raise H2OConnectionError(\"Connection not initialized. Did you run h2o.connect()?\")\n    ver_h2o = ci.version\n    if ver_pkg == \"SUBST_PROJECT_VERSION\": ver_pkg = \"UNKNOWN\"\n    if str(ver_h2o) != str(ver_pkg):\n        branch_name_h2o = ci.branch_name\n        build_number_h2o = ci.build_number\n        if build_number_h2o is None or build_number_h2o == \"unknown\":\n            raise H2OConnectionError(\n                \"Version mismatch. H2O is version {0}, but the h2o-python package is version {1}. \"\n                \"Upgrade H2O and h2o-Python to latest stable version - \"\n                \"http://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\"\n                \"\".format(ver_h2o, ver_pkg))\n        elif build_number_h2o == \"99999\":\n            raise H2OConnectionError(\n                \"Version mismatch. H2O is version {0}, but the h2o-python package is version {1}. \"\n                \"This is a developer build, please contact your developer.\"\n                \"\".format(ver_h2o, ver_pkg))\n        else:\n            raise H2OConnectionError(\n                \"Version mismatch. H2O is version {0}, but the h2o-python package is version {1}. \"\n                \"Install the matching h2o-Python version from - \"\n                \"http://h2o-release.s3.amazonaws.com/h2o/{2}/{3}/index.html.\"\n                \"\".format(ver_h2o, ver_pkg, branch_name_h2o, build_number_h2o))\n    # Check age of the install\n    if ci.build_too_old:\n        print(\"Warning: Your H2O cluster version is too old ({})! Please download and install the latest \"\n              \"version from http://h2o.ai/download/\".format(ci.build_age))", "code_tokens": ["def", "version_check", "(", ")", ":", "from", ".", "__init__", "import", "__version__", "as", "ver_pkg", "ci", "=", "h2oconn", ".", "cluster", "if", "not", "ci", ":", "raise", "H2OConnectionError", "(", "\"Connection not initialized. Did you run h2o.connect()?\"", ")", "ver_h2o", "=", "ci", ".", "version", "if", "ver_pkg", "==", "\"SUBST_PROJECT_VERSION\"", ":", "ver_pkg", "=", "\"UNKNOWN\"", "if", "str", "(", "ver_h2o", ")", "!=", "str", "(", "ver_pkg", ")", ":", "branch_name_h2o", "=", "ci", ".", "branch_name", "build_number_h2o", "=", "ci", ".", "build_number", "if", "build_number_h2o", "is", "None", "or", "build_number_h2o", "==", "\"unknown\"", ":", "raise", "H2OConnectionError", "(", "\"Version mismatch. H2O is version {0}, but the h2o-python package is version {1}. \"", "\"Upgrade H2O and h2o-Python to latest stable version - \"", "\"http://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\"", "\"\"", ".", "format", "(", "ver_h2o", ",", "ver_pkg", ")", ")", "elif", "build_number_h2o", "==", "\"99999\"", ":", "raise", "H2OConnectionError", "(", "\"Version mismatch. H2O is version {0}, but the h2o-python package is version {1}. \"", "\"This is a developer build, please contact your developer.\"", "\"\"", ".", "format", "(", "ver_h2o", ",", "ver_pkg", ")", ")", "else", ":", "raise", "H2OConnectionError", "(", "\"Version mismatch. H2O is version {0}, but the h2o-python package is version {1}. \"", "\"Install the matching h2o-Python version from - \"", "\"http://h2o-release.s3.amazonaws.com/h2o/{2}/{3}/index.html.\"", "\"\"", ".", "format", "(", "ver_h2o", ",", "ver_pkg", ",", "branch_name_h2o", ",", "build_number_h2o", ")", ")", "# Check age of the install", "if", "ci", ".", "build_too_old", ":", "print", "(", "\"Warning: Your H2O cluster version is too old ({})! Please download and install the latest \"", "\"version from http://h2o.ai/download/\"", ".", "format", "(", "ci", ".", "build_age", ")", ")"], "docstring": "Used to verify that h2o-python module and the H2O server are compatible with each other.", "docstring_tokens": ["Used", "to", "verify", "that", "h2o", "-", "python", "module", "and", "the", "H2O", "server", "are", "compatible", "with", "each", "other", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L115-L146", "partition": "test", "index": 1454, "time": "2016-07-12 18:35:49"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/connection.py", "func_name": "H2OConnection.session_id", "original_string": "def session_id(self):\n        \"\"\"\n        Return the session id of the current connection.\n\n        The session id is issued (through an API request) the first time it is requested, but no sooner. This is\n        because generating a session id puts it into the DKV on the server, which effectively locks the cluster. Once\n        issued, the session id will stay the same until the connection is closed.\n        \"\"\"\n        if self._session_id is None:\n            req = self.request(\"POST /4/sessions\")\n            self._session_id = req.get(\"session_key\") or req.get(\"session_id\")\n        return CallableString(self._session_id)", "language": "python", "code": "def session_id(self):\n        \"\"\"\n        Return the session id of the current connection.\n\n        The session id is issued (through an API request) the first time it is requested, but no sooner. This is\n        because generating a session id puts it into the DKV on the server, which effectively locks the cluster. Once\n        issued, the session id will stay the same until the connection is closed.\n        \"\"\"\n        if self._session_id is None:\n            req = self.request(\"POST /4/sessions\")\n            self._session_id = req.get(\"session_key\") or req.get(\"session_id\")\n        return CallableString(self._session_id)", "code_tokens": ["def", "session_id", "(", "self", ")", ":", "if", "self", ".", "_session_id", "is", "None", ":", "req", "=", "self", ".", "request", "(", "\"POST /4/sessions\"", ")", "self", ".", "_session_id", "=", "req", ".", "get", "(", "\"session_key\"", ")", "or", "req", ".", "get", "(", "\"session_id\"", ")", "return", "CallableString", "(", "self", ".", "_session_id", ")"], "docstring": "Return the session id of the current connection.\n\n        The session id is issued (through an API request) the first time it is requested, but no sooner. This is\n        because generating a session id puts it into the DKV on the server, which effectively locks the cluster. Once\n        issued, the session id will stay the same until the connection is closed.", "docstring_tokens": ["Return", "the", "session", "id", "of", "the", "current", "connection", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L448-L459", "partition": "test", "index": 1499, "time": "2016-07-12 18:35:49"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/connection.py", "func_name": "H2OConnection._prepare_file_payload", "original_string": "def _prepare_file_payload(filename):\n        \"\"\"\n        Prepare `filename` to be sent to the server.\n\n        The \"preparation\" consists of creating a data structure suitable\n        for passing to requests.request().\n        \"\"\"\n        if not filename: return None\n        absfilename = os.path.abspath(filename)\n        if not os.path.exists(absfilename):\n            raise H2OValueError(\"File %s does not exist\" % filename, skip_frames=1)\n        return {os.path.basename(absfilename): open(absfilename, \"rb\")}", "language": "python", "code": "def _prepare_file_payload(filename):\n        \"\"\"\n        Prepare `filename` to be sent to the server.\n\n        The \"preparation\" consists of creating a data structure suitable\n        for passing to requests.request().\n        \"\"\"\n        if not filename: return None\n        absfilename = os.path.abspath(filename)\n        if not os.path.exists(absfilename):\n            raise H2OValueError(\"File %s does not exist\" % filename, skip_frames=1)\n        return {os.path.basename(absfilename): open(absfilename, \"rb\")}", "code_tokens": ["def", "_prepare_file_payload", "(", "filename", ")", ":", "if", "not", "filename", ":", "return", "None", "absfilename", "=", "os", ".", "path", ".", "abspath", "(", "filename", ")", "if", "not", "os", ".", "path", ".", "exists", "(", "absfilename", ")", ":", "raise", "H2OValueError", "(", "\"File %s does not exist\"", "%", "filename", ",", "skip_frames", "=", "1", ")", "return", "{", "os", ".", "path", ".", "basename", "(", "absfilename", ")", ":", "open", "(", "absfilename", ",", "\"rb\"", ")", "}"], "docstring": "Prepare `filename` to be sent to the server.\n\n        The \"preparation\" consists of creating a data structure suitable\n        for passing to requests.request().", "docstring_tokens": ["Prepare", "filename", "to", "be", "sent", "to", "the", "server", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L632-L643", "partition": "test", "index": 1502, "time": "2016-07-12 18:35:49"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/connection.py", "func_name": "H2OConnection._log_end_transaction", "original_string": "def _log_end_transaction(self, start_time, response):\n        \"\"\"Log response from an API request.\"\"\"\n        if not self._is_logging: return\n        elapsed_time = int((time.time() - start_time) * 1000)\n        msg = \"<<< HTTP %d %s   (%d ms)\\n\" % (response.status_code, response.reason, elapsed_time)\n        if \"Content-Type\" in response.headers:\n            msg += \"    Content-Type: %s\\n\" % response.headers[\"Content-Type\"]\n        msg += response.text\n        self._log_message(msg + \"\\n\\n\")", "language": "python", "code": "def _log_end_transaction(self, start_time, response):\n        \"\"\"Log response from an API request.\"\"\"\n        if not self._is_logging: return\n        elapsed_time = int((time.time() - start_time) * 1000)\n        msg = \"<<< HTTP %d %s   (%d ms)\\n\" % (response.status_code, response.reason, elapsed_time)\n        if \"Content-Type\" in response.headers:\n            msg += \"    Content-Type: %s\\n\" % response.headers[\"Content-Type\"]\n        msg += response.text\n        self._log_message(msg + \"\\n\\n\")", "code_tokens": ["def", "_log_end_transaction", "(", "self", ",", "start_time", ",", "response", ")", ":", "if", "not", "self", ".", "_is_logging", ":", "return", "elapsed_time", "=", "int", "(", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", "*", "1000", ")", "msg", "=", "\"<<< HTTP %d %s   (%d ms)\\n\"", "%", "(", "response", ".", "status_code", ",", "response", ".", "reason", ",", "elapsed_time", ")", "if", "\"Content-Type\"", "in", "response", ".", "headers", ":", "msg", "+=", "\"    Content-Type: %s\\n\"", "%", "response", ".", "headers", "[", "\"Content-Type\"", "]", "msg", "+=", "response", ".", "text", "self", ".", "_log_message", "(", "msg", "+", "\"\\n\\n\"", ")"], "docstring": "Log response from an API request.", "docstring_tokens": ["Log", "response", "from", "an", "API", "request", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L663-L671", "partition": "test", "index": 1504, "time": "2016-07-12 18:35:49"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/connection.py", "func_name": "H2OConnection.start_logging", "original_string": "def start_logging(self, dest=None):\n        \"\"\"\n        Start logging all API requests to the provided destination.\n\n        :param dest: Where to write the log: either a filename (str), or an open file handle (file). If not given,\n            then a new temporary file will be created.\n        \"\"\"\n        assert_is_type(dest, None, str, type(sys.stdout))\n        if dest is None:\n            dest = os.path.join(tempfile.mkdtemp(), \"h2o-connection.log\")\n        self._print(\"Now logging all API requests to file %r\" % dest)\n        self._is_logging = True\n        self._logging_dest = dest", "language": "python", "code": "def start_logging(self, dest=None):\n        \"\"\"\n        Start logging all API requests to the provided destination.\n\n        :param dest: Where to write the log: either a filename (str), or an open file handle (file). If not given,\n            then a new temporary file will be created.\n        \"\"\"\n        assert_is_type(dest, None, str, type(sys.stdout))\n        if dest is None:\n            dest = os.path.join(tempfile.mkdtemp(), \"h2o-connection.log\")\n        self._print(\"Now logging all API requests to file %r\" % dest)\n        self._is_logging = True\n        self._logging_dest = dest", "code_tokens": ["def", "start_logging", "(", "self", ",", "dest", "=", "None", ")", ":", "assert_is_type", "(", "dest", ",", "None", ",", "str", ",", "type", "(", "sys", ".", "stdout", ")", ")", "if", "dest", "is", "None", ":", "dest", "=", "os", ".", "path", ".", "join", "(", "tempfile", ".", "mkdtemp", "(", ")", ",", "\"h2o-connection.log\"", ")", "self", ".", "_print", "(", "\"Now logging all API requests to file %r\"", "%", "dest", ")", "self", ".", "_is_logging", "=", "True", "self", ".", "_logging_dest", "=", "dest"], "docstring": "Start logging all API requests to the provided destination.\n\n        :param dest: Where to write the log: either a filename (str), or an open file handle (file). If not given,\n            then a new temporary file will be created.", "docstring_tokens": ["Start", "logging", "all", "API", "requests", "to", "the", "provided", "destination", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L503-L515", "partition": "test", "index": 1500, "time": "2016-07-13 16:03:11"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/connection.py", "func_name": "H2OConnection._log_message", "original_string": "def _log_message(self, msg):\n        \"\"\"\n        Log the message `msg` to the destination `self._logging_dest`.\n\n        If this destination is a file name, then we append the message to the file and then close the file\n        immediately. If the destination is an open file handle, then we simply write the message there and do not\n        attempt to close it.\n        \"\"\"\n        if is_type(self._logging_dest, str):\n            with open(self._logging_dest, \"at\", encoding=\"utf-8\") as f:\n                f.write(msg)\n        else:\n            self._logging_dest.write(msg)", "language": "python", "code": "def _log_message(self, msg):\n        \"\"\"\n        Log the message `msg` to the destination `self._logging_dest`.\n\n        If this destination is a file name, then we append the message to the file and then close the file\n        immediately. If the destination is an open file handle, then we simply write the message there and do not\n        attempt to close it.\n        \"\"\"\n        if is_type(self._logging_dest, str):\n            with open(self._logging_dest, \"at\", encoding=\"utf-8\") as f:\n                f.write(msg)\n        else:\n            self._logging_dest.write(msg)", "code_tokens": ["def", "_log_message", "(", "self", ",", "msg", ")", ":", "if", "is_type", "(", "self", ".", "_logging_dest", ",", "str", ")", ":", "with", "open", "(", "self", ".", "_logging_dest", ",", "\"at\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "f", ".", "write", "(", "msg", ")", "else", ":", "self", ".", "_logging_dest", ".", "write", "(", "msg", ")"], "docstring": "Log the message `msg` to the destination `self._logging_dest`.\n\n        If this destination is a file name, then we append the message to the file and then close the file\n        immediately. If the destination is an open file handle, then we simply write the message there and do not\n        attempt to close it.", "docstring_tokens": ["Log", "the", "message", "msg", "to", "the", "destination", "self", ".", "_logging_dest", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L680-L692", "partition": "test", "index": 1505, "time": "2016-07-13 16:03:11"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/job.py", "func_name": "H2OJob.poll", "original_string": "def poll(self, verbose_model_scoring_history = False):\n        \"\"\"\n        Wait until the job finishes.\n\n        This method will continuously query the server about the status of the job, until the job reaches a\n        completion. During this time we will display (in stdout) a progress bar with % completion status.\n        \"\"\"\n        try:\n            hidden = not H2OJob.__PROGRESS_BAR__\n            pb = ProgressBar(title=self._job_type + \" progress\", hidden=hidden)\n            if verbose_model_scoring_history:\n                pb.execute(self._refresh_job_status, print_verbose_info=lambda x: self._print_verbose_info() if int(x * 10) % 5 == 0  else \" \")\n            else:\n                pb.execute(self._refresh_job_status)\n        except StopIteration as e:\n            if str(e) == \"cancelled\":\n                h2o.api(\"POST /3/Jobs/%s/cancel\" % self.job_key)\n                self.status = \"CANCELLED\"\n            # Potentially we may want to re-raise the exception here\n\n        assert self.status in {\"DONE\", \"CANCELLED\", \"FAILED\"} or self._poll_count <= 0, \\\n            \"Polling finished while the job has status %s\" % self.status\n        if self.warnings:\n            for w in self.warnings:\n                warnings.warn(w)\n\n        # check if failed... and politely print relevant message\n        if self.status == \"CANCELLED\":\n            raise H2OJobCancelled(\"Job<%s> was cancelled by the user.\" % self.job_key)\n        if self.status == \"FAILED\":\n            if (isinstance(self.job, dict)) and (\"stacktrace\" in list(self.job)):\n                raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n                                       \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n            else:\n                raise EnvironmentError(\"Job with key %s failed with an exception: %s\" % (self.job_key, self.exception))\n\n        return self", "language": "python", "code": "def poll(self, verbose_model_scoring_history = False):\n        \"\"\"\n        Wait until the job finishes.\n\n        This method will continuously query the server about the status of the job, until the job reaches a\n        completion. During this time we will display (in stdout) a progress bar with % completion status.\n        \"\"\"\n        try:\n            hidden = not H2OJob.__PROGRESS_BAR__\n            pb = ProgressBar(title=self._job_type + \" progress\", hidden=hidden)\n            if verbose_model_scoring_history:\n                pb.execute(self._refresh_job_status, print_verbose_info=lambda x: self._print_verbose_info() if int(x * 10) % 5 == 0  else \" \")\n            else:\n                pb.execute(self._refresh_job_status)\n        except StopIteration as e:\n            if str(e) == \"cancelled\":\n                h2o.api(\"POST /3/Jobs/%s/cancel\" % self.job_key)\n                self.status = \"CANCELLED\"\n            # Potentially we may want to re-raise the exception here\n\n        assert self.status in {\"DONE\", \"CANCELLED\", \"FAILED\"} or self._poll_count <= 0, \\\n            \"Polling finished while the job has status %s\" % self.status\n        if self.warnings:\n            for w in self.warnings:\n                warnings.warn(w)\n\n        # check if failed... and politely print relevant message\n        if self.status == \"CANCELLED\":\n            raise H2OJobCancelled(\"Job<%s> was cancelled by the user.\" % self.job_key)\n        if self.status == \"FAILED\":\n            if (isinstance(self.job, dict)) and (\"stacktrace\" in list(self.job)):\n                raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n                                       \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n            else:\n                raise EnvironmentError(\"Job with key %s failed with an exception: %s\" % (self.job_key, self.exception))\n\n        return self", "code_tokens": ["def", "poll", "(", "self", ",", "verbose_model_scoring_history", "=", "False", ")", ":", "try", ":", "hidden", "=", "not", "H2OJob", ".", "__PROGRESS_BAR__", "pb", "=", "ProgressBar", "(", "title", "=", "self", ".", "_job_type", "+", "\" progress\"", ",", "hidden", "=", "hidden", ")", "if", "verbose_model_scoring_history", ":", "pb", ".", "execute", "(", "self", ".", "_refresh_job_status", ",", "print_verbose_info", "=", "lambda", "x", ":", "self", ".", "_print_verbose_info", "(", ")", "if", "int", "(", "x", "*", "10", ")", "%", "5", "==", "0", "else", "\" \"", ")", "else", ":", "pb", ".", "execute", "(", "self", ".", "_refresh_job_status", ")", "except", "StopIteration", "as", "e", ":", "if", "str", "(", "e", ")", "==", "\"cancelled\"", ":", "h2o", ".", "api", "(", "\"POST /3/Jobs/%s/cancel\"", "%", "self", ".", "job_key", ")", "self", ".", "status", "=", "\"CANCELLED\"", "# Potentially we may want to re-raise the exception here", "assert", "self", ".", "status", "in", "{", "\"DONE\"", ",", "\"CANCELLED\"", ",", "\"FAILED\"", "}", "or", "self", ".", "_poll_count", "<=", "0", ",", "\"Polling finished while the job has status %s\"", "%", "self", ".", "status", "if", "self", ".", "warnings", ":", "for", "w", "in", "self", ".", "warnings", ":", "warnings", ".", "warn", "(", "w", ")", "# check if failed... and politely print relevant message", "if", "self", ".", "status", "==", "\"CANCELLED\"", ":", "raise", "H2OJobCancelled", "(", "\"Job<%s> was cancelled by the user.\"", "%", "self", ".", "job_key", ")", "if", "self", ".", "status", "==", "\"FAILED\"", ":", "if", "(", "isinstance", "(", "self", ".", "job", ",", "dict", ")", ")", "and", "(", "\"stacktrace\"", "in", "list", "(", "self", ".", "job", ")", ")", ":", "raise", "EnvironmentError", "(", "\"Job with key {} failed with an exception: {}\\nstacktrace: \"", "\"\\n{}\"", ".", "format", "(", "self", ".", "job_key", ",", "self", ".", "exception", ",", "self", ".", "job", "[", "\"stacktrace\"", "]", ")", ")", "else", ":", "raise", "EnvironmentError", "(", "\"Job with key %s failed with an exception: %s\"", "%", "(", "self", ".", "job_key", ",", "self", ".", "exception", ")", ")", "return", "self"], "docstring": "Wait until the job finishes.\n\n        This method will continuously query the server about the status of the job, until the job reaches a\n        completion. During this time we will display (in stdout) a progress bar with % completion status.", "docstring_tokens": ["Wait", "until", "the", "job", "finishes", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/job.py#L45-L81", "partition": "test", "index": 1529, "time": "2016-07-14 17:58:45"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/compatibility.py", "func_name": "csv_dict_writer", "original_string": "def csv_dict_writer(f, fieldnames, **kwargs):\n    \"\"\"Equivalent of csv.DictWriter, but allows `delimiter` to be a unicode string on Py2.\"\"\"\n    import csv\n    if \"delimiter\" in kwargs:\n        kwargs[\"delimiter\"] = str(kwargs[\"delimiter\"])\n    return csv.DictWriter(f, fieldnames, **kwargs)", "language": "python", "code": "def csv_dict_writer(f, fieldnames, **kwargs):\n    \"\"\"Equivalent of csv.DictWriter, but allows `delimiter` to be a unicode string on Py2.\"\"\"\n    import csv\n    if \"delimiter\" in kwargs:\n        kwargs[\"delimiter\"] = str(kwargs[\"delimiter\"])\n    return csv.DictWriter(f, fieldnames, **kwargs)", "code_tokens": ["def", "csv_dict_writer", "(", "f", ",", "fieldnames", ",", "*", "*", "kwargs", ")", ":", "import", "csv", "if", "\"delimiter\"", "in", "kwargs", ":", "kwargs", "[", "\"delimiter\"", "]", "=", "str", "(", "kwargs", "[", "\"delimiter\"", "]", ")", "return", "csv", ".", "DictWriter", "(", "f", ",", "fieldnames", ",", "*", "*", "kwargs", ")"], "docstring": "Equivalent of csv.DictWriter, but allows `delimiter` to be a unicode string on Py2.", "docstring_tokens": ["Equivalent", "of", "csv", ".", "DictWriter", "but", "allows", "delimiter", "to", "be", "a", "unicode", "string", "on", "Py2", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/compatibility.py#L136-L141", "partition": "test", "index": 1556, "time": "2016-07-15 14:39:19"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/demos.py", "func_name": "deeplearning", "original_string": "def deeplearning(interactive=True, echo=True, testing=False):\n    \"\"\"Deep Learning model demo.\"\"\"\n\n    def demo_body(go):\n        \"\"\"\n        Demo of H2O's Deep Learning model.\n\n        This demo uploads a dataset to h2o, parses it, and shows a description.\n        Then it divides the dataset into training and test sets, builds a GLM\n        from the training set, and makes predictions for the test set.\n        Finally, default performance metrics are displayed.\n        \"\"\"\n        go()\n        # Connect to H2O\n        h2o.init()\n\n        go()\n        # Upload the prostate dataset that comes included in the h2o python package\n        prostate = h2o.load_dataset(\"prostate\")\n\n        go()\n        # Print a description of the prostate data\n        prostate.describe()\n\n        go()\n        # Randomly split the dataset into ~70/30, training/test sets\n        train, test = prostate.split_frame(ratios=[0.70])\n\n        go()\n        # Convert the response columns to factors (for binary classification problems)\n        train[\"CAPSULE\"] = train[\"CAPSULE\"].asfactor()\n        test[\"CAPSULE\"] = test[\"CAPSULE\"].asfactor()\n\n        go()\n        # Build a (classification) GLM\n        from h2o.estimators import H2ODeepLearningEstimator\n        prostate_dl = H2ODeepLearningEstimator(activation=\"Tanh\", hidden=[10, 10, 10], epochs=10000)\n        prostate_dl.train(x=list(set(prostate.col_names) - {\"ID\", \"CAPSULE\"}),\n                          y=\"CAPSULE\", training_frame=train)\n\n        go()\n        # Show the model\n        prostate_dl.show()\n\n        go()\n        # Predict on the test set and show the first ten predictions\n        predictions = prostate_dl.predict(test)\n        predictions.show()\n\n        go()\n        # Show default performance metrics\n        performance = prostate_dl.model_performance(test)\n        performance.show()\n\n    # Execute:\n    _run_demo(demo_body, interactive, echo, testing)", "language": "python", "code": "def deeplearning(interactive=True, echo=True, testing=False):\n    \"\"\"Deep Learning model demo.\"\"\"\n\n    def demo_body(go):\n        \"\"\"\n        Demo of H2O's Deep Learning model.\n\n        This demo uploads a dataset to h2o, parses it, and shows a description.\n        Then it divides the dataset into training and test sets, builds a GLM\n        from the training set, and makes predictions for the test set.\n        Finally, default performance metrics are displayed.\n        \"\"\"\n        go()\n        # Connect to H2O\n        h2o.init()\n\n        go()\n        # Upload the prostate dataset that comes included in the h2o python package\n        prostate = h2o.load_dataset(\"prostate\")\n\n        go()\n        # Print a description of the prostate data\n        prostate.describe()\n\n        go()\n        # Randomly split the dataset into ~70/30, training/test sets\n        train, test = prostate.split_frame(ratios=[0.70])\n\n        go()\n        # Convert the response columns to factors (for binary classification problems)\n        train[\"CAPSULE\"] = train[\"CAPSULE\"].asfactor()\n        test[\"CAPSULE\"] = test[\"CAPSULE\"].asfactor()\n\n        go()\n        # Build a (classification) GLM\n        from h2o.estimators import H2ODeepLearningEstimator\n        prostate_dl = H2ODeepLearningEstimator(activation=\"Tanh\", hidden=[10, 10, 10], epochs=10000)\n        prostate_dl.train(x=list(set(prostate.col_names) - {\"ID\", \"CAPSULE\"}),\n                          y=\"CAPSULE\", training_frame=train)\n\n        go()\n        # Show the model\n        prostate_dl.show()\n\n        go()\n        # Predict on the test set and show the first ten predictions\n        predictions = prostate_dl.predict(test)\n        predictions.show()\n\n        go()\n        # Show default performance metrics\n        performance = prostate_dl.model_performance(test)\n        performance.show()\n\n    # Execute:\n    _run_demo(demo_body, interactive, echo, testing)", "code_tokens": ["def", "deeplearning", "(", "interactive", "=", "True", ",", "echo", "=", "True", ",", "testing", "=", "False", ")", ":", "def", "demo_body", "(", "go", ")", ":", "\"\"\"\n        Demo of H2O's Deep Learning model.\n\n        This demo uploads a dataset to h2o, parses it, and shows a description.\n        Then it divides the dataset into training and test sets, builds a GLM\n        from the training set, and makes predictions for the test set.\n        Finally, default performance metrics are displayed.\n        \"\"\"", "go", "(", ")", "# Connect to H2O", "h2o", ".", "init", "(", ")", "go", "(", ")", "# Upload the prostate dataset that comes included in the h2o python package", "prostate", "=", "h2o", ".", "load_dataset", "(", "\"prostate\"", ")", "go", "(", ")", "# Print a description of the prostate data", "prostate", ".", "describe", "(", ")", "go", "(", ")", "# Randomly split the dataset into ~70/30, training/test sets", "train", ",", "test", "=", "prostate", ".", "split_frame", "(", "ratios", "=", "[", "0.70", "]", ")", "go", "(", ")", "# Convert the response columns to factors (for binary classification problems)", "train", "[", "\"CAPSULE\"", "]", "=", "train", "[", "\"CAPSULE\"", "]", ".", "asfactor", "(", ")", "test", "[", "\"CAPSULE\"", "]", "=", "test", "[", "\"CAPSULE\"", "]", ".", "asfactor", "(", ")", "go", "(", ")", "# Build a (classification) GLM", "from", "h2o", ".", "estimators", "import", "H2ODeepLearningEstimator", "prostate_dl", "=", "H2ODeepLearningEstimator", "(", "activation", "=", "\"Tanh\"", ",", "hidden", "=", "[", "10", ",", "10", ",", "10", "]", ",", "epochs", "=", "10000", ")", "prostate_dl", ".", "train", "(", "x", "=", "list", "(", "set", "(", "prostate", ".", "col_names", ")", "-", "{", "\"ID\"", ",", "\"CAPSULE\"", "}", ")", ",", "y", "=", "\"CAPSULE\"", ",", "training_frame", "=", "train", ")", "go", "(", ")", "# Show the model", "prostate_dl", ".", "show", "(", ")", "go", "(", ")", "# Predict on the test set and show the first ten predictions", "predictions", "=", "prostate_dl", ".", "predict", "(", "test", ")", "predictions", ".", "show", "(", ")", "go", "(", ")", "# Show default performance metrics", "performance", "=", "prostate_dl", ".", "model_performance", "(", "test", ")", "performance", ".", "show", "(", ")", "# Execute:", "_run_demo", "(", "demo_body", ",", "interactive", ",", "echo", ",", "testing", ")"], "docstring": "Deep Learning model demo.", "docstring_tokens": ["Deep", "Learning", "model", "demo", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/demos.py#L89-L144", "partition": "test", "index": 1547, "time": "2016-07-20 16:41:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/demos.py", "func_name": "glm", "original_string": "def glm(interactive=True, echo=True, testing=False):\n    \"\"\"GLM model demo.\"\"\"\n\n    def demo_body(go):\n        \"\"\"\n        Demo of H2O's Generalized Linear Estimator.\n\n        This demo uploads a dataset to h2o, parses it, and shows a description.\n        Then it divides the dataset into training and test sets, builds a GLM\n        from the training set, and makes predictions for the test set.\n        Finally, default performance metrics are displayed.\n        \"\"\"\n        go()\n        # Connect to H2O\n        h2o.init()\n\n        go()\n        # Upload the prostate dataset that comes included in the h2o python package\n        prostate = h2o.load_dataset(\"prostate\")\n\n        go()\n        # Print a description of the prostate data\n        prostate.describe()\n\n        go()\n        # Randomly split the dataset into ~70/30, training/test sets\n        train, test = prostate.split_frame(ratios=[0.70])\n\n        go()\n        # Convert the response columns to factors (for binary classification problems)\n        train[\"CAPSULE\"] = train[\"CAPSULE\"].asfactor()\n        test[\"CAPSULE\"] = test[\"CAPSULE\"].asfactor()\n\n        go()\n        # Build a (classification) GLM\n        from h2o.estimators import H2OGeneralizedLinearEstimator\n        prostate_glm = H2OGeneralizedLinearEstimator(family=\"binomial\", alpha=[0.5])\n        prostate_glm.train(x=[\"AGE\", \"RACE\", \"PSA\", \"VOL\", \"GLEASON\"],\n                           y=\"CAPSULE\", training_frame=train)\n\n        go()\n        # Show the model\n        prostate_glm.show()\n\n        go()\n        # Predict on the test set and show the first ten predictions\n        predictions = prostate_glm.predict(test)\n        predictions.show()\n\n        go()\n        # Show default performance metrics\n        performance = prostate_glm.model_performance(test)\n        performance.show()\n\n    # Execute:\n    _run_demo(demo_body, interactive, echo, testing)", "language": "python", "code": "def glm(interactive=True, echo=True, testing=False):\n    \"\"\"GLM model demo.\"\"\"\n\n    def demo_body(go):\n        \"\"\"\n        Demo of H2O's Generalized Linear Estimator.\n\n        This demo uploads a dataset to h2o, parses it, and shows a description.\n        Then it divides the dataset into training and test sets, builds a GLM\n        from the training set, and makes predictions for the test set.\n        Finally, default performance metrics are displayed.\n        \"\"\"\n        go()\n        # Connect to H2O\n        h2o.init()\n\n        go()\n        # Upload the prostate dataset that comes included in the h2o python package\n        prostate = h2o.load_dataset(\"prostate\")\n\n        go()\n        # Print a description of the prostate data\n        prostate.describe()\n\n        go()\n        # Randomly split the dataset into ~70/30, training/test sets\n        train, test = prostate.split_frame(ratios=[0.70])\n\n        go()\n        # Convert the response columns to factors (for binary classification problems)\n        train[\"CAPSULE\"] = train[\"CAPSULE\"].asfactor()\n        test[\"CAPSULE\"] = test[\"CAPSULE\"].asfactor()\n\n        go()\n        # Build a (classification) GLM\n        from h2o.estimators import H2OGeneralizedLinearEstimator\n        prostate_glm = H2OGeneralizedLinearEstimator(family=\"binomial\", alpha=[0.5])\n        prostate_glm.train(x=[\"AGE\", \"RACE\", \"PSA\", \"VOL\", \"GLEASON\"],\n                           y=\"CAPSULE\", training_frame=train)\n\n        go()\n        # Show the model\n        prostate_glm.show()\n\n        go()\n        # Predict on the test set and show the first ten predictions\n        predictions = prostate_glm.predict(test)\n        predictions.show()\n\n        go()\n        # Show default performance metrics\n        performance = prostate_glm.model_performance(test)\n        performance.show()\n\n    # Execute:\n    _run_demo(demo_body, interactive, echo, testing)", "code_tokens": ["def", "glm", "(", "interactive", "=", "True", ",", "echo", "=", "True", ",", "testing", "=", "False", ")", ":", "def", "demo_body", "(", "go", ")", ":", "\"\"\"\n        Demo of H2O's Generalized Linear Estimator.\n\n        This demo uploads a dataset to h2o, parses it, and shows a description.\n        Then it divides the dataset into training and test sets, builds a GLM\n        from the training set, and makes predictions for the test set.\n        Finally, default performance metrics are displayed.\n        \"\"\"", "go", "(", ")", "# Connect to H2O", "h2o", ".", "init", "(", ")", "go", "(", ")", "# Upload the prostate dataset that comes included in the h2o python package", "prostate", "=", "h2o", ".", "load_dataset", "(", "\"prostate\"", ")", "go", "(", ")", "# Print a description of the prostate data", "prostate", ".", "describe", "(", ")", "go", "(", ")", "# Randomly split the dataset into ~70/30, training/test sets", "train", ",", "test", "=", "prostate", ".", "split_frame", "(", "ratios", "=", "[", "0.70", "]", ")", "go", "(", ")", "# Convert the response columns to factors (for binary classification problems)", "train", "[", "\"CAPSULE\"", "]", "=", "train", "[", "\"CAPSULE\"", "]", ".", "asfactor", "(", ")", "test", "[", "\"CAPSULE\"", "]", "=", "test", "[", "\"CAPSULE\"", "]", ".", "asfactor", "(", ")", "go", "(", ")", "# Build a (classification) GLM", "from", "h2o", ".", "estimators", "import", "H2OGeneralizedLinearEstimator", "prostate_glm", "=", "H2OGeneralizedLinearEstimator", "(", "family", "=", "\"binomial\"", ",", "alpha", "=", "[", "0.5", "]", ")", "prostate_glm", ".", "train", "(", "x", "=", "[", "\"AGE\"", ",", "\"RACE\"", ",", "\"PSA\"", ",", "\"VOL\"", ",", "\"GLEASON\"", "]", ",", "y", "=", "\"CAPSULE\"", ",", "training_frame", "=", "train", ")", "go", "(", ")", "# Show the model", "prostate_glm", ".", "show", "(", ")", "go", "(", ")", "# Predict on the test set and show the first ten predictions", "predictions", "=", "prostate_glm", ".", "predict", "(", "test", ")", "predictions", ".", "show", "(", ")", "go", "(", ")", "# Show default performance metrics", "performance", "=", "prostate_glm", ".", "model_performance", "(", "test", ")", "performance", ".", "show", "(", ")", "# Execute:", "_run_demo", "(", "demo_body", ",", "interactive", ",", "echo", ",", "testing", ")"], "docstring": "GLM model demo.", "docstring_tokens": ["GLM", "model", "demo", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/demos.py#L148-L203", "partition": "test", "index": 1548, "time": "2016-07-20 16:41:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "demo", "original_string": "def demo(funcname, interactive=True, echo=True, test=False):\n    \"\"\"\n    H2O built-in demo facility.\n\n    :param funcname: A string that identifies the h2o python function to demonstrate.\n    :param interactive: If True, the user will be prompted to continue the demonstration after every segment.\n    :param echo: If True, the python commands that are executed will be displayed.\n    :param test: If True, `h2o.init()` will not be called (used for pyunit testing).\n\n    :example:\n        >>> import h2o\n        >>> h2o.demo(\"gbm\")\n    \"\"\"\n    import h2o.demos as h2odemo\n    assert_is_type(funcname, str)\n    assert_is_type(interactive, bool)\n    assert_is_type(echo, bool)\n    assert_is_type(test, bool)\n\n    demo_function = getattr(h2odemo, funcname, None)\n    if demo_function and type(demo_function) is type(demo):\n        demo_function(interactive, echo, test)\n    else:\n        print(\"Demo for %s is not available.\" % funcname)", "language": "python", "code": "def demo(funcname, interactive=True, echo=True, test=False):\n    \"\"\"\n    H2O built-in demo facility.\n\n    :param funcname: A string that identifies the h2o python function to demonstrate.\n    :param interactive: If True, the user will be prompted to continue the demonstration after every segment.\n    :param echo: If True, the python commands that are executed will be displayed.\n    :param test: If True, `h2o.init()` will not be called (used for pyunit testing).\n\n    :example:\n        >>> import h2o\n        >>> h2o.demo(\"gbm\")\n    \"\"\"\n    import h2o.demos as h2odemo\n    assert_is_type(funcname, str)\n    assert_is_type(interactive, bool)\n    assert_is_type(echo, bool)\n    assert_is_type(test, bool)\n\n    demo_function = getattr(h2odemo, funcname, None)\n    if demo_function and type(demo_function) is type(demo):\n        demo_function(interactive, echo, test)\n    else:\n        print(\"Demo for %s is not available.\" % funcname)", "code_tokens": ["def", "demo", "(", "funcname", ",", "interactive", "=", "True", ",", "echo", "=", "True", ",", "test", "=", "False", ")", ":", "import", "h2o", ".", "demos", "as", "h2odemo", "assert_is_type", "(", "funcname", ",", "str", ")", "assert_is_type", "(", "interactive", ",", "bool", ")", "assert_is_type", "(", "echo", ",", "bool", ")", "assert_is_type", "(", "test", ",", "bool", ")", "demo_function", "=", "getattr", "(", "h2odemo", ",", "funcname", ",", "None", ")", "if", "demo_function", "and", "type", "(", "demo_function", ")", "is", "type", "(", "demo", ")", ":", "demo_function", "(", "interactive", ",", "echo", ",", "test", ")", "else", ":", "print", "(", "\"Demo for %s is not available.\"", "%", "funcname", ")"], "docstring": "H2O built-in demo facility.\n\n    :param funcname: A string that identifies the h2o python function to demonstrate.\n    :param interactive: If True, the user will be prompted to continue the demonstration after every segment.\n    :param echo: If True, the python commands that are executed will be displayed.\n    :param test: If True, `h2o.init()` will not be called (used for pyunit testing).\n\n    :example:\n        >>> import h2o\n        >>> h2o.demo(\"gbm\")", "docstring_tokens": ["H2O", "built", "-", "in", "demo", "facility", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L1319-L1342", "partition": "test", "index": 1471, "time": "2016-07-20 16:41:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/demos.py", "func_name": "gbm", "original_string": "def gbm(interactive=True, echo=True, testing=False):\n    \"\"\"GBM model demo.\"\"\"\n\n    def demo_body(go):\n        \"\"\"\n        Demo of H2O's Gradient Boosting estimator.\n\n        This demo uploads a dataset to h2o, parses it, and shows a description.\n        Then it divides the dataset into training and test sets, builds a GLM\n        from the training set, and makes predictions for the test set.\n        Finally, default performance metrics are displayed.\n        \"\"\"\n        go()\n        # Connect to H2O\n        h2o.init()\n\n        go()\n        # Upload the prostate dataset that comes included in the h2o python package\n        prostate = h2o.load_dataset(\"prostate\")\n\n        go()\n        # Print a description of the prostate data\n        prostate.describe()\n\n        go()\n        # Randomly split the dataset into ~70/30, training/test sets\n        train, test = prostate.split_frame(ratios=[0.70])\n\n        go()\n        # Convert the response columns to factors (for binary classification problems)\n        train[\"CAPSULE\"] = train[\"CAPSULE\"].asfactor()\n        test[\"CAPSULE\"] = test[\"CAPSULE\"].asfactor()\n\n        go()\n        # Build a (classification) GLM\n        from h2o.estimators import H2OGradientBoostingEstimator\n        prostate_gbm = H2OGradientBoostingEstimator(distribution=\"bernoulli\", ntrees=10, max_depth=8,\n                                                    min_rows=10, learn_rate=0.2)\n        prostate_gbm.train(x=[\"AGE\", \"RACE\", \"PSA\", \"VOL\", \"GLEASON\"],\n                           y=\"CAPSULE\", training_frame=train)\n\n        go()\n        # Show the model\n        prostate_gbm.show()\n\n        go()\n        # Predict on the test set and show the first ten predictions\n        predictions = prostate_gbm.predict(test)\n        predictions.show()\n\n        go()\n        # Fetch a tree, print number of tree nodes, show root node description\n        from h2o.tree import H2OTree, H2ONode\n        tree = H2OTree(prostate_gbm, 0, \"0\")\n        len(tree)\n        tree.left_children\n        tree.right_children\n        tree.root_node.show()\n\n        go()\n        # Show default performance metrics\n        performance = prostate_gbm.model_performance(test)\n        performance.show()\n\n    # Execute:\n    _run_demo(demo_body, interactive, echo, testing)", "language": "python", "code": "def gbm(interactive=True, echo=True, testing=False):\n    \"\"\"GBM model demo.\"\"\"\n\n    def demo_body(go):\n        \"\"\"\n        Demo of H2O's Gradient Boosting estimator.\n\n        This demo uploads a dataset to h2o, parses it, and shows a description.\n        Then it divides the dataset into training and test sets, builds a GLM\n        from the training set, and makes predictions for the test set.\n        Finally, default performance metrics are displayed.\n        \"\"\"\n        go()\n        # Connect to H2O\n        h2o.init()\n\n        go()\n        # Upload the prostate dataset that comes included in the h2o python package\n        prostate = h2o.load_dataset(\"prostate\")\n\n        go()\n        # Print a description of the prostate data\n        prostate.describe()\n\n        go()\n        # Randomly split the dataset into ~70/30, training/test sets\n        train, test = prostate.split_frame(ratios=[0.70])\n\n        go()\n        # Convert the response columns to factors (for binary classification problems)\n        train[\"CAPSULE\"] = train[\"CAPSULE\"].asfactor()\n        test[\"CAPSULE\"] = test[\"CAPSULE\"].asfactor()\n\n        go()\n        # Build a (classification) GLM\n        from h2o.estimators import H2OGradientBoostingEstimator\n        prostate_gbm = H2OGradientBoostingEstimator(distribution=\"bernoulli\", ntrees=10, max_depth=8,\n                                                    min_rows=10, learn_rate=0.2)\n        prostate_gbm.train(x=[\"AGE\", \"RACE\", \"PSA\", \"VOL\", \"GLEASON\"],\n                           y=\"CAPSULE\", training_frame=train)\n\n        go()\n        # Show the model\n        prostate_gbm.show()\n\n        go()\n        # Predict on the test set and show the first ten predictions\n        predictions = prostate_gbm.predict(test)\n        predictions.show()\n\n        go()\n        # Fetch a tree, print number of tree nodes, show root node description\n        from h2o.tree import H2OTree, H2ONode\n        tree = H2OTree(prostate_gbm, 0, \"0\")\n        len(tree)\n        tree.left_children\n        tree.right_children\n        tree.root_node.show()\n\n        go()\n        # Show default performance metrics\n        performance = prostate_gbm.model_performance(test)\n        performance.show()\n\n    # Execute:\n    _run_demo(demo_body, interactive, echo, testing)", "code_tokens": ["def", "gbm", "(", "interactive", "=", "True", ",", "echo", "=", "True", ",", "testing", "=", "False", ")", ":", "def", "demo_body", "(", "go", ")", ":", "\"\"\"\n        Demo of H2O's Gradient Boosting estimator.\n\n        This demo uploads a dataset to h2o, parses it, and shows a description.\n        Then it divides the dataset into training and test sets, builds a GLM\n        from the training set, and makes predictions for the test set.\n        Finally, default performance metrics are displayed.\n        \"\"\"", "go", "(", ")", "# Connect to H2O", "h2o", ".", "init", "(", ")", "go", "(", ")", "# Upload the prostate dataset that comes included in the h2o python package", "prostate", "=", "h2o", ".", "load_dataset", "(", "\"prostate\"", ")", "go", "(", ")", "# Print a description of the prostate data", "prostate", ".", "describe", "(", ")", "go", "(", ")", "# Randomly split the dataset into ~70/30, training/test sets", "train", ",", "test", "=", "prostate", ".", "split_frame", "(", "ratios", "=", "[", "0.70", "]", ")", "go", "(", ")", "# Convert the response columns to factors (for binary classification problems)", "train", "[", "\"CAPSULE\"", "]", "=", "train", "[", "\"CAPSULE\"", "]", ".", "asfactor", "(", ")", "test", "[", "\"CAPSULE\"", "]", "=", "test", "[", "\"CAPSULE\"", "]", ".", "asfactor", "(", ")", "go", "(", ")", "# Build a (classification) GLM", "from", "h2o", ".", "estimators", "import", "H2OGradientBoostingEstimator", "prostate_gbm", "=", "H2OGradientBoostingEstimator", "(", "distribution", "=", "\"bernoulli\"", ",", "ntrees", "=", "10", ",", "max_depth", "=", "8", ",", "min_rows", "=", "10", ",", "learn_rate", "=", "0.2", ")", "prostate_gbm", ".", "train", "(", "x", "=", "[", "\"AGE\"", ",", "\"RACE\"", ",", "\"PSA\"", ",", "\"VOL\"", ",", "\"GLEASON\"", "]", ",", "y", "=", "\"CAPSULE\"", ",", "training_frame", "=", "train", ")", "go", "(", ")", "# Show the model", "prostate_gbm", ".", "show", "(", ")", "go", "(", ")", "# Predict on the test set and show the first ten predictions", "predictions", "=", "prostate_gbm", ".", "predict", "(", "test", ")", "predictions", ".", "show", "(", ")", "go", "(", ")", "# Fetch a tree, print number of tree nodes, show root node description", "from", "h2o", ".", "tree", "import", "H2OTree", ",", "H2ONode", "tree", "=", "H2OTree", "(", "prostate_gbm", ",", "0", ",", "\"0\"", ")", "len", "(", "tree", ")", "tree", ".", "left_children", "tree", ".", "right_children", "tree", ".", "root_node", ".", "show", "(", ")", "go", "(", ")", "# Show default performance metrics", "performance", "=", "prostate_gbm", ".", "model_performance", "(", "test", ")", "performance", ".", "show", "(", ")", "# Execute:", "_run_demo", "(", "demo_body", ",", "interactive", ",", "echo", ",", "testing", ")"], "docstring": "GBM model demo.", "docstring_tokens": ["GBM", "model", "demo", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/demos.py#L20-L85", "partition": "test", "index": 1546, "time": "2016-07-20 16:41:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "load_dataset", "original_string": "def load_dataset(relative_path):\n    \"\"\"Imports a data file within the 'h2o_data' folder.\"\"\"\n    assert_is_type(relative_path, str)\n    h2o_dir = os.path.split(__file__)[0]\n    for possible_file in [os.path.join(h2o_dir, relative_path),\n                          os.path.join(h2o_dir, \"h2o_data\", relative_path),\n                          os.path.join(h2o_dir, \"h2o_data\", relative_path + \".csv\")]:\n        if os.path.exists(possible_file):\n            return upload_file(possible_file)\n    # File not found -- raise an error!\n    raise H2OValueError(\"Data file %s cannot be found\" % relative_path)", "language": "python", "code": "def load_dataset(relative_path):\n    \"\"\"Imports a data file within the 'h2o_data' folder.\"\"\"\n    assert_is_type(relative_path, str)\n    h2o_dir = os.path.split(__file__)[0]\n    for possible_file in [os.path.join(h2o_dir, relative_path),\n                          os.path.join(h2o_dir, \"h2o_data\", relative_path),\n                          os.path.join(h2o_dir, \"h2o_data\", relative_path + \".csv\")]:\n        if os.path.exists(possible_file):\n            return upload_file(possible_file)\n    # File not found -- raise an error!\n    raise H2OValueError(\"Data file %s cannot be found\" % relative_path)", "code_tokens": ["def", "load_dataset", "(", "relative_path", ")", ":", "assert_is_type", "(", "relative_path", ",", "str", ")", "h2o_dir", "=", "os", ".", "path", ".", "split", "(", "__file__", ")", "[", "0", "]", "for", "possible_file", "in", "[", "os", ".", "path", ".", "join", "(", "h2o_dir", ",", "relative_path", ")", ",", "os", ".", "path", ".", "join", "(", "h2o_dir", ",", "\"h2o_data\"", ",", "relative_path", ")", ",", "os", ".", "path", ".", "join", "(", "h2o_dir", ",", "\"h2o_data\"", ",", "relative_path", "+", "\".csv\"", ")", "]", ":", "if", "os", ".", "path", ".", "exists", "(", "possible_file", ")", ":", "return", "upload_file", "(", "possible_file", ")", "# File not found -- raise an error!", "raise", "H2OValueError", "(", "\"Data file %s cannot be found\"", "%", "relative_path", ")"], "docstring": "Imports a data file within the 'h2o_data' folder.", "docstring_tokens": ["Imports", "a", "data", "file", "within", "the", "h2o_data", "folder", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L1345-L1355", "partition": "test", "index": 1472, "time": "2016-07-21 14:41:19"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/shared_utils.py", "func_name": "deprecated", "original_string": "def deprecated(message):\n    \"\"\"The decorator to mark deprecated functions.\"\"\"\n    from traceback import extract_stack\n    assert message, \"`message` argument in @deprecated is required.\"\n\n    def deprecated_decorator(fun):\n        def decorator_invisible(*args, **kwargs):\n            stack = extract_stack()\n            assert len(stack) >= 2 and stack[-1][2] == \"decorator_invisible\", \"Got confusing stack... %r\" % stack\n            print(\"[WARNING] in %s line %d:\" % (stack[-2][0], stack[-2][1]))\n            print(\"    >>> %s\" % (stack[-2][3] or \"????\"))\n            print(\"        ^^^^ %s\" % message)\n            return fun(*args, **kwargs)\n\n        decorator_invisible.__doc__ = message\n        decorator_invisible.__name__ = fun.__name__\n        decorator_invisible.__module__ = fun.__module__\n        decorator_invisible.__deprecated__ = True\n        return decorator_invisible\n\n    return deprecated_decorator", "language": "python", "code": "def deprecated(message):\n    \"\"\"The decorator to mark deprecated functions.\"\"\"\n    from traceback import extract_stack\n    assert message, \"`message` argument in @deprecated is required.\"\n\n    def deprecated_decorator(fun):\n        def decorator_invisible(*args, **kwargs):\n            stack = extract_stack()\n            assert len(stack) >= 2 and stack[-1][2] == \"decorator_invisible\", \"Got confusing stack... %r\" % stack\n            print(\"[WARNING] in %s line %d:\" % (stack[-2][0], stack[-2][1]))\n            print(\"    >>> %s\" % (stack[-2][3] or \"????\"))\n            print(\"        ^^^^ %s\" % message)\n            return fun(*args, **kwargs)\n\n        decorator_invisible.__doc__ = message\n        decorator_invisible.__name__ = fun.__name__\n        decorator_invisible.__module__ = fun.__module__\n        decorator_invisible.__deprecated__ = True\n        return decorator_invisible\n\n    return deprecated_decorator", "code_tokens": ["def", "deprecated", "(", "message", ")", ":", "from", "traceback", "import", "extract_stack", "assert", "message", ",", "\"`message` argument in @deprecated is required.\"", "def", "deprecated_decorator", "(", "fun", ")", ":", "def", "decorator_invisible", "(", "*", "args", ",", "*", "*", "kwargs", ")", ":", "stack", "=", "extract_stack", "(", ")", "assert", "len", "(", "stack", ")", ">=", "2", "and", "stack", "[", "-", "1", "]", "[", "2", "]", "==", "\"decorator_invisible\"", ",", "\"Got confusing stack... %r\"", "%", "stack", "print", "(", "\"[WARNING] in %s line %d:\"", "%", "(", "stack", "[", "-", "2", "]", "[", "0", "]", ",", "stack", "[", "-", "2", "]", "[", "1", "]", ")", ")", "print", "(", "\"    >>> %s\"", "%", "(", "stack", "[", "-", "2", "]", "[", "3", "]", "or", "\"????\"", ")", ")", "print", "(", "\"        ^^^^ %s\"", "%", "message", ")", "return", "fun", "(", "*", "args", ",", "*", "*", "kwargs", ")", "decorator_invisible", ".", "__doc__", "=", "message", "decorator_invisible", ".", "__name__", "=", "fun", ".", "__name__", "decorator_invisible", ".", "__module__", "=", "fun", ".", "__module__", "decorator_invisible", ".", "__deprecated__", "=", "True", "return", "decorator_invisible", "return", "deprecated_decorator"], "docstring": "The decorator to mark deprecated functions.", "docstring_tokens": ["The", "decorator", "to", "mark", "deprecated", "functions", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/shared_utils.py#L494-L514", "partition": "test", "index": 1482, "time": "2016-07-21 14:41:19"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/grid/grid_search.py", "func_name": "H2OGridSearch.show", "original_string": "def show(self):\n        \"\"\"Print models sorted by metric.\"\"\"\n        hyper_combos = itertools.product(*list(self.hyper_params.values()))\n        if not self.models:\n            c_values = [[idx + 1, list(val)] for idx, val in enumerate(hyper_combos)]\n            print(H2OTwoDimTable(\n                col_header=['Model', 'Hyperparameters: [' + ', '.join(list(self.hyper_params.keys())) + ']'],\n                table_header='Grid Search of Model ' + self.model.__class__.__name__, cell_values=c_values))\n        else:\n            print(self.sorted_metric_table())", "language": "python", "code": "def show(self):\n        \"\"\"Print models sorted by metric.\"\"\"\n        hyper_combos = itertools.product(*list(self.hyper_params.values()))\n        if not self.models:\n            c_values = [[idx + 1, list(val)] for idx, val in enumerate(hyper_combos)]\n            print(H2OTwoDimTable(\n                col_header=['Model', 'Hyperparameters: [' + ', '.join(list(self.hyper_params.keys())) + ']'],\n                table_header='Grid Search of Model ' + self.model.__class__.__name__, cell_values=c_values))\n        else:\n            print(self.sorted_metric_table())", "code_tokens": ["def", "show", "(", "self", ")", ":", "hyper_combos", "=", "itertools", ".", "product", "(", "*", "list", "(", "self", ".", "hyper_params", ".", "values", "(", ")", ")", ")", "if", "not", "self", ".", "models", ":", "c_values", "=", "[", "[", "idx", "+", "1", ",", "list", "(", "val", ")", "]", "for", "idx", ",", "val", "in", "enumerate", "(", "hyper_combos", ")", "]", "print", "(", "H2OTwoDimTable", "(", "col_header", "=", "[", "'Model'", ",", "'Hyperparameters: ['", "+", "', '", ".", "join", "(", "list", "(", "self", ".", "hyper_params", ".", "keys", "(", ")", ")", ")", "+", "']'", "]", ",", "table_header", "=", "'Grid Search of Model '", "+", "self", ".", "model", ".", "__class__", ".", "__name__", ",", "cell_values", "=", "c_values", ")", ")", "else", ":", "print", "(", "self", ".", "sorted_metric_table", "(", ")", ")"], "docstring": "Print models sorted by metric.", "docstring_tokens": ["Print", "models", "sorted", "by", "metric", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/grid/grid_search.py#L460-L469", "partition": "test", "index": 1486, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/grid/grid_search.py", "func_name": "H2OGridSearch.get_grid", "original_string": "def get_grid(self, sort_by=None, decreasing=None):\n        \"\"\"\n        Retrieve an H2OGridSearch instance.\n\n        Optionally specify a metric by which to sort models and a sort order.\n        Note that if neither cross-validation nor a validation frame is used in the grid search, then the\n        training metrics will display in the \"get grid\" output. If a validation frame is passed to the grid, and\n        ``nfolds = 0``, then the validation metrics will display. However, if ``nfolds`` > 1, then cross-validation\n        metrics will display even if a validation frame is provided.\n\n        :param str sort_by: A metric by which to sort the models in the grid space. Choices are: ``\"logloss\"``,\n            ``\"residual_deviance\"``, ``\"mse\"``, ``\"auc\"``, ``\"r2\"``, ``\"accuracy\"``, ``\"precision\"``, ``\"recall\"``,\n            ``\"f1\"``, etc.\n        :param bool decreasing: Sort the models in decreasing order of metric if true, otherwise sort in increasing\n            order (default).\n\n        :returns: A new H2OGridSearch instance optionally sorted on the specified metric.\n        \"\"\"\n        if sort_by is None and decreasing is None: return self\n\n        grid_json = h2o.api(\"GET /99/Grids/%s\" % self._id, data={\"sort_by\": sort_by, \"decreasing\": decreasing})\n        grid = H2OGridSearch(self.model, self.hyper_params, self._id)\n        grid.models = [h2o.get_model(key['name']) for key in grid_json['model_ids']]  # reordered\n        first_model_json = h2o.api(\"GET /99/Models/%s\" % grid_json['model_ids'][0]['name'])['models'][0]\n        model_class = H2OGridSearch._metrics_class(first_model_json)\n        m = model_class()\n        m._id = self._id\n        m._grid_json = grid_json\n        # m._metrics_class = metrics_class\n        m._parms = grid._parms\n        H2OEstimator.mixin(grid, model_class)\n        grid.__dict__.update(m.__dict__.copy())\n        return grid", "language": "python", "code": "def get_grid(self, sort_by=None, decreasing=None):\n        \"\"\"\n        Retrieve an H2OGridSearch instance.\n\n        Optionally specify a metric by which to sort models and a sort order.\n        Note that if neither cross-validation nor a validation frame is used in the grid search, then the\n        training metrics will display in the \"get grid\" output. If a validation frame is passed to the grid, and\n        ``nfolds = 0``, then the validation metrics will display. However, if ``nfolds`` > 1, then cross-validation\n        metrics will display even if a validation frame is provided.\n\n        :param str sort_by: A metric by which to sort the models in the grid space. Choices are: ``\"logloss\"``,\n            ``\"residual_deviance\"``, ``\"mse\"``, ``\"auc\"``, ``\"r2\"``, ``\"accuracy\"``, ``\"precision\"``, ``\"recall\"``,\n            ``\"f1\"``, etc.\n        :param bool decreasing: Sort the models in decreasing order of metric if true, otherwise sort in increasing\n            order (default).\n\n        :returns: A new H2OGridSearch instance optionally sorted on the specified metric.\n        \"\"\"\n        if sort_by is None and decreasing is None: return self\n\n        grid_json = h2o.api(\"GET /99/Grids/%s\" % self._id, data={\"sort_by\": sort_by, \"decreasing\": decreasing})\n        grid = H2OGridSearch(self.model, self.hyper_params, self._id)\n        grid.models = [h2o.get_model(key['name']) for key in grid_json['model_ids']]  # reordered\n        first_model_json = h2o.api(\"GET /99/Models/%s\" % grid_json['model_ids'][0]['name'])['models'][0]\n        model_class = H2OGridSearch._metrics_class(first_model_json)\n        m = model_class()\n        m._id = self._id\n        m._grid_json = grid_json\n        # m._metrics_class = metrics_class\n        m._parms = grid._parms\n        H2OEstimator.mixin(grid, model_class)\n        grid.__dict__.update(m.__dict__.copy())\n        return grid", "code_tokens": ["def", "get_grid", "(", "self", ",", "sort_by", "=", "None", ",", "decreasing", "=", "None", ")", ":", "if", "sort_by", "is", "None", "and", "decreasing", "is", "None", ":", "return", "self", "grid_json", "=", "h2o", ".", "api", "(", "\"GET /99/Grids/%s\"", "%", "self", ".", "_id", ",", "data", "=", "{", "\"sort_by\"", ":", "sort_by", ",", "\"decreasing\"", ":", "decreasing", "}", ")", "grid", "=", "H2OGridSearch", "(", "self", ".", "model", ",", "self", ".", "hyper_params", ",", "self", ".", "_id", ")", "grid", ".", "models", "=", "[", "h2o", ".", "get_model", "(", "key", "[", "'name'", "]", ")", "for", "key", "in", "grid_json", "[", "'model_ids'", "]", "]", "# reordered", "first_model_json", "=", "h2o", ".", "api", "(", "\"GET /99/Models/%s\"", "%", "grid_json", "[", "'model_ids'", "]", "[", "0", "]", "[", "'name'", "]", ")", "[", "'models'", "]", "[", "0", "]", "model_class", "=", "H2OGridSearch", ".", "_metrics_class", "(", "first_model_json", ")", "m", "=", "model_class", "(", ")", "m", ".", "_id", "=", "self", ".", "_id", "m", ".", "_grid_json", "=", "grid_json", "# m._metrics_class = metrics_class", "m", ".", "_parms", "=", "grid", ".", "_parms", "H2OEstimator", ".", "mixin", "(", "grid", ",", "model_class", ")", "grid", ".", "__dict__", ".", "update", "(", "m", ".", "__dict__", ".", "copy", "(", ")", ")", "return", "grid"], "docstring": "Retrieve an H2OGridSearch instance.\n\n        Optionally specify a metric by which to sort models and a sort order.\n        Note that if neither cross-validation nor a validation frame is used in the grid search, then the\n        training metrics will display in the \"get grid\" output. If a validation frame is passed to the grid, and\n        ``nfolds = 0``, then the validation metrics will display. However, if ``nfolds`` > 1, then cross-validation\n        metrics will display even if a validation frame is provided.\n\n        :param str sort_by: A metric by which to sort the models in the grid space. Choices are: ``\"logloss\"``,\n            ``\"residual_deviance\"``, ``\"mse\"``, ``\"auc\"``, ``\"r2\"``, ``\"accuracy\"``, ``\"precision\"``, ``\"recall\"``,\n            ``\"f1\"``, etc.\n        :param bool decreasing: Sort the models in decreasing order of metric if true, otherwise sort in increasing\n            order (default).\n\n        :returns: A new H2OGridSearch instance optionally sorted on the specified metric.", "docstring_tokens": ["Retrieve", "an", "H2OGridSearch", "instance", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/grid/grid_search.py#L770-L802", "partition": "test", "index": 1489, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/grid/grid_search.py", "func_name": "H2OGridSearch.get_hyperparams_dict", "original_string": "def get_hyperparams_dict(self, id, display=True):\n        \"\"\"\n        Derived and returned the model parameters used to train the particular grid search model.\n\n        :param str id: The model id of the model with hyperparameters of interest.\n        :param bool display: Flag to indicate whether to display the hyperparameter names.\n\n        :returns: A dict of model pararmeters derived from the hyper-parameters used to train this particular model.\n        \"\"\"\n        idx = id if is_type(id, int) else self.model_ids.index(id)\n        model = self[idx]\n\n        model_params = dict()\n\n        # if cross-validation is turned on, parameters in one of the fold model actual contains the max_runtime_secs\n        # parameter and not the main model that is returned.\n        if model._is_xvalidated:\n            model = h2o.get_model(model._xval_keys[0])\n\n        for param_name in self.hyper_names:\n            model_params[param_name] = model.params[param_name]['actual'][0] if \\\n                isinstance(model.params[param_name]['actual'], list) else model.params[param_name]['actual']\n\n        if display: print('Hyperparameters: [' + ', '.join(list(self.hyper_params.keys())) + ']')\n        return model_params", "language": "python", "code": "def get_hyperparams_dict(self, id, display=True):\n        \"\"\"\n        Derived and returned the model parameters used to train the particular grid search model.\n\n        :param str id: The model id of the model with hyperparameters of interest.\n        :param bool display: Flag to indicate whether to display the hyperparameter names.\n\n        :returns: A dict of model pararmeters derived from the hyper-parameters used to train this particular model.\n        \"\"\"\n        idx = id if is_type(id, int) else self.model_ids.index(id)\n        model = self[idx]\n\n        model_params = dict()\n\n        # if cross-validation is turned on, parameters in one of the fold model actual contains the max_runtime_secs\n        # parameter and not the main model that is returned.\n        if model._is_xvalidated:\n            model = h2o.get_model(model._xval_keys[0])\n\n        for param_name in self.hyper_names:\n            model_params[param_name] = model.params[param_name]['actual'][0] if \\\n                isinstance(model.params[param_name]['actual'], list) else model.params[param_name]['actual']\n\n        if display: print('Hyperparameters: [' + ', '.join(list(self.hyper_params.keys())) + ']')\n        return model_params", "code_tokens": ["def", "get_hyperparams_dict", "(", "self", ",", "id", ",", "display", "=", "True", ")", ":", "idx", "=", "id", "if", "is_type", "(", "id", ",", "int", ")", "else", "self", ".", "model_ids", ".", "index", "(", "id", ")", "model", "=", "self", "[", "idx", "]", "model_params", "=", "dict", "(", ")", "# if cross-validation is turned on, parameters in one of the fold model actual contains the max_runtime_secs", "# parameter and not the main model that is returned.", "if", "model", ".", "_is_xvalidated", ":", "model", "=", "h2o", ".", "get_model", "(", "model", ".", "_xval_keys", "[", "0", "]", ")", "for", "param_name", "in", "self", ".", "hyper_names", ":", "model_params", "[", "param_name", "]", "=", "model", ".", "params", "[", "param_name", "]", "[", "'actual'", "]", "[", "0", "]", "if", "isinstance", "(", "model", ".", "params", "[", "param_name", "]", "[", "'actual'", "]", ",", "list", ")", "else", "model", ".", "params", "[", "param_name", "]", "[", "'actual'", "]", "if", "display", ":", "print", "(", "'Hyperparameters: ['", "+", "', '", ".", "join", "(", "list", "(", "self", ".", "hyper_params", ".", "keys", "(", ")", ")", ")", "+", "']'", ")", "return", "model_params"], "docstring": "Derived and returned the model parameters used to train the particular grid search model.\n\n        :param str id: The model id of the model with hyperparameters of interest.\n        :param bool display: Flag to indicate whether to display the hyperparameter names.\n\n        :returns: A dict of model pararmeters derived from the hyper-parameters used to train this particular model.", "docstring_tokens": ["Derived", "and", "returned", "the", "model", "parameters", "used", "to", "train", "the", "particular", "grid", "search", "model", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/grid/grid_search.py#L710-L734", "partition": "test", "index": 1488, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/grid/grid_search.py", "func_name": "H2OGridSearch.get_hyperparams", "original_string": "def get_hyperparams(self, id, display=True):\n        \"\"\"\n        Get the hyperparameters of a model explored by grid search.\n\n        :param str id: The model id of the model with hyperparameters of interest.\n        :param bool display: Flag to indicate whether to display the hyperparameter names.\n\n        :returns: A list of the hyperparameters for the specified model.\n        \"\"\"\n        idx = id if is_type(id, int) else self.model_ids.index(id)\n        model = self[idx]\n\n        # if cross-validation is turned on, parameters in one of the fold model actuall contains the max_runtime_secs\n        # parameter and not the main model that is returned.\n        if model._is_xvalidated:\n            model = h2o.get_model(model._xval_keys[0])\n\n        res = [model.params[h]['actual'][0] if isinstance(model.params[h]['actual'], list)\n               else model.params[h]['actual']\n               for h in self.hyper_params]\n        if display: print('Hyperparameters: [' + ', '.join(list(self.hyper_params.keys())) + ']')\n        return res", "language": "python", "code": "def get_hyperparams(self, id, display=True):\n        \"\"\"\n        Get the hyperparameters of a model explored by grid search.\n\n        :param str id: The model id of the model with hyperparameters of interest.\n        :param bool display: Flag to indicate whether to display the hyperparameter names.\n\n        :returns: A list of the hyperparameters for the specified model.\n        \"\"\"\n        idx = id if is_type(id, int) else self.model_ids.index(id)\n        model = self[idx]\n\n        # if cross-validation is turned on, parameters in one of the fold model actuall contains the max_runtime_secs\n        # parameter and not the main model that is returned.\n        if model._is_xvalidated:\n            model = h2o.get_model(model._xval_keys[0])\n\n        res = [model.params[h]['actual'][0] if isinstance(model.params[h]['actual'], list)\n               else model.params[h]['actual']\n               for h in self.hyper_params]\n        if display: print('Hyperparameters: [' + ', '.join(list(self.hyper_params.keys())) + ']')\n        return res", "code_tokens": ["def", "get_hyperparams", "(", "self", ",", "id", ",", "display", "=", "True", ")", ":", "idx", "=", "id", "if", "is_type", "(", "id", ",", "int", ")", "else", "self", ".", "model_ids", ".", "index", "(", "id", ")", "model", "=", "self", "[", "idx", "]", "# if cross-validation is turned on, parameters in one of the fold model actuall contains the max_runtime_secs", "# parameter and not the main model that is returned.", "if", "model", ".", "_is_xvalidated", ":", "model", "=", "h2o", ".", "get_model", "(", "model", ".", "_xval_keys", "[", "0", "]", ")", "res", "=", "[", "model", ".", "params", "[", "h", "]", "[", "'actual'", "]", "[", "0", "]", "if", "isinstance", "(", "model", ".", "params", "[", "h", "]", "[", "'actual'", "]", ",", "list", ")", "else", "model", ".", "params", "[", "h", "]", "[", "'actual'", "]", "for", "h", "in", "self", ".", "hyper_params", "]", "if", "display", ":", "print", "(", "'Hyperparameters: ['", "+", "', '", ".", "join", "(", "list", "(", "self", ".", "hyper_params", ".", "keys", "(", ")", ")", ")", "+", "']'", ")", "return", "res"], "docstring": "Get the hyperparameters of a model explored by grid search.\n\n        :param str id: The model id of the model with hyperparameters of interest.\n        :param bool display: Flag to indicate whether to display the hyperparameter names.\n\n        :returns: A list of the hyperparameters for the specified model.", "docstring_tokens": ["Get", "the", "hyperparameters", "of", "a", "model", "explored", "by", "grid", "search", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/grid/grid_search.py#L686-L707", "partition": "test", "index": 1487, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/grid/grid_search.py", "func_name": "H2OGridSearch.summary", "original_string": "def summary(self, header=True):\n        \"\"\"Print a detailed summary of the explored models.\"\"\"\n        table = []\n        for model in self.models:\n            model_summary = model._model_json[\"output\"][\"model_summary\"]\n            r_values = list(model_summary.cell_values[0])\n            r_values[0] = model.model_id\n            table.append(r_values)\n\n        # if h2o.can_use_pandas():\n        #  import pandas\n        #  pandas.options.display.max_rows = 20\n        #  print pandas.DataFrame(table,columns=self.col_header)\n        #  return\n        print()\n        if header:\n            print('Grid Summary:')\n        print()\n        H2ODisplay(table, ['Model Id'] + model_summary.col_header[1:], numalign=\"left\", stralign=\"left\")", "language": "python", "code": "def summary(self, header=True):\n        \"\"\"Print a detailed summary of the explored models.\"\"\"\n        table = []\n        for model in self.models:\n            model_summary = model._model_json[\"output\"][\"model_summary\"]\n            r_values = list(model_summary.cell_values[0])\n            r_values[0] = model.model_id\n            table.append(r_values)\n\n        # if h2o.can_use_pandas():\n        #  import pandas\n        #  pandas.options.display.max_rows = 20\n        #  print pandas.DataFrame(table,columns=self.col_header)\n        #  return\n        print()\n        if header:\n            print('Grid Summary:')\n        print()\n        H2ODisplay(table, ['Model Id'] + model_summary.col_header[1:], numalign=\"left\", stralign=\"left\")", "code_tokens": ["def", "summary", "(", "self", ",", "header", "=", "True", ")", ":", "table", "=", "[", "]", "for", "model", "in", "self", ".", "models", ":", "model_summary", "=", "model", ".", "_model_json", "[", "\"output\"", "]", "[", "\"model_summary\"", "]", "r_values", "=", "list", "(", "model_summary", ".", "cell_values", "[", "0", "]", ")", "r_values", "[", "0", "]", "=", "model", ".", "model_id", "table", ".", "append", "(", "r_values", ")", "# if h2o.can_use_pandas():", "#  import pandas", "#  pandas.options.display.max_rows = 20", "#  print pandas.DataFrame(table,columns=self.col_header)", "#  return", "print", "(", ")", "if", "header", ":", "print", "(", "'Grid Summary:'", ")", "print", "(", ")", "H2ODisplay", "(", "table", ",", "[", "'Model Id'", "]", "+", "model_summary", ".", "col_header", "[", "1", ":", "]", ",", "numalign", "=", "\"left\"", ",", "stralign", "=", "\"left\"", ")"], "docstring": "Print a detailed summary of the explored models.", "docstring_tokens": ["Print", "a", "detailed", "summary", "of", "the", "explored", "models", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/grid/grid_search.py#L439-L457", "partition": "test", "index": 1485, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/grid/grid_search.py", "func_name": "H2OGridSearch.deepfeatures", "original_string": "def deepfeatures(self, test_data, layer):\n        \"\"\"\n        Obtain a hidden layer's details on a dataset.\n\n        :param test_data: Data to create a feature space on.\n        :param int layer: Index of the hidden layer.\n        :returns: A dictionary of hidden layer details for each model.\n        \"\"\"\n        return {model.model_id: model.deepfeatures(test_data, layer) for model in self.models}", "language": "python", "code": "def deepfeatures(self, test_data, layer):\n        \"\"\"\n        Obtain a hidden layer's details on a dataset.\n\n        :param test_data: Data to create a feature space on.\n        :param int layer: Index of the hidden layer.\n        :returns: A dictionary of hidden layer details for each model.\n        \"\"\"\n        return {model.model_id: model.deepfeatures(test_data, layer) for model in self.models}", "code_tokens": ["def", "deepfeatures", "(", "self", ",", "test_data", ",", "layer", ")", ":", "return", "{", "model", ".", "model_id", ":", "model", ".", "deepfeatures", "(", "test_data", ",", "layer", ")", "for", "model", "in", "self", ".", "models", "}"], "docstring": "Obtain a hidden layer's details on a dataset.\n\n        :param test_data: Data to create a feature space on.\n        :param int layer: Index of the hidden layer.\n        :returns: A dictionary of hidden layer details for each model.", "docstring_tokens": ["Obtain", "a", "hidden", "layer", "s", "details", "on", "a", "dataset", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/grid/grid_search.py#L358-L366", "partition": "test", "index": 1484, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/grid/metrics.py", "func_name": "H2OBinomialGridSearch.F1", "original_string": "def F1(self, thresholds=None, train=False, valid=False, xval=False):\n        \"\"\"\n        Get the F1 values for a set of thresholds for the models explored.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where\n        the keys are \"train\", \"valid\", and \"xval\".\n\n        :param List thresholds: If None, then the thresholds in this set of metrics will be used.\n        :param bool train: If True, return the F1 value for the training data.\n        :param bool valid: If True, return the F1 value for the validation data.\n        :param bool xval: If True, return the F1 value for each of the cross-validated splits.\n        :returns: Dictionary of model keys to F1 values\n        \"\"\"\n        return {model.model_id: model.F1(thresholds, train, valid, xval) for model in\n                self.models}", "language": "python", "code": "def F1(self, thresholds=None, train=False, valid=False, xval=False):\n        \"\"\"\n        Get the F1 values for a set of thresholds for the models explored.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where\n        the keys are \"train\", \"valid\", and \"xval\".\n\n        :param List thresholds: If None, then the thresholds in this set of metrics will be used.\n        :param bool train: If True, return the F1 value for the training data.\n        :param bool valid: If True, return the F1 value for the validation data.\n        :param bool xval: If True, return the F1 value for each of the cross-validated splits.\n        :returns: Dictionary of model keys to F1 values\n        \"\"\"\n        return {model.model_id: model.F1(thresholds, train, valid, xval) for model in\n                self.models}", "code_tokens": ["def", "F1", "(", "self", ",", "thresholds", "=", "None", ",", "train", "=", "False", ",", "valid", "=", "False", ",", "xval", "=", "False", ")", ":", "return", "{", "model", ".", "model_id", ":", "model", ".", "F1", "(", "thresholds", ",", "train", ",", "valid", ",", "xval", ")", "for", "model", "in", "self", ".", "models", "}"], "docstring": "Get the F1 values for a set of thresholds for the models explored.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where\n        the keys are \"train\", \"valid\", and \"xval\".\n\n        :param List thresholds: If None, then the thresholds in this set of metrics will be used.\n        :param bool train: If True, return the F1 value for the training data.\n        :param bool valid: If True, return the F1 value for the validation data.\n        :param bool xval: If True, return the F1 value for each of the cross-validated splits.\n        :returns: Dictionary of model keys to F1 values", "docstring_tokens": ["Get", "the", "F1", "values", "for", "a", "set", "of", "thresholds", "for", "the", "models", "explored", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/grid/metrics.py#L30-L45", "partition": "test", "index": 1490, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/grid/grid_search.py", "func_name": "H2OGridSearch.join", "original_string": "def join(self):\n        \"\"\"Wait until grid finishes computing.\"\"\"\n        self._future = False\n        self._job.poll()\n        self._job = None", "language": "python", "code": "def join(self):\n        \"\"\"Wait until grid finishes computing.\"\"\"\n        self._future = False\n        self._job.poll()\n        self._job = None", "code_tokens": ["def", "join", "(", "self", ")", ":", "self", ".", "_future", "=", "False", "self", ".", "_job", ".", "poll", "(", ")", "self", ".", "_job", "=", "None"], "docstring": "Wait until grid finishes computing.", "docstring_tokens": ["Wait", "until", "grid", "finishes", "computing", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/grid/grid_search.py#L147-L151", "partition": "test", "index": 1483, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/transforms/preprocessing.py", "func_name": "H2OScaler.fit", "original_string": "def fit(self, X, y=None, **params):\n        \"\"\"\n        Fit this object by computing the means and standard deviations used by the transform method.\n\n        :param X: An H2OFrame; may contain NAs and/or categoricals.\n        :param y: None (Ignored)\n        :param params: Ignored\n        :returns: This H2OScaler instance\n        \"\"\"\n        if isinstance(self.parms[\"center\"], (tuple, list)): self._means = self.parms[\"center\"]\n        if isinstance(self.parms[\"scale\"], (tuple, list)): self._stds = self.parms[\"scale\"]\n        if self.means is None and self.parms[\"center\"]:\n            self._means = X.mean(return_frame=True).getrow()\n        else:\n            self._means = False\n        if self.stds is None and self.parms[\"scale\"]:\n            self._stds = X.sd()\n        else:\n            self._stds = False\n        return self", "language": "python", "code": "def fit(self, X, y=None, **params):\n        \"\"\"\n        Fit this object by computing the means and standard deviations used by the transform method.\n\n        :param X: An H2OFrame; may contain NAs and/or categoricals.\n        :param y: None (Ignored)\n        :param params: Ignored\n        :returns: This H2OScaler instance\n        \"\"\"\n        if isinstance(self.parms[\"center\"], (tuple, list)): self._means = self.parms[\"center\"]\n        if isinstance(self.parms[\"scale\"], (tuple, list)): self._stds = self.parms[\"scale\"]\n        if self.means is None and self.parms[\"center\"]:\n            self._means = X.mean(return_frame=True).getrow()\n        else:\n            self._means = False\n        if self.stds is None and self.parms[\"scale\"]:\n            self._stds = X.sd()\n        else:\n            self._stds = False\n        return self", "code_tokens": ["def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ",", "*", "*", "params", ")", ":", "if", "isinstance", "(", "self", ".", "parms", "[", "\"center\"", "]", ",", "(", "tuple", ",", "list", ")", ")", ":", "self", ".", "_means", "=", "self", ".", "parms", "[", "\"center\"", "]", "if", "isinstance", "(", "self", ".", "parms", "[", "\"scale\"", "]", ",", "(", "tuple", ",", "list", ")", ")", ":", "self", ".", "_stds", "=", "self", ".", "parms", "[", "\"scale\"", "]", "if", "self", ".", "means", "is", "None", "and", "self", ".", "parms", "[", "\"center\"", "]", ":", "self", ".", "_means", "=", "X", ".", "mean", "(", "return_frame", "=", "True", ")", ".", "getrow", "(", ")", "else", ":", "self", ".", "_means", "=", "False", "if", "self", ".", "stds", "is", "None", "and", "self", ".", "parms", "[", "\"scale\"", "]", ":", "self", ".", "_stds", "=", "X", ".", "sd", "(", ")", "else", ":", "self", ".", "_stds", "=", "False", "return", "self"], "docstring": "Fit this object by computing the means and standard deviations used by the transform method.\n\n        :param X: An H2OFrame; may contain NAs and/or categoricals.\n        :param y: None (Ignored)\n        :param params: Ignored\n        :returns: This H2OScaler instance", "docstring_tokens": ["Fit", "this", "object", "by", "computing", "the", "means", "and", "standard", "deviations", "used", "by", "the", "transform", "method", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/transforms/preprocessing.py#L44-L63", "partition": "test", "index": 1511, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/transforms/preprocessing.py", "func_name": "H2OScaler.transform", "original_string": "def transform(self, X, y=None, **params):\n        \"\"\"\n        Scale an H2OFrame with the fitted means and standard deviations.\n\n        :param X: An H2OFrame; may contain NAs and/or categoricals.\n        :param y: None (Ignored)\n        :param params: (Ignored)\n        :returns: A scaled H2OFrame.\n        \"\"\"\n        return X.scale(self.means, self.stds)", "language": "python", "code": "def transform(self, X, y=None, **params):\n        \"\"\"\n        Scale an H2OFrame with the fitted means and standard deviations.\n\n        :param X: An H2OFrame; may contain NAs and/or categoricals.\n        :param y: None (Ignored)\n        :param params: (Ignored)\n        :returns: A scaled H2OFrame.\n        \"\"\"\n        return X.scale(self.means, self.stds)", "code_tokens": ["def", "transform", "(", "self", ",", "X", ",", "y", "=", "None", ",", "*", "*", "params", ")", ":", "return", "X", ".", "scale", "(", "self", ".", "means", ",", "self", ".", "stds", ")"], "docstring": "Scale an H2OFrame with the fitted means and standard deviations.\n\n        :param X: An H2OFrame; may contain NAs and/or categoricals.\n        :param y: None (Ignored)\n        :param params: (Ignored)\n        :returns: A scaled H2OFrame.", "docstring_tokens": ["Scale", "an", "H2OFrame", "with", "the", "fitted", "means", "and", "standard", "deviations", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/transforms/preprocessing.py#L66-L75", "partition": "test", "index": 1512, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/metrics_base.py", "func_name": "H2OBinomialModelMetrics.confusion_matrix", "original_string": "def confusion_matrix(self, metrics=None, thresholds=None):\n        \"\"\"\n        Get the confusion matrix for the specified metric\n\n        :param metrics: A string (or list of strings) among metrics listed in :const:`max_metrics`. Defaults to 'f1'.\n        :param thresholds: A value (or list of values) between 0 and 1.\n        :returns: a list of ConfusionMatrix objects (if there are more than one to return), or a single ConfusionMatrix\n            (if there is only one).\n        \"\"\"\n        # make lists out of metrics and thresholds arguments\n        if metrics is None and thresholds is None:\n            metrics = ['f1']\n\n        if isinstance(metrics, list):\n            metrics_list = metrics\n        elif metrics is None:\n            metrics_list = []\n        else:\n            metrics_list = [metrics]\n\n        if isinstance(thresholds, list):\n            thresholds_list = thresholds\n        elif thresholds is None:\n            thresholds_list = []\n        else:\n            thresholds_list = [thresholds]\n\n        # error check the metrics_list and thresholds_list\n        assert_is_type(thresholds_list, [numeric])\n        assert_satisfies(thresholds_list, all(0 <= t <= 1 for t in thresholds_list))\n\n        if not all(m.lower() in H2OBinomialModelMetrics.max_metrics for m in metrics_list):\n            raise ValueError(\"The only allowable metrics are {}\", ', '.join(H2OBinomialModelMetrics.max_metrics))\n\n        # make one big list that combines the thresholds and metric-thresholds\n        metrics_thresholds = [self.find_threshold_by_max_metric(m) for m in metrics_list]\n        for mt in metrics_thresholds:\n            thresholds_list.append(mt)\n        first_metrics_thresholds_offset = len(thresholds_list) - len(metrics_thresholds)\n\n        thresh2d = self._metric_json['thresholds_and_metric_scores']\n        actual_thresholds = [float(e[0]) for i, e in enumerate(thresh2d.cell_values)]\n        cms = []\n        for i, t in enumerate(thresholds_list):\n            idx = self.find_idx_by_threshold(t)\n            row = thresh2d.cell_values[idx]\n            tns = row[11]\n            fns = row[12]\n            fps = row[13]\n            tps = row[14]\n            p = tps + fns\n            n = tns + fps\n            c0 = n - fps\n            c1 = p - tps\n            if t in metrics_thresholds:\n                m = metrics_list[i - first_metrics_thresholds_offset]\n                table_header = \"Confusion Matrix (Act/Pred) for max {} @ threshold = {}\".format(m, actual_thresholds[idx])\n            else:\n                table_header = \"Confusion Matrix (Act/Pred) @ threshold = {}\".format(actual_thresholds[idx])\n            cms.append(ConfusionMatrix(cm=[[c0, fps], [c1, tps]], domains=self._metric_json['domain'],\n                                       table_header=table_header))\n\n        if len(cms) == 1:\n            return cms[0]\n        else:\n            return cms", "language": "python", "code": "def confusion_matrix(self, metrics=None, thresholds=None):\n        \"\"\"\n        Get the confusion matrix for the specified metric\n\n        :param metrics: A string (or list of strings) among metrics listed in :const:`max_metrics`. Defaults to 'f1'.\n        :param thresholds: A value (or list of values) between 0 and 1.\n        :returns: a list of ConfusionMatrix objects (if there are more than one to return), or a single ConfusionMatrix\n            (if there is only one).\n        \"\"\"\n        # make lists out of metrics and thresholds arguments\n        if metrics is None and thresholds is None:\n            metrics = ['f1']\n\n        if isinstance(metrics, list):\n            metrics_list = metrics\n        elif metrics is None:\n            metrics_list = []\n        else:\n            metrics_list = [metrics]\n\n        if isinstance(thresholds, list):\n            thresholds_list = thresholds\n        elif thresholds is None:\n            thresholds_list = []\n        else:\n            thresholds_list = [thresholds]\n\n        # error check the metrics_list and thresholds_list\n        assert_is_type(thresholds_list, [numeric])\n        assert_satisfies(thresholds_list, all(0 <= t <= 1 for t in thresholds_list))\n\n        if not all(m.lower() in H2OBinomialModelMetrics.max_metrics for m in metrics_list):\n            raise ValueError(\"The only allowable metrics are {}\", ', '.join(H2OBinomialModelMetrics.max_metrics))\n\n        # make one big list that combines the thresholds and metric-thresholds\n        metrics_thresholds = [self.find_threshold_by_max_metric(m) for m in metrics_list]\n        for mt in metrics_thresholds:\n            thresholds_list.append(mt)\n        first_metrics_thresholds_offset = len(thresholds_list) - len(metrics_thresholds)\n\n        thresh2d = self._metric_json['thresholds_and_metric_scores']\n        actual_thresholds = [float(e[0]) for i, e in enumerate(thresh2d.cell_values)]\n        cms = []\n        for i, t in enumerate(thresholds_list):\n            idx = self.find_idx_by_threshold(t)\n            row = thresh2d.cell_values[idx]\n            tns = row[11]\n            fns = row[12]\n            fps = row[13]\n            tps = row[14]\n            p = tps + fns\n            n = tns + fps\n            c0 = n - fps\n            c1 = p - tps\n            if t in metrics_thresholds:\n                m = metrics_list[i - first_metrics_thresholds_offset]\n                table_header = \"Confusion Matrix (Act/Pred) for max {} @ threshold = {}\".format(m, actual_thresholds[idx])\n            else:\n                table_header = \"Confusion Matrix (Act/Pred) @ threshold = {}\".format(actual_thresholds[idx])\n            cms.append(ConfusionMatrix(cm=[[c0, fps], [c1, tps]], domains=self._metric_json['domain'],\n                                       table_header=table_header))\n\n        if len(cms) == 1:\n            return cms[0]\n        else:\n            return cms", "code_tokens": ["def", "confusion_matrix", "(", "self", ",", "metrics", "=", "None", ",", "thresholds", "=", "None", ")", ":", "# make lists out of metrics and thresholds arguments", "if", "metrics", "is", "None", "and", "thresholds", "is", "None", ":", "metrics", "=", "[", "'f1'", "]", "if", "isinstance", "(", "metrics", ",", "list", ")", ":", "metrics_list", "=", "metrics", "elif", "metrics", "is", "None", ":", "metrics_list", "=", "[", "]", "else", ":", "metrics_list", "=", "[", "metrics", "]", "if", "isinstance", "(", "thresholds", ",", "list", ")", ":", "thresholds_list", "=", "thresholds", "elif", "thresholds", "is", "None", ":", "thresholds_list", "=", "[", "]", "else", ":", "thresholds_list", "=", "[", "thresholds", "]", "# error check the metrics_list and thresholds_list", "assert_is_type", "(", "thresholds_list", ",", "[", "numeric", "]", ")", "assert_satisfies", "(", "thresholds_list", ",", "all", "(", "0", "<=", "t", "<=", "1", "for", "t", "in", "thresholds_list", ")", ")", "if", "not", "all", "(", "m", ".", "lower", "(", ")", "in", "H2OBinomialModelMetrics", ".", "max_metrics", "for", "m", "in", "metrics_list", ")", ":", "raise", "ValueError", "(", "\"The only allowable metrics are {}\"", ",", "', '", ".", "join", "(", "H2OBinomialModelMetrics", ".", "max_metrics", ")", ")", "# make one big list that combines the thresholds and metric-thresholds", "metrics_thresholds", "=", "[", "self", ".", "find_threshold_by_max_metric", "(", "m", ")", "for", "m", "in", "metrics_list", "]", "for", "mt", "in", "metrics_thresholds", ":", "thresholds_list", ".", "append", "(", "mt", ")", "first_metrics_thresholds_offset", "=", "len", "(", "thresholds_list", ")", "-", "len", "(", "metrics_thresholds", ")", "thresh2d", "=", "self", ".", "_metric_json", "[", "'thresholds_and_metric_scores'", "]", "actual_thresholds", "=", "[", "float", "(", "e", "[", "0", "]", ")", "for", "i", ",", "e", "in", "enumerate", "(", "thresh2d", ".", "cell_values", ")", "]", "cms", "=", "[", "]", "for", "i", ",", "t", "in", "enumerate", "(", "thresholds_list", ")", ":", "idx", "=", "self", ".", "find_idx_by_threshold", "(", "t", ")", "row", "=", "thresh2d", ".", "cell_values", "[", "idx", "]", "tns", "=", "row", "[", "11", "]", "fns", "=", "row", "[", "12", "]", "fps", "=", "row", "[", "13", "]", "tps", "=", "row", "[", "14", "]", "p", "=", "tps", "+", "fns", "n", "=", "tns", "+", "fps", "c0", "=", "n", "-", "fps", "c1", "=", "p", "-", "tps", "if", "t", "in", "metrics_thresholds", ":", "m", "=", "metrics_list", "[", "i", "-", "first_metrics_thresholds_offset", "]", "table_header", "=", "\"Confusion Matrix (Act/Pred) for max {} @ threshold = {}\"", ".", "format", "(", "m", ",", "actual_thresholds", "[", "idx", "]", ")", "else", ":", "table_header", "=", "\"Confusion Matrix (Act/Pred) @ threshold = {}\"", ".", "format", "(", "actual_thresholds", "[", "idx", "]", ")", "cms", ".", "append", "(", "ConfusionMatrix", "(", "cm", "=", "[", "[", "c0", ",", "fps", "]", ",", "[", "c1", ",", "tps", "]", "]", ",", "domains", "=", "self", ".", "_metric_json", "[", "'domain'", "]", ",", "table_header", "=", "table_header", ")", ")", "if", "len", "(", "cms", ")", "==", "1", ":", "return", "cms", "[", "0", "]", "else", ":", "return", "cms"], "docstring": "Get the confusion matrix for the specified metric\n\n        :param metrics: A string (or list of strings) among metrics listed in :const:`max_metrics`. Defaults to 'f1'.\n        :param thresholds: A value (or list of values) between 0 and 1.\n        :returns: a list of ConfusionMatrix objects (if there are more than one to return), or a single ConfusionMatrix\n            (if there is only one).", "docstring_tokens": ["Get", "the", "confusion", "matrix", "for", "the", "specified", "metric"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/metrics_base.py#L588-L653", "partition": "test", "index": 1580, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/metrics_base.py", "func_name": "H2OBinomialModelMetrics.plot", "original_string": "def plot(self, type=\"roc\", server=False):\n        \"\"\"\n        Produce the desired metric plot.\n\n        :param type: the type of metric plot (currently, only ROC supported).\n        :param server: if True, generate plot inline using matplotlib's \"Agg\" backend.\n        :returns: None\n        \"\"\"\n        # TODO: add more types (i.e. cutoffs)\n        assert_is_type(type, \"roc\")\n        # check for matplotlib. exit if absent.\n        try:\n            imp.find_module('matplotlib')\n            import matplotlib\n            if server: matplotlib.use('Agg', warn=False)\n            import matplotlib.pyplot as plt\n        except ImportError:\n            print(\"matplotlib is required for this function!\")\n            return\n\n        if type == \"roc\":\n            plt.xlabel('False Positive Rate (FPR)')\n            plt.ylabel('True Positive Rate (TPR)')\n            plt.title('ROC Curve')\n            plt.text(0.5, 0.5, r'AUC={0:.4f}'.format(self._metric_json[\"AUC\"]))\n            plt.plot(self.fprs, self.tprs, 'b--')\n            plt.axis([0, 1, 0, 1])\n            if not server: plt.show()", "language": "python", "code": "def plot(self, type=\"roc\", server=False):\n        \"\"\"\n        Produce the desired metric plot.\n\n        :param type: the type of metric plot (currently, only ROC supported).\n        :param server: if True, generate plot inline using matplotlib's \"Agg\" backend.\n        :returns: None\n        \"\"\"\n        # TODO: add more types (i.e. cutoffs)\n        assert_is_type(type, \"roc\")\n        # check for matplotlib. exit if absent.\n        try:\n            imp.find_module('matplotlib')\n            import matplotlib\n            if server: matplotlib.use('Agg', warn=False)\n            import matplotlib.pyplot as plt\n        except ImportError:\n            print(\"matplotlib is required for this function!\")\n            return\n\n        if type == \"roc\":\n            plt.xlabel('False Positive Rate (FPR)')\n            plt.ylabel('True Positive Rate (TPR)')\n            plt.title('ROC Curve')\n            plt.text(0.5, 0.5, r'AUC={0:.4f}'.format(self._metric_json[\"AUC\"]))\n            plt.plot(self.fprs, self.tprs, 'b--')\n            plt.axis([0, 1, 0, 1])\n            if not server: plt.show()", "code_tokens": ["def", "plot", "(", "self", ",", "type", "=", "\"roc\"", ",", "server", "=", "False", ")", ":", "# TODO: add more types (i.e. cutoffs)", "assert_is_type", "(", "type", ",", "\"roc\"", ")", "# check for matplotlib. exit if absent.", "try", ":", "imp", ".", "find_module", "(", "'matplotlib'", ")", "import", "matplotlib", "if", "server", ":", "matplotlib", ".", "use", "(", "'Agg'", ",", "warn", "=", "False", ")", "import", "matplotlib", ".", "pyplot", "as", "plt", "except", "ImportError", ":", "print", "(", "\"matplotlib is required for this function!\"", ")", "return", "if", "type", "==", "\"roc\"", ":", "plt", ".", "xlabel", "(", "'False Positive Rate (FPR)'", ")", "plt", ".", "ylabel", "(", "'True Positive Rate (TPR)'", ")", "plt", ".", "title", "(", "'ROC Curve'", ")", "plt", ".", "text", "(", "0.5", ",", "0.5", ",", "r'AUC={0:.4f}'", ".", "format", "(", "self", ".", "_metric_json", "[", "\"AUC\"", "]", ")", ")", "plt", ".", "plot", "(", "self", ".", "fprs", ",", "self", ".", "tprs", ",", "'b--'", ")", "plt", ".", "axis", "(", "[", "0", ",", "1", ",", "0", ",", "1", "]", ")", "if", "not", "server", ":", "plt", ".", "show", "(", ")"], "docstring": "Produce the desired metric plot.\n\n        :param type: the type of metric plot (currently, only ROC supported).\n        :param server: if True, generate plot inline using matplotlib's \"Agg\" backend.\n        :returns: None", "docstring_tokens": ["Produce", "the", "desired", "metric", "plot", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/metrics_base.py#L527-L554", "partition": "test", "index": 1579, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/confusion_matrix.py", "func_name": "ConfusionMatrix.to_list", "original_string": "def to_list(self):\n        \"\"\"Convert this confusion matrix into a 2x2 plain list of values.\"\"\"\n        return [[int(self.table.cell_values[0][1]), int(self.table.cell_values[0][2])],\n                [int(self.table.cell_values[1][1]), int(self.table.cell_values[1][2])]]", "language": "python", "code": "def to_list(self):\n        \"\"\"Convert this confusion matrix into a 2x2 plain list of values.\"\"\"\n        return [[int(self.table.cell_values[0][1]), int(self.table.cell_values[0][2])],\n                [int(self.table.cell_values[1][1]), int(self.table.cell_values[1][2])]]", "code_tokens": ["def", "to_list", "(", "self", ")", ":", "return", "[", "[", "int", "(", "self", ".", "table", ".", "cell_values", "[", "0", "]", "[", "1", "]", ")", ",", "int", "(", "self", ".", "table", ".", "cell_values", "[", "0", "]", "[", "2", "]", ")", "]", ",", "[", "int", "(", "self", ".", "table", ".", "cell_values", "[", "1", "]", "[", "1", "]", ")", ",", "int", "(", "self", ".", "table", ".", "cell_values", "[", "1", "]", "[", "2", "]", ")", "]", "]"], "docstring": "Convert this confusion matrix into a 2x2 plain list of values.", "docstring_tokens": ["Convert", "this", "confusion", "matrix", "into", "a", "2x2", "plain", "list", "of", "values", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/confusion_matrix.py#L73-L76", "partition": "test", "index": 1564, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/expr.py", "func_name": "H2OCache._tabulate", "original_string": "def _tabulate(self, tablefmt=\"simple\", rollups=False, rows=10):\n        \"\"\"Pretty tabulated string of all the cached data, and column names\"\"\"\n        if not self.is_valid(): self.fill(rows=rows)\n        # Pretty print cached data\n        d = collections.OrderedDict()\n        # If also printing the rollup stats, build a full row-header\n        if rollups:\n            col = next(iter(viewvalues(self._data)))  # Get a sample column\n            lrows = len(col['data'])  # Cached rows being displayed\n            d[\"\"] = [\"type\", \"mins\", \"mean\", \"maxs\", \"sigma\", \"zeros\", \"missing\"] + list(map(str, range(lrows)))\n        # For all columns...\n        for k, v in viewitems(self._data):\n            x = v['data']  # Data to display\n            t = v[\"type\"]  # Column type\n            if t == \"enum\":\n                domain = v['domain']  # Map to cat strings as needed\n                x = [\"\" if math.isnan(idx) else domain[int(idx)] for idx in x]\n            elif t == \"time\":\n                x = [\"\" if math.isnan(z) else time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(z / 1000)) for z in x]\n            if rollups:  # Rollups, if requested\n                mins = v['mins'][0] if v['mins'] and v[\"type\"] != \"enum\" else None\n                maxs = v['maxs'][0] if v['maxs'] and v[\"type\"] != \"enum\" else None\n                #Cross check type with mean and sigma. Set to None if of type enum.\n                if v['type'] == \"enum\":\n                    v['mean'] = v['sigma'] = v['zero_count'] = None\n                x = [v['type'], mins, v['mean'], maxs, v['sigma'], v['zero_count'], v['missing_count']] + x\n            d[k] = x  # Insert into ordered-dict\n        return tabulate.tabulate(d, headers=\"keys\", tablefmt=tablefmt)", "language": "python", "code": "def _tabulate(self, tablefmt=\"simple\", rollups=False, rows=10):\n        \"\"\"Pretty tabulated string of all the cached data, and column names\"\"\"\n        if not self.is_valid(): self.fill(rows=rows)\n        # Pretty print cached data\n        d = collections.OrderedDict()\n        # If also printing the rollup stats, build a full row-header\n        if rollups:\n            col = next(iter(viewvalues(self._data)))  # Get a sample column\n            lrows = len(col['data'])  # Cached rows being displayed\n            d[\"\"] = [\"type\", \"mins\", \"mean\", \"maxs\", \"sigma\", \"zeros\", \"missing\"] + list(map(str, range(lrows)))\n        # For all columns...\n        for k, v in viewitems(self._data):\n            x = v['data']  # Data to display\n            t = v[\"type\"]  # Column type\n            if t == \"enum\":\n                domain = v['domain']  # Map to cat strings as needed\n                x = [\"\" if math.isnan(idx) else domain[int(idx)] for idx in x]\n            elif t == \"time\":\n                x = [\"\" if math.isnan(z) else time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(z / 1000)) for z in x]\n            if rollups:  # Rollups, if requested\n                mins = v['mins'][0] if v['mins'] and v[\"type\"] != \"enum\" else None\n                maxs = v['maxs'][0] if v['maxs'] and v[\"type\"] != \"enum\" else None\n                #Cross check type with mean and sigma. Set to None if of type enum.\n                if v['type'] == \"enum\":\n                    v['mean'] = v['sigma'] = v['zero_count'] = None\n                x = [v['type'], mins, v['mean'], maxs, v['sigma'], v['zero_count'], v['missing_count']] + x\n            d[k] = x  # Insert into ordered-dict\n        return tabulate.tabulate(d, headers=\"keys\", tablefmt=tablefmt)", "code_tokens": ["def", "_tabulate", "(", "self", ",", "tablefmt", "=", "\"simple\"", ",", "rollups", "=", "False", ",", "rows", "=", "10", ")", ":", "if", "not", "self", ".", "is_valid", "(", ")", ":", "self", ".", "fill", "(", "rows", "=", "rows", ")", "# Pretty print cached data", "d", "=", "collections", ".", "OrderedDict", "(", ")", "# If also printing the rollup stats, build a full row-header", "if", "rollups", ":", "col", "=", "next", "(", "iter", "(", "viewvalues", "(", "self", ".", "_data", ")", ")", ")", "# Get a sample column", "lrows", "=", "len", "(", "col", "[", "'data'", "]", ")", "# Cached rows being displayed", "d", "[", "\"\"", "]", "=", "[", "\"type\"", ",", "\"mins\"", ",", "\"mean\"", ",", "\"maxs\"", ",", "\"sigma\"", ",", "\"zeros\"", ",", "\"missing\"", "]", "+", "list", "(", "map", "(", "str", ",", "range", "(", "lrows", ")", ")", ")", "# For all columns...", "for", "k", ",", "v", "in", "viewitems", "(", "self", ".", "_data", ")", ":", "x", "=", "v", "[", "'data'", "]", "# Data to display", "t", "=", "v", "[", "\"type\"", "]", "# Column type", "if", "t", "==", "\"enum\"", ":", "domain", "=", "v", "[", "'domain'", "]", "# Map to cat strings as needed", "x", "=", "[", "\"\"", "if", "math", ".", "isnan", "(", "idx", ")", "else", "domain", "[", "int", "(", "idx", ")", "]", "for", "idx", "in", "x", "]", "elif", "t", "==", "\"time\"", ":", "x", "=", "[", "\"\"", "if", "math", ".", "isnan", "(", "z", ")", "else", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "time", ".", "gmtime", "(", "z", "/", "1000", ")", ")", "for", "z", "in", "x", "]", "if", "rollups", ":", "# Rollups, if requested", "mins", "=", "v", "[", "'mins'", "]", "[", "0", "]", "if", "v", "[", "'mins'", "]", "and", "v", "[", "\"type\"", "]", "!=", "\"enum\"", "else", "None", "maxs", "=", "v", "[", "'maxs'", "]", "[", "0", "]", "if", "v", "[", "'maxs'", "]", "and", "v", "[", "\"type\"", "]", "!=", "\"enum\"", "else", "None", "#Cross check type with mean and sigma. Set to None if of type enum.", "if", "v", "[", "'type'", "]", "==", "\"enum\"", ":", "v", "[", "'mean'", "]", "=", "v", "[", "'sigma'", "]", "=", "v", "[", "'zero_count'", "]", "=", "None", "x", "=", "[", "v", "[", "'type'", "]", ",", "mins", ",", "v", "[", "'mean'", "]", ",", "maxs", ",", "v", "[", "'sigma'", "]", ",", "v", "[", "'zero_count'", "]", ",", "v", "[", "'missing_count'", "]", "]", "+", "x", "d", "[", "k", "]", "=", "x", "# Insert into ordered-dict", "return", "tabulate", ".", "tabulate", "(", "d", ",", "headers", "=", "\"keys\"", ",", "tablefmt", "=", "tablefmt", ")"], "docstring": "Pretty tabulated string of all the cached data, and column names", "docstring_tokens": ["Pretty", "tabulated", "string", "of", "all", "the", "cached", "data", "and", "column", "names"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/expr.py#L382-L409", "partition": "test", "index": 1334, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/multinomial.py", "func_name": "H2OMultinomialModel.hit_ratio_table", "original_string": "def hit_ratio_table(self, train=False, valid=False, xval=False):\n        \"\"\"\n        Retrieve the Hit Ratios.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n        \"valid\", and \"xval\".\n\n        :param train: If train is True, then return the hit ratio value for the training data.\n        :param valid: If valid is True, then return the hit ratio value for the validation data.\n        :param xval:  If xval is True, then return the hit ratio value for the cross validation data.\n        :return: The hit ratio for this regression model.\n        \"\"\"\n        tm = ModelBase._get_metrics(self, train, valid, xval)\n        m = {}\n        for k, v in zip(list(tm.keys()), list(tm.values())): m[k] = None if v is None else v.hit_ratio_table()\n        return list(m.values())[0] if len(m) == 1 else m", "language": "python", "code": "def hit_ratio_table(self, train=False, valid=False, xval=False):\n        \"\"\"\n        Retrieve the Hit Ratios.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n        \"valid\", and \"xval\".\n\n        :param train: If train is True, then return the hit ratio value for the training data.\n        :param valid: If valid is True, then return the hit ratio value for the validation data.\n        :param xval:  If xval is True, then return the hit ratio value for the cross validation data.\n        :return: The hit ratio for this regression model.\n        \"\"\"\n        tm = ModelBase._get_metrics(self, train, valid, xval)\n        m = {}\n        for k, v in zip(list(tm.keys()), list(tm.values())): m[k] = None if v is None else v.hit_ratio_table()\n        return list(m.values())[0] if len(m) == 1 else m", "code_tokens": ["def", "hit_ratio_table", "(", "self", ",", "train", "=", "False", ",", "valid", "=", "False", ",", "xval", "=", "False", ")", ":", "tm", "=", "ModelBase", ".", "_get_metrics", "(", "self", ",", "train", ",", "valid", ",", "xval", ")", "m", "=", "{", "}", "for", "k", ",", "v", "in", "zip", "(", "list", "(", "tm", ".", "keys", "(", ")", ")", ",", "list", "(", "tm", ".", "values", "(", ")", ")", ")", ":", "m", "[", "k", "]", "=", "None", "if", "v", "is", "None", "else", "v", ".", "hit_ratio_table", "(", ")", "return", "list", "(", "m", ".", "values", "(", ")", ")", "[", "0", "]", "if", "len", "(", "m", ")", "==", "1", "else", "m"], "docstring": "Retrieve the Hit Ratios.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n        \"valid\", and \"xval\".\n\n        :param train: If train is True, then return the hit ratio value for the training data.\n        :param valid: If valid is True, then return the hit ratio value for the validation data.\n        :param xval:  If xval is True, then return the hit ratio value for the cross validation data.\n        :return: The hit ratio for this regression model.", "docstring_tokens": ["Retrieve", "the", "Hit", "Ratios", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/multinomial.py#L29-L45", "partition": "test", "index": 1555, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/two_dim_table.py", "func_name": "H2OTwoDimTable.as_data_frame", "original_string": "def as_data_frame(self):\n        \"\"\"Convert to a python 'data frame'.\"\"\"\n        if can_use_pandas():\n            import pandas\n            pandas.options.display.max_colwidth = 70\n            return pandas.DataFrame(self._cell_values, columns=self._col_header)\n        return self", "language": "python", "code": "def as_data_frame(self):\n        \"\"\"Convert to a python 'data frame'.\"\"\"\n        if can_use_pandas():\n            import pandas\n            pandas.options.display.max_colwidth = 70\n            return pandas.DataFrame(self._cell_values, columns=self._col_header)\n        return self", "code_tokens": ["def", "as_data_frame", "(", "self", ")", ":", "if", "can_use_pandas", "(", ")", ":", "import", "pandas", "pandas", ".", "options", ".", "display", ".", "max_colwidth", "=", "70", "return", "pandas", ".", "DataFrame", "(", "self", ".", "_cell_values", ",", "columns", "=", "self", ".", "_col_header", ")", "return", "self"], "docstring": "Convert to a python 'data frame'.", "docstring_tokens": ["Convert", "to", "a", "python", "data", "frame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/two_dim_table.py#L77-L83", "partition": "test", "index": 1550, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.cross_validation_models", "original_string": "def cross_validation_models(self):\n        \"\"\"\n        Obtain a list of cross-validation models.\n\n        :returns: list of H2OModel objects.\n        \"\"\"\n        cvmodels = self._model_json[\"output\"][\"cross_validation_models\"]\n        if cvmodels is None: return None\n        m = []\n        for p in cvmodels: m.append(h2o.get_model(p[\"name\"]))\n        return m", "language": "python", "code": "def cross_validation_models(self):\n        \"\"\"\n        Obtain a list of cross-validation models.\n\n        :returns: list of H2OModel objects.\n        \"\"\"\n        cvmodels = self._model_json[\"output\"][\"cross_validation_models\"]\n        if cvmodels is None: return None\n        m = []\n        for p in cvmodels: m.append(h2o.get_model(p[\"name\"]))\n        return m", "code_tokens": ["def", "cross_validation_models", "(", "self", ")", ":", "cvmodels", "=", "self", ".", "_model_json", "[", "\"output\"", "]", "[", "\"cross_validation_models\"", "]", "if", "cvmodels", "is", "None", ":", "return", "None", "m", "=", "[", "]", "for", "p", "in", "cvmodels", ":", "m", ".", "append", "(", "h2o", ".", "get_model", "(", "p", "[", "\"name\"", "]", ")", ")", "return", "m"], "docstring": "Obtain a list of cross-validation models.\n\n        :returns: list of H2OModel objects.", "docstring_tokens": ["Obtain", "a", "list", "of", "cross", "-", "validation", "models", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L1311-L1321", "partition": "test", "index": 1545, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase._check_targets", "original_string": "def _check_targets(y_actual, y_predicted):\n        \"\"\"Check that y_actual and y_predicted have the same length.\n\n        :param H2OFrame y_actual:\n        :param H2OFrame y_predicted:\n\n        :returns: None\n        \"\"\"\n        if len(y_actual) != len(y_predicted):\n            raise ValueError(\"Row mismatch: [{},{}]\".format(len(y_actual), len(y_predicted)))", "language": "python", "code": "def _check_targets(y_actual, y_predicted):\n        \"\"\"Check that y_actual and y_predicted have the same length.\n\n        :param H2OFrame y_actual:\n        :param H2OFrame y_predicted:\n\n        :returns: None\n        \"\"\"\n        if len(y_actual) != len(y_predicted):\n            raise ValueError(\"Row mismatch: [{},{}]\".format(len(y_actual), len(y_predicted)))", "code_tokens": ["def", "_check_targets", "(", "y_actual", ",", "y_predicted", ")", ":", "if", "len", "(", "y_actual", ")", "!=", "len", "(", "y_predicted", ")", ":", "raise", "ValueError", "(", "\"Row mismatch: [{},{}]\"", ".", "format", "(", "len", "(", "y_actual", ")", ",", "len", "(", "y_predicted", ")", ")", ")"], "docstring": "Check that y_actual and y_predicted have the same length.\n\n        :param H2OFrame y_actual:\n        :param H2OFrame y_predicted:\n\n        :returns: None", "docstring_tokens": ["Check", "that", "y_actual", "and", "y_predicted", "have", "the", "same", "length", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L1299-L1308", "partition": "test", "index": 1544, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.download_pojo", "original_string": "def download_pojo(self, path=\"\", get_genmodel_jar=False, genmodel_name=\"\"):\n        \"\"\"\n        Download the POJO for this model to the directory specified by path.\n\n        If path is an empty string, then dump the output to screen.\n\n        :param path:  An absolute path to the directory where POJO should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the POJO file written.\n        \"\"\"\n        assert_is_type(path, str)\n        assert_is_type(get_genmodel_jar, bool)\n        path = path.rstrip(\"/\")\n        return h2o.download_pojo(self, path, get_jar=get_genmodel_jar, jar_name=genmodel_name)", "language": "python", "code": "def download_pojo(self, path=\"\", get_genmodel_jar=False, genmodel_name=\"\"):\n        \"\"\"\n        Download the POJO for this model to the directory specified by path.\n\n        If path is an empty string, then dump the output to screen.\n\n        :param path:  An absolute path to the directory where POJO should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the POJO file written.\n        \"\"\"\n        assert_is_type(path, str)\n        assert_is_type(get_genmodel_jar, bool)\n        path = path.rstrip(\"/\")\n        return h2o.download_pojo(self, path, get_jar=get_genmodel_jar, jar_name=genmodel_name)", "code_tokens": ["def", "download_pojo", "(", "self", ",", "path", "=", "\"\"", ",", "get_genmodel_jar", "=", "False", ",", "genmodel_name", "=", "\"\"", ")", ":", "assert_is_type", "(", "path", ",", "str", ")", "assert_is_type", "(", "get_genmodel_jar", ",", "bool", ")", "path", "=", "path", ".", "rstrip", "(", "\"/\"", ")", "return", "h2o", ".", "download_pojo", "(", "self", ",", "path", ",", "get_jar", "=", "get_genmodel_jar", ",", "jar_name", "=", "genmodel_name", ")"], "docstring": "Download the POJO for this model to the directory specified by path.\n\n        If path is an empty string, then dump the output to screen.\n\n        :param path:  An absolute path to the directory where POJO should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the POJO file written.", "docstring_tokens": ["Download", "the", "POJO", "for", "this", "model", "to", "the", "directory", "specified", "by", "path", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L784-L798", "partition": "test", "index": 1541, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.coef", "original_string": "def coef(self):\n        \"\"\"\n        Return the coefficients which can be applied to the non-standardized data.\n\n        Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n        \"\"\"\n        tbl = self._model_json[\"output\"][\"coefficients_table\"]\n        if tbl is None:\n            return None\n        return {name: coef for name, coef in zip(tbl[\"names\"], tbl[\"coefficients\"])}", "language": "python", "code": "def coef(self):\n        \"\"\"\n        Return the coefficients which can be applied to the non-standardized data.\n\n        Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n        \"\"\"\n        tbl = self._model_json[\"output\"][\"coefficients_table\"]\n        if tbl is None:\n            return None\n        return {name: coef for name, coef in zip(tbl[\"names\"], tbl[\"coefficients\"])}", "code_tokens": ["def", "coef", "(", "self", ")", ":", "tbl", "=", "self", ".", "_model_json", "[", "\"output\"", "]", "[", "\"coefficients_table\"", "]", "if", "tbl", "is", "None", ":", "return", "None", "return", "{", "name", ":", "coef", "for", "name", ",", "coef", "in", "zip", "(", "tbl", "[", "\"names\"", "]", ",", "tbl", "[", "\"coefficients\"", "]", ")", "}"], "docstring": "Return the coefficients which can be applied to the non-standardized data.\n\n        Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.", "docstring_tokens": ["Return", "the", "coefficients", "which", "can", "be", "applied", "to", "the", "non", "-", "standardized", "data", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L547-L556", "partition": "test", "index": 1540, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.residual_degrees_of_freedom", "original_string": "def residual_degrees_of_freedom(self, train=False, valid=False, xval=False):\n        \"\"\"\n        Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n\n        :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n            is selected by default.\n        :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n            is selected by default.\n\n        :returns: Return the residual dof, or None if it is not present.\n        \"\"\"\n        if xval: raise H2OValueError(\"Cross-validation metrics are not available.\")\n        if not train and not valid: train = True\n        if train and valid:         train = True\n        if train:\n            return self._model_json[\"output\"][\"training_metrics\"].residual_degrees_of_freedom()\n        else:\n            return self._model_json[\"output\"][\"validation_metrics\"].residual_degrees_of_freedom()", "language": "python", "code": "def residual_degrees_of_freedom(self, train=False, valid=False, xval=False):\n        \"\"\"\n        Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n\n        :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n            is selected by default.\n        :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n            is selected by default.\n\n        :returns: Return the residual dof, or None if it is not present.\n        \"\"\"\n        if xval: raise H2OValueError(\"Cross-validation metrics are not available.\")\n        if not train and not valid: train = True\n        if train and valid:         train = True\n        if train:\n            return self._model_json[\"output\"][\"training_metrics\"].residual_degrees_of_freedom()\n        else:\n            return self._model_json[\"output\"][\"validation_metrics\"].residual_degrees_of_freedom()", "code_tokens": ["def", "residual_degrees_of_freedom", "(", "self", ",", "train", "=", "False", ",", "valid", "=", "False", ",", "xval", "=", "False", ")", ":", "if", "xval", ":", "raise", "H2OValueError", "(", "\"Cross-validation metrics are not available.\"", ")", "if", "not", "train", "and", "not", "valid", ":", "train", "=", "True", "if", "train", "and", "valid", ":", "train", "=", "True", "if", "train", ":", "return", "self", ".", "_model_json", "[", "\"output\"", "]", "[", "\"training_metrics\"", "]", ".", "residual_degrees_of_freedom", "(", ")", "else", ":", "return", "self", ".", "_model_json", "[", "\"output\"", "]", "[", "\"validation_metrics\"", "]", ".", "residual_degrees_of_freedom", "(", ")"], "docstring": "Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n\n        :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n            is selected by default.\n        :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n            is selected by default.\n\n        :returns: Return the residual dof, or None if it is not present.", "docstring_tokens": ["Retreive", "the", "residual", "degress", "of", "freedom", "if", "this", "model", "has", "the", "attribute", "or", "None", "otherwise", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L482-L499", "partition": "test", "index": 1539, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.varimp", "original_string": "def varimp(self, use_pandas=False):\n        \"\"\"\n        Pretty print the variable importances, or return them in a list.\n\n        :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n\n        :returns: A list or Pandas DataFrame.\n        \"\"\"\n        model = self._model_json[\"output\"]\n        if self.algo=='glm' or \"variable_importances\" in list(model.keys()) and model[\"variable_importances\"]:\n            if self.algo=='glm':\n                tempvals = model[\"standardized_coefficient_magnitudes\"].cell_values\n                maxVal = 0\n                sum=0\n                for item in tempvals:\n                    sum=sum+item[1]\n                    if item[1]>maxVal:\n                        maxVal = item[1]\n                vals = []\n                for item in tempvals:\n                    tempT = (item[0], item[1], item[1]/maxVal, item[1]/sum)\n                    vals.append(tempT)\n                header = [\"variable\", \"relative_importance\", \"scaled_importance\", \"percentage\"]\n            else:\n                vals = model[\"variable_importances\"].cell_values\n                header = model[\"variable_importances\"].col_header\n                \n            if use_pandas and can_use_pandas():\n                import pandas\n                return pandas.DataFrame(vals, columns=header)\n            else:\n                return vals\n        else:\n            print(\"Warning: This model doesn't have variable importances\")", "language": "python", "code": "def varimp(self, use_pandas=False):\n        \"\"\"\n        Pretty print the variable importances, or return them in a list.\n\n        :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n\n        :returns: A list or Pandas DataFrame.\n        \"\"\"\n        model = self._model_json[\"output\"]\n        if self.algo=='glm' or \"variable_importances\" in list(model.keys()) and model[\"variable_importances\"]:\n            if self.algo=='glm':\n                tempvals = model[\"standardized_coefficient_magnitudes\"].cell_values\n                maxVal = 0\n                sum=0\n                for item in tempvals:\n                    sum=sum+item[1]\n                    if item[1]>maxVal:\n                        maxVal = item[1]\n                vals = []\n                for item in tempvals:\n                    tempT = (item[0], item[1], item[1]/maxVal, item[1]/sum)\n                    vals.append(tempT)\n                header = [\"variable\", \"relative_importance\", \"scaled_importance\", \"percentage\"]\n            else:\n                vals = model[\"variable_importances\"].cell_values\n                header = model[\"variable_importances\"].col_header\n                \n            if use_pandas and can_use_pandas():\n                import pandas\n                return pandas.DataFrame(vals, columns=header)\n            else:\n                return vals\n        else:\n            print(\"Warning: This model doesn't have variable importances\")", "code_tokens": ["def", "varimp", "(", "self", ",", "use_pandas", "=", "False", ")", ":", "model", "=", "self", ".", "_model_json", "[", "\"output\"", "]", "if", "self", ".", "algo", "==", "'glm'", "or", "\"variable_importances\"", "in", "list", "(", "model", ".", "keys", "(", ")", ")", "and", "model", "[", "\"variable_importances\"", "]", ":", "if", "self", ".", "algo", "==", "'glm'", ":", "tempvals", "=", "model", "[", "\"standardized_coefficient_magnitudes\"", "]", ".", "cell_values", "maxVal", "=", "0", "sum", "=", "0", "for", "item", "in", "tempvals", ":", "sum", "=", "sum", "+", "item", "[", "1", "]", "if", "item", "[", "1", "]", ">", "maxVal", ":", "maxVal", "=", "item", "[", "1", "]", "vals", "=", "[", "]", "for", "item", "in", "tempvals", ":", "tempT", "=", "(", "item", "[", "0", "]", ",", "item", "[", "1", "]", ",", "item", "[", "1", "]", "/", "maxVal", ",", "item", "[", "1", "]", "/", "sum", ")", "vals", ".", "append", "(", "tempT", ")", "header", "=", "[", "\"variable\"", ",", "\"relative_importance\"", ",", "\"scaled_importance\"", ",", "\"percentage\"", "]", "else", ":", "vals", "=", "model", "[", "\"variable_importances\"", "]", ".", "cell_values", "header", "=", "model", "[", "\"variable_importances\"", "]", ".", "col_header", "if", "use_pandas", "and", "can_use_pandas", "(", ")", ":", "import", "pandas", "return", "pandas", ".", "DataFrame", "(", "vals", ",", "columns", "=", "header", ")", "else", ":", "return", "vals", "else", ":", "print", "(", "\"Warning: This model doesn't have variable importances\"", ")"], "docstring": "Pretty print the variable importances, or return them in a list.\n\n        :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n\n        :returns: A list or Pandas DataFrame.", "docstring_tokens": ["Pretty", "print", "the", "variable", "importances", "or", "return", "them", "in", "a", "list", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L426-L459", "partition": "test", "index": 1538, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.show", "original_string": "def show(self):\n        \"\"\"Print innards of model, without regards to type.\"\"\"\n        if self._future:\n            self._job.poll_once()\n            return\n        if self._model_json is None:\n            print(\"No model trained yet\")\n            return\n        if self.model_id is None:\n            print(\"This H2OEstimator has been removed.\")\n            return\n        model = self._model_json[\"output\"]\n        print(\"Model Details\")\n        print(\"=============\")\n\n        print(self.__class__.__name__, \": \", self._model_json[\"algo_full_name\"])\n        print(\"Model Key: \", self._id)\n\n        self.summary()\n\n        print()\n        # training metrics\n        tm = model[\"training_metrics\"]\n        if tm: tm.show()\n        vm = model[\"validation_metrics\"]\n        if vm: vm.show()\n        xm = model[\"cross_validation_metrics\"]\n        if xm: xm.show()\n        xms = model[\"cross_validation_metrics_summary\"]\n        if xms: xms.show()\n\n        if \"scoring_history\" in model and model[\"scoring_history\"]:\n            model[\"scoring_history\"].show()\n        if \"variable_importances\" in model and model[\"variable_importances\"]:\n            model[\"variable_importances\"].show()", "language": "python", "code": "def show(self):\n        \"\"\"Print innards of model, without regards to type.\"\"\"\n        if self._future:\n            self._job.poll_once()\n            return\n        if self._model_json is None:\n            print(\"No model trained yet\")\n            return\n        if self.model_id is None:\n            print(\"This H2OEstimator has been removed.\")\n            return\n        model = self._model_json[\"output\"]\n        print(\"Model Details\")\n        print(\"=============\")\n\n        print(self.__class__.__name__, \": \", self._model_json[\"algo_full_name\"])\n        print(\"Model Key: \", self._id)\n\n        self.summary()\n\n        print()\n        # training metrics\n        tm = model[\"training_metrics\"]\n        if tm: tm.show()\n        vm = model[\"validation_metrics\"]\n        if vm: vm.show()\n        xm = model[\"cross_validation_metrics\"]\n        if xm: xm.show()\n        xms = model[\"cross_validation_metrics_summary\"]\n        if xms: xms.show()\n\n        if \"scoring_history\" in model and model[\"scoring_history\"]:\n            model[\"scoring_history\"].show()\n        if \"variable_importances\" in model and model[\"variable_importances\"]:\n            model[\"variable_importances\"].show()", "code_tokens": ["def", "show", "(", "self", ")", ":", "if", "self", ".", "_future", ":", "self", ".", "_job", ".", "poll_once", "(", ")", "return", "if", "self", ".", "_model_json", "is", "None", ":", "print", "(", "\"No model trained yet\"", ")", "return", "if", "self", ".", "model_id", "is", "None", ":", "print", "(", "\"This H2OEstimator has been removed.\"", ")", "return", "model", "=", "self", ".", "_model_json", "[", "\"output\"", "]", "print", "(", "\"Model Details\"", ")", "print", "(", "\"=============\"", ")", "print", "(", "self", ".", "__class__", ".", "__name__", ",", "\": \"", ",", "self", ".", "_model_json", "[", "\"algo_full_name\"", "]", ")", "print", "(", "\"Model Key: \"", ",", "self", ".", "_id", ")", "self", ".", "summary", "(", ")", "print", "(", ")", "# training metrics", "tm", "=", "model", "[", "\"training_metrics\"", "]", "if", "tm", ":", "tm", ".", "show", "(", ")", "vm", "=", "model", "[", "\"validation_metrics\"", "]", "if", "vm", ":", "vm", ".", "show", "(", ")", "xm", "=", "model", "[", "\"cross_validation_metrics\"", "]", "if", "xm", ":", "xm", ".", "show", "(", ")", "xms", "=", "model", "[", "\"cross_validation_metrics_summary\"", "]", "if", "xms", ":", "xms", ".", "show", "(", ")", "if", "\"scoring_history\"", "in", "model", "and", "model", "[", "\"scoring_history\"", "]", ":", "model", "[", "\"scoring_history\"", "]", ".", "show", "(", ")", "if", "\"variable_importances\"", "in", "model", "and", "model", "[", "\"variable_importances\"", "]", ":", "model", "[", "\"variable_importances\"", "]", ".", "show", "(", ")"], "docstring": "Print innards of model, without regards to type.", "docstring_tokens": ["Print", "innards", "of", "model", "without", "regards", "to", "type", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L389-L423", "partition": "test", "index": 1537, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.scoring_history", "original_string": "def scoring_history(self):\n        \"\"\"\n        Retrieve Model Score History.\n\n        :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n        \"\"\"\n        model = self._model_json[\"output\"]\n        if \"scoring_history\" in model and model[\"scoring_history\"] is not None:\n            return model[\"scoring_history\"].as_data_frame()\n        print(\"No score history for this model\")", "language": "python", "code": "def scoring_history(self):\n        \"\"\"\n        Retrieve Model Score History.\n\n        :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n        \"\"\"\n        model = self._model_json[\"output\"]\n        if \"scoring_history\" in model and model[\"scoring_history\"] is not None:\n            return model[\"scoring_history\"].as_data_frame()\n        print(\"No score history for this model\")", "code_tokens": ["def", "scoring_history", "(", "self", ")", ":", "model", "=", "self", ".", "_model_json", "[", "\"output\"", "]", "if", "\"scoring_history\"", "in", "model", "and", "model", "[", "\"scoring_history\"", "]", "is", "not", "None", ":", "return", "model", "[", "\"scoring_history\"", "]", ".", "as_data_frame", "(", ")", "print", "(", "\"No score history for this model\"", ")"], "docstring": "Retrieve Model Score History.\n\n        :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.", "docstring_tokens": ["Retrieve", "Model", "Score", "History", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L357-L366", "partition": "test", "index": 1536, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.deepfeatures", "original_string": "def deepfeatures(self, test_data, layer):\n        \"\"\"\n        Return hidden layer details.\n\n        :param test_data: Data to create a feature space on\n        :param layer: 0 index hidden layer\n        \"\"\"\n        if test_data is None: raise ValueError(\"Must specify test data\")\n        if str(layer).isdigit():\n            j = H2OJob(h2o.api(\"POST /4/Predictions/models/%s/frames/%s\" % (self._id, test_data.frame_id),\n                               data={\"deep_features_hidden_layer\": layer}), \"deepfeatures\")\n        else:\n            j = H2OJob(h2o.api(\"POST /4/Predictions/models/%s/frames/%s\" % (self._id, test_data.frame_id),\n                               data={\"deep_features_hidden_layer_name\": layer}), \"deepfeatures\")\n        j.poll()\n        return h2o.get_frame(j.dest_key)", "language": "python", "code": "def deepfeatures(self, test_data, layer):\n        \"\"\"\n        Return hidden layer details.\n\n        :param test_data: Data to create a feature space on\n        :param layer: 0 index hidden layer\n        \"\"\"\n        if test_data is None: raise ValueError(\"Must specify test data\")\n        if str(layer).isdigit():\n            j = H2OJob(h2o.api(\"POST /4/Predictions/models/%s/frames/%s\" % (self._id, test_data.frame_id),\n                               data={\"deep_features_hidden_layer\": layer}), \"deepfeatures\")\n        else:\n            j = H2OJob(h2o.api(\"POST /4/Predictions/models/%s/frames/%s\" % (self._id, test_data.frame_id),\n                               data={\"deep_features_hidden_layer_name\": layer}), \"deepfeatures\")\n        j.poll()\n        return h2o.get_frame(j.dest_key)", "code_tokens": ["def", "deepfeatures", "(", "self", ",", "test_data", ",", "layer", ")", ":", "if", "test_data", "is", "None", ":", "raise", "ValueError", "(", "\"Must specify test data\"", ")", "if", "str", "(", "layer", ")", ".", "isdigit", "(", ")", ":", "j", "=", "H2OJob", "(", "h2o", ".", "api", "(", "\"POST /4/Predictions/models/%s/frames/%s\"", "%", "(", "self", ".", "_id", ",", "test_data", ".", "frame_id", ")", ",", "data", "=", "{", "\"deep_features_hidden_layer\"", ":", "layer", "}", ")", ",", "\"deepfeatures\"", ")", "else", ":", "j", "=", "H2OJob", "(", "h2o", ".", "api", "(", "\"POST /4/Predictions/models/%s/frames/%s\"", "%", "(", "self", ".", "_id", ",", "test_data", ".", "frame_id", ")", ",", "data", "=", "{", "\"deep_features_hidden_layer_name\"", ":", "layer", "}", ")", ",", "\"deepfeatures\"", ")", "j", ".", "poll", "(", ")", "return", "h2o", ".", "get_frame", "(", "j", ".", "dest_key", ")"], "docstring": "Return hidden layer details.\n\n        :param test_data: Data to create a feature space on\n        :param layer: 0 index hidden layer", "docstring_tokens": ["Return", "hidden", "layer", "details", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L246-L261", "partition": "test", "index": 1535, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/assembly.py", "func_name": "H2OAssembly.fit", "original_string": "def fit(self, fr):\n        \"\"\"\n        To perform the munging operations on a frame specified in steps on the frame fr.\n\n        :param fr: H2OFrame where munging operations are to be performed on.\n        :return: H2OFrame after munging operations are completed.\n        \"\"\"\n        assert_is_type(fr, H2OFrame)\n        steps = \"[%s]\" % \",\".join(quoted(step[1].to_rest(step[0]).replace('\"', \"'\")) for step in self.steps)\n        j = h2o.api(\"POST /99/Assembly\", data={\"steps\": steps, \"frame\": fr.frame_id})\n        self.id = j[\"assembly\"][\"name\"]\n        return H2OFrame.get_frame(j[\"result\"][\"name\"])", "language": "python", "code": "def fit(self, fr):\n        \"\"\"\n        To perform the munging operations on a frame specified in steps on the frame fr.\n\n        :param fr: H2OFrame where munging operations are to be performed on.\n        :return: H2OFrame after munging operations are completed.\n        \"\"\"\n        assert_is_type(fr, H2OFrame)\n        steps = \"[%s]\" % \",\".join(quoted(step[1].to_rest(step[0]).replace('\"', \"'\")) for step in self.steps)\n        j = h2o.api(\"POST /99/Assembly\", data={\"steps\": steps, \"frame\": fr.frame_id})\n        self.id = j[\"assembly\"][\"name\"]\n        return H2OFrame.get_frame(j[\"result\"][\"name\"])", "code_tokens": ["def", "fit", "(", "self", ",", "fr", ")", ":", "assert_is_type", "(", "fr", ",", "H2OFrame", ")", "steps", "=", "\"[%s]\"", "%", "\",\"", ".", "join", "(", "quoted", "(", "step", "[", "1", "]", ".", "to_rest", "(", "step", "[", "0", "]", ")", ".", "replace", "(", "'\"'", ",", "\"'\"", ")", ")", "for", "step", "in", "self", ".", "steps", ")", "j", "=", "h2o", ".", "api", "(", "\"POST /99/Assembly\"", ",", "data", "=", "{", "\"steps\"", ":", "steps", ",", "\"frame\"", ":", "fr", ".", "frame_id", "}", ")", "self", ".", "id", "=", "j", "[", "\"assembly\"", "]", "[", "\"name\"", "]", "return", "H2OFrame", ".", "get_frame", "(", "j", "[", "\"result\"", "]", "[", "\"name\"", "]", ")"], "docstring": "To perform the munging operations on a frame specified in steps on the frame fr.\n\n        :param fr: H2OFrame where munging operations are to be performed on.\n        :return: H2OFrame after munging operations are completed.", "docstring_tokens": ["To", "perform", "the", "munging", "operations", "on", "a", "frame", "specified", "in", "steps", "on", "the", "frame", "fr", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/assembly.py#L131-L142", "partition": "test", "index": 1531, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/assembly.py", "func_name": "H2OAssembly.to_pojo", "original_string": "def to_pojo(self, pojo_name=\"\", path=\"\", get_jar=True):\n        \"\"\"\n        Convert the munging operations performed on H2OFrame into a POJO.\n\n        :param pojo_name:  (str) Name of POJO\n        :param path:  (str) path of POJO.\n        :param get_jar: (bool) Whether to also download the h2o-genmodel.jar file needed to compile the POJO\n        :return: None\n        \"\"\"\n        assert_is_type(pojo_name, str)\n        assert_is_type(path, str)\n        assert_is_type(get_jar, bool)\n        if pojo_name == \"\":\n            pojo_name = \"AssemblyPOJO_\" + str(uuid.uuid4())\n        java = h2o.api(\"GET /99/Assembly.java/%s/%s\" % (self.id, pojo_name))\n        file_path = path + \"/\" + pojo_name + \".java\"\n        if path == \"\":\n            print(java)\n        else:\n            with open(file_path, 'w', encoding=\"utf-8\") as f:\n                f.write(java)  # this had better be utf-8 ?\n        if get_jar and path != \"\":\n            h2o.api(\"GET /3/h2o-genmodel.jar\", save_to=os.path.join(path, \"h2o-genmodel.jar\"))", "language": "python", "code": "def to_pojo(self, pojo_name=\"\", path=\"\", get_jar=True):\n        \"\"\"\n        Convert the munging operations performed on H2OFrame into a POJO.\n\n        :param pojo_name:  (str) Name of POJO\n        :param path:  (str) path of POJO.\n        :param get_jar: (bool) Whether to also download the h2o-genmodel.jar file needed to compile the POJO\n        :return: None\n        \"\"\"\n        assert_is_type(pojo_name, str)\n        assert_is_type(path, str)\n        assert_is_type(get_jar, bool)\n        if pojo_name == \"\":\n            pojo_name = \"AssemblyPOJO_\" + str(uuid.uuid4())\n        java = h2o.api(\"GET /99/Assembly.java/%s/%s\" % (self.id, pojo_name))\n        file_path = path + \"/\" + pojo_name + \".java\"\n        if path == \"\":\n            print(java)\n        else:\n            with open(file_path, 'w', encoding=\"utf-8\") as f:\n                f.write(java)  # this had better be utf-8 ?\n        if get_jar and path != \"\":\n            h2o.api(\"GET /3/h2o-genmodel.jar\", save_to=os.path.join(path, \"h2o-genmodel.jar\"))", "code_tokens": ["def", "to_pojo", "(", "self", ",", "pojo_name", "=", "\"\"", ",", "path", "=", "\"\"", ",", "get_jar", "=", "True", ")", ":", "assert_is_type", "(", "pojo_name", ",", "str", ")", "assert_is_type", "(", "path", ",", "str", ")", "assert_is_type", "(", "get_jar", ",", "bool", ")", "if", "pojo_name", "==", "\"\"", ":", "pojo_name", "=", "\"AssemblyPOJO_\"", "+", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "java", "=", "h2o", ".", "api", "(", "\"GET /99/Assembly.java/%s/%s\"", "%", "(", "self", ".", "id", ",", "pojo_name", ")", ")", "file_path", "=", "path", "+", "\"/\"", "+", "pojo_name", "+", "\".java\"", "if", "path", "==", "\"\"", ":", "print", "(", "java", ")", "else", ":", "with", "open", "(", "file_path", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "f", ".", "write", "(", "java", ")", "# this had better be utf-8 ?", "if", "get_jar", "and", "path", "!=", "\"\"", ":", "h2o", ".", "api", "(", "\"GET /3/h2o-genmodel.jar\"", ",", "save_to", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"h2o-genmodel.jar\"", ")", ")"], "docstring": "Convert the munging operations performed on H2OFrame into a POJO.\n\n        :param pojo_name:  (str) Name of POJO\n        :param path:  (str) path of POJO.\n        :param get_jar: (bool) Whether to also download the h2o-genmodel.jar file needed to compile the POJO\n        :return: None", "docstring_tokens": ["Convert", "the", "munging", "operations", "performed", "on", "H2OFrame", "into", "a", "POJO", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/assembly.py#L95-L117", "partition": "test", "index": 1530, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/binomial.py", "func_name": "H2OBinomialModel.roc", "original_string": "def roc(self, train=False, valid=False, xval=False):\n        \"\"\"\n        Return the coordinates of the ROC curve for a given set of data.\n\n        The coordinates are two-tuples containing the false positive rates as a list and true positive rates as a list.\n        If all are False (default), then return is the training data. If more than one ROC\n        curve is requested, the data is returned as a dictionary of two-tuples.\n\n        :param bool train: If True, return the ROC value for the training data.\n        :param bool valid: If True, return the ROC value for the validation data.\n        :param bool xval: If True, return the ROC value for each of the cross-validated splits.\n\n        :returns: The ROC values for the specified key(s).\n        \"\"\"\n        tm = ModelBase._get_metrics(self, train, valid, xval)\n        m = {}\n        for k, v in viewitems(tm):\n\n            if v is not None:\n                m[k] = (v.fprs, v.tprs)\n        return list(m.values())[0] if len(m) == 1 else m", "language": "python", "code": "def roc(self, train=False, valid=False, xval=False):\n        \"\"\"\n        Return the coordinates of the ROC curve for a given set of data.\n\n        The coordinates are two-tuples containing the false positive rates as a list and true positive rates as a list.\n        If all are False (default), then return is the training data. If more than one ROC\n        curve is requested, the data is returned as a dictionary of two-tuples.\n\n        :param bool train: If True, return the ROC value for the training data.\n        :param bool valid: If True, return the ROC value for the validation data.\n        :param bool xval: If True, return the ROC value for each of the cross-validated splits.\n\n        :returns: The ROC values for the specified key(s).\n        \"\"\"\n        tm = ModelBase._get_metrics(self, train, valid, xval)\n        m = {}\n        for k, v in viewitems(tm):\n\n            if v is not None:\n                m[k] = (v.fprs, v.tprs)\n        return list(m.values())[0] if len(m) == 1 else m", "code_tokens": ["def", "roc", "(", "self", ",", "train", "=", "False", ",", "valid", "=", "False", ",", "xval", "=", "False", ")", ":", "tm", "=", "ModelBase", ".", "_get_metrics", "(", "self", ",", "train", ",", "valid", ",", "xval", ")", "m", "=", "{", "}", "for", "k", ",", "v", "in", "viewitems", "(", "tm", ")", ":", "if", "v", "is", "not", "None", ":", "m", "[", "k", "]", "=", "(", "v", ".", "fprs", ",", "v", ".", "tprs", ")", "return", "list", "(", "m", ".", "values", "(", ")", ")", "[", "0", "]", "if", "len", "(", "m", ")", "==", "1", "else", "m"], "docstring": "Return the coordinates of the ROC curve for a given set of data.\n\n        The coordinates are two-tuples containing the false positive rates as a list and true positive rates as a list.\n        If all are False (default), then return is the training data. If more than one ROC\n        curve is requested, the data is returned as a dictionary of two-tuples.\n\n        :param bool train: If True, return the ROC value for the training data.\n        :param bool valid: If True, return the ROC value for the validation data.\n        :param bool xval: If True, return the ROC value for each of the cross-validated splits.\n\n        :returns: The ROC values for the specified key(s).", "docstring_tokens": ["Return", "the", "coordinates", "of", "the", "ROC", "curve", "for", "a", "given", "set", "of", "data", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/binomial.py#L462-L482", "partition": "test", "index": 1358, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/transforms/preprocessing.py", "func_name": "H2OScaler.inverse_transform", "original_string": "def inverse_transform(self, X, y=None, **params):\n        \"\"\"\n        Undo the scale transformation.\n\n        :param X: An H2OFrame; may contain NAs and/or categoricals.\n        :param y: None (Ignored)\n        :param params: (Ignored)\n        :returns: An H2OFrame\n        \"\"\"\n        for i in range(X.ncol):\n            X[i] = self.means[i] + self.stds[i] * X[i]\n        return X", "language": "python", "code": "def inverse_transform(self, X, y=None, **params):\n        \"\"\"\n        Undo the scale transformation.\n\n        :param X: An H2OFrame; may contain NAs and/or categoricals.\n        :param y: None (Ignored)\n        :param params: (Ignored)\n        :returns: An H2OFrame\n        \"\"\"\n        for i in range(X.ncol):\n            X[i] = self.means[i] + self.stds[i] * X[i]\n        return X", "code_tokens": ["def", "inverse_transform", "(", "self", ",", "X", ",", "y", "=", "None", ",", "*", "*", "params", ")", ":", "for", "i", "in", "range", "(", "X", ".", "ncol", ")", ":", "X", "[", "i", "]", "=", "self", ".", "means", "[", "i", "]", "+", "self", ".", "stds", "[", "i", "]", "*", "X", "[", "i", "]", "return", "X"], "docstring": "Undo the scale transformation.\n\n        :param X: An H2OFrame; may contain NAs and/or categoricals.\n        :param y: None (Ignored)\n        :param params: (Ignored)\n        :returns: An H2OFrame", "docstring_tokens": ["Undo", "the", "scale", "transformation", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/transforms/preprocessing.py#L78-L89", "partition": "test", "index": 1513, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/clustering.py", "func_name": "H2OClusteringModel.centers_std", "original_string": "def centers_std(self):\n        \"\"\"The standardized centers for the kmeans model.\"\"\"\n        o = self._model_json[\"output\"]\n        cvals = o[\"centers_std\"].cell_values\n        centers_std = [list(cval[1:]) for cval in cvals]\n        centers_std = [list(x) for x in zip(*centers_std)]\n        return centers_std", "language": "python", "code": "def centers_std(self):\n        \"\"\"The standardized centers for the kmeans model.\"\"\"\n        o = self._model_json[\"output\"]\n        cvals = o[\"centers_std\"].cell_values\n        centers_std = [list(cval[1:]) for cval in cvals]\n        centers_std = [list(x) for x in zip(*centers_std)]\n        return centers_std", "code_tokens": ["def", "centers_std", "(", "self", ")", ":", "o", "=", "self", ".", "_model_json", "[", "\"output\"", "]", "cvals", "=", "o", "[", "\"centers_std\"", "]", ".", "cell_values", "centers_std", "=", "[", "list", "(", "cval", "[", "1", ":", "]", ")", "for", "cval", "in", "cvals", "]", "centers_std", "=", "[", "list", "(", "x", ")", "for", "x", "in", "zip", "(", "*", "centers_std", ")", "]", "return", "centers_std"], "docstring": "The standardized centers for the kmeans model.", "docstring_tokens": ["The", "standardized", "centers", "for", "the", "kmeans", "model", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/clustering.py#L151-L157", "partition": "test", "index": 1451, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/clustering.py", "func_name": "H2OClusteringModel.centers", "original_string": "def centers(self):\n        \"\"\"The centers for the KMeans model.\"\"\"\n        o = self._model_json[\"output\"]\n        cvals = o[\"centers\"].cell_values\n        centers = [list(cval[1:]) for cval in cvals]\n        return centers", "language": "python", "code": "def centers(self):\n        \"\"\"The centers for the KMeans model.\"\"\"\n        o = self._model_json[\"output\"]\n        cvals = o[\"centers\"].cell_values\n        centers = [list(cval[1:]) for cval in cvals]\n        return centers", "code_tokens": ["def", "centers", "(", "self", ")", ":", "o", "=", "self", ".", "_model_json", "[", "\"output\"", "]", "cvals", "=", "o", "[", "\"centers\"", "]", ".", "cell_values", "centers", "=", "[", "list", "(", "cval", "[", "1", ":", "]", ")", "for", "cval", "in", "cvals", "]", "return", "centers"], "docstring": "The centers for the KMeans model.", "docstring_tokens": ["The", "centers", "for", "the", "KMeans", "model", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/clustering.py#L143-L148", "partition": "test", "index": 1450, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/clustering.py", "func_name": "H2OClusteringModel.size", "original_string": "def size(self, train=False, valid=False, xval=False):\n        \"\"\"\n        Get the sizes of each cluster.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where\n        the keys are \"train\", \"valid\", and \"xval\".\n\n        :param bool train: If True, return the cluster sizes for the training data.\n        :param bool valid: If True, return the cluster sizes for the validation data.\n        :param bool xval: If True, return the cluster sizes for each of the cross-validated splits.\n\n        :returns: The cluster sizes for the specified key(s).\n        \"\"\"\n        tm = ModelBase._get_metrics(self, train, valid, xval)\n        m = {}\n        for k, v in tm.items():\n            m[k] = None if v is None else [v[2] for v in v._metric_json[\"centroid_stats\"].cell_values]\n        return list(m.values())[0] if len(m) == 1 else m", "language": "python", "code": "def size(self, train=False, valid=False, xval=False):\n        \"\"\"\n        Get the sizes of each cluster.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where\n        the keys are \"train\", \"valid\", and \"xval\".\n\n        :param bool train: If True, return the cluster sizes for the training data.\n        :param bool valid: If True, return the cluster sizes for the validation data.\n        :param bool xval: If True, return the cluster sizes for each of the cross-validated splits.\n\n        :returns: The cluster sizes for the specified key(s).\n        \"\"\"\n        tm = ModelBase._get_metrics(self, train, valid, xval)\n        m = {}\n        for k, v in tm.items():\n            m[k] = None if v is None else [v[2] for v in v._metric_json[\"centroid_stats\"].cell_values]\n        return list(m.values())[0] if len(m) == 1 else m", "code_tokens": ["def", "size", "(", "self", ",", "train", "=", "False", ",", "valid", "=", "False", ",", "xval", "=", "False", ")", ":", "tm", "=", "ModelBase", ".", "_get_metrics", "(", "self", ",", "train", ",", "valid", ",", "xval", ")", "m", "=", "{", "}", "for", "k", ",", "v", "in", "tm", ".", "items", "(", ")", ":", "m", "[", "k", "]", "=", "None", "if", "v", "is", "None", "else", "[", "v", "[", "2", "]", "for", "v", "in", "v", ".", "_metric_json", "[", "\"centroid_stats\"", "]", ".", "cell_values", "]", "return", "list", "(", "m", ".", "values", "(", ")", ")", "[", "0", "]", "if", "len", "(", "m", ")", "==", "1", "else", "m"], "docstring": "Get the sizes of each cluster.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where\n        the keys are \"train\", \"valid\", and \"xval\".\n\n        :param bool train: If True, return the cluster sizes for the training data.\n        :param bool valid: If True, return the cluster sizes for the validation data.\n        :param bool xval: If True, return the cluster sizes for each of the cross-validated splits.\n\n        :returns: The cluster sizes for the specified key(s).", "docstring_tokens": ["Get", "the", "sizes", "of", "each", "cluster", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/clustering.py#L9-L27", "partition": "test", "index": 1449, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.set_levels", "original_string": "def set_levels(self, levels):\n        \"\"\"\n        Replace the levels of a categorical column.\n\n        New levels must be aligned with the old domain. This call has copy-on-write semantics.\n\n        :param List[str] levels: A list of strings specifying the new levels. The number of new\n            levels must match the number of old levels.\n        :returns: A single-column H2OFrame with the desired levels.\n        \"\"\"\n        assert_is_type(levels, [str])\n        return H2OFrame._expr(expr=ExprNode(\"setDomain\", self, False, levels), cache=self._ex._cache)", "language": "python", "code": "def set_levels(self, levels):\n        \"\"\"\n        Replace the levels of a categorical column.\n\n        New levels must be aligned with the old domain. This call has copy-on-write semantics.\n\n        :param List[str] levels: A list of strings specifying the new levels. The number of new\n            levels must match the number of old levels.\n        :returns: A single-column H2OFrame with the desired levels.\n        \"\"\"\n        assert_is_type(levels, [str])\n        return H2OFrame._expr(expr=ExprNode(\"setDomain\", self, False, levels), cache=self._ex._cache)", "code_tokens": ["def", "set_levels", "(", "self", ",", "levels", ")", ":", "assert_is_type", "(", "levels", ",", "[", "str", "]", ")", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"setDomain\"", ",", "self", ",", "False", ",", "levels", ")", ",", "cache", "=", "self", ".", "_ex", ".", "_cache", ")"], "docstring": "Replace the levels of a categorical column.\n\n        New levels must be aligned with the old domain. This call has copy-on-write semantics.\n\n        :param List[str] levels: A list of strings specifying the new levels. The number of new\n            levels must match the number of old levels.\n        :returns: A single-column H2OFrame with the desired levels.", "docstring_tokens": ["Replace", "the", "levels", "of", "a", "categorical", "column", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1021-L1032", "partition": "test", "index": 1399, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.describe", "original_string": "def describe(self, chunk_summary=False):\n        \"\"\"\n        Generate an in-depth description of this H2OFrame.\n\n        This will print to the console the dimensions of the frame; names/types/summary statistics for each column;\n        and finally first ten rows of the frame.\n\n        :param bool chunk_summary: Retrieve the chunk summary along with the distribution summary\n        \"\"\"\n        if self._has_content():\n            res = h2o.api(\"GET /3/Frames/%s\" % self.frame_id, data={\"row_count\": 10})[\"frames\"][0]\n            self._ex._cache._fill_data(res)\n\n            print(\"Rows:{}\".format(self.nrow))\n            print(\"Cols:{}\".format(self.ncol))\n\n            #The chunk & distribution summaries are not cached, so must be pulled if chunk_summary=True.\n            if chunk_summary:\n                res[\"chunk_summary\"].show()\n                res[\"distribution_summary\"].show()\n            print(\"\\n\")\n        self.summary()", "language": "python", "code": "def describe(self, chunk_summary=False):\n        \"\"\"\n        Generate an in-depth description of this H2OFrame.\n\n        This will print to the console the dimensions of the frame; names/types/summary statistics for each column;\n        and finally first ten rows of the frame.\n\n        :param bool chunk_summary: Retrieve the chunk summary along with the distribution summary\n        \"\"\"\n        if self._has_content():\n            res = h2o.api(\"GET /3/Frames/%s\" % self.frame_id, data={\"row_count\": 10})[\"frames\"][0]\n            self._ex._cache._fill_data(res)\n\n            print(\"Rows:{}\".format(self.nrow))\n            print(\"Cols:{}\".format(self.ncol))\n\n            #The chunk & distribution summaries are not cached, so must be pulled if chunk_summary=True.\n            if chunk_summary:\n                res[\"chunk_summary\"].show()\n                res[\"distribution_summary\"].show()\n            print(\"\\n\")\n        self.summary()", "code_tokens": ["def", "describe", "(", "self", ",", "chunk_summary", "=", "False", ")", ":", "if", "self", ".", "_has_content", "(", ")", ":", "res", "=", "h2o", ".", "api", "(", "\"GET /3/Frames/%s\"", "%", "self", ".", "frame_id", ",", "data", "=", "{", "\"row_count\"", ":", "10", "}", ")", "[", "\"frames\"", "]", "[", "0", "]", "self", ".", "_ex", ".", "_cache", ".", "_fill_data", "(", "res", ")", "print", "(", "\"Rows:{}\"", ".", "format", "(", "self", ".", "nrow", ")", ")", "print", "(", "\"Cols:{}\"", ".", "format", "(", "self", ".", "ncol", ")", ")", "#The chunk & distribution summaries are not cached, so must be pulled if chunk_summary=True.", "if", "chunk_summary", ":", "res", "[", "\"chunk_summary\"", "]", ".", "show", "(", ")", "res", "[", "\"distribution_summary\"", "]", ".", "show", "(", ")", "print", "(", "\"\\n\"", ")", "self", ".", "summary", "(", ")"], "docstring": "Generate an in-depth description of this H2OFrame.\n\n        This will print to the console the dimensions of the frame; names/types/summary statistics for each column;\n        and finally first ten rows of the frame.\n\n        :param bool chunk_summary: Retrieve the chunk summary along with the distribution summary", "docstring_tokens": ["Generate", "an", "in", "-", "depth", "description", "of", "this", "H2OFrame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L483-L504", "partition": "test", "index": 1393, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.impute", "original_string": "def impute(self, column=-1, method=\"mean\", combine_method=\"interpolate\", by=None, group_by_frame=None, values=None):\n        \"\"\"\n        Impute missing values into the frame, modifying it in-place.\n\n        :param int column: Index of the column to impute, or -1 to impute the entire frame.\n        :param str method: The method of imputation: ``\"mean\"``, ``\"median\"``, or ``\"mode\"``.\n        :param str combine_method: When the method is ``\"median\"``, this setting dictates how to combine quantiles\n            for even samples. One of ``\"interpolate\"``, ``\"average\"``, ``\"low\"``, ``\"high\"``.\n        :param by: The list of columns to group on.\n        :param H2OFrame group_by_frame: Impute the values with this pre-computed grouped frame.\n        :param List values: The list of impute values, one per column. None indicates to skip the column.\n\n        :returns: A list of values used in the imputation or the group-by result used in imputation.\n        \"\"\"\n        if is_type(column, str): column = self.names.index(column)\n        if is_type(by, str):     by = self.names.index(by)\n\n        if values is None:\n            values = \"_\"\n        else:\n            assert len(values) == len(self.columns), \"Length of values does not match length of columns\"\n            # convert string values to categorical num values\n            values2 = []\n            for i in range(0,len(values)):\n                if self.type(i) == \"enum\":\n                    try:\n                        values2.append(self.levels()[i].index(values[i]))\n                    except:\n                        raise H2OValueError(\"Impute value of: \" + values[i] + \" not found in existing levels of\"\n                                            \" column: \" + self.col_names[i])\n                else:\n                    values2.append(values[i])\n            values = values2\n        if group_by_frame is None: group_by_frame = \"_\"\n\n\n        # This code below is needed to ensure the frame (self) exists on the server. Without it, self._ex._cache.fill()\n        # fails with an assertion that ._id is None.\n        # This code should be removed / reworked once we have a more consistent strategy of dealing with frames.\n        self._ex._eager_frame()\n\n        if by is not None or group_by_frame is not \"_\":\n            res = H2OFrame._expr(\n                expr=ExprNode(\"h2o.impute\", self, column, method, combine_method, by, group_by_frame, values))._frame()\n        else:\n            res = ExprNode(\"h2o.impute\", self, column, method, combine_method, by, group_by_frame,\n                           values)._eager_scalar()\n\n        self._ex._cache.flush()\n        self._ex._cache.fill(10)\n        return res", "language": "python", "code": "def impute(self, column=-1, method=\"mean\", combine_method=\"interpolate\", by=None, group_by_frame=None, values=None):\n        \"\"\"\n        Impute missing values into the frame, modifying it in-place.\n\n        :param int column: Index of the column to impute, or -1 to impute the entire frame.\n        :param str method: The method of imputation: ``\"mean\"``, ``\"median\"``, or ``\"mode\"``.\n        :param str combine_method: When the method is ``\"median\"``, this setting dictates how to combine quantiles\n            for even samples. One of ``\"interpolate\"``, ``\"average\"``, ``\"low\"``, ``\"high\"``.\n        :param by: The list of columns to group on.\n        :param H2OFrame group_by_frame: Impute the values with this pre-computed grouped frame.\n        :param List values: The list of impute values, one per column. None indicates to skip the column.\n\n        :returns: A list of values used in the imputation or the group-by result used in imputation.\n        \"\"\"\n        if is_type(column, str): column = self.names.index(column)\n        if is_type(by, str):     by = self.names.index(by)\n\n        if values is None:\n            values = \"_\"\n        else:\n            assert len(values) == len(self.columns), \"Length of values does not match length of columns\"\n            # convert string values to categorical num values\n            values2 = []\n            for i in range(0,len(values)):\n                if self.type(i) == \"enum\":\n                    try:\n                        values2.append(self.levels()[i].index(values[i]))\n                    except:\n                        raise H2OValueError(\"Impute value of: \" + values[i] + \" not found in existing levels of\"\n                                            \" column: \" + self.col_names[i])\n                else:\n                    values2.append(values[i])\n            values = values2\n        if group_by_frame is None: group_by_frame = \"_\"\n\n\n        # This code below is needed to ensure the frame (self) exists on the server. Without it, self._ex._cache.fill()\n        # fails with an assertion that ._id is None.\n        # This code should be removed / reworked once we have a more consistent strategy of dealing with frames.\n        self._ex._eager_frame()\n\n        if by is not None or group_by_frame is not \"_\":\n            res = H2OFrame._expr(\n                expr=ExprNode(\"h2o.impute\", self, column, method, combine_method, by, group_by_frame, values))._frame()\n        else:\n            res = ExprNode(\"h2o.impute\", self, column, method, combine_method, by, group_by_frame,\n                           values)._eager_scalar()\n\n        self._ex._cache.flush()\n        self._ex._cache.fill(10)\n        return res", "code_tokens": ["def", "impute", "(", "self", ",", "column", "=", "-", "1", ",", "method", "=", "\"mean\"", ",", "combine_method", "=", "\"interpolate\"", ",", "by", "=", "None", ",", "group_by_frame", "=", "None", ",", "values", "=", "None", ")", ":", "if", "is_type", "(", "column", ",", "str", ")", ":", "column", "=", "self", ".", "names", ".", "index", "(", "column", ")", "if", "is_type", "(", "by", ",", "str", ")", ":", "by", "=", "self", ".", "names", ".", "index", "(", "by", ")", "if", "values", "is", "None", ":", "values", "=", "\"_\"", "else", ":", "assert", "len", "(", "values", ")", "==", "len", "(", "self", ".", "columns", ")", ",", "\"Length of values does not match length of columns\"", "# convert string values to categorical num values", "values2", "=", "[", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "values", ")", ")", ":", "if", "self", ".", "type", "(", "i", ")", "==", "\"enum\"", ":", "try", ":", "values2", ".", "append", "(", "self", ".", "levels", "(", ")", "[", "i", "]", ".", "index", "(", "values", "[", "i", "]", ")", ")", "except", ":", "raise", "H2OValueError", "(", "\"Impute value of: \"", "+", "values", "[", "i", "]", "+", "\" not found in existing levels of\"", "\" column: \"", "+", "self", ".", "col_names", "[", "i", "]", ")", "else", ":", "values2", ".", "append", "(", "values", "[", "i", "]", ")", "values", "=", "values2", "if", "group_by_frame", "is", "None", ":", "group_by_frame", "=", "\"_\"", "# This code below is needed to ensure the frame (self) exists on the server. Without it, self._ex._cache.fill()", "# fails with an assertion that ._id is None.", "# This code should be removed / reworked once we have a more consistent strategy of dealing with frames.", "self", ".", "_ex", ".", "_eager_frame", "(", ")", "if", "by", "is", "not", "None", "or", "group_by_frame", "is", "not", "\"_\"", ":", "res", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"h2o.impute\"", ",", "self", ",", "column", ",", "method", ",", "combine_method", ",", "by", ",", "group_by_frame", ",", "values", ")", ")", ".", "_frame", "(", ")", "else", ":", "res", "=", "ExprNode", "(", "\"h2o.impute\"", ",", "self", ",", "column", ",", "method", ",", "combine_method", ",", "by", ",", "group_by_frame", ",", "values", ")", ".", "_eager_scalar", "(", ")", "self", ".", "_ex", ".", "_cache", ".", "flush", "(", ")", "self", ".", "_ex", ".", "_cache", ".", "fill", "(", "10", ")", "return", "res"], "docstring": "Impute missing values into the frame, modifying it in-place.\n\n        :param int column: Index of the column to impute, or -1 to impute the entire frame.\n        :param str method: The method of imputation: ``\"mean\"``, ``\"median\"``, or ``\"mode\"``.\n        :param str combine_method: When the method is ``\"median\"``, this setting dictates how to combine quantiles\n            for even samples. One of ``\"interpolate\"``, ``\"average\"``, ``\"low\"``, ``\"high\"``.\n        :param by: The list of columns to group on.\n        :param H2OFrame group_by_frame: Impute the values with this pre-computed grouped frame.\n        :param List values: The list of impute values, one per column. None indicates to skip the column.\n\n        :returns: A list of values used in the imputation or the group-by result used in imputation.", "docstring_tokens": ["Impute", "missing", "values", "into", "the", "frame", "modifying", "it", "in", "-", "place", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1883-L1933", "partition": "test", "index": 1416, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.merge", "original_string": "def merge(self, other, all_x=False, all_y=False, by_x=None, by_y=None, method=\"auto\"):\n        \"\"\"\n        Merge two datasets based on common column names.  We do not support all_x=True and all_y=True.\n        Only one can be True or none is True.  The default merge method is auto and it will default to the\n        radix method.  The radix method will return the correct merge result regardless of duplicated rows\n         in the right frame.  In addition, the radix method can perform merge even if you have string columns\n         in your frames.  If there are duplicated rows in your rite frame, they will not be included if you use\n        the hash method.  The hash method cannot perform merge if you have string columns in your left frame.\n        Hence, we consider the radix method superior to the hash method and is the default method to use.\n\n        :param H2OFrame other: The frame to merge to the current one. By default, must have at least one column in common with\n            this frame, and all columns in common are used as the merge key.  If you want to use only a subset of the\n            columns in common, rename the other columns so the columns are unique in the merged result.\n        :param bool all_x: If True, include all rows from the left/self frame\n        :param bool all_y: If True, include all rows from the right/other frame\n        :param by_x: list of columns in the current frame to use as a merge key.\n        :param by_y: list of columns in the ``other`` frame to use as a merge key. Should have the same number of\n            columns as in the ``by_x`` list.\n        :param method: string representing the merge method, one of auto(default), radix or hash.\n\n        :returns: New H2OFrame with the result of merging the current frame with the ``other`` frame.\n        \"\"\"\n\n        if by_x is None and by_y is None:\n            common_names = list(set(self.names) & set(other.names))\n            if not common_names:\n                raise H2OValueError(\"No columns in common to merge on!\")\n\n        if by_x is None:\n            by_x = [self.names.index(c) for c in common_names]\n        else:\n            by_x = _getValidCols(by_x,self)\n\n        if by_y is None:\n            by_y = [other.names.index(c) for c in common_names]\n        else:\n            by_y = _getValidCols(by_y,other)\n\n\n        return H2OFrame._expr(expr=ExprNode(\"merge\", self, other, all_x, all_y, by_x, by_y, method))", "language": "python", "code": "def merge(self, other, all_x=False, all_y=False, by_x=None, by_y=None, method=\"auto\"):\n        \"\"\"\n        Merge two datasets based on common column names.  We do not support all_x=True and all_y=True.\n        Only one can be True or none is True.  The default merge method is auto and it will default to the\n        radix method.  The radix method will return the correct merge result regardless of duplicated rows\n         in the right frame.  In addition, the radix method can perform merge even if you have string columns\n         in your frames.  If there are duplicated rows in your rite frame, they will not be included if you use\n        the hash method.  The hash method cannot perform merge if you have string columns in your left frame.\n        Hence, we consider the radix method superior to the hash method and is the default method to use.\n\n        :param H2OFrame other: The frame to merge to the current one. By default, must have at least one column in common with\n            this frame, and all columns in common are used as the merge key.  If you want to use only a subset of the\n            columns in common, rename the other columns so the columns are unique in the merged result.\n        :param bool all_x: If True, include all rows from the left/self frame\n        :param bool all_y: If True, include all rows from the right/other frame\n        :param by_x: list of columns in the current frame to use as a merge key.\n        :param by_y: list of columns in the ``other`` frame to use as a merge key. Should have the same number of\n            columns as in the ``by_x`` list.\n        :param method: string representing the merge method, one of auto(default), radix or hash.\n\n        :returns: New H2OFrame with the result of merging the current frame with the ``other`` frame.\n        \"\"\"\n\n        if by_x is None and by_y is None:\n            common_names = list(set(self.names) & set(other.names))\n            if not common_names:\n                raise H2OValueError(\"No columns in common to merge on!\")\n\n        if by_x is None:\n            by_x = [self.names.index(c) for c in common_names]\n        else:\n            by_x = _getValidCols(by_x,self)\n\n        if by_y is None:\n            by_y = [other.names.index(c) for c in common_names]\n        else:\n            by_y = _getValidCols(by_y,other)\n\n\n        return H2OFrame._expr(expr=ExprNode(\"merge\", self, other, all_x, all_y, by_x, by_y, method))", "code_tokens": ["def", "merge", "(", "self", ",", "other", ",", "all_x", "=", "False", ",", "all_y", "=", "False", ",", "by_x", "=", "None", ",", "by_y", "=", "None", ",", "method", "=", "\"auto\"", ")", ":", "if", "by_x", "is", "None", "and", "by_y", "is", "None", ":", "common_names", "=", "list", "(", "set", "(", "self", ".", "names", ")", "&", "set", "(", "other", ".", "names", ")", ")", "if", "not", "common_names", ":", "raise", "H2OValueError", "(", "\"No columns in common to merge on!\"", ")", "if", "by_x", "is", "None", ":", "by_x", "=", "[", "self", ".", "names", ".", "index", "(", "c", ")", "for", "c", "in", "common_names", "]", "else", ":", "by_x", "=", "_getValidCols", "(", "by_x", ",", "self", ")", "if", "by_y", "is", "None", ":", "by_y", "=", "[", "other", ".", "names", ".", "index", "(", "c", ")", "for", "c", "in", "common_names", "]", "else", ":", "by_y", "=", "_getValidCols", "(", "by_y", ",", "other", ")", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"merge\"", ",", "self", ",", "other", ",", "all_x", ",", "all_y", ",", "by_x", ",", "by_y", ",", "method", ")", ")"], "docstring": "Merge two datasets based on common column names.  We do not support all_x=True and all_y=True.\n        Only one can be True or none is True.  The default merge method is auto and it will default to the\n        radix method.  The radix method will return the correct merge result regardless of duplicated rows\n         in the right frame.  In addition, the radix method can perform merge even if you have string columns\n         in your frames.  If there are duplicated rows in your rite frame, they will not be included if you use\n        the hash method.  The hash method cannot perform merge if you have string columns in your left frame.\n        Hence, we consider the radix method superior to the hash method and is the default method to use.\n\n        :param H2OFrame other: The frame to merge to the current one. By default, must have at least one column in common with\n            this frame, and all columns in common are used as the merge key.  If you want to use only a subset of the\n            columns in common, rename the other columns so the columns are unique in the merged result.\n        :param bool all_x: If True, include all rows from the left/self frame\n        :param bool all_y: If True, include all rows from the right/other frame\n        :param by_x: list of columns in the current frame to use as a merge key.\n        :param by_y: list of columns in the ``other`` frame to use as a merge key. Should have the same number of\n            columns as in the ``by_x`` list.\n        :param method: string representing the merge method, one of auto(default), radix or hash.\n\n        :returns: New H2OFrame with the result of merging the current frame with the ``other`` frame.", "docstring_tokens": ["Merge", "two", "datasets", "based", "on", "common", "column", "names", ".", "We", "do", "not", "support", "all_x", "=", "True", "and", "all_y", "=", "True", ".", "Only", "one", "can", "be", "True", "or", "none", "is", "True", ".", "The", "default", "merge", "method", "is", "auto", "and", "it", "will", "default", "to", "the", "radix", "method", ".", "The", "radix", "method", "will", "return", "the", "correct", "merge", "result", "regardless", "of", "duplicated", "rows", "in", "the", "right", "frame", ".", "In", "addition", "the", "radix", "method", "can", "perform", "merge", "even", "if", "you", "have", "string", "columns", "in", "your", "frames", ".", "If", "there", "are", "duplicated", "rows", "in", "your", "rite", "frame", "they", "will", "not", "be", "included", "if", "you", "use", "the", "hash", "method", ".", "The", "hash", "method", "cannot", "perform", "merge", "if", "you", "have", "string", "columns", "in", "your", "left", "frame", ".", "Hence", "we", "consider", "the", "radix", "method", "superior", "to", "the", "hash", "method", "and", "is", "the", "default", "method", "to", "use", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1936-L1975", "partition": "test", "index": 1417, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.nlevels", "original_string": "def nlevels(self):\n        \"\"\"\n        Get the number of factor levels for each categorical column.\n\n        :returns: A list of the number of levels per column.\n        \"\"\"\n        levels = self.levels()\n        return [len(l) for l in levels] if levels else 0", "language": "python", "code": "def nlevels(self):\n        \"\"\"\n        Get the number of factor levels for each categorical column.\n\n        :returns: A list of the number of levels per column.\n        \"\"\"\n        levels = self.levels()\n        return [len(l) for l in levels] if levels else 0", "code_tokens": ["def", "nlevels", "(", "self", ")", ":", "levels", "=", "self", ".", "levels", "(", ")", "return", "[", "len", "(", "l", ")", "for", "l", "in", "levels", "]", "if", "levels", "else", "0"], "docstring": "Get the number of factor levels for each categorical column.\n\n        :returns: A list of the number of levels per column.", "docstring_tokens": ["Get", "the", "number", "of", "factor", "levels", "for", "each", "categorical", "column", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1000-L1007", "partition": "test", "index": 1397, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.levels", "original_string": "def levels(self):\n        \"\"\"\n        Get the factor levels.\n\n        :returns: A list of lists, one list per column, of levels.\n        \"\"\"\n        lol = H2OFrame._expr(expr=ExprNode(\"levels\", self)).as_data_frame(False)\n        lol.pop(0)  # Remove column headers\n        lol = list(zip(*lol))\n        return [[ll for ll in l if ll != ''] for l in lol]", "language": "python", "code": "def levels(self):\n        \"\"\"\n        Get the factor levels.\n\n        :returns: A list of lists, one list per column, of levels.\n        \"\"\"\n        lol = H2OFrame._expr(expr=ExprNode(\"levels\", self)).as_data_frame(False)\n        lol.pop(0)  # Remove column headers\n        lol = list(zip(*lol))\n        return [[ll for ll in l if ll != ''] for l in lol]", "code_tokens": ["def", "levels", "(", "self", ")", ":", "lol", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"levels\"", ",", "self", ")", ")", ".", "as_data_frame", "(", "False", ")", "lol", ".", "pop", "(", "0", ")", "# Remove column headers", "lol", "=", "list", "(", "zip", "(", "*", "lol", ")", ")", "return", "[", "[", "ll", "for", "ll", "in", "l", "if", "ll", "!=", "''", "]", "for", "l", "in", "lol", "]"], "docstring": "Get the factor levels.\n\n        :returns: A list of lists, one list per column, of levels.", "docstring_tokens": ["Get", "the", "factor", "levels", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L988-L997", "partition": "test", "index": 1396, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.relevel", "original_string": "def relevel(self, y):\n        \"\"\"\n        Reorder levels of an H2O factor for one single column of a H2O frame\n\n        The levels of a factor are reordered such that the reference level is at level 0, all remaining levels are\n        moved down as needed.\n\n        :param str y: The reference level\n        :returns: New reordered factor column\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"relevel\", self, quote(y)))", "language": "python", "code": "def relevel(self, y):\n        \"\"\"\n        Reorder levels of an H2O factor for one single column of a H2O frame\n\n        The levels of a factor are reordered such that the reference level is at level 0, all remaining levels are\n        moved down as needed.\n\n        :param str y: The reference level\n        :returns: New reordered factor column\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"relevel\", self, quote(y)))", "code_tokens": ["def", "relevel", "(", "self", ",", "y", ")", ":", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"relevel\"", ",", "self", ",", "quote", "(", "y", ")", ")", ")"], "docstring": "Reorder levels of an H2O factor for one single column of a H2O frame\n\n        The levels of a factor are reordered such that the reference level is at level 0, all remaining levels are\n        moved down as needed.\n\n        :param str y: The reference level\n        :returns: New reordered factor column", "docstring_tokens": ["Reorder", "levels", "of", "an", "H2O", "factor", "for", "one", "single", "column", "of", "a", "H2O", "frame"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1978-L1988", "partition": "test", "index": 1418, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.toupper", "original_string": "def toupper(self):\n        \"\"\"\n        Translate characters from lower to upper case for a particular column.\n\n        :returns: new H2OFrame with all strings in the current frame converted to the uppercase.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"toupper\", self), cache=self._ex._cache)", "language": "python", "code": "def toupper(self):\n        \"\"\"\n        Translate characters from lower to upper case for a particular column.\n\n        :returns: new H2OFrame with all strings in the current frame converted to the uppercase.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"toupper\", self), cache=self._ex._cache)", "code_tokens": ["def", "toupper", "(", "self", ")", ":", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"toupper\"", ",", "self", ")", ",", "cache", "=", "self", ".", "_ex", ".", "_cache", ")"], "docstring": "Translate characters from lower to upper case for a particular column.\n\n        :returns: new H2OFrame with all strings in the current frame converted to the uppercase.", "docstring_tokens": ["Translate", "characters", "from", "lower", "to", "upper", "case", "for", "a", "particular", "column", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2924-L2930", "partition": "test", "index": 1434, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.sub", "original_string": "def sub(self, pattern, replacement, ignore_case=False):\n        \"\"\"\n        Substitute the first occurrence of pattern in a string with replacement.\n\n        :param str pattern: A regular expression.\n        :param str replacement: A replacement string.\n        :param bool ignore_case: If True then pattern will match case-insensitively.\n        :returns: an H2OFrame with all values matching ``pattern`` replaced with ``replacement``.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"replacefirst\", self, pattern, replacement, ignore_case))", "language": "python", "code": "def sub(self, pattern, replacement, ignore_case=False):\n        \"\"\"\n        Substitute the first occurrence of pattern in a string with replacement.\n\n        :param str pattern: A regular expression.\n        :param str replacement: A replacement string.\n        :param bool ignore_case: If True then pattern will match case-insensitively.\n        :returns: an H2OFrame with all values matching ``pattern`` replaced with ``replacement``.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"replacefirst\", self, pattern, replacement, ignore_case))", "code_tokens": ["def", "sub", "(", "self", ",", "pattern", ",", "replacement", ",", "ignore_case", "=", "False", ")", ":", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"replacefirst\"", ",", "self", ",", "pattern", ",", "replacement", ",", "ignore_case", ")", ")"], "docstring": "Substitute the first occurrence of pattern in a string with replacement.\n\n        :param str pattern: A regular expression.\n        :param str replacement: A replacement string.\n        :param bool ignore_case: If True then pattern will match case-insensitively.\n        :returns: an H2OFrame with all values matching ``pattern`` replaced with ``replacement``.", "docstring_tokens": ["Substitute", "the", "first", "occurrence", "of", "pattern", "in", "a", "string", "with", "replacement", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2879-L2888", "partition": "test", "index": 1433, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.isax", "original_string": "def isax(self, num_words, max_cardinality, optimize_card=False, **kwargs):\n        \"\"\"\n        Compute the iSAX index for DataFrame which is assumed to be numeric time series data.\n\n        References:\n\n            - http://www.cs.ucr.edu/~eamonn/SAX.pdf\n            - http://www.cs.ucr.edu/~eamonn/iSAX_2.0.pdf\n\n        :param int num_words: Number of iSAX words for the timeseries, i.e. granularity along the time series\n        :param int max_cardinality: Maximum cardinality of the iSAX word. Each word can have less than the max\n        :param bool optimized_card: An optimization flag that will find the max cardinality regardless of what is\n            passed in for ``max_cardinality``.\n\n        :returns: An H2OFrame with the name of time series, string representation of iSAX word, followed by\n            binary representation.\n        \"\"\"\n        if num_words <= 0: raise H2OValueError(\"num_words must be greater than 0\")\n        if max_cardinality <= 0: raise H2OValueError(\"max_cardinality must be greater than 0\")\n        return H2OFrame._expr(expr=ExprNode(\"isax\", self, num_words, max_cardinality, optimize_card))", "language": "python", "code": "def isax(self, num_words, max_cardinality, optimize_card=False, **kwargs):\n        \"\"\"\n        Compute the iSAX index for DataFrame which is assumed to be numeric time series data.\n\n        References:\n\n            - http://www.cs.ucr.edu/~eamonn/SAX.pdf\n            - http://www.cs.ucr.edu/~eamonn/iSAX_2.0.pdf\n\n        :param int num_words: Number of iSAX words for the timeseries, i.e. granularity along the time series\n        :param int max_cardinality: Maximum cardinality of the iSAX word. Each word can have less than the max\n        :param bool optimized_card: An optimization flag that will find the max cardinality regardless of what is\n            passed in for ``max_cardinality``.\n\n        :returns: An H2OFrame with the name of time series, string representation of iSAX word, followed by\n            binary representation.\n        \"\"\"\n        if num_words <= 0: raise H2OValueError(\"num_words must be greater than 0\")\n        if max_cardinality <= 0: raise H2OValueError(\"max_cardinality must be greater than 0\")\n        return H2OFrame._expr(expr=ExprNode(\"isax\", self, num_words, max_cardinality, optimize_card))", "code_tokens": ["def", "isax", "(", "self", ",", "num_words", ",", "max_cardinality", ",", "optimize_card", "=", "False", ",", "*", "*", "kwargs", ")", ":", "if", "num_words", "<=", "0", ":", "raise", "H2OValueError", "(", "\"num_words must be greater than 0\"", ")", "if", "max_cardinality", "<=", "0", ":", "raise", "H2OValueError", "(", "\"max_cardinality must be greater than 0\"", ")", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"isax\"", ",", "self", ",", "num_words", ",", "max_cardinality", ",", "optimize_card", ")", ")"], "docstring": "Compute the iSAX index for DataFrame which is assumed to be numeric time series data.\n\n        References:\n\n            - http://www.cs.ucr.edu/~eamonn/SAX.pdf\n            - http://www.cs.ucr.edu/~eamonn/iSAX_2.0.pdf\n\n        :param int num_words: Number of iSAX words for the timeseries, i.e. granularity along the time series\n        :param int max_cardinality: Maximum cardinality of the iSAX word. Each word can have less than the max\n        :param bool optimized_card: An optimization flag that will find the max cardinality regardless of what is\n            passed in for ``max_cardinality``.\n\n        :returns: An H2OFrame with the name of time series, string representation of iSAX word, followed by\n            binary representation.", "docstring_tokens": ["Compute", "the", "iSAX", "index", "for", "DataFrame", "which", "is", "assumed", "to", "be", "numeric", "time", "series", "data", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2547-L2566", "partition": "test", "index": 1432, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.hist", "original_string": "def hist(self, breaks=\"sturges\", plot=True, **kwargs):\n        \"\"\"\n        Compute a histogram over a numeric column.\n\n        :param breaks: Can be one of ``\"sturges\"``, ``\"rice\"``, ``\"sqrt\"``, ``\"doane\"``, ``\"fd\"``, ``\"scott\"``;\n            or a single number for the number of breaks; or a list containing the split points, e.g:\n            ``[-50, 213.2123, 9324834]``. If breaks is \"fd\", the MAD is used over the IQR in computing bin width.\n        :param bool plot: If True (default), then a plot will be generated using ``matplotlib``.\n\n        :returns: If ``plot`` is False, return H2OFrame with these columns: breaks, counts, mids_true,\n            mids, and density; otherwise this method draws a plot and returns nothing.\n        \"\"\"\n        server = kwargs.pop(\"server\") if \"server\" in kwargs else False\n        assert_is_type(breaks, int, [numeric], Enum(\"sturges\", \"rice\", \"sqrt\", \"doane\", \"fd\", \"scott\"))\n        assert_is_type(plot, bool)\n        assert_is_type(server, bool)\n        if kwargs:\n            raise H2OValueError(\"Unknown parameters to hist(): %r\" % kwargs)\n        hist = H2OFrame._expr(expr=ExprNode(\"hist\", self, breaks))._frame()\n\n        if plot:\n            try:\n                import matplotlib\n                if server:\n                    matplotlib.use(\"Agg\", warn=False)\n                import matplotlib.pyplot as plt\n            except ImportError:\n                print(\"ERROR: matplotlib is required to make the histogram plot. \"\n                      \"Set `plot` to False, if a plot is not desired.\")\n                return\n\n            hist[\"widths\"] = hist[\"breaks\"].difflag1()\n            # [2:] because we're removing the title and the first row (which consists of NaNs)\n            lefts = [float(c[0]) for c in h2o.as_list(hist[\"breaks\"], use_pandas=False)[2:]]\n            widths = [float(c[0]) for c in h2o.as_list(hist[\"widths\"], use_pandas=False)[2:]]\n            counts = [float(c[0]) for c in h2o.as_list(hist[\"counts\"], use_pandas=False)[2:]]\n\n            plt.xlabel(self.names[0])\n            plt.ylabel(\"Frequency\")\n            plt.title(\"Histogram of %s\" % self.names[0])\n            plt.bar(left=lefts, width=widths, height=counts, bottom=0)\n            if not server:\n                plt.show()\n        else:\n            hist[\"density\"] = hist[\"counts\"] / (hist[\"breaks\"].difflag1() * hist[\"counts\"].sum())\n            return hist", "language": "python", "code": "def hist(self, breaks=\"sturges\", plot=True, **kwargs):\n        \"\"\"\n        Compute a histogram over a numeric column.\n\n        :param breaks: Can be one of ``\"sturges\"``, ``\"rice\"``, ``\"sqrt\"``, ``\"doane\"``, ``\"fd\"``, ``\"scott\"``;\n            or a single number for the number of breaks; or a list containing the split points, e.g:\n            ``[-50, 213.2123, 9324834]``. If breaks is \"fd\", the MAD is used over the IQR in computing bin width.\n        :param bool plot: If True (default), then a plot will be generated using ``matplotlib``.\n\n        :returns: If ``plot`` is False, return H2OFrame with these columns: breaks, counts, mids_true,\n            mids, and density; otherwise this method draws a plot and returns nothing.\n        \"\"\"\n        server = kwargs.pop(\"server\") if \"server\" in kwargs else False\n        assert_is_type(breaks, int, [numeric], Enum(\"sturges\", \"rice\", \"sqrt\", \"doane\", \"fd\", \"scott\"))\n        assert_is_type(plot, bool)\n        assert_is_type(server, bool)\n        if kwargs:\n            raise H2OValueError(\"Unknown parameters to hist(): %r\" % kwargs)\n        hist = H2OFrame._expr(expr=ExprNode(\"hist\", self, breaks))._frame()\n\n        if plot:\n            try:\n                import matplotlib\n                if server:\n                    matplotlib.use(\"Agg\", warn=False)\n                import matplotlib.pyplot as plt\n            except ImportError:\n                print(\"ERROR: matplotlib is required to make the histogram plot. \"\n                      \"Set `plot` to False, if a plot is not desired.\")\n                return\n\n            hist[\"widths\"] = hist[\"breaks\"].difflag1()\n            # [2:] because we're removing the title and the first row (which consists of NaNs)\n            lefts = [float(c[0]) for c in h2o.as_list(hist[\"breaks\"], use_pandas=False)[2:]]\n            widths = [float(c[0]) for c in h2o.as_list(hist[\"widths\"], use_pandas=False)[2:]]\n            counts = [float(c[0]) for c in h2o.as_list(hist[\"counts\"], use_pandas=False)[2:]]\n\n            plt.xlabel(self.names[0])\n            plt.ylabel(\"Frequency\")\n            plt.title(\"Histogram of %s\" % self.names[0])\n            plt.bar(left=lefts, width=widths, height=counts, bottom=0)\n            if not server:\n                plt.show()\n        else:\n            hist[\"density\"] = hist[\"counts\"] / (hist[\"breaks\"].difflag1() * hist[\"counts\"].sum())\n            return hist", "code_tokens": ["def", "hist", "(", "self", ",", "breaks", "=", "\"sturges\"", ",", "plot", "=", "True", ",", "*", "*", "kwargs", ")", ":", "server", "=", "kwargs", ".", "pop", "(", "\"server\"", ")", "if", "\"server\"", "in", "kwargs", "else", "False", "assert_is_type", "(", "breaks", ",", "int", ",", "[", "numeric", "]", ",", "Enum", "(", "\"sturges\"", ",", "\"rice\"", ",", "\"sqrt\"", ",", "\"doane\"", ",", "\"fd\"", ",", "\"scott\"", ")", ")", "assert_is_type", "(", "plot", ",", "bool", ")", "assert_is_type", "(", "server", ",", "bool", ")", "if", "kwargs", ":", "raise", "H2OValueError", "(", "\"Unknown parameters to hist(): %r\"", "%", "kwargs", ")", "hist", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"hist\"", ",", "self", ",", "breaks", ")", ")", ".", "_frame", "(", ")", "if", "plot", ":", "try", ":", "import", "matplotlib", "if", "server", ":", "matplotlib", ".", "use", "(", "\"Agg\"", ",", "warn", "=", "False", ")", "import", "matplotlib", ".", "pyplot", "as", "plt", "except", "ImportError", ":", "print", "(", "\"ERROR: matplotlib is required to make the histogram plot. \"", "\"Set `plot` to False, if a plot is not desired.\"", ")", "return", "hist", "[", "\"widths\"", "]", "=", "hist", "[", "\"breaks\"", "]", ".", "difflag1", "(", ")", "# [2:] because we're removing the title and the first row (which consists of NaNs)", "lefts", "=", "[", "float", "(", "c", "[", "0", "]", ")", "for", "c", "in", "h2o", ".", "as_list", "(", "hist", "[", "\"breaks\"", "]", ",", "use_pandas", "=", "False", ")", "[", "2", ":", "]", "]", "widths", "=", "[", "float", "(", "c", "[", "0", "]", ")", "for", "c", "in", "h2o", ".", "as_list", "(", "hist", "[", "\"widths\"", "]", ",", "use_pandas", "=", "False", ")", "[", "2", ":", "]", "]", "counts", "=", "[", "float", "(", "c", "[", "0", "]", ")", "for", "c", "in", "h2o", ".", "as_list", "(", "hist", "[", "\"counts\"", "]", ",", "use_pandas", "=", "False", ")", "[", "2", ":", "]", "]", "plt", ".", "xlabel", "(", "self", ".", "names", "[", "0", "]", ")", "plt", ".", "ylabel", "(", "\"Frequency\"", ")", "plt", ".", "title", "(", "\"Histogram of %s\"", "%", "self", ".", "names", "[", "0", "]", ")", "plt", ".", "bar", "(", "left", "=", "lefts", ",", "width", "=", "widths", ",", "height", "=", "counts", ",", "bottom", "=", "0", ")", "if", "not", "server", ":", "plt", ".", "show", "(", ")", "else", ":", "hist", "[", "\"density\"", "]", "=", "hist", "[", "\"counts\"", "]", "/", "(", "hist", "[", "\"breaks\"", "]", ".", "difflag1", "(", ")", "*", "hist", "[", "\"counts\"", "]", ".", "sum", "(", ")", ")", "return", "hist"], "docstring": "Compute a histogram over a numeric column.\n\n        :param breaks: Can be one of ``\"sturges\"``, ``\"rice\"``, ``\"sqrt\"``, ``\"doane\"``, ``\"fd\"``, ``\"scott\"``;\n            or a single number for the number of breaks; or a list containing the split points, e.g:\n            ``[-50, 213.2123, 9324834]``. If breaks is \"fd\", the MAD is used over the IQR in computing bin width.\n        :param bool plot: If True (default), then a plot will be generated using ``matplotlib``.\n\n        :returns: If ``plot`` is False, return H2OFrame with these columns: breaks, counts, mids_true,\n            mids, and density; otherwise this method draws a plot and returns nothing.", "docstring_tokens": ["Compute", "a", "histogram", "over", "a", "numeric", "column", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2499-L2544", "partition": "test", "index": 1431, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.insert_missing_values", "original_string": "def insert_missing_values(self, fraction=0.1, seed=None):\n        \"\"\"\n        Insert missing values into the current frame, modifying it in-place.\n\n        Randomly replaces a user-specified fraction of entries in a H2O dataset with missing\n        values.\n\n        :param float fraction: A number between 0 and 1 indicating the fraction of entries to replace with missing.\n        :param int seed: The seed for the random number generator used to determine which values to make missing.\n\n        :returns: the original H2OFrame with missing values inserted.\n        \"\"\"\n        kwargs = {}\n        kwargs['dataset'] = self.frame_id  # Eager; forces eval now for following REST call\n        kwargs['fraction'] = fraction\n        if seed is not None: kwargs['seed'] = seed\n        job = {}\n        job['job'] = h2o.api(\"POST /3/MissingInserter\", data=kwargs)\n        H2OJob(job, job_type=(\"Insert Missing Values\")).poll()\n        self._ex._cache.flush()\n        return self", "language": "python", "code": "def insert_missing_values(self, fraction=0.1, seed=None):\n        \"\"\"\n        Insert missing values into the current frame, modifying it in-place.\n\n        Randomly replaces a user-specified fraction of entries in a H2O dataset with missing\n        values.\n\n        :param float fraction: A number between 0 and 1 indicating the fraction of entries to replace with missing.\n        :param int seed: The seed for the random number generator used to determine which values to make missing.\n\n        :returns: the original H2OFrame with missing values inserted.\n        \"\"\"\n        kwargs = {}\n        kwargs['dataset'] = self.frame_id  # Eager; forces eval now for following REST call\n        kwargs['fraction'] = fraction\n        if seed is not None: kwargs['seed'] = seed\n        job = {}\n        job['job'] = h2o.api(\"POST /3/MissingInserter\", data=kwargs)\n        H2OJob(job, job_type=(\"Insert Missing Values\")).poll()\n        self._ex._cache.flush()\n        return self", "code_tokens": ["def", "insert_missing_values", "(", "self", ",", "fraction", "=", "0.1", ",", "seed", "=", "None", ")", ":", "kwargs", "=", "{", "}", "kwargs", "[", "'dataset'", "]", "=", "self", ".", "frame_id", "# Eager; forces eval now for following REST call", "kwargs", "[", "'fraction'", "]", "=", "fraction", "if", "seed", "is", "not", "None", ":", "kwargs", "[", "'seed'", "]", "=", "seed", "job", "=", "{", "}", "job", "[", "'job'", "]", "=", "h2o", ".", "api", "(", "\"POST /3/MissingInserter\"", ",", "data", "=", "kwargs", ")", "H2OJob", "(", "job", ",", "job_type", "=", "(", "\"Insert Missing Values\"", ")", ")", ".", "poll", "(", ")", "self", ".", "_ex", ".", "_cache", ".", "flush", "(", ")", "return", "self"], "docstring": "Insert missing values into the current frame, modifying it in-place.\n\n        Randomly replaces a user-specified fraction of entries in a H2O dataset with missing\n        values.\n\n        :param float fraction: A number between 0 and 1 indicating the fraction of entries to replace with missing.\n        :param int seed: The seed for the random number generator used to determine which values to make missing.\n\n        :returns: the original H2OFrame with missing values inserted.", "docstring_tokens": ["Insert", "missing", "values", "into", "the", "current", "frame", "modifying", "it", "in", "-", "place", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1991-L2011", "partition": "test", "index": 1419, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.table", "original_string": "def table(self, data2=None, dense=True):\n        \"\"\"\n        Compute the counts of values appearing in a column, or co-occurence counts between two columns.\n\n        :param H2OFrame data2: An optional single column to aggregate counts by.\n        :param bool dense: If True (default) then use dense representation, which lists only non-zero counts,\n            1 combination per row. Set to False to expand counts across all combinations.\n\n        :returns: H2OFrame of the counts at each combination of factor levels\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"table\", self, data2, dense)) if data2 is not None else H2OFrame._expr(\n            expr=ExprNode(\"table\", self, dense))", "language": "python", "code": "def table(self, data2=None, dense=True):\n        \"\"\"\n        Compute the counts of values appearing in a column, or co-occurence counts between two columns.\n\n        :param H2OFrame data2: An optional single column to aggregate counts by.\n        :param bool dense: If True (default) then use dense representation, which lists only non-zero counts,\n            1 combination per row. Set to False to expand counts across all combinations.\n\n        :returns: H2OFrame of the counts at each combination of factor levels\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"table\", self, data2, dense)) if data2 is not None else H2OFrame._expr(\n            expr=ExprNode(\"table\", self, dense))", "code_tokens": ["def", "table", "(", "self", ",", "data2", "=", "None", ",", "dense", "=", "True", ")", ":", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"table\"", ",", "self", ",", "data2", ",", "dense", ")", ")", "if", "data2", "is", "not", "None", "else", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"table\"", ",", "self", ",", "dense", ")", ")"], "docstring": "Compute the counts of values appearing in a column, or co-occurence counts between two columns.\n\n        :param H2OFrame data2: An optional single column to aggregate counts by.\n        :param bool dense: If True (default) then use dense representation, which lists only non-zero counts,\n            1 combination per row. Set to False to expand counts across all combinations.\n\n        :returns: H2OFrame of the counts at each combination of factor levels", "docstring_tokens": ["Compute", "the", "counts", "of", "values", "appearing", "in", "a", "column", "or", "co", "-", "occurence", "counts", "between", "two", "columns", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2485-L2496", "partition": "test", "index": 1430, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.num_valid_substrings", "original_string": "def num_valid_substrings(self, path_to_words):\n        \"\"\"\n        For each string, find the count of all possible substrings with 2 characters or more that are contained in\n        the line-separated text file whose path is given.\n\n        :param str path_to_words: Path to file that contains a line-separated list of strings considered valid.\n        :returns: An H2OFrame with the number of substrings that are contained in the given word list.\n        \"\"\"\n        assert_is_type(path_to_words, str)\n        fr = H2OFrame._expr(expr=ExprNode(\"num_valid_substrings\", self, path_to_words))\n        fr._ex._cache.nrows = self.nrow\n        fr._ex._cache.ncol = self.ncol\n        return fr", "language": "python", "code": "def num_valid_substrings(self, path_to_words):\n        \"\"\"\n        For each string, find the count of all possible substrings with 2 characters or more that are contained in\n        the line-separated text file whose path is given.\n\n        :param str path_to_words: Path to file that contains a line-separated list of strings considered valid.\n        :returns: An H2OFrame with the number of substrings that are contained in the given word list.\n        \"\"\"\n        assert_is_type(path_to_words, str)\n        fr = H2OFrame._expr(expr=ExprNode(\"num_valid_substrings\", self, path_to_words))\n        fr._ex._cache.nrows = self.nrow\n        fr._ex._cache.ncol = self.ncol\n        return fr", "code_tokens": ["def", "num_valid_substrings", "(", "self", ",", "path_to_words", ")", ":", "assert_is_type", "(", "path_to_words", ",", "str", ")", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"num_valid_substrings\"", ",", "self", ",", "path_to_words", ")", ")", "fr", ".", "_ex", ".", "_cache", ".", "nrows", "=", "self", ".", "nrow", "fr", ".", "_ex", ".", "_cache", ".", "ncol", "=", "self", ".", "ncol", "return", "fr"], "docstring": "For each string, find the count of all possible substrings with 2 characters or more that are contained in\n        the line-separated text file whose path is given.\n\n        :param str path_to_words: Path to file that contains a line-separated list of strings considered valid.\n        :returns: An H2OFrame with the number of substrings that are contained in the given word list.", "docstring_tokens": ["For", "each", "string", "find", "the", "count", "of", "all", "possible", "substrings", "with", "2", "characters", "or", "more", "that", "are", "contained", "in", "the", "line", "-", "separated", "text", "file", "whose", "path", "is", "given", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2461-L2473", "partition": "test", "index": 1429, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.entropy", "original_string": "def entropy(self):\n        \"\"\"\n        For each string compute its Shannon entropy, if the string is empty the entropy is 0.\n\n        :returns: an H2OFrame of Shannon entropies.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"entropy\", self))\n        fr._ex._cache.nrows = self.nrow\n        fr._ex._cache.ncol = self.ncol\n        return fr", "language": "python", "code": "def entropy(self):\n        \"\"\"\n        For each string compute its Shannon entropy, if the string is empty the entropy is 0.\n\n        :returns: an H2OFrame of Shannon entropies.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"entropy\", self))\n        fr._ex._cache.nrows = self.nrow\n        fr._ex._cache.ncol = self.ncol\n        return fr", "code_tokens": ["def", "entropy", "(", "self", ")", ":", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"entropy\"", ",", "self", ")", ")", "fr", ".", "_ex", ".", "_cache", ".", "nrows", "=", "self", ".", "nrow", "fr", ".", "_ex", ".", "_cache", ".", "ncol", "=", "self", ".", "ncol", "return", "fr"], "docstring": "For each string compute its Shannon entropy, if the string is empty the entropy is 0.\n\n        :returns: an H2OFrame of Shannon entropies.", "docstring_tokens": ["For", "each", "string", "compute", "its", "Shannon", "entropy", "if", "the", "string", "is", "empty", "the", "entropy", "is", "0", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2449-L2458", "partition": "test", "index": 1428, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.lstrip", "original_string": "def lstrip(self, set=\" \"):\n        \"\"\"\n        Return a copy of the column with leading characters removed.\n\n        The set argument is a string specifying the set of characters to be removed.\n        If omitted, the set argument defaults to removing whitespace.\n\n        :param character set: The set of characters to lstrip from strings in column.\n        :returns: a new H2OFrame with the same shape as the original frame and having all its values\n            trimmed from the left (equivalent of Python's ``str.lstrip()``).\n        \"\"\"\n        # work w/ None; parity with python lstrip\n        if set is None: set = \" \"\n\n        fr = H2OFrame._expr(expr=ExprNode(\"lstrip\", self, set))\n        fr._ex._cache.nrows = self.nrow\n        fr._ex._cache.ncol = self.ncol\n        return fr", "language": "python", "code": "def lstrip(self, set=\" \"):\n        \"\"\"\n        Return a copy of the column with leading characters removed.\n\n        The set argument is a string specifying the set of characters to be removed.\n        If omitted, the set argument defaults to removing whitespace.\n\n        :param character set: The set of characters to lstrip from strings in column.\n        :returns: a new H2OFrame with the same shape as the original frame and having all its values\n            trimmed from the left (equivalent of Python's ``str.lstrip()``).\n        \"\"\"\n        # work w/ None; parity with python lstrip\n        if set is None: set = \" \"\n\n        fr = H2OFrame._expr(expr=ExprNode(\"lstrip\", self, set))\n        fr._ex._cache.nrows = self.nrow\n        fr._ex._cache.ncol = self.ncol\n        return fr", "code_tokens": ["def", "lstrip", "(", "self", ",", "set", "=", "\" \"", ")", ":", "# work w/ None; parity with python lstrip", "if", "set", "is", "None", ":", "set", "=", "\" \"", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"lstrip\"", ",", "self", ",", "set", ")", ")", "fr", ".", "_ex", ".", "_cache", ".", "nrows", "=", "self", ".", "nrow", "fr", ".", "_ex", ".", "_cache", ".", "ncol", "=", "self", ".", "ncol", "return", "fr"], "docstring": "Return a copy of the column with leading characters removed.\n\n        The set argument is a string specifying the set of characters to be removed.\n        If omitted, the set argument defaults to removing whitespace.\n\n        :param character set: The set of characters to lstrip from strings in column.\n        :returns: a new H2OFrame with the same shape as the original frame and having all its values\n            trimmed from the left (equivalent of Python's ``str.lstrip()``).", "docstring_tokens": ["Return", "a", "copy", "of", "the", "column", "with", "leading", "characters", "removed", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2409-L2426", "partition": "test", "index": 1427, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.head", "original_string": "def head(self, rows=10, cols=200):\n        \"\"\"\n        Return the first ``rows`` and ``cols`` of the frame as a new H2OFrame.\n\n        :param int rows: maximum number of rows to return\n        :param int cols: maximum number of columns to return\n        :returns: a new H2OFrame cut from the top left corner of the current frame, and having dimensions at\n            most ``rows`` x ``cols``.\n        \"\"\"\n        assert_is_type(rows, int)\n        assert_is_type(cols, int)\n        nrows = min(self.nrows, rows)\n        ncols = min(self.ncols, cols)\n        newdt = self[:nrows, :ncols]\n        return newdt._frame(rows=nrows, cols=cols, fill_cache=True)", "language": "python", "code": "def head(self, rows=10, cols=200):\n        \"\"\"\n        Return the first ``rows`` and ``cols`` of the frame as a new H2OFrame.\n\n        :param int rows: maximum number of rows to return\n        :param int cols: maximum number of columns to return\n        :returns: a new H2OFrame cut from the top left corner of the current frame, and having dimensions at\n            most ``rows`` x ``cols``.\n        \"\"\"\n        assert_is_type(rows, int)\n        assert_is_type(cols, int)\n        nrows = min(self.nrows, rows)\n        ncols = min(self.ncols, cols)\n        newdt = self[:nrows, :ncols]\n        return newdt._frame(rows=nrows, cols=cols, fill_cache=True)", "code_tokens": ["def", "head", "(", "self", ",", "rows", "=", "10", ",", "cols", "=", "200", ")", ":", "assert_is_type", "(", "rows", ",", "int", ")", "assert_is_type", "(", "cols", ",", "int", ")", "nrows", "=", "min", "(", "self", ".", "nrows", ",", "rows", ")", "ncols", "=", "min", "(", "self", ".", "ncols", ",", "cols", ")", "newdt", "=", "self", "[", ":", "nrows", ",", ":", "ncols", "]", "return", "newdt", ".", "_frame", "(", "rows", "=", "nrows", ",", "cols", "=", "cols", ",", "fill_cache", "=", "True", ")"], "docstring": "Return the first ``rows`` and ``cols`` of the frame as a new H2OFrame.\n\n        :param int rows: maximum number of rows to return\n        :param int cols: maximum number of columns to return\n        :returns: a new H2OFrame cut from the top left corner of the current frame, and having dimensions at\n            most ``rows`` x ``cols``.", "docstring_tokens": ["Return", "the", "first", "rows", "and", "cols", "of", "the", "frame", "as", "a", "new", "H2OFrame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L514-L528", "partition": "test", "index": 1394, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.var", "original_string": "def var(self, y=None, na_rm=False, use=None):\n        \"\"\"\n        Compute the variance-covariance matrix of one or two H2OFrames.\n\n        :param H2OFrame y: If this parameter is given, then a covariance  matrix between the columns of the target\n            frame and the columns of ``y`` is computed. If this parameter is not provided then the covariance matrix\n            of the target frame is returned. If target frame has just a single column, then return the scalar variance\n            instead of the matrix. Single rows are treated as single columns.\n        :param str use: A string indicating how to handle missing values. This could be one of the following:\n\n            - ``\"everything\"``: outputs NaNs whenever one of its contributing observations is missing\n            - ``\"all.obs\"``: presence of missing observations will throw an error\n            - ``\"complete.obs\"``: discards missing values along with all observations in their rows so that only\n              complete observations are used\n        :param bool na_rm: an alternative to ``use``: when this is True then default value for ``use`` is\n            ``\"everything\"``; and if False then default ``use`` is ``\"complete.obs\"``. This parameter has no effect\n            if ``use`` is given explicitly.\n\n        :returns: An H2OFrame of the covariance matrix of the columns of this frame (if ``y`` is not given),\n            or with the columns of ``y`` (if ``y`` is given). However when this frame and ``y`` are both single rows\n            or single columns, then the variance is returned as a scalar.\n        \"\"\"\n        symmetric = False\n        if y is None:\n            y = self\n            symmetric = True\n        if use is None: use = \"complete.obs\" if na_rm else \"everything\"\n        if self.nrow == 1 or (self.ncol == 1 and y.ncol == 1):\n            return ExprNode(\"var\", self, y, use, symmetric)._eager_scalar()\n        return H2OFrame._expr(expr=ExprNode(\"var\", self, y, use, symmetric))._frame()", "language": "python", "code": "def var(self, y=None, na_rm=False, use=None):\n        \"\"\"\n        Compute the variance-covariance matrix of one or two H2OFrames.\n\n        :param H2OFrame y: If this parameter is given, then a covariance  matrix between the columns of the target\n            frame and the columns of ``y`` is computed. If this parameter is not provided then the covariance matrix\n            of the target frame is returned. If target frame has just a single column, then return the scalar variance\n            instead of the matrix. Single rows are treated as single columns.\n        :param str use: A string indicating how to handle missing values. This could be one of the following:\n\n            - ``\"everything\"``: outputs NaNs whenever one of its contributing observations is missing\n            - ``\"all.obs\"``: presence of missing observations will throw an error\n            - ``\"complete.obs\"``: discards missing values along with all observations in their rows so that only\n              complete observations are used\n        :param bool na_rm: an alternative to ``use``: when this is True then default value for ``use`` is\n            ``\"everything\"``; and if False then default ``use`` is ``\"complete.obs\"``. This parameter has no effect\n            if ``use`` is given explicitly.\n\n        :returns: An H2OFrame of the covariance matrix of the columns of this frame (if ``y`` is not given),\n            or with the columns of ``y`` (if ``y`` is given). However when this frame and ``y`` are both single rows\n            or single columns, then the variance is returned as a scalar.\n        \"\"\"\n        symmetric = False\n        if y is None:\n            y = self\n            symmetric = True\n        if use is None: use = \"complete.obs\" if na_rm else \"everything\"\n        if self.nrow == 1 or (self.ncol == 1 and y.ncol == 1):\n            return ExprNode(\"var\", self, y, use, symmetric)._eager_scalar()\n        return H2OFrame._expr(expr=ExprNode(\"var\", self, y, use, symmetric))._frame()", "code_tokens": ["def", "var", "(", "self", ",", "y", "=", "None", ",", "na_rm", "=", "False", ",", "use", "=", "None", ")", ":", "symmetric", "=", "False", "if", "y", "is", "None", ":", "y", "=", "self", "symmetric", "=", "True", "if", "use", "is", "None", ":", "use", "=", "\"complete.obs\"", "if", "na_rm", "else", "\"everything\"", "if", "self", ".", "nrow", "==", "1", "or", "(", "self", ".", "ncol", "==", "1", "and", "y", ".", "ncol", "==", "1", ")", ":", "return", "ExprNode", "(", "\"var\"", ",", "self", ",", "y", ",", "use", ",", "symmetric", ")", ".", "_eager_scalar", "(", ")", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"var\"", ",", "self", ",", "y", ",", "use", ",", "symmetric", ")", ")", ".", "_frame", "(", ")"], "docstring": "Compute the variance-covariance matrix of one or two H2OFrames.\n\n        :param H2OFrame y: If this parameter is given, then a covariance  matrix between the columns of the target\n            frame and the columns of ``y`` is computed. If this parameter is not provided then the covariance matrix\n            of the target frame is returned. If target frame has just a single column, then return the scalar variance\n            instead of the matrix. Single rows are treated as single columns.\n        :param str use: A string indicating how to handle missing values. This could be one of the following:\n\n            - ``\"everything\"``: outputs NaNs whenever one of its contributing observations is missing\n            - ``\"all.obs\"``: presence of missing observations will throw an error\n            - ``\"complete.obs\"``: discards missing values along with all observations in their rows so that only\n              complete observations are used\n        :param bool na_rm: an alternative to ``use``: when this is True then default value for ``use`` is\n            ``\"everything\"``; and if False then default ``use`` is ``\"complete.obs\"``. This parameter has no effect\n            if ``use`` is given explicitly.\n\n        :returns: An H2OFrame of the covariance matrix of the columns of this frame (if ``y`` is not given),\n            or with the columns of ``y`` (if ``y`` is given). However when this frame and ``y`` are both single rows\n            or single columns, then the variance is returned as a scalar.", "docstring_tokens": ["Compute", "the", "variance", "-", "covariance", "matrix", "of", "one", "or", "two", "H2OFrames", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2141-L2170", "partition": "test", "index": 1420, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.cor", "original_string": "def cor(self, y=None, na_rm=False, use=None):\n        \"\"\"\n        Compute the correlation matrix of one or two H2OFrames.\n\n        :param H2OFrame y: If this parameter is provided, then compute correlation between the columns of ``y``\n            and the columns of the current frame. If this parameter is not given, then just compute the correlation\n            matrix for the columns of the current frame.\n        :param str use: A string indicating how to handle missing values. This could be one of the following:\n\n            - ``\"everything\"``: outputs NaNs whenever one of its contributing observations is missing\n            - ``\"all.obs\"``: presence of missing observations will throw an error\n            - ``\"complete.obs\"``: discards missing values along with all observations in their rows so that only\n              complete observations are used\n        :param bool na_rm: an alternative to ``use``: when this is True then default value for ``use`` is\n            ``\"everything\"``; and if False then default ``use`` is ``\"complete.obs\"``. This parameter has no effect\n            if ``use`` is given explicitly.\n\n        :returns: An H2OFrame of the correlation matrix of the columns of this frame (if ``y`` is not given),\n            or with the columns of ``y`` (if ``y`` is given). However when this frame and ``y`` are both single rows\n            or single columns, then the correlation is returned as a scalar.\n        \"\"\"\n        assert_is_type(y, H2OFrame, None)\n        assert_is_type(na_rm, bool)\n        assert_is_type(use, None, \"everything\", \"all.obs\", \"complete.obs\")\n        if y is None:\n            y = self\n        if use is None: use = \"complete.obs\" if na_rm else \"everything\"\n        if self.nrow == 1 or (self.ncol == 1 and y.ncol == 1): return ExprNode(\"cor\", self, y, use)._eager_scalar()\n        return H2OFrame._expr(expr=ExprNode(\"cor\", self, y, use))._frame()", "language": "python", "code": "def cor(self, y=None, na_rm=False, use=None):\n        \"\"\"\n        Compute the correlation matrix of one or two H2OFrames.\n\n        :param H2OFrame y: If this parameter is provided, then compute correlation between the columns of ``y``\n            and the columns of the current frame. If this parameter is not given, then just compute the correlation\n            matrix for the columns of the current frame.\n        :param str use: A string indicating how to handle missing values. This could be one of the following:\n\n            - ``\"everything\"``: outputs NaNs whenever one of its contributing observations is missing\n            - ``\"all.obs\"``: presence of missing observations will throw an error\n            - ``\"complete.obs\"``: discards missing values along with all observations in their rows so that only\n              complete observations are used\n        :param bool na_rm: an alternative to ``use``: when this is True then default value for ``use`` is\n            ``\"everything\"``; and if False then default ``use`` is ``\"complete.obs\"``. This parameter has no effect\n            if ``use`` is given explicitly.\n\n        :returns: An H2OFrame of the correlation matrix of the columns of this frame (if ``y`` is not given),\n            or with the columns of ``y`` (if ``y`` is given). However when this frame and ``y`` are both single rows\n            or single columns, then the correlation is returned as a scalar.\n        \"\"\"\n        assert_is_type(y, H2OFrame, None)\n        assert_is_type(na_rm, bool)\n        assert_is_type(use, None, \"everything\", \"all.obs\", \"complete.obs\")\n        if y is None:\n            y = self\n        if use is None: use = \"complete.obs\" if na_rm else \"everything\"\n        if self.nrow == 1 or (self.ncol == 1 and y.ncol == 1): return ExprNode(\"cor\", self, y, use)._eager_scalar()\n        return H2OFrame._expr(expr=ExprNode(\"cor\", self, y, use))._frame()", "code_tokens": ["def", "cor", "(", "self", ",", "y", "=", "None", ",", "na_rm", "=", "False", ",", "use", "=", "None", ")", ":", "assert_is_type", "(", "y", ",", "H2OFrame", ",", "None", ")", "assert_is_type", "(", "na_rm", ",", "bool", ")", "assert_is_type", "(", "use", ",", "None", ",", "\"everything\"", ",", "\"all.obs\"", ",", "\"complete.obs\"", ")", "if", "y", "is", "None", ":", "y", "=", "self", "if", "use", "is", "None", ":", "use", "=", "\"complete.obs\"", "if", "na_rm", "else", "\"everything\"", "if", "self", ".", "nrow", "==", "1", "or", "(", "self", ".", "ncol", "==", "1", "and", "y", ".", "ncol", "==", "1", ")", ":", "return", "ExprNode", "(", "\"cor\"", ",", "self", ",", "y", ",", "use", ")", ".", "_eager_scalar", "(", ")", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"cor\"", ",", "self", ",", "y", ",", "use", ")", ")", ".", "_frame", "(", ")"], "docstring": "Compute the correlation matrix of one or two H2OFrames.\n\n        :param H2OFrame y: If this parameter is provided, then compute correlation between the columns of ``y``\n            and the columns of the current frame. If this parameter is not given, then just compute the correlation\n            matrix for the columns of the current frame.\n        :param str use: A string indicating how to handle missing values. This could be one of the following:\n\n            - ``\"everything\"``: outputs NaNs whenever one of its contributing observations is missing\n            - ``\"all.obs\"``: presence of missing observations will throw an error\n            - ``\"complete.obs\"``: discards missing values along with all observations in their rows so that only\n              complete observations are used\n        :param bool na_rm: an alternative to ``use``: when this is True then default value for ``use`` is\n            ``\"everything\"``; and if False then default ``use`` is ``\"complete.obs\"``. This parameter has no effect\n            if ``use`` is given explicitly.\n\n        :returns: An H2OFrame of the correlation matrix of the columns of this frame (if ``y`` is not given),\n            or with the columns of ``y`` (if ``y`` is given). However when this frame and ``y`` are both single rows\n            or single columns, then the correlation is returned as a scalar.", "docstring_tokens": ["Compute", "the", "correlation", "matrix", "of", "one", "or", "two", "H2OFrames", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2183-L2211", "partition": "test", "index": 1421, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.mult", "original_string": "def mult(self, matrix):\n        \"\"\"\n        Multiply this frame, viewed as a matrix, by another matrix.\n\n        :param matrix: another frame that you want to multiply the current frame by; must be compatible with the\n            current frame (i.e. its number of rows must be the same as number of columns in the current frame).\n        :returns: new H2OFrame, which is the result of multiplying the current frame by ``matrix``.\n        \"\"\"\n        if self.ncols != matrix.nrows:\n            raise H2OValueError(\"Matrix is not compatible for multiplication with the current frame\")\n        return H2OFrame._expr(expr=ExprNode(\"x\", self, matrix))", "language": "python", "code": "def mult(self, matrix):\n        \"\"\"\n        Multiply this frame, viewed as a matrix, by another matrix.\n\n        :param matrix: another frame that you want to multiply the current frame by; must be compatible with the\n            current frame (i.e. its number of rows must be the same as number of columns in the current frame).\n        :returns: new H2OFrame, which is the result of multiplying the current frame by ``matrix``.\n        \"\"\"\n        if self.ncols != matrix.nrows:\n            raise H2OValueError(\"Matrix is not compatible for multiplication with the current frame\")\n        return H2OFrame._expr(expr=ExprNode(\"x\", self, matrix))", "code_tokens": ["def", "mult", "(", "self", ",", "matrix", ")", ":", "if", "self", ".", "ncols", "!=", "matrix", ".", "nrows", ":", "raise", "H2OValueError", "(", "\"Matrix is not compatible for multiplication with the current frame\"", ")", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"x\"", ",", "self", ",", "matrix", ")", ")"], "docstring": "Multiply this frame, viewed as a matrix, by another matrix.\n\n        :param matrix: another frame that you want to multiply the current frame by; must be compatible with the\n            current frame (i.e. its number of rows must be the same as number of columns in the current frame).\n        :returns: new H2OFrame, which is the result of multiplying the current frame by ``matrix``.", "docstring_tokens": ["Multiply", "this", "frame", "viewed", "as", "a", "matrix", "by", "another", "matrix", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L697-L707", "partition": "test", "index": 1395, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.asfactor", "original_string": "def asfactor(self):\n        \"\"\"\n        Convert columns in the current frame to categoricals.\n\n        :returns: new H2OFrame with columns of the \"enum\" type.\n        \"\"\"\n        for colname in self.names:\n            t = self.types[colname]\n            if t not in {\"bool\", \"int\", \"string\", \"enum\"}:\n                raise H2OValueError(\"Only 'int' or 'string' are allowed for \"\n                                    \"asfactor(), got %s:%s \" % (colname, t))\n        fr = H2OFrame._expr(expr=ExprNode(\"as.factor\", self), cache=self._ex._cache)\n        if fr._ex._cache.types_valid():\n            fr._ex._cache.types = {name: \"enum\" for name in self.types}\n        else:\n            raise H2OTypeError(\"Types are not available in result\")\n        \n        return fr", "language": "python", "code": "def asfactor(self):\n        \"\"\"\n        Convert columns in the current frame to categoricals.\n\n        :returns: new H2OFrame with columns of the \"enum\" type.\n        \"\"\"\n        for colname in self.names:\n            t = self.types[colname]\n            if t not in {\"bool\", \"int\", \"string\", \"enum\"}:\n                raise H2OValueError(\"Only 'int' or 'string' are allowed for \"\n                                    \"asfactor(), got %s:%s \" % (colname, t))\n        fr = H2OFrame._expr(expr=ExprNode(\"as.factor\", self), cache=self._ex._cache)\n        if fr._ex._cache.types_valid():\n            fr._ex._cache.types = {name: \"enum\" for name in self.types}\n        else:\n            raise H2OTypeError(\"Types are not available in result\")\n        \n        return fr", "code_tokens": ["def", "asfactor", "(", "self", ")", ":", "for", "colname", "in", "self", ".", "names", ":", "t", "=", "self", ".", "types", "[", "colname", "]", "if", "t", "not", "in", "{", "\"bool\"", ",", "\"int\"", ",", "\"string\"", ",", "\"enum\"", "}", ":", "raise", "H2OValueError", "(", "\"Only 'int' or 'string' are allowed for \"", "\"asfactor(), got %s:%s \"", "%", "(", "colname", ",", "t", ")", ")", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"as.factor\"", ",", "self", ")", ",", "cache", "=", "self", ".", "_ex", ".", "_cache", ")", "if", "fr", ".", "_ex", ".", "_cache", ".", "types_valid", "(", ")", ":", "fr", ".", "_ex", ".", "_cache", ".", "types", "=", "{", "name", ":", "\"enum\"", "for", "name", "in", "self", ".", "types", "}", "else", ":", "raise", "H2OTypeError", "(", "\"Types are not available in result\"", ")", "return", "fr"], "docstring": "Convert columns in the current frame to categoricals.\n\n        :returns: new H2OFrame with columns of the \"enum\" type.", "docstring_tokens": ["Convert", "columns", "in", "the", "current", "frame", "to", "categoricals", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2278-L2295", "partition": "test", "index": 1423, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.substring", "original_string": "def substring(self, start_index, end_index=None):\n        \"\"\"\n        For each string, return a new string that is a substring of the original string.\n\n        If end_index is not specified, then the substring extends to the end of the original string. If the start_index\n        is longer than the length of the string, or is greater than or equal to the end_index, an empty string is\n        returned. Negative start_index is coerced to 0.\n\n        :param int start_index: The index of the original string at which to start the substring, inclusive.\n        :param int end_index: The index of the original string at which to end the substring, exclusive.\n        :returns: An H2OFrame containing the specified substrings.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"substring\", self, start_index, end_index))\n        fr._ex._cache.nrows = self.nrow\n        fr._ex._cache.ncol = self.ncol\n        return fr", "language": "python", "code": "def substring(self, start_index, end_index=None):\n        \"\"\"\n        For each string, return a new string that is a substring of the original string.\n\n        If end_index is not specified, then the substring extends to the end of the original string. If the start_index\n        is longer than the length of the string, or is greater than or equal to the end_index, an empty string is\n        returned. Negative start_index is coerced to 0.\n\n        :param int start_index: The index of the original string at which to start the substring, inclusive.\n        :param int end_index: The index of the original string at which to end the substring, exclusive.\n        :returns: An H2OFrame containing the specified substrings.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"substring\", self, start_index, end_index))\n        fr._ex._cache.nrows = self.nrow\n        fr._ex._cache.ncol = self.ncol\n        return fr", "code_tokens": ["def", "substring", "(", "self", ",", "start_index", ",", "end_index", "=", "None", ")", ":", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"substring\"", ",", "self", ",", "start_index", ",", "end_index", ")", ")", "fr", ".", "_ex", ".", "_cache", ".", "nrows", "=", "self", ".", "nrow", "fr", ".", "_ex", ".", "_cache", ".", "ncol", "=", "self", ".", "ncol", "return", "fr"], "docstring": "For each string, return a new string that is a substring of the original string.\n\n        If end_index is not specified, then the substring extends to the end of the original string. If the start_index\n        is longer than the length of the string, or is greater than or equal to the end_index, an empty string is\n        returned. Negative start_index is coerced to 0.\n\n        :param int start_index: The index of the original string at which to start the substring, inclusive.\n        :param int end_index: The index of the original string at which to end the substring, exclusive.\n        :returns: An H2OFrame containing the specified substrings.", "docstring_tokens": ["For", "each", "string", "return", "a", "new", "string", "that", "is", "a", "substring", "of", "the", "original", "string", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2391-L2406", "partition": "test", "index": 1426, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.countmatches", "original_string": "def countmatches(self, pattern):\n        \"\"\"\n        For each string in the frame, count the occurrences of the provided pattern.  If countmathces is applied to\n        a frame, all columns of the frame must be type string, otherwise, the returned frame will contain errors.\n\n        The pattern here is a plain string, not a regular expression. We will search for the occurrences of the\n        pattern as a substring in element of the frame. This function is applicable to frames containing only\n        string or categorical columns.\n\n        :param str pattern: The pattern to count matches on in each string. This can also be a list of strings,\n            in which case all of them will be searched for.\n        :returns: numeric H2OFrame with the same shape as the original, containing counts of matches of the\n            pattern for each cell in the original frame.\n        \"\"\"\n        assert_is_type(pattern, str, [str])\n        fr = H2OFrame._expr(expr=ExprNode(\"countmatches\", self, pattern))\n        fr._ex._cache.nrows = self.nrow\n        fr._ex._cache.ncols = self.ncol\n        return fr", "language": "python", "code": "def countmatches(self, pattern):\n        \"\"\"\n        For each string in the frame, count the occurrences of the provided pattern.  If countmathces is applied to\n        a frame, all columns of the frame must be type string, otherwise, the returned frame will contain errors.\n\n        The pattern here is a plain string, not a regular expression. We will search for the occurrences of the\n        pattern as a substring in element of the frame. This function is applicable to frames containing only\n        string or categorical columns.\n\n        :param str pattern: The pattern to count matches on in each string. This can also be a list of strings,\n            in which case all of them will be searched for.\n        :returns: numeric H2OFrame with the same shape as the original, containing counts of matches of the\n            pattern for each cell in the original frame.\n        \"\"\"\n        assert_is_type(pattern, str, [str])\n        fr = H2OFrame._expr(expr=ExprNode(\"countmatches\", self, pattern))\n        fr._ex._cache.nrows = self.nrow\n        fr._ex._cache.ncols = self.ncol\n        return fr", "code_tokens": ["def", "countmatches", "(", "self", ",", "pattern", ")", ":", "assert_is_type", "(", "pattern", ",", "str", ",", "[", "str", "]", ")", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"countmatches\"", ",", "self", ",", "pattern", ")", ")", "fr", ".", "_ex", ".", "_cache", ".", "nrows", "=", "self", ".", "nrow", "fr", ".", "_ex", ".", "_cache", ".", "ncols", "=", "self", ".", "ncol", "return", "fr"], "docstring": "For each string in the frame, count the occurrences of the provided pattern.  If countmathces is applied to\n        a frame, all columns of the frame must be type string, otherwise, the returned frame will contain errors.\n\n        The pattern here is a plain string, not a regular expression. We will search for the occurrences of the\n        pattern as a substring in element of the frame. This function is applicable to frames containing only\n        string or categorical columns.\n\n        :param str pattern: The pattern to count matches on in each string. This can also be a list of strings,\n            in which case all of them will be searched for.\n        :returns: numeric H2OFrame with the same shape as the original, containing counts of matches of the\n            pattern for each cell in the original frame.", "docstring_tokens": ["For", "each", "string", "in", "the", "frame", "count", "the", "occurrences", "of", "the", "provided", "pattern", ".", "If", "countmathces", "is", "applied", "to", "a", "frame", "all", "columns", "of", "the", "frame", "must", "be", "type", "string", "otherwise", "the", "returned", "frame", "will", "contain", "errors", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2358-L2376", "partition": "test", "index": 1425, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.na_omit", "original_string": "def na_omit(self):\n        \"\"\"\n        Remove rows with NAs from the H2OFrame.\n\n        :returns: new H2OFrame with all rows from the original frame containing any NAs removed.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"na.omit\", self), cache=self._ex._cache)\n        fr._ex._cache.nrows = -1\n        return fr", "language": "python", "code": "def na_omit(self):\n        \"\"\"\n        Remove rows with NAs from the H2OFrame.\n\n        :returns: new H2OFrame with all rows from the original frame containing any NAs removed.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"na.omit\", self), cache=self._ex._cache)\n        fr._ex._cache.nrows = -1\n        return fr", "code_tokens": ["def", "na_omit", "(", "self", ")", ":", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"na.omit\"", ",", "self", ")", ",", "cache", "=", "self", ".", "_ex", ".", "_cache", ")", "fr", ".", "_ex", ".", "_cache", ".", "nrows", "=", "-", "1", "return", "fr"], "docstring": "Remove rows with NAs from the H2OFrame.\n\n        :returns: new H2OFrame with all rows from the original frame containing any NAs removed.", "docstring_tokens": ["Remove", "rows", "with", "NAs", "from", "the", "H2OFrame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L3030-L3038", "partition": "test", "index": 1436, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.strsplit", "original_string": "def strsplit(self, pattern):\n        \"\"\"\n        Split the strings in the target column on the given regular expression pattern.\n\n        :param str pattern: The split pattern.\n        :returns: H2OFrame containing columns of the split strings.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"strsplit\", self, pattern))\n        fr._ex._cache.nrows = self.nrow\n        return fr", "language": "python", "code": "def strsplit(self, pattern):\n        \"\"\"\n        Split the strings in the target column on the given regular expression pattern.\n\n        :param str pattern: The split pattern.\n        :returns: H2OFrame containing columns of the split strings.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"strsplit\", self, pattern))\n        fr._ex._cache.nrows = self.nrow\n        return fr", "code_tokens": ["def", "strsplit", "(", "self", ",", "pattern", ")", ":", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"strsplit\"", ",", "self", ",", "pattern", ")", ")", "fr", ".", "_ex", ".", "_cache", ".", "nrows", "=", "self", ".", "nrow", "return", "fr"], "docstring": "Split the strings in the target column on the given regular expression pattern.\n\n        :param str pattern: The split pattern.\n        :returns: H2OFrame containing columns of the split strings.", "docstring_tokens": ["Split", "the", "strings", "in", "the", "target", "column", "on", "the", "given", "regular", "expression", "pattern", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2334-L2343", "partition": "test", "index": 1424, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.as_data_frame", "original_string": "def as_data_frame(self, use_pandas=True, header=True):\n        \"\"\"\n        Obtain the dataset as a python-local object.\n\n        :param bool use_pandas: If True (default) then return the H2OFrame as a pandas DataFrame (requires that the\n            ``pandas`` library was installed). If False, then return the contents of the H2OFrame as plain nested\n            list, in a row-wise order.\n        :param bool header: If True (default), then column names will be appended as the first row in list\n\n        :returns: A python object (a list of lists of strings, each list is a row, if use_pandas=False, otherwise\n            a pandas DataFrame) containing this H2OFrame instance's data.\n        \"\"\" \n        if can_use_pandas() and use_pandas:\n            import pandas\n            return pandas.read_csv(StringIO(self.get_frame_data()), low_memory=False, skip_blank_lines=False)\n        from h2o.utils.csv.readers import reader\n        frame = [row for row in reader(StringIO(self.get_frame_data()))]\n        if not header:\n            frame.pop(0)\n        return frame", "language": "python", "code": "def as_data_frame(self, use_pandas=True, header=True):\n        \"\"\"\n        Obtain the dataset as a python-local object.\n\n        :param bool use_pandas: If True (default) then return the H2OFrame as a pandas DataFrame (requires that the\n            ``pandas`` library was installed). If False, then return the contents of the H2OFrame as plain nested\n            list, in a row-wise order.\n        :param bool header: If True (default), then column names will be appended as the first row in list\n\n        :returns: A python object (a list of lists of strings, each list is a row, if use_pandas=False, otherwise\n            a pandas DataFrame) containing this H2OFrame instance's data.\n        \"\"\" \n        if can_use_pandas() and use_pandas:\n            import pandas\n            return pandas.read_csv(StringIO(self.get_frame_data()), low_memory=False, skip_blank_lines=False)\n        from h2o.utils.csv.readers import reader\n        frame = [row for row in reader(StringIO(self.get_frame_data()))]\n        if not header:\n            frame.pop(0)\n        return frame", "code_tokens": ["def", "as_data_frame", "(", "self", ",", "use_pandas", "=", "True", ",", "header", "=", "True", ")", ":", "if", "can_use_pandas", "(", ")", "and", "use_pandas", ":", "import", "pandas", "return", "pandas", ".", "read_csv", "(", "StringIO", "(", "self", ".", "get_frame_data", "(", ")", ")", ",", "low_memory", "=", "False", ",", "skip_blank_lines", "=", "False", ")", "from", "h2o", ".", "utils", ".", "csv", ".", "readers", "import", "reader", "frame", "=", "[", "row", "for", "row", "in", "reader", "(", "StringIO", "(", "self", ".", "get_frame_data", "(", ")", ")", ")", "]", "if", "not", "header", ":", "frame", ".", "pop", "(", "0", ")", "return", "frame"], "docstring": "Obtain the dataset as a python-local object.\n\n        :param bool use_pandas: If True (default) then return the H2OFrame as a pandas DataFrame (requires that the\n            ``pandas`` library was installed). If False, then return the contents of the H2OFrame as plain nested\n            list, in a row-wise order.\n        :param bool header: If True (default), then column names will be appended as the first row in list\n\n        :returns: A python object (a list of lists of strings, each list is a row, if use_pandas=False, otherwise\n            a pandas DataFrame) containing this H2OFrame instance's data.", "docstring_tokens": ["Obtain", "the", "dataset", "as", "a", "python", "-", "local", "object", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1286-L1305", "partition": "test", "index": 1407, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.stratified_kfold_column", "original_string": "def stratified_kfold_column(self, n_folds=3, seed=-1):\n        \"\"\"\n        Build a fold assignment column with the constraint that each fold has the same class\n        distribution as the fold column.\n\n        :param int n_folds: The number of folds to build.\n        :param int seed: A seed for the random number generator.\n\n        :returns: A single column H2OFrame with the fold assignments.\n        \"\"\"\n        return H2OFrame._expr(\n            expr=ExprNode(\"stratified_kfold_column\", self, n_folds, seed))._frame()", "language": "python", "code": "def stratified_kfold_column(self, n_folds=3, seed=-1):\n        \"\"\"\n        Build a fold assignment column with the constraint that each fold has the same class\n        distribution as the fold column.\n\n        :param int n_folds: The number of folds to build.\n        :param int seed: A seed for the random number generator.\n\n        :returns: A single column H2OFrame with the fold assignments.\n        \"\"\"\n        return H2OFrame._expr(\n            expr=ExprNode(\"stratified_kfold_column\", self, n_folds, seed))._frame()", "code_tokens": ["def", "stratified_kfold_column", "(", "self", ",", "n_folds", "=", "3", ",", "seed", "=", "-", "1", ")", ":", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"stratified_kfold_column\"", ",", "self", ",", "n_folds", ",", "seed", ")", ")", ".", "_frame", "(", ")"], "docstring": "Build a fold assignment column with the constraint that each fold has the same class\n        distribution as the fold column.\n\n        :param int n_folds: The number of folds to build.\n        :param int seed: A seed for the random number generator.\n\n        :returns: A single column H2OFrame with the fold assignments.", "docstring_tokens": ["Build", "a", "fold", "assignment", "column", "with", "the", "constraint", "that", "each", "fold", "has", "the", "same", "class", "distribution", "as", "the", "fold", "column", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1253-L1264", "partition": "test", "index": 1405, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.summary", "original_string": "def summary(self, return_data=False):\n        \"\"\"\n        Display summary information about the frame.\n\n        Summary includes min/mean/max/sigma and other rollup data.\n\n        :param bool return_data: Return a dictionary of the summary output\n        \"\"\"\n        if not self._has_content():\n            print(\"This H2OFrame is empty and not initialized.\")\n            return self._ex._cache._data;\n        if not self._ex._cache.is_valid(): self._frame()._ex._cache.fill()\n        if not return_data:\n            if self.nrows == 0:\n                print(\"This H2OFrame is empty.\")\n            elif H2ODisplay._in_ipy():\n                import IPython.display\n                IPython.display.display_html(self._ex._cache._tabulate(\"html\", True), raw=True)\n            else:\n                print(self._ex._cache._tabulate(\"simple\", True))\n        else:\n            return self._ex._cache._data", "language": "python", "code": "def summary(self, return_data=False):\n        \"\"\"\n        Display summary information about the frame.\n\n        Summary includes min/mean/max/sigma and other rollup data.\n\n        :param bool return_data: Return a dictionary of the summary output\n        \"\"\"\n        if not self._has_content():\n            print(\"This H2OFrame is empty and not initialized.\")\n            return self._ex._cache._data;\n        if not self._ex._cache.is_valid(): self._frame()._ex._cache.fill()\n        if not return_data:\n            if self.nrows == 0:\n                print(\"This H2OFrame is empty.\")\n            elif H2ODisplay._in_ipy():\n                import IPython.display\n                IPython.display.display_html(self._ex._cache._tabulate(\"html\", True), raw=True)\n            else:\n                print(self._ex._cache._tabulate(\"simple\", True))\n        else:\n            return self._ex._cache._data", "code_tokens": ["def", "summary", "(", "self", ",", "return_data", "=", "False", ")", ":", "if", "not", "self", ".", "_has_content", "(", ")", ":", "print", "(", "\"This H2OFrame is empty and not initialized.\"", ")", "return", "self", ".", "_ex", ".", "_cache", ".", "_data", "if", "not", "self", ".", "_ex", ".", "_cache", ".", "is_valid", "(", ")", ":", "self", ".", "_frame", "(", ")", ".", "_ex", ".", "_cache", ".", "fill", "(", ")", "if", "not", "return_data", ":", "if", "self", ".", "nrows", "==", "0", ":", "print", "(", "\"This H2OFrame is empty.\"", ")", "elif", "H2ODisplay", ".", "_in_ipy", "(", ")", ":", "import", "IPython", ".", "display", "IPython", ".", "display", ".", "display_html", "(", "self", ".", "_ex", ".", "_cache", ".", "_tabulate", "(", "\"html\"", ",", "True", ")", ",", "raw", "=", "True", ")", "else", ":", "print", "(", "self", ".", "_ex", ".", "_cache", ".", "_tabulate", "(", "\"simple\"", ",", "True", ")", ")", "else", ":", "return", "self", ".", "_ex", ".", "_cache", ".", "_data"], "docstring": "Display summary information about the frame.\n\n        Summary includes min/mean/max/sigma and other rollup data.\n\n        :param bool return_data: Return a dictionary of the summary output", "docstring_tokens": ["Display", "summary", "information", "about", "the", "frame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L459-L480", "partition": "test", "index": 1392, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.structure", "original_string": "def structure(self):\n        \"\"\"Compactly display the internal structure of an H2OFrame.\"\"\"\n        df = self.as_data_frame(use_pandas=False)\n        cn = df.pop(0)\n        nr = self.nrow\n        nc = self.ncol\n        width = max([len(c) for c in cn])\n        isfactor = self.isfactor()\n        numlevels = self.nlevels()\n        lvls = self.levels()\n        print(\"H2OFrame: '{}' \\nDimensions: {} obs. of {} variables\".format(self.frame_id, nr, nc))\n        for i in range(nc):\n            print(\"$ {} {}: \".format(cn[i], ' ' * (width - max(0, len(cn[i])))), end=' ')\n            if isfactor[i]:\n                nl = numlevels[i]\n                print(\"Factor w/ {} level(s) {} \".format(nl, '\"' + '\",\"'.join(lvls[i]) + '\"'), end='\\n')\n            else:\n                print(\"num {}\".format(\" \".join(it[0] if it else \"nan\" for it in h2o.as_list(self[:10, i], False)[1:])))", "language": "python", "code": "def structure(self):\n        \"\"\"Compactly display the internal structure of an H2OFrame.\"\"\"\n        df = self.as_data_frame(use_pandas=False)\n        cn = df.pop(0)\n        nr = self.nrow\n        nc = self.ncol\n        width = max([len(c) for c in cn])\n        isfactor = self.isfactor()\n        numlevels = self.nlevels()\n        lvls = self.levels()\n        print(\"H2OFrame: '{}' \\nDimensions: {} obs. of {} variables\".format(self.frame_id, nr, nc))\n        for i in range(nc):\n            print(\"$ {} {}: \".format(cn[i], ' ' * (width - max(0, len(cn[i])))), end=' ')\n            if isfactor[i]:\n                nl = numlevels[i]\n                print(\"Factor w/ {} level(s) {} \".format(nl, '\"' + '\",\"'.join(lvls[i]) + '\"'), end='\\n')\n            else:\n                print(\"num {}\".format(\" \".join(it[0] if it else \"nan\" for it in h2o.as_list(self[:10, i], False)[1:])))", "code_tokens": ["def", "structure", "(", "self", ")", ":", "df", "=", "self", ".", "as_data_frame", "(", "use_pandas", "=", "False", ")", "cn", "=", "df", ".", "pop", "(", "0", ")", "nr", "=", "self", ".", "nrow", "nc", "=", "self", ".", "ncol", "width", "=", "max", "(", "[", "len", "(", "c", ")", "for", "c", "in", "cn", "]", ")", "isfactor", "=", "self", ".", "isfactor", "(", ")", "numlevels", "=", "self", ".", "nlevels", "(", ")", "lvls", "=", "self", ".", "levels", "(", ")", "print", "(", "\"H2OFrame: '{}' \\nDimensions: {} obs. of {} variables\"", ".", "format", "(", "self", ".", "frame_id", ",", "nr", ",", "nc", ")", ")", "for", "i", "in", "range", "(", "nc", ")", ":", "print", "(", "\"$ {} {}: \"", ".", "format", "(", "cn", "[", "i", "]", ",", "' '", "*", "(", "width", "-", "max", "(", "0", ",", "len", "(", "cn", "[", "i", "]", ")", ")", ")", ")", ",", "end", "=", "' '", ")", "if", "isfactor", "[", "i", "]", ":", "nl", "=", "numlevels", "[", "i", "]", "print", "(", "\"Factor w/ {} level(s) {} \"", ".", "format", "(", "nl", ",", "'\"'", "+", "'\",\"'", ".", "join", "(", "lvls", "[", "i", "]", ")", "+", "'\"'", ")", ",", "end", "=", "'\\n'", ")", "else", ":", "print", "(", "\"num {}\"", ".", "format", "(", "\" \"", ".", "join", "(", "it", "[", "0", "]", "if", "it", "else", "\"nan\"", "for", "it", "in", "h2o", ".", "as_list", "(", "self", "[", ":", "10", ",", "i", "]", ",", "False", ")", "[", "1", ":", "]", ")", ")", ")"], "docstring": "Compactly display the internal structure of an H2OFrame.", "docstring_tokens": ["Compactly", "display", "the", "internal", "structure", "of", "an", "H2OFrame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1267-L1284", "partition": "test", "index": 1406, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.cut", "original_string": "def cut(self, breaks, labels=None, include_lowest=False, right=True, dig_lab=3):\n        \"\"\"\n        Cut a numeric vector into categorical \"buckets\".\n\n        This method is only applicable to a single-column numeric frame.\n\n        :param List[float] breaks: The cut points in the numeric vector.\n        :param List[str] labels: Labels for categorical levels produced. Defaults to set notation of\n            intervals defined by the breaks.\n        :param bool include_lowest: By default, cuts are defined as intervals ``(lo, hi]``. If this parameter\n            is True, then the interval becomes ``[lo, hi]``.\n        :param bool right: Include the high value: ``(lo, hi]``. If False, get ``(lo, hi)``.\n        :param int dig_lab: Number of digits following the decimal point to consider.\n\n        :returns: Single-column H2OFrame of categorical data.\n        \"\"\"\n        assert_is_type(breaks, [numeric])\n        if self.ncols != 1: raise H2OValueError(\"Single-column frame is expected\")\n        if self.types[self.names[0]] not in {\"int\", \"real\"}: raise H2OValueError(\"A numeric column is expected\")\n        fr = H2OFrame._expr(expr=ExprNode(\"cut\", self, breaks, labels, include_lowest, right, dig_lab),\n                            cache=self._ex._cache)\n        fr._ex._cache.types = {k: \"enum\" for k in self.names}\n        return fr", "language": "python", "code": "def cut(self, breaks, labels=None, include_lowest=False, right=True, dig_lab=3):\n        \"\"\"\n        Cut a numeric vector into categorical \"buckets\".\n\n        This method is only applicable to a single-column numeric frame.\n\n        :param List[float] breaks: The cut points in the numeric vector.\n        :param List[str] labels: Labels for categorical levels produced. Defaults to set notation of\n            intervals defined by the breaks.\n        :param bool include_lowest: By default, cuts are defined as intervals ``(lo, hi]``. If this parameter\n            is True, then the interval becomes ``[lo, hi]``.\n        :param bool right: Include the high value: ``(lo, hi]``. If False, get ``(lo, hi)``.\n        :param int dig_lab: Number of digits following the decimal point to consider.\n\n        :returns: Single-column H2OFrame of categorical data.\n        \"\"\"\n        assert_is_type(breaks, [numeric])\n        if self.ncols != 1: raise H2OValueError(\"Single-column frame is expected\")\n        if self.types[self.names[0]] not in {\"int\", \"real\"}: raise H2OValueError(\"A numeric column is expected\")\n        fr = H2OFrame._expr(expr=ExprNode(\"cut\", self, breaks, labels, include_lowest, right, dig_lab),\n                            cache=self._ex._cache)\n        fr._ex._cache.types = {k: \"enum\" for k in self.names}\n        return fr", "code_tokens": ["def", "cut", "(", "self", ",", "breaks", ",", "labels", "=", "None", ",", "include_lowest", "=", "False", ",", "right", "=", "True", ",", "dig_lab", "=", "3", ")", ":", "assert_is_type", "(", "breaks", ",", "[", "numeric", "]", ")", "if", "self", ".", "ncols", "!=", "1", ":", "raise", "H2OValueError", "(", "\"Single-column frame is expected\"", ")", "if", "self", ".", "types", "[", "self", ".", "names", "[", "0", "]", "]", "not", "in", "{", "\"int\"", ",", "\"real\"", "}", ":", "raise", "H2OValueError", "(", "\"A numeric column is expected\"", ")", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"cut\"", ",", "self", ",", "breaks", ",", "labels", ",", "include_lowest", ",", "right", ",", "dig_lab", ")", ",", "cache", "=", "self", ".", "_ex", ".", "_cache", ")", "fr", ".", "_ex", ".", "_cache", ".", "types", "=", "{", "k", ":", "\"enum\"", "for", "k", "in", "self", ".", "names", "}", "return", "fr"], "docstring": "Cut a numeric vector into categorical \"buckets\".\n\n        This method is only applicable to a single-column numeric frame.\n\n        :param List[float] breaks: The cut points in the numeric vector.\n        :param List[str] labels: Labels for categorical levels produced. Defaults to set notation of\n            intervals defined by the breaks.\n        :param bool include_lowest: By default, cuts are defined as intervals ``(lo, hi]``. If this parameter\n            is True, then the interval becomes ``[lo, hi]``.\n        :param bool right: Include the high value: ``(lo, hi]``. If False, get ``(lo, hi)``.\n        :param int dig_lab: Number of digits following the decimal point to consider.\n\n        :returns: Single-column H2OFrame of categorical data.", "docstring_tokens": ["Cut", "a", "numeric", "vector", "into", "categorical", "buckets", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L3219-L3241", "partition": "test", "index": 1442, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.runif", "original_string": "def runif(self, seed=None):\n        \"\"\"\n        Generate a column of random numbers drawn from a uniform distribution [0,1) and\n        having the same data layout as the source frame.\n\n        :param int seed: seed for the random number generator.\n\n        :returns: Single-column H2OFrame filled with doubles sampled uniformly from [0,1).\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"h2o.runif\", self, -1 if seed is None else seed))\n        fr._ex._cache.ncols = 1\n        fr._ex._cache.nrows = self.nrow\n        return fr", "language": "python", "code": "def runif(self, seed=None):\n        \"\"\"\n        Generate a column of random numbers drawn from a uniform distribution [0,1) and\n        having the same data layout as the source frame.\n\n        :param int seed: seed for the random number generator.\n\n        :returns: Single-column H2OFrame filled with doubles sampled uniformly from [0,1).\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"h2o.runif\", self, -1 if seed is None else seed))\n        fr._ex._cache.ncols = 1\n        fr._ex._cache.nrows = self.nrow\n        return fr", "code_tokens": ["def", "runif", "(", "self", ",", "seed", "=", "None", ")", ":", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"h2o.runif\"", ",", "self", ",", "-", "1", "if", "seed", "is", "None", "else", "seed", ")", ")", "fr", ".", "_ex", ".", "_cache", ".", "ncols", "=", "1", "fr", ".", "_ex", ".", "_cache", ".", "nrows", "=", "self", ".", "nrow", "return", "fr"], "docstring": "Generate a column of random numbers drawn from a uniform distribution [0,1) and\n        having the same data layout as the source frame.\n\n        :param int seed: seed for the random number generator.\n\n        :returns: Single-column H2OFrame filled with doubles sampled uniformly from [0,1).", "docstring_tokens": ["Generate", "a", "column", "of", "random", "numbers", "drawn", "from", "a", "uniform", "distribution", "[", "0", "1", ")", "and", "having", "the", "same", "data", "layout", "as", "the", "source", "frame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L3167-L3179", "partition": "test", "index": 1440, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.pop", "original_string": "def pop(self, i):\n        \"\"\"\n        Pop a column from the H2OFrame at index i.\n\n        :param i: The index (int) or name (str) of the column to pop.\n        :returns: an H2OFrame containing the column dropped from the current frame; the current frame is modified\n            in-place and loses the column.\n        \"\"\"\n        if is_type(i, str): i = self.names.index(i)\n        col = H2OFrame._expr(expr=ExprNode(\"cols\", self, i))\n        old_cache = self._ex._cache\n        self._ex = ExprNode(\"cols\", self, -(i + 1))\n        self._ex._cache.ncols -= 1\n        self._ex._cache.names = old_cache.names[:i] + old_cache.names[i + 1:]\n        self._ex._cache.types = {name: old_cache.types[name] for name in self._ex._cache.names}\n        self._ex._cache._data = None\n        col._ex._cache.ncols = 1\n        col._ex._cache.names = [old_cache.names[i]]\n        return col", "language": "python", "code": "def pop(self, i):\n        \"\"\"\n        Pop a column from the H2OFrame at index i.\n\n        :param i: The index (int) or name (str) of the column to pop.\n        :returns: an H2OFrame containing the column dropped from the current frame; the current frame is modified\n            in-place and loses the column.\n        \"\"\"\n        if is_type(i, str): i = self.names.index(i)\n        col = H2OFrame._expr(expr=ExprNode(\"cols\", self, i))\n        old_cache = self._ex._cache\n        self._ex = ExprNode(\"cols\", self, -(i + 1))\n        self._ex._cache.ncols -= 1\n        self._ex._cache.names = old_cache.names[:i] + old_cache.names[i + 1:]\n        self._ex._cache.types = {name: old_cache.types[name] for name in self._ex._cache.names}\n        self._ex._cache._data = None\n        col._ex._cache.ncols = 1\n        col._ex._cache.names = [old_cache.names[i]]\n        return col", "code_tokens": ["def", "pop", "(", "self", ",", "i", ")", ":", "if", "is_type", "(", "i", ",", "str", ")", ":", "i", "=", "self", ".", "names", ".", "index", "(", "i", ")", "col", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"cols\"", ",", "self", ",", "i", ")", ")", "old_cache", "=", "self", ".", "_ex", ".", "_cache", "self", ".", "_ex", "=", "ExprNode", "(", "\"cols\"", ",", "self", ",", "-", "(", "i", "+", "1", ")", ")", "self", ".", "_ex", ".", "_cache", ".", "ncols", "-=", "1", "self", ".", "_ex", ".", "_cache", ".", "names", "=", "old_cache", ".", "names", "[", ":", "i", "]", "+", "old_cache", ".", "names", "[", "i", "+", "1", ":", "]", "self", ".", "_ex", ".", "_cache", ".", "types", "=", "{", "name", ":", "old_cache", ".", "types", "[", "name", "]", "for", "name", "in", "self", ".", "_ex", ".", "_cache", ".", "names", "}", "self", ".", "_ex", ".", "_cache", ".", "_data", "=", "None", "col", ".", "_ex", ".", "_cache", ".", "ncols", "=", "1", "col", ".", "_ex", ".", "_cache", ".", "names", "=", "[", "old_cache", ".", "names", "[", "i", "]", "]", "return", "col"], "docstring": "Pop a column from the H2OFrame at index i.\n\n        :param i: The index (int) or name (str) of the column to pop.\n        :returns: an H2OFrame containing the column dropped from the current frame; the current frame is modified\n            in-place and loses the column.", "docstring_tokens": ["Pop", "a", "column", "from", "the", "H2OFrame", "at", "index", "i", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1629-L1647", "partition": "test", "index": 1408, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.quantile", "original_string": "def quantile(self, prob=None, combine_method=\"interpolate\", weights_column=None):\n        \"\"\"\n        Compute quantiles.\n\n        :param List[float] prob: list of probabilities for which quantiles should be computed.\n        :param str combine_method: for even samples this setting determines how to combine quantiles. This can be\n            one of ``\"interpolate\"``, ``\"average\"``, ``\"low\"``, ``\"high\"``.\n        :param weights_column: optional weights for each row. If not given, all rows are assumed to have equal\n            importance. This parameter can be either the name of column containing the observation weights in\n            this frame, or a single-column separate H2OFrame of observation weights.\n\n        :returns: a new H2OFrame containing the quantiles and probabilities.\n        \"\"\"\n        if len(self) == 0: return self\n        if prob is None: prob = [0.01, 0.1, 0.25, 0.333, 0.5, 0.667, 0.75, 0.9, 0.99]\n        if weights_column is None:\n            weights_column = \"_\"\n        else:\n            assert_is_type(weights_column, str, I(H2OFrame, lambda wc: wc.ncol == 1 and wc.nrow == self.nrow))\n            if isinstance(weights_column, H2OFrame):\n                merged = self.cbind(weights_column)\n                weights_column = merged.names[-1]\n                return H2OFrame._expr(expr=ExprNode(\"quantile\", merged, prob, combine_method, weights_column))\n        return H2OFrame._expr(expr=ExprNode(\"quantile\", self, prob, combine_method, weights_column))", "language": "python", "code": "def quantile(self, prob=None, combine_method=\"interpolate\", weights_column=None):\n        \"\"\"\n        Compute quantiles.\n\n        :param List[float] prob: list of probabilities for which quantiles should be computed.\n        :param str combine_method: for even samples this setting determines how to combine quantiles. This can be\n            one of ``\"interpolate\"``, ``\"average\"``, ``\"low\"``, ``\"high\"``.\n        :param weights_column: optional weights for each row. If not given, all rows are assumed to have equal\n            importance. This parameter can be either the name of column containing the observation weights in\n            this frame, or a single-column separate H2OFrame of observation weights.\n\n        :returns: a new H2OFrame containing the quantiles and probabilities.\n        \"\"\"\n        if len(self) == 0: return self\n        if prob is None: prob = [0.01, 0.1, 0.25, 0.333, 0.5, 0.667, 0.75, 0.9, 0.99]\n        if weights_column is None:\n            weights_column = \"_\"\n        else:\n            assert_is_type(weights_column, str, I(H2OFrame, lambda wc: wc.ncol == 1 and wc.nrow == self.nrow))\n            if isinstance(weights_column, H2OFrame):\n                merged = self.cbind(weights_column)\n                weights_column = merged.names[-1]\n                return H2OFrame._expr(expr=ExprNode(\"quantile\", merged, prob, combine_method, weights_column))\n        return H2OFrame._expr(expr=ExprNode(\"quantile\", self, prob, combine_method, weights_column))", "code_tokens": ["def", "quantile", "(", "self", ",", "prob", "=", "None", ",", "combine_method", "=", "\"interpolate\"", ",", "weights_column", "=", "None", ")", ":", "if", "len", "(", "self", ")", "==", "0", ":", "return", "self", "if", "prob", "is", "None", ":", "prob", "=", "[", "0.01", ",", "0.1", ",", "0.25", ",", "0.333", ",", "0.5", ",", "0.667", ",", "0.75", ",", "0.9", ",", "0.99", "]", "if", "weights_column", "is", "None", ":", "weights_column", "=", "\"_\"", "else", ":", "assert_is_type", "(", "weights_column", ",", "str", ",", "I", "(", "H2OFrame", ",", "lambda", "wc", ":", "wc", ".", "ncol", "==", "1", "and", "wc", ".", "nrow", "==", "self", ".", "nrow", ")", ")", "if", "isinstance", "(", "weights_column", ",", "H2OFrame", ")", ":", "merged", "=", "self", ".", "cbind", "(", "weights_column", ")", "weights_column", "=", "merged", ".", "names", "[", "-", "1", "]", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"quantile\"", ",", "merged", ",", "prob", ",", "combine_method", ",", "weights_column", ")", ")", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"quantile\"", ",", "self", ",", "prob", ",", "combine_method", ",", "weights_column", ")", ")"], "docstring": "Compute quantiles.\n\n        :param List[float] prob: list of probabilities for which quantiles should be computed.\n        :param str combine_method: for even samples this setting determines how to combine quantiles. This can be\n            one of ``\"interpolate\"``, ``\"average\"``, ``\"low\"``, ``\"high\"``.\n        :param weights_column: optional weights for each row. If not given, all rows are assumed to have equal\n            importance. This parameter can be either the name of column containing the observation weights in\n            this frame, or a single-column separate H2OFrame of observation weights.\n\n        :returns: a new H2OFrame containing the quantiles and probabilities.", "docstring_tokens": ["Compute", "quantiles", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1650-L1673", "partition": "test", "index": 1409, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.concat", "original_string": "def concat(self, frames, axis=1):\n        \"\"\"\n        Append multiple H2OFrames to this frame, column-wise or row-wise.\n\n        :param List[H2OFrame] frames: list of frames that should be appended to the current frame.\n        :param int axis: if 1 then append column-wise (default), if 0 then append row-wise.\n\n        :returns: an H2OFrame of the combined datasets.\n        \"\"\"\n        if len(frames) == 0:\n            raise ValueError(\"Input list of frames is empty! Nothing to concat.\")\n\n        if axis == 1:\n            df = self.cbind(frames)\n        else:\n            df = self.rbind(frames)\n        return df", "language": "python", "code": "def concat(self, frames, axis=1):\n        \"\"\"\n        Append multiple H2OFrames to this frame, column-wise or row-wise.\n\n        :param List[H2OFrame] frames: list of frames that should be appended to the current frame.\n        :param int axis: if 1 then append column-wise (default), if 0 then append row-wise.\n\n        :returns: an H2OFrame of the combined datasets.\n        \"\"\"\n        if len(frames) == 0:\n            raise ValueError(\"Input list of frames is empty! Nothing to concat.\")\n\n        if axis == 1:\n            df = self.cbind(frames)\n        else:\n            df = self.rbind(frames)\n        return df", "code_tokens": ["def", "concat", "(", "self", ",", "frames", ",", "axis", "=", "1", ")", ":", "if", "len", "(", "frames", ")", "==", "0", ":", "raise", "ValueError", "(", "\"Input list of frames is empty! Nothing to concat.\"", ")", "if", "axis", "==", "1", ":", "df", "=", "self", ".", "cbind", "(", "frames", ")", "else", ":", "df", "=", "self", ".", "rbind", "(", "frames", ")", "return", "df"], "docstring": "Append multiple H2OFrames to this frame, column-wise or row-wise.\n\n        :param List[H2OFrame] frames: list of frames that should be appended to the current frame.\n        :param int axis: if 1 then append column-wise (default), if 0 then append row-wise.\n\n        :returns: an H2OFrame of the combined datasets.", "docstring_tokens": ["Append", "multiple", "H2OFrames", "to", "this", "frame", "column", "-", "wise", "or", "row", "-", "wise", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1676-L1692", "partition": "test", "index": 1410, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.set_level", "original_string": "def set_level(self, level):\n        \"\"\"\n        A method to set all column values to one of the levels.\n\n        :param str level: The level at which the column will be set (a string)\n\n        :returns: H2OFrame with entries set to the desired level.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"setLevel\", self, level), cache=self._ex._cache)", "language": "python", "code": "def set_level(self, level):\n        \"\"\"\n        A method to set all column values to one of the levels.\n\n        :param str level: The level at which the column will be set (a string)\n\n        :returns: H2OFrame with entries set to the desired level.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"setLevel\", self, level), cache=self._ex._cache)", "code_tokens": ["def", "set_level", "(", "self", ",", "level", ")", ":", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"setLevel\"", ",", "self", ",", "level", ")", ",", "cache", "=", "self", ".", "_ex", ".", "_cache", ")"], "docstring": "A method to set all column values to one of the levels.\n\n        :param str level: The level at which the column will be set (a string)\n\n        :returns: H2OFrame with entries set to the desired level.", "docstring_tokens": ["A", "method", "to", "set", "all", "column", "values", "to", "one", "of", "the", "levels", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1010-L1018", "partition": "test", "index": 1398, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.rbind", "original_string": "def rbind(self, data):\n        \"\"\"\n        Append data to this frame row-wise.\n\n        :param data: an H2OFrame or a list of H2OFrame's to be combined with current frame row-wise.\n        :returns: this H2OFrame with all frames in data appended row-wise.\n        \"\"\"\n        assert_is_type(data, H2OFrame, [H2OFrame])\n        frames = [data] if not isinstance(data, list) else data\n        for frame in frames:\n            if frame.ncol != self.ncol:\n                raise H2OValueError(\"Cannot row-bind a dataframe with %d columns to a data frame with %d columns: \"\n                                    \"the columns must match\" % (frame.ncol, self.ncol))\n            if frame.columns != self.columns or frame.types != self.types:\n                raise H2OValueError(\"Column names and types must match for rbind() to work\")\n        fr = H2OFrame._expr(expr=ExprNode(\"rbind\", self, *frames), cache=self._ex._cache)\n        fr._ex._cache.nrows = self.nrow + sum(frame.nrow for frame in frames)\n        return fr", "language": "python", "code": "def rbind(self, data):\n        \"\"\"\n        Append data to this frame row-wise.\n\n        :param data: an H2OFrame or a list of H2OFrame's to be combined with current frame row-wise.\n        :returns: this H2OFrame with all frames in data appended row-wise.\n        \"\"\"\n        assert_is_type(data, H2OFrame, [H2OFrame])\n        frames = [data] if not isinstance(data, list) else data\n        for frame in frames:\n            if frame.ncol != self.ncol:\n                raise H2OValueError(\"Cannot row-bind a dataframe with %d columns to a data frame with %d columns: \"\n                                    \"the columns must match\" % (frame.ncol, self.ncol))\n            if frame.columns != self.columns or frame.types != self.types:\n                raise H2OValueError(\"Column names and types must match for rbind() to work\")\n        fr = H2OFrame._expr(expr=ExprNode(\"rbind\", self, *frames), cache=self._ex._cache)\n        fr._ex._cache.nrows = self.nrow + sum(frame.nrow for frame in frames)\n        return fr", "code_tokens": ["def", "rbind", "(", "self", ",", "data", ")", ":", "assert_is_type", "(", "data", ",", "H2OFrame", ",", "[", "H2OFrame", "]", ")", "frames", "=", "[", "data", "]", "if", "not", "isinstance", "(", "data", ",", "list", ")", "else", "data", "for", "frame", "in", "frames", ":", "if", "frame", ".", "ncol", "!=", "self", ".", "ncol", ":", "raise", "H2OValueError", "(", "\"Cannot row-bind a dataframe with %d columns to a data frame with %d columns: \"", "\"the columns must match\"", "%", "(", "frame", ".", "ncol", ",", "self", ".", "ncol", ")", ")", "if", "frame", ".", "columns", "!=", "self", ".", "columns", "or", "frame", ".", "types", "!=", "self", ".", "types", ":", "raise", "H2OValueError", "(", "\"Column names and types must match for rbind() to work\"", ")", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"rbind\"", ",", "self", ",", "*", "frames", ")", ",", "cache", "=", "self", ".", "_ex", ".", "_cache", ")", "fr", ".", "_ex", ".", "_cache", ".", "nrows", "=", "self", ".", "nrow", "+", "sum", "(", "frame", ".", "nrow", "for", "frame", "in", "frames", ")", "return", "fr"], "docstring": "Append data to this frame row-wise.\n\n        :param data: an H2OFrame or a list of H2OFrame's to be combined with current frame row-wise.\n        :returns: this H2OFrame with all frames in data appended row-wise.", "docstring_tokens": ["Append", "data", "to", "this", "frame", "row", "-", "wise", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1730-L1747", "partition": "test", "index": 1412, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.split_frame", "original_string": "def split_frame(self, ratios=None, destination_frames=None, seed=None):\n        \"\"\"\n        Split a frame into distinct subsets of size determined by the given ratios.\n\n        The number of subsets is always 1 more than the number of ratios given. Note that\n        this does not give an exact split. H2O is designed to be efficient on big data\n        using a probabilistic splitting method rather than an exact split. For example\n        when specifying a split of 0.75/0.25, H2O will produce a test/train split with\n        an expected value of 0.75/0.25 rather than exactly 0.75/0.25. On small datasets,\n        the sizes of the resulting splits will deviate from the expected value more than\n        on big data, where they will be very close to exact.\n\n        :param List[float] ratios: The fractions of rows for each split.\n        :param List[str] destination_frames: The names of the split frames.\n        :param int seed: seed for the random number generator\n\n        :returns: A list of H2OFrames\n        \"\"\"\n        assert_is_type(ratios, [numeric], None)\n        assert_is_type(destination_frames, [str], None)\n        assert_is_type(seed, int, None)\n\n        if ratios is None:\n            ratios = [0.75]\n        if not ratios:\n            raise ValueError(\"Ratios array may not be empty\")\n\n        if destination_frames is not None:\n            if len(ratios) + 1 != len(destination_frames):\n                raise ValueError(\"The number of provided destination_frames must be one more \"\n                                 \"than the number of provided ratios\")\n\n        num_slices = len(ratios) + 1\n        boundaries = []\n\n        last_boundary = 0\n        i = 0\n        while i < num_slices - 1:\n            ratio = ratios[i]\n            if ratio < 0:\n                raise ValueError(\"Ratio must be greater than 0\")\n            boundary = last_boundary + ratio\n            if boundary >= 1.0:\n                raise ValueError(\"Ratios must add up to less than 1.0\")\n            boundaries.append(boundary)\n            last_boundary = boundary\n            i += 1\n\n        splits = []\n        tmp_runif = self.runif(seed)\n        tmp_runif.frame_id = \"%s_splitter\" % _py_tmp_key(h2o.connection().session_id)\n\n        i = 0\n        while i < num_slices:\n            if i == 0:\n                # lower_boundary is 0.0\n                upper_boundary = boundaries[i]\n                tmp_slice = self[(tmp_runif <= upper_boundary), :]\n            elif i == num_slices - 1:\n                lower_boundary = boundaries[i - 1]\n                # upper_boundary is 1.0\n                tmp_slice = self[(tmp_runif > lower_boundary), :]\n            else:\n                lower_boundary = boundaries[i - 1]\n                upper_boundary = boundaries[i]\n                tmp_slice = self[((tmp_runif > lower_boundary) & (tmp_runif <= upper_boundary)), :]\n\n            if destination_frames is None:\n                splits.append(tmp_slice)\n            else:\n                destination_frame_id = destination_frames[i]\n                tmp_slice.frame_id = destination_frame_id\n                splits.append(tmp_slice)\n\n            i += 1\n\n        del tmp_runif\n        return splits", "language": "python", "code": "def split_frame(self, ratios=None, destination_frames=None, seed=None):\n        \"\"\"\n        Split a frame into distinct subsets of size determined by the given ratios.\n\n        The number of subsets is always 1 more than the number of ratios given. Note that\n        this does not give an exact split. H2O is designed to be efficient on big data\n        using a probabilistic splitting method rather than an exact split. For example\n        when specifying a split of 0.75/0.25, H2O will produce a test/train split with\n        an expected value of 0.75/0.25 rather than exactly 0.75/0.25. On small datasets,\n        the sizes of the resulting splits will deviate from the expected value more than\n        on big data, where they will be very close to exact.\n\n        :param List[float] ratios: The fractions of rows for each split.\n        :param List[str] destination_frames: The names of the split frames.\n        :param int seed: seed for the random number generator\n\n        :returns: A list of H2OFrames\n        \"\"\"\n        assert_is_type(ratios, [numeric], None)\n        assert_is_type(destination_frames, [str], None)\n        assert_is_type(seed, int, None)\n\n        if ratios is None:\n            ratios = [0.75]\n        if not ratios:\n            raise ValueError(\"Ratios array may not be empty\")\n\n        if destination_frames is not None:\n            if len(ratios) + 1 != len(destination_frames):\n                raise ValueError(\"The number of provided destination_frames must be one more \"\n                                 \"than the number of provided ratios\")\n\n        num_slices = len(ratios) + 1\n        boundaries = []\n\n        last_boundary = 0\n        i = 0\n        while i < num_slices - 1:\n            ratio = ratios[i]\n            if ratio < 0:\n                raise ValueError(\"Ratio must be greater than 0\")\n            boundary = last_boundary + ratio\n            if boundary >= 1.0:\n                raise ValueError(\"Ratios must add up to less than 1.0\")\n            boundaries.append(boundary)\n            last_boundary = boundary\n            i += 1\n\n        splits = []\n        tmp_runif = self.runif(seed)\n        tmp_runif.frame_id = \"%s_splitter\" % _py_tmp_key(h2o.connection().session_id)\n\n        i = 0\n        while i < num_slices:\n            if i == 0:\n                # lower_boundary is 0.0\n                upper_boundary = boundaries[i]\n                tmp_slice = self[(tmp_runif <= upper_boundary), :]\n            elif i == num_slices - 1:\n                lower_boundary = boundaries[i - 1]\n                # upper_boundary is 1.0\n                tmp_slice = self[(tmp_runif > lower_boundary), :]\n            else:\n                lower_boundary = boundaries[i - 1]\n                upper_boundary = boundaries[i]\n                tmp_slice = self[((tmp_runif > lower_boundary) & (tmp_runif <= upper_boundary)), :]\n\n            if destination_frames is None:\n                splits.append(tmp_slice)\n            else:\n                destination_frame_id = destination_frames[i]\n                tmp_slice.frame_id = destination_frame_id\n                splits.append(tmp_slice)\n\n            i += 1\n\n        del tmp_runif\n        return splits", "code_tokens": ["def", "split_frame", "(", "self", ",", "ratios", "=", "None", ",", "destination_frames", "=", "None", ",", "seed", "=", "None", ")", ":", "assert_is_type", "(", "ratios", ",", "[", "numeric", "]", ",", "None", ")", "assert_is_type", "(", "destination_frames", ",", "[", "str", "]", ",", "None", ")", "assert_is_type", "(", "seed", ",", "int", ",", "None", ")", "if", "ratios", "is", "None", ":", "ratios", "=", "[", "0.75", "]", "if", "not", "ratios", ":", "raise", "ValueError", "(", "\"Ratios array may not be empty\"", ")", "if", "destination_frames", "is", "not", "None", ":", "if", "len", "(", "ratios", ")", "+", "1", "!=", "len", "(", "destination_frames", ")", ":", "raise", "ValueError", "(", "\"The number of provided destination_frames must be one more \"", "\"than the number of provided ratios\"", ")", "num_slices", "=", "len", "(", "ratios", ")", "+", "1", "boundaries", "=", "[", "]", "last_boundary", "=", "0", "i", "=", "0", "while", "i", "<", "num_slices", "-", "1", ":", "ratio", "=", "ratios", "[", "i", "]", "if", "ratio", "<", "0", ":", "raise", "ValueError", "(", "\"Ratio must be greater than 0\"", ")", "boundary", "=", "last_boundary", "+", "ratio", "if", "boundary", ">=", "1.0", ":", "raise", "ValueError", "(", "\"Ratios must add up to less than 1.0\"", ")", "boundaries", ".", "append", "(", "boundary", ")", "last_boundary", "=", "boundary", "i", "+=", "1", "splits", "=", "[", "]", "tmp_runif", "=", "self", ".", "runif", "(", "seed", ")", "tmp_runif", ".", "frame_id", "=", "\"%s_splitter\"", "%", "_py_tmp_key", "(", "h2o", ".", "connection", "(", ")", ".", "session_id", ")", "i", "=", "0", "while", "i", "<", "num_slices", ":", "if", "i", "==", "0", ":", "# lower_boundary is 0.0", "upper_boundary", "=", "boundaries", "[", "i", "]", "tmp_slice", "=", "self", "[", "(", "tmp_runif", "<=", "upper_boundary", ")", ",", ":", "]", "elif", "i", "==", "num_slices", "-", "1", ":", "lower_boundary", "=", "boundaries", "[", "i", "-", "1", "]", "# upper_boundary is 1.0", "tmp_slice", "=", "self", "[", "(", "tmp_runif", ">", "lower_boundary", ")", ",", ":", "]", "else", ":", "lower_boundary", "=", "boundaries", "[", "i", "-", "1", "]", "upper_boundary", "=", "boundaries", "[", "i", "]", "tmp_slice", "=", "self", "[", "(", "(", "tmp_runif", ">", "lower_boundary", ")", "&", "(", "tmp_runif", "<=", "upper_boundary", ")", ")", ",", ":", "]", "if", "destination_frames", "is", "None", ":", "splits", ".", "append", "(", "tmp_slice", ")", "else", ":", "destination_frame_id", "=", "destination_frames", "[", "i", "]", "tmp_slice", ".", "frame_id", "=", "destination_frame_id", "splits", ".", "append", "(", "tmp_slice", ")", "i", "+=", "1", "del", "tmp_runif", "return", "splits"], "docstring": "Split a frame into distinct subsets of size determined by the given ratios.\n\n        The number of subsets is always 1 more than the number of ratios given. Note that\n        this does not give an exact split. H2O is designed to be efficient on big data\n        using a probabilistic splitting method rather than an exact split. For example\n        when specifying a split of 0.75/0.25, H2O will produce a test/train split with\n        an expected value of 0.75/0.25 rather than exactly 0.75/0.25. On small datasets,\n        the sizes of the resulting splits will deviate from the expected value more than\n        on big data, where they will be very close to exact.\n\n        :param List[float] ratios: The fractions of rows for each split.\n        :param List[str] destination_frames: The names of the split frames.\n        :param int seed: seed for the random number generator\n\n        :returns: A list of H2OFrames", "docstring_tokens": ["Split", "a", "frame", "into", "distinct", "subsets", "of", "size", "determined", "by", "the", "given", "ratios", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1750-L1827", "partition": "test", "index": 1413, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.group_by", "original_string": "def group_by(self, by):\n        \"\"\"\n        Return a new ``GroupBy`` object using this frame and the desired grouping columns.\n\n        The returned groups are sorted by the natural group-by column sort.\n\n        :param by: The columns to group on (either a single column name, or a list of column names, or\n            a list of column indices).\n        \"\"\"\n        assert_is_type(by, str, int, [str, int])\n        return GroupBy(self, by)", "language": "python", "code": "def group_by(self, by):\n        \"\"\"\n        Return a new ``GroupBy`` object using this frame and the desired grouping columns.\n\n        The returned groups are sorted by the natural group-by column sort.\n\n        :param by: The columns to group on (either a single column name, or a list of column names, or\n            a list of column indices).\n        \"\"\"\n        assert_is_type(by, str, int, [str, int])\n        return GroupBy(self, by)", "code_tokens": ["def", "group_by", "(", "self", ",", "by", ")", ":", "assert_is_type", "(", "by", ",", "str", ",", "int", ",", "[", "str", ",", "int", "]", ")", "return", "GroupBy", "(", "self", ",", "by", ")"], "docstring": "Return a new ``GroupBy`` object using this frame and the desired grouping columns.\n\n        The returned groups are sorted by the natural group-by column sort.\n\n        :param by: The columns to group on (either a single column name, or a list of column names, or\n            a list of column indices).", "docstring_tokens": ["Return", "a", "new", "GroupBy", "object", "using", "this", "frame", "and", "the", "desired", "grouping", "columns", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1830-L1840", "partition": "test", "index": 1414, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.apply", "original_string": "def apply(self, fun=None, axis=0):\n        \"\"\"\n        Apply a lambda expression to an H2OFrame.\n\n        :param fun: a lambda expression to be applied per row or per column.\n        :param axis: 0 = apply to each column; 1 = apply to each row\n        :returns: a new H2OFrame with the results of applying ``fun`` to the current frame.\n        \"\"\"\n        from .astfun import lambda_to_expr\n        assert_is_type(axis, 0, 1)\n        assert_is_type(fun, FunctionType)\n        assert_satisfies(fun, fun.__name__ == \"<lambda>\")\n        res = lambda_to_expr(fun)\n        return H2OFrame._expr(expr=ExprNode(\"apply\", self, 1 + (axis == 0), *res))", "language": "python", "code": "def apply(self, fun=None, axis=0):\n        \"\"\"\n        Apply a lambda expression to an H2OFrame.\n\n        :param fun: a lambda expression to be applied per row or per column.\n        :param axis: 0 = apply to each column; 1 = apply to each row\n        :returns: a new H2OFrame with the results of applying ``fun`` to the current frame.\n        \"\"\"\n        from .astfun import lambda_to_expr\n        assert_is_type(axis, 0, 1)\n        assert_is_type(fun, FunctionType)\n        assert_satisfies(fun, fun.__name__ == \"<lambda>\")\n        res = lambda_to_expr(fun)\n        return H2OFrame._expr(expr=ExprNode(\"apply\", self, 1 + (axis == 0), *res))", "code_tokens": ["def", "apply", "(", "self", ",", "fun", "=", "None", ",", "axis", "=", "0", ")", ":", "from", ".", "astfun", "import", "lambda_to_expr", "assert_is_type", "(", "axis", ",", "0", ",", "1", ")", "assert_is_type", "(", "fun", ",", "FunctionType", ")", "assert_satisfies", "(", "fun", ",", "fun", ".", "__name__", "==", "\"<lambda>\"", ")", "res", "=", "lambda_to_expr", "(", "fun", ")", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"apply\"", ",", "self", ",", "1", "+", "(", "axis", "==", "0", ")", ",", "*", "res", ")", ")"], "docstring": "Apply a lambda expression to an H2OFrame.\n\n        :param fun: a lambda expression to be applied per row or per column.\n        :param axis: 0 = apply to each column; 1 = apply to each row\n        :returns: a new H2OFrame with the results of applying ``fun`` to the current frame.", "docstring_tokens": ["Apply", "a", "lambda", "expression", "to", "an", "H2OFrame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L3302-L3315", "partition": "test", "index": 1444, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.isin", "original_string": "def isin(self, item):\n        \"\"\"\n        Test whether elements of an H2OFrame are contained in the ``item``.\n\n        :param items: An item or a list of items to compare the H2OFrame against.\n\n        :returns: An H2OFrame of 0s and 1s showing whether each element in the original H2OFrame is contained in item.\n        \"\"\"\n        if is_type(item, list, tuple, set):\n            if self.ncols == 1 and (self.type(0) == 'str' or self.type(0) == 'enum'):\n                return self.match(item)\n            else:\n                return functools.reduce(H2OFrame.__or__, (self == i for i in item))\n        else:\n            return self == item", "language": "python", "code": "def isin(self, item):\n        \"\"\"\n        Test whether elements of an H2OFrame are contained in the ``item``.\n\n        :param items: An item or a list of items to compare the H2OFrame against.\n\n        :returns: An H2OFrame of 0s and 1s showing whether each element in the original H2OFrame is contained in item.\n        \"\"\"\n        if is_type(item, list, tuple, set):\n            if self.ncols == 1 and (self.type(0) == 'str' or self.type(0) == 'enum'):\n                return self.match(item)\n            else:\n                return functools.reduce(H2OFrame.__or__, (self == i for i in item))\n        else:\n            return self == item", "code_tokens": ["def", "isin", "(", "self", ",", "item", ")", ":", "if", "is_type", "(", "item", ",", "list", ",", "tuple", ",", "set", ")", ":", "if", "self", ".", "ncols", "==", "1", "and", "(", "self", ".", "type", "(", "0", ")", "==", "'str'", "or", "self", ".", "type", "(", "0", ")", "==", "'enum'", ")", ":", "return", "self", ".", "match", "(", "item", ")", "else", ":", "return", "functools", ".", "reduce", "(", "H2OFrame", ".", "__or__", ",", "(", "self", "==", "i", "for", "i", "in", "item", ")", ")", "else", ":", "return", "self", "==", "item"], "docstring": "Test whether elements of an H2OFrame are contained in the ``item``.\n\n        :param items: An item or a list of items to compare the H2OFrame against.\n\n        :returns: An H2OFrame of 0s and 1s showing whether each element in the original H2OFrame is contained in item.", "docstring_tokens": ["Test", "whether", "elements", "of", "an", "H2OFrame", "are", "contained", "in", "the", "item", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1210-L1224", "partition": "test", "index": 1403, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.set_name", "original_string": "def set_name(self, col=None, name=None):\n        \"\"\"\n        Set a new name for a column.\n\n        :param col: index or name of the column whose name is to be set; may be skipped for 1-column frames\n        :param name: the new name of the column\n        \"\"\"\n        assert_is_type(col, None, int, str)\n        assert_is_type(name, str)\n        ncols = self.ncols\n\n        col_index = None\n        if is_type(col, int):\n            if not(-ncols <= col < ncols):\n                raise H2OValueError(\"Index %d is out of bounds for a frame with %d columns\" % (col, ncols))\n            col_index = (col + ncols) % ncols  # handle negative indices\n        elif is_type(col, str):\n            if col not in self.names:\n                raise H2OValueError(\"Column %s doesn't exist in the frame.\" % col)\n            col_index = self.names.index(col)  # lookup the name\n        else:\n            assert col is None\n            if ncols != 1:\n                raise H2OValueError(\"The frame has %d columns; please specify which one to rename\" % ncols)\n            col_index = 0\n        if name != self.names[col_index] and name in self.types:\n            raise H2OValueError(\"Column '%s' already exists in the frame\" % name)\n\n        oldname = self.names[col_index]\n        old_cache = self._ex._cache\n        self._ex = ExprNode(\"colnames=\", self, col_index, name)  # Update-in-place, but still lazy\n        self._ex._cache.fill_from(old_cache)\n        if self.names is None:\n            self._frame()._ex._cache.fill()\n        else:\n            self._ex._cache._names = self.names[:col_index] + [name] + self.names[col_index + 1:]\n            self._ex._cache._types[name] = self._ex._cache._types.pop(oldname)\n        return", "language": "python", "code": "def set_name(self, col=None, name=None):\n        \"\"\"\n        Set a new name for a column.\n\n        :param col: index or name of the column whose name is to be set; may be skipped for 1-column frames\n        :param name: the new name of the column\n        \"\"\"\n        assert_is_type(col, None, int, str)\n        assert_is_type(name, str)\n        ncols = self.ncols\n\n        col_index = None\n        if is_type(col, int):\n            if not(-ncols <= col < ncols):\n                raise H2OValueError(\"Index %d is out of bounds for a frame with %d columns\" % (col, ncols))\n            col_index = (col + ncols) % ncols  # handle negative indices\n        elif is_type(col, str):\n            if col not in self.names:\n                raise H2OValueError(\"Column %s doesn't exist in the frame.\" % col)\n            col_index = self.names.index(col)  # lookup the name\n        else:\n            assert col is None\n            if ncols != 1:\n                raise H2OValueError(\"The frame has %d columns; please specify which one to rename\" % ncols)\n            col_index = 0\n        if name != self.names[col_index] and name in self.types:\n            raise H2OValueError(\"Column '%s' already exists in the frame\" % name)\n\n        oldname = self.names[col_index]\n        old_cache = self._ex._cache\n        self._ex = ExprNode(\"colnames=\", self, col_index, name)  # Update-in-place, but still lazy\n        self._ex._cache.fill_from(old_cache)\n        if self.names is None:\n            self._frame()._ex._cache.fill()\n        else:\n            self._ex._cache._names = self.names[:col_index] + [name] + self.names[col_index + 1:]\n            self._ex._cache._types[name] = self._ex._cache._types.pop(oldname)\n        return", "code_tokens": ["def", "set_name", "(", "self", ",", "col", "=", "None", ",", "name", "=", "None", ")", ":", "assert_is_type", "(", "col", ",", "None", ",", "int", ",", "str", ")", "assert_is_type", "(", "name", ",", "str", ")", "ncols", "=", "self", ".", "ncols", "col_index", "=", "None", "if", "is_type", "(", "col", ",", "int", ")", ":", "if", "not", "(", "-", "ncols", "<=", "col", "<", "ncols", ")", ":", "raise", "H2OValueError", "(", "\"Index %d is out of bounds for a frame with %d columns\"", "%", "(", "col", ",", "ncols", ")", ")", "col_index", "=", "(", "col", "+", "ncols", ")", "%", "ncols", "# handle negative indices", "elif", "is_type", "(", "col", ",", "str", ")", ":", "if", "col", "not", "in", "self", ".", "names", ":", "raise", "H2OValueError", "(", "\"Column %s doesn't exist in the frame.\"", "%", "col", ")", "col_index", "=", "self", ".", "names", ".", "index", "(", "col", ")", "# lookup the name", "else", ":", "assert", "col", "is", "None", "if", "ncols", "!=", "1", ":", "raise", "H2OValueError", "(", "\"The frame has %d columns; please specify which one to rename\"", "%", "ncols", ")", "col_index", "=", "0", "if", "name", "!=", "self", ".", "names", "[", "col_index", "]", "and", "name", "in", "self", ".", "types", ":", "raise", "H2OValueError", "(", "\"Column '%s' already exists in the frame\"", "%", "name", ")", "oldname", "=", "self", ".", "names", "[", "col_index", "]", "old_cache", "=", "self", ".", "_ex", ".", "_cache", "self", ".", "_ex", "=", "ExprNode", "(", "\"colnames=\"", ",", "self", ",", "col_index", ",", "name", ")", "# Update-in-place, but still lazy", "self", ".", "_ex", ".", "_cache", ".", "fill_from", "(", "old_cache", ")", "if", "self", ".", "names", "is", "None", ":", "self", ".", "_frame", "(", ")", ".", "_ex", ".", "_cache", ".", "fill", "(", ")", "else", ":", "self", ".", "_ex", ".", "_cache", ".", "_names", "=", "self", ".", "names", "[", ":", "col_index", "]", "+", "[", "name", "]", "+", "self", ".", "names", "[", "col_index", "+", "1", ":", "]", "self", ".", "_ex", ".", "_cache", ".", "_types", "[", "name", "]", "=", "self", ".", "_ex", ".", "_cache", ".", "_types", ".", "pop", "(", "oldname", ")", "return"], "docstring": "Set a new name for a column.\n\n        :param col: index or name of the column whose name is to be set; may be skipped for 1-column frames\n        :param name: the new name of the column", "docstring_tokens": ["Set", "a", "new", "name", "for", "a", "column", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1073-L1110", "partition": "test", "index": 1402, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.set_names", "original_string": "def set_names(self, names):\n        \"\"\"\n        Change names of all columns in the frame.\n\n        :param List[str] names: The list of new names for every column in the frame.\n        \"\"\"\n        assert_is_type(names, [str])\n        assert_satisfies(names, len(names) == self.ncol)\n        self._ex = ExprNode(\"colnames=\", self, range(self.ncol), names)  # Update-in-place, but still lazy\n        return self", "language": "python", "code": "def set_names(self, names):\n        \"\"\"\n        Change names of all columns in the frame.\n\n        :param List[str] names: The list of new names for every column in the frame.\n        \"\"\"\n        assert_is_type(names, [str])\n        assert_satisfies(names, len(names) == self.ncol)\n        self._ex = ExprNode(\"colnames=\", self, range(self.ncol), names)  # Update-in-place, but still lazy\n        return self", "code_tokens": ["def", "set_names", "(", "self", ",", "names", ")", ":", "assert_is_type", "(", "names", ",", "[", "str", "]", ")", "assert_satisfies", "(", "names", ",", "len", "(", "names", ")", "==", "self", ".", "ncol", ")", "self", ".", "_ex", "=", "ExprNode", "(", "\"colnames=\"", ",", "self", ",", "range", "(", "self", ".", "ncol", ")", ",", "names", ")", "# Update-in-place, but still lazy", "return", "self"], "docstring": "Change names of all columns in the frame.\n\n        :param List[str] names: The list of new names for every column in the frame.", "docstring_tokens": ["Change", "names", "of", "all", "columns", "in", "the", "frame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1061-L1070", "partition": "test", "index": 1401, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.isna", "original_string": "def isna(self):\n        \"\"\"\n        For each element in an H2OFrame, determine if it is NA or not.\n\n        :returns: an H2OFrame of 1s and 0s, where 1s mean the values were NAs.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"is.na\", self))\n        fr._ex._cache.nrows = self._ex._cache.nrows\n        fr._ex._cache.ncols = self._ex._cache.ncols\n        if self._ex._cache.names:\n            fr._ex._cache.names = [\"isNA(%s)\" % n for n in self._ex._cache.names]\n            fr._ex._cache.types = {\"isNA(%s)\" % n: \"int\" for n in self._ex._cache.names}\n        return fr", "language": "python", "code": "def isna(self):\n        \"\"\"\n        For each element in an H2OFrame, determine if it is NA or not.\n\n        :returns: an H2OFrame of 1s and 0s, where 1s mean the values were NAs.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"is.na\", self))\n        fr._ex._cache.nrows = self._ex._cache.nrows\n        fr._ex._cache.ncols = self._ex._cache.ncols\n        if self._ex._cache.names:\n            fr._ex._cache.names = [\"isNA(%s)\" % n for n in self._ex._cache.names]\n            fr._ex._cache.types = {\"isNA(%s)\" % n: \"int\" for n in self._ex._cache.names}\n        return fr", "code_tokens": ["def", "isna", "(", "self", ")", ":", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"is.na\"", ",", "self", ")", ")", "fr", ".", "_ex", ".", "_cache", ".", "nrows", "=", "self", ".", "_ex", ".", "_cache", ".", "nrows", "fr", ".", "_ex", ".", "_cache", ".", "ncols", "=", "self", ".", "_ex", ".", "_cache", ".", "ncols", "if", "self", ".", "_ex", ".", "_cache", ".", "names", ":", "fr", ".", "_ex", ".", "_cache", ".", "names", "=", "[", "\"isNA(%s)\"", "%", "n", "for", "n", "in", "self", ".", "_ex", ".", "_cache", ".", "names", "]", "fr", ".", "_ex", ".", "_cache", ".", "types", "=", "{", "\"isNA(%s)\"", "%", "n", ":", "\"int\"", "for", "n", "in", "self", ".", "_ex", ".", "_cache", ".", "names", "}", "return", "fr"], "docstring": "For each element in an H2OFrame, determine if it is NA or not.\n\n        :returns: an H2OFrame of 1s and 0s, where 1s mean the values were NAs.", "docstring_tokens": ["For", "each", "element", "in", "an", "H2OFrame", "determine", "if", "it", "is", "NA", "or", "not", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L3056-L3068", "partition": "test", "index": 1438, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.stratified_split", "original_string": "def stratified_split(self, test_frac=0.2, seed=-1):\n        \"\"\"\n        Construct a column that can be used to perform a random stratified split.\n\n        :param float test_frac: The fraction of rows that will belong to the \"test\".\n        :param int seed: The seed for the random number generator.\n\n        :returns: an H2OFrame having single categorical column with two levels: ``\"train\"`` and ``\"test\"``.\n\n        :examples:\n          >>> stratsplit = df[\"y\"].stratified_split(test_frac=0.3, seed=12349453)\n          >>> train = df[stratsplit==\"train\"]\n          >>> test = df[stratsplit==\"test\"]\n          >>>\n          >>> # check that the distributions among the initial frame, and the\n          >>> # train/test frames match\n          >>> df[\"y\"].table()[\"Count\"] / df[\"y\"].table()[\"Count\"].sum()\n          >>> train[\"y\"].table()[\"Count\"] / train[\"y\"].table()[\"Count\"].sum()\n          >>> test[\"y\"].table()[\"Count\"] / test[\"y\"].table()[\"Count\"].sum()\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode('h2o.random_stratified_split', self, test_frac, seed))", "language": "python", "code": "def stratified_split(self, test_frac=0.2, seed=-1):\n        \"\"\"\n        Construct a column that can be used to perform a random stratified split.\n\n        :param float test_frac: The fraction of rows that will belong to the \"test\".\n        :param int seed: The seed for the random number generator.\n\n        :returns: an H2OFrame having single categorical column with two levels: ``\"train\"`` and ``\"test\"``.\n\n        :examples:\n          >>> stratsplit = df[\"y\"].stratified_split(test_frac=0.3, seed=12349453)\n          >>> train = df[stratsplit==\"train\"]\n          >>> test = df[stratsplit==\"test\"]\n          >>>\n          >>> # check that the distributions among the initial frame, and the\n          >>> # train/test frames match\n          >>> df[\"y\"].table()[\"Count\"] / df[\"y\"].table()[\"Count\"].sum()\n          >>> train[\"y\"].table()[\"Count\"] / train[\"y\"].table()[\"Count\"].sum()\n          >>> test[\"y\"].table()[\"Count\"] / test[\"y\"].table()[\"Count\"].sum()\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode('h2o.random_stratified_split', self, test_frac, seed))", "code_tokens": ["def", "stratified_split", "(", "self", ",", "test_frac", "=", "0.2", ",", "seed", "=", "-", "1", ")", ":", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "'h2o.random_stratified_split'", ",", "self", ",", "test_frac", ",", "seed", ")", ")"], "docstring": "Construct a column that can be used to perform a random stratified split.\n\n        :param float test_frac: The fraction of rows that will belong to the \"test\".\n        :param int seed: The seed for the random number generator.\n\n        :returns: an H2OFrame having single categorical column with two levels: ``\"train\"`` and ``\"test\"``.\n\n        :examples:\n          >>> stratsplit = df[\"y\"].stratified_split(test_frac=0.3, seed=12349453)\n          >>> train = df[stratsplit==\"train\"]\n          >>> test = df[stratsplit==\"test\"]\n          >>>\n          >>> # check that the distributions among the initial frame, and the\n          >>> # train/test frames match\n          >>> df[\"y\"].table()[\"Count\"] / df[\"y\"].table()[\"Count\"].sum()\n          >>> train[\"y\"].table()[\"Count\"] / train[\"y\"].table()[\"Count\"].sum()\n          >>> test[\"y\"].table()[\"Count\"] / test[\"y\"].table()[\"Count\"].sum()", "docstring_tokens": ["Construct", "a", "column", "that", "can", "be", "used", "to", "perform", "a", "random", "stratified", "split", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L3182-L3202", "partition": "test", "index": 1441, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.modulo_kfold_column", "original_string": "def modulo_kfold_column(self, n_folds=3):\n        \"\"\"\n        Build a fold assignments column for cross-validation.\n\n        Rows are assigned a fold according to the current row number modulo ``n_folds``.\n\n        :param int n_folds: An integer specifying the number of validation sets to split the training data into.\n        :returns: A single-column H2OFrame with the fold assignments.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"modulo_kfold_column\", self, n_folds))._frame()", "language": "python", "code": "def modulo_kfold_column(self, n_folds=3):\n        \"\"\"\n        Build a fold assignments column for cross-validation.\n\n        Rows are assigned a fold according to the current row number modulo ``n_folds``.\n\n        :param int n_folds: An integer specifying the number of validation sets to split the training data into.\n        :returns: A single-column H2OFrame with the fold assignments.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"modulo_kfold_column\", self, n_folds))._frame()", "code_tokens": ["def", "modulo_kfold_column", "(", "self", ",", "n_folds", "=", "3", ")", ":", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"modulo_kfold_column\"", ",", "self", ",", "n_folds", ")", ")", ".", "_frame", "(", ")"], "docstring": "Build a fold assignments column for cross-validation.\n\n        Rows are assigned a fold according to the current row number modulo ``n_folds``.\n\n        :param int n_folds: An integer specifying the number of validation sets to split the training data into.\n        :returns: A single-column H2OFrame with the fold assignments.", "docstring_tokens": ["Build", "a", "fold", "assignments", "column", "for", "cross", "-", "validation", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1241-L1250", "partition": "test", "index": 1404, "time": "2016-07-21 16:43:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/server.py", "func_name": "H2OLocalServer._find_jar", "original_string": "def _find_jar(self, path0=None):\n        \"\"\"\n        Return the location of an h2o.jar executable.\n\n        :param path0: Explicitly given h2o.jar path. If provided, then we will simply check whether the file is there,\n            otherwise we will search for an executable in locations returned by ._jar_paths().\n\n        :raises H2OStartupError: if no h2o.jar executable can be found.\n        \"\"\"\n        jar_paths = [path0] if path0 else self._jar_paths()\n        searched_paths = []\n        for jp in jar_paths:\n            searched_paths.append(jp)\n            if os.path.exists(jp):\n                return jp\n        raise H2OStartupError(\"Cannot start local server: h2o.jar not found. Paths searched:\\n\" +\n                              \"\".join(\"    %s\\n\" % s for s in searched_paths))", "language": "python", "code": "def _find_jar(self, path0=None):\n        \"\"\"\n        Return the location of an h2o.jar executable.\n\n        :param path0: Explicitly given h2o.jar path. If provided, then we will simply check whether the file is there,\n            otherwise we will search for an executable in locations returned by ._jar_paths().\n\n        :raises H2OStartupError: if no h2o.jar executable can be found.\n        \"\"\"\n        jar_paths = [path0] if path0 else self._jar_paths()\n        searched_paths = []\n        for jp in jar_paths:\n            searched_paths.append(jp)\n            if os.path.exists(jp):\n                return jp\n        raise H2OStartupError(\"Cannot start local server: h2o.jar not found. Paths searched:\\n\" +\n                              \"\".join(\"    %s\\n\" % s for s in searched_paths))", "code_tokens": ["def", "_find_jar", "(", "self", ",", "path0", "=", "None", ")", ":", "jar_paths", "=", "[", "path0", "]", "if", "path0", "else", "self", ".", "_jar_paths", "(", ")", "searched_paths", "=", "[", "]", "for", "jp", "in", "jar_paths", ":", "searched_paths", ".", "append", "(", "jp", ")", "if", "os", ".", "path", ".", "exists", "(", "jp", ")", ":", "return", "jp", "raise", "H2OStartupError", "(", "\"Cannot start local server: h2o.jar not found. Paths searched:\\n\"", "+", "\"\"", ".", "join", "(", "\"    %s\\n\"", "%", "s", "for", "s", "in", "searched_paths", ")", ")"], "docstring": "Return the location of an h2o.jar executable.\n\n        :param path0: Explicitly given h2o.jar path. If provided, then we will simply check whether the file is there,\n            otherwise we will search for an executable in locations returned by ._jar_paths().\n\n        :raises H2OStartupError: if no h2o.jar executable can be found.", "docstring_tokens": ["Return", "the", "location", "of", "an", "h2o", ".", "jar", "executable", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/server.py#L212-L228", "partition": "test", "index": 1553, "time": "2016-07-21 23:55:36"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/server.py", "func_name": "H2OLocalServer.start", "original_string": "def start(jar_path=None, nthreads=-1, enable_assertions=True, max_mem_size=None, min_mem_size=None,\n              ice_root=None, log_dir=None, log_level=None, port=\"54321+\", name=None, extra_classpath=None,\n              verbose=True, jvm_custom_args=None, bind_to_localhost=True):\n        \"\"\"\n        Start new H2O server on the local machine.\n\n        :param jar_path: Path to the h2o.jar executable. If not given, then we will search for h2o.jar in the\n            locations returned by `._jar_paths()`.\n        :param nthreads: Number of threads in the thread pool. This should be related to the number of CPUs used.\n            -1 means use all CPUs on the host. A positive integer specifies the number of CPUs directly.\n        :param enable_assertions: If True, pass `-ea` option to the JVM.\n        :param max_mem_size: Maximum heap size (jvm option Xmx), in bytes.\n        :param min_mem_size: Minimum heap size (jvm option Xms), in bytes.\n        :param log_dir: Directory for H2O logs to be stored if a new instance is started. Default directory is determined\n        by H2O internally.\n        :param log_level: The logger level for H2O if a new instance is started.\n        :param ice_root: A directory where H2O stores its temporary files. Default location is determined by\n            tempfile.mkdtemp().\n        :param port: Port where to start the new server. This could be either an integer, or a string of the form\n            \"DDDDD+\", indicating that the server should start looking for an open port starting from DDDDD and up.\n        :param name: name of the h2o cluster to be started\n        :param extra_classpath List of paths to libraries that should be included on the Java classpath.\n        :param verbose: If True, then connection info will be printed to the stdout.\n        :param jvm_custom_args Custom, user-defined arguments for the JVM H2O is instantiated in\n        :param bind_to_localhost A flag indicating whether access to the H2O instance should be restricted to the local\n            machine (default) or if it can be reached from other computers on the network.\n            Only applicable when H2O is started from the Python client.\n\n        :returns: a new H2OLocalServer instance\n        \"\"\"\n        assert_is_type(jar_path, None, str)\n        assert_is_type(port, None, int, str)\n        assert_is_type(name, None, str)\n        assert_is_type(nthreads, -1, BoundInt(1, 4096))\n        assert_is_type(enable_assertions, bool)\n        assert_is_type(min_mem_size, None, int)\n        assert_is_type(max_mem_size, None, BoundInt(1 << 25))\n        assert_is_type(log_dir, str, None)\n        assert_is_type(log_level, str, None)\n        assert_satisfies(log_level, log_level in [None, \"TRACE\", \"DEBUG\", \"INFO\", \"WARN\", \"ERRR\", \"FATA\"])\n        assert_is_type(ice_root, None, I(str, os.path.isdir))\n        assert_is_type(extra_classpath, None, [str])\n        assert_is_type(jvm_custom_args, list, None)\n        assert_is_type(bind_to_localhost, bool)\n        if jar_path:\n            assert_satisfies(jar_path, jar_path.endswith(\"h2o.jar\"))\n\n        if min_mem_size is not None and max_mem_size is not None and min_mem_size > max_mem_size:\n            raise H2OValueError(\"`min_mem_size`=%d is larger than the `max_mem_size`=%d\" % (min_mem_size, max_mem_size))\n        if port is None: port = \"54321+\"\n        baseport = None\n        # TODO: get rid of this port gimmick and have 2 separate parameters.\n        if is_type(port, str):\n            if port.isdigit():\n                port = int(port)\n            else:\n                if not(port[-1] == \"+\" and port[:-1].isdigit()):\n                    raise H2OValueError(\"`port` should be of the form 'DDDD+', where D is a digit. Got: %s\" % port)\n                baseport = int(port[:-1])\n                port = 0\n\n        hs = H2OLocalServer()\n        hs._verbose = bool(verbose)\n        hs._jar_path = hs._find_jar(jar_path)\n        hs._extra_classpath = extra_classpath\n        hs._ice_root = ice_root\n        hs._name = name\n        if not ice_root:\n            hs._ice_root = tempfile.mkdtemp()\n            hs._tempdir = hs._ice_root\n\n        if verbose: print(\"Attempting to start a local H2O server...\")\n        hs._launch_server(port=port, baseport=baseport, nthreads=int(nthreads), ea=enable_assertions,\n                          mmax=max_mem_size, mmin=min_mem_size, jvm_custom_args=jvm_custom_args,\n                          bind_to_localhost=bind_to_localhost, log_dir=log_dir, log_level=log_level)\n        if verbose: print(\"  Server is running at %s://%s:%d\" % (hs.scheme, hs.ip, hs.port))\n        atexit.register(lambda: hs.shutdown())\n        return hs", "language": "python", "code": "def start(jar_path=None, nthreads=-1, enable_assertions=True, max_mem_size=None, min_mem_size=None,\n              ice_root=None, log_dir=None, log_level=None, port=\"54321+\", name=None, extra_classpath=None,\n              verbose=True, jvm_custom_args=None, bind_to_localhost=True):\n        \"\"\"\n        Start new H2O server on the local machine.\n\n        :param jar_path: Path to the h2o.jar executable. If not given, then we will search for h2o.jar in the\n            locations returned by `._jar_paths()`.\n        :param nthreads: Number of threads in the thread pool. This should be related to the number of CPUs used.\n            -1 means use all CPUs on the host. A positive integer specifies the number of CPUs directly.\n        :param enable_assertions: If True, pass `-ea` option to the JVM.\n        :param max_mem_size: Maximum heap size (jvm option Xmx), in bytes.\n        :param min_mem_size: Minimum heap size (jvm option Xms), in bytes.\n        :param log_dir: Directory for H2O logs to be stored if a new instance is started. Default directory is determined\n        by H2O internally.\n        :param log_level: The logger level for H2O if a new instance is started.\n        :param ice_root: A directory where H2O stores its temporary files. Default location is determined by\n            tempfile.mkdtemp().\n        :param port: Port where to start the new server. This could be either an integer, or a string of the form\n            \"DDDDD+\", indicating that the server should start looking for an open port starting from DDDDD and up.\n        :param name: name of the h2o cluster to be started\n        :param extra_classpath List of paths to libraries that should be included on the Java classpath.\n        :param verbose: If True, then connection info will be printed to the stdout.\n        :param jvm_custom_args Custom, user-defined arguments for the JVM H2O is instantiated in\n        :param bind_to_localhost A flag indicating whether access to the H2O instance should be restricted to the local\n            machine (default) or if it can be reached from other computers on the network.\n            Only applicable when H2O is started from the Python client.\n\n        :returns: a new H2OLocalServer instance\n        \"\"\"\n        assert_is_type(jar_path, None, str)\n        assert_is_type(port, None, int, str)\n        assert_is_type(name, None, str)\n        assert_is_type(nthreads, -1, BoundInt(1, 4096))\n        assert_is_type(enable_assertions, bool)\n        assert_is_type(min_mem_size, None, int)\n        assert_is_type(max_mem_size, None, BoundInt(1 << 25))\n        assert_is_type(log_dir, str, None)\n        assert_is_type(log_level, str, None)\n        assert_satisfies(log_level, log_level in [None, \"TRACE\", \"DEBUG\", \"INFO\", \"WARN\", \"ERRR\", \"FATA\"])\n        assert_is_type(ice_root, None, I(str, os.path.isdir))\n        assert_is_type(extra_classpath, None, [str])\n        assert_is_type(jvm_custom_args, list, None)\n        assert_is_type(bind_to_localhost, bool)\n        if jar_path:\n            assert_satisfies(jar_path, jar_path.endswith(\"h2o.jar\"))\n\n        if min_mem_size is not None and max_mem_size is not None and min_mem_size > max_mem_size:\n            raise H2OValueError(\"`min_mem_size`=%d is larger than the `max_mem_size`=%d\" % (min_mem_size, max_mem_size))\n        if port is None: port = \"54321+\"\n        baseport = None\n        # TODO: get rid of this port gimmick and have 2 separate parameters.\n        if is_type(port, str):\n            if port.isdigit():\n                port = int(port)\n            else:\n                if not(port[-1] == \"+\" and port[:-1].isdigit()):\n                    raise H2OValueError(\"`port` should be of the form 'DDDD+', where D is a digit. Got: %s\" % port)\n                baseport = int(port[:-1])\n                port = 0\n\n        hs = H2OLocalServer()\n        hs._verbose = bool(verbose)\n        hs._jar_path = hs._find_jar(jar_path)\n        hs._extra_classpath = extra_classpath\n        hs._ice_root = ice_root\n        hs._name = name\n        if not ice_root:\n            hs._ice_root = tempfile.mkdtemp()\n            hs._tempdir = hs._ice_root\n\n        if verbose: print(\"Attempting to start a local H2O server...\")\n        hs._launch_server(port=port, baseport=baseport, nthreads=int(nthreads), ea=enable_assertions,\n                          mmax=max_mem_size, mmin=min_mem_size, jvm_custom_args=jvm_custom_args,\n                          bind_to_localhost=bind_to_localhost, log_dir=log_dir, log_level=log_level)\n        if verbose: print(\"  Server is running at %s://%s:%d\" % (hs.scheme, hs.ip, hs.port))\n        atexit.register(lambda: hs.shutdown())\n        return hs", "code_tokens": ["def", "start", "(", "jar_path", "=", "None", ",", "nthreads", "=", "-", "1", ",", "enable_assertions", "=", "True", ",", "max_mem_size", "=", "None", ",", "min_mem_size", "=", "None", ",", "ice_root", "=", "None", ",", "log_dir", "=", "None", ",", "log_level", "=", "None", ",", "port", "=", "\"54321+\"", ",", "name", "=", "None", ",", "extra_classpath", "=", "None", ",", "verbose", "=", "True", ",", "jvm_custom_args", "=", "None", ",", "bind_to_localhost", "=", "True", ")", ":", "assert_is_type", "(", "jar_path", ",", "None", ",", "str", ")", "assert_is_type", "(", "port", ",", "None", ",", "int", ",", "str", ")", "assert_is_type", "(", "name", ",", "None", ",", "str", ")", "assert_is_type", "(", "nthreads", ",", "-", "1", ",", "BoundInt", "(", "1", ",", "4096", ")", ")", "assert_is_type", "(", "enable_assertions", ",", "bool", ")", "assert_is_type", "(", "min_mem_size", ",", "None", ",", "int", ")", "assert_is_type", "(", "max_mem_size", ",", "None", ",", "BoundInt", "(", "1", "<<", "25", ")", ")", "assert_is_type", "(", "log_dir", ",", "str", ",", "None", ")", "assert_is_type", "(", "log_level", ",", "str", ",", "None", ")", "assert_satisfies", "(", "log_level", ",", "log_level", "in", "[", "None", ",", "\"TRACE\"", ",", "\"DEBUG\"", ",", "\"INFO\"", ",", "\"WARN\"", ",", "\"ERRR\"", ",", "\"FATA\"", "]", ")", "assert_is_type", "(", "ice_root", ",", "None", ",", "I", "(", "str", ",", "os", ".", "path", ".", "isdir", ")", ")", "assert_is_type", "(", "extra_classpath", ",", "None", ",", "[", "str", "]", ")", "assert_is_type", "(", "jvm_custom_args", ",", "list", ",", "None", ")", "assert_is_type", "(", "bind_to_localhost", ",", "bool", ")", "if", "jar_path", ":", "assert_satisfies", "(", "jar_path", ",", "jar_path", ".", "endswith", "(", "\"h2o.jar\"", ")", ")", "if", "min_mem_size", "is", "not", "None", "and", "max_mem_size", "is", "not", "None", "and", "min_mem_size", ">", "max_mem_size", ":", "raise", "H2OValueError", "(", "\"`min_mem_size`=%d is larger than the `max_mem_size`=%d\"", "%", "(", "min_mem_size", ",", "max_mem_size", ")", ")", "if", "port", "is", "None", ":", "port", "=", "\"54321+\"", "baseport", "=", "None", "# TODO: get rid of this port gimmick and have 2 separate parameters.", "if", "is_type", "(", "port", ",", "str", ")", ":", "if", "port", ".", "isdigit", "(", ")", ":", "port", "=", "int", "(", "port", ")", "else", ":", "if", "not", "(", "port", "[", "-", "1", "]", "==", "\"+\"", "and", "port", "[", ":", "-", "1", "]", ".", "isdigit", "(", ")", ")", ":", "raise", "H2OValueError", "(", "\"`port` should be of the form 'DDDD+', where D is a digit. Got: %s\"", "%", "port", ")", "baseport", "=", "int", "(", "port", "[", ":", "-", "1", "]", ")", "port", "=", "0", "hs", "=", "H2OLocalServer", "(", ")", "hs", ".", "_verbose", "=", "bool", "(", "verbose", ")", "hs", ".", "_jar_path", "=", "hs", ".", "_find_jar", "(", "jar_path", ")", "hs", ".", "_extra_classpath", "=", "extra_classpath", "hs", ".", "_ice_root", "=", "ice_root", "hs", ".", "_name", "=", "name", "if", "not", "ice_root", ":", "hs", ".", "_ice_root", "=", "tempfile", ".", "mkdtemp", "(", ")", "hs", ".", "_tempdir", "=", "hs", ".", "_ice_root", "if", "verbose", ":", "print", "(", "\"Attempting to start a local H2O server...\"", ")", "hs", ".", "_launch_server", "(", "port", "=", "port", ",", "baseport", "=", "baseport", ",", "nthreads", "=", "int", "(", "nthreads", ")", ",", "ea", "=", "enable_assertions", ",", "mmax", "=", "max_mem_size", ",", "mmin", "=", "min_mem_size", ",", "jvm_custom_args", "=", "jvm_custom_args", ",", "bind_to_localhost", "=", "bind_to_localhost", ",", "log_dir", "=", "log_dir", ",", "log_level", "=", "log_level", ")", "if", "verbose", ":", "print", "(", "\"  Server is running at %s://%s:%d\"", "%", "(", "hs", ".", "scheme", ",", "hs", ".", "ip", ",", "hs", ".", "port", ")", ")", "atexit", ".", "register", "(", "lambda", ":", "hs", ".", "shutdown", "(", ")", ")", "return", "hs"], "docstring": "Start new H2O server on the local machine.\n\n        :param jar_path: Path to the h2o.jar executable. If not given, then we will search for h2o.jar in the\n            locations returned by `._jar_paths()`.\n        :param nthreads: Number of threads in the thread pool. This should be related to the number of CPUs used.\n            -1 means use all CPUs on the host. A positive integer specifies the number of CPUs directly.\n        :param enable_assertions: If True, pass `-ea` option to the JVM.\n        :param max_mem_size: Maximum heap size (jvm option Xmx), in bytes.\n        :param min_mem_size: Minimum heap size (jvm option Xms), in bytes.\n        :param log_dir: Directory for H2O logs to be stored if a new instance is started. Default directory is determined\n        by H2O internally.\n        :param log_level: The logger level for H2O if a new instance is started.\n        :param ice_root: A directory where H2O stores its temporary files. Default location is determined by\n            tempfile.mkdtemp().\n        :param port: Port where to start the new server. This could be either an integer, or a string of the form\n            \"DDDDD+\", indicating that the server should start looking for an open port starting from DDDDD and up.\n        :param name: name of the h2o cluster to be started\n        :param extra_classpath List of paths to libraries that should be included on the Java classpath.\n        :param verbose: If True, then connection info will be printed to the stdout.\n        :param jvm_custom_args Custom, user-defined arguments for the JVM H2O is instantiated in\n        :param bind_to_localhost A flag indicating whether access to the H2O instance should be restricted to the local\n            machine (default) or if it can be reached from other computers on the network.\n            Only applicable when H2O is started from the Python client.\n\n        :returns: a new H2OLocalServer instance", "docstring_tokens": ["Start", "new", "H2O", "server", "on", "the", "local", "machine", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/server.py#L64-L141", "partition": "test", "index": 1552, "time": "2016-07-21 23:55:36"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/server.py", "func_name": "H2OLocalServer._jar_paths", "original_string": "def _jar_paths():\n        \"\"\"Produce potential paths for an h2o.jar executable.\"\"\"\n\n        # PUBDEV-3534 hook to use arbitrary h2o.jar\n        own_jar = os.getenv(\"H2O_JAR_PATH\", \"\")\n        if own_jar != \"\":\n            if not os.path.isfile(own_jar):\n                raise H2OStartupError(\"Environment variable H2O_JAR_PATH is set to '%d' but file does not exists, unset environment variable or provide valid path to h2o.jar file.\" % own_jar)\n            yield own_jar\n\n        # Check if running from an h2o-3 src folder (or any subfolder), in which case use the freshly-built h2o.jar\n        cwd_chunks = os.path.abspath(\".\").split(os.path.sep)\n        for i in range(len(cwd_chunks), 0, -1):\n            if cwd_chunks[i - 1] == \"h2o-3\":\n                yield os.path.sep.join(cwd_chunks[:i] + [\"build\", \"h2o.jar\"])\n        # Then check the backend/bin folder:\n        # (the following works assuming this code is located in h2o/backend/server.py file)\n        backend_dir = os.path.split(os.path.realpath(__file__))[0]\n        yield os.path.join(backend_dir, \"bin\", \"h2o.jar\")\n\n        # Then try several old locations where h2o.jar might have been installed\n        prefix1 = prefix2 = sys.prefix\n        # On Unix-like systems Python typically gets installed into /Library/... or /System/Library/... If one of\n        # those paths is sys.prefix, then we also build its counterpart.\n        if prefix1.startswith(os.path.sep + \"Library\"):\n            prefix2 = os.path.join(\"\", \"System\", prefix1)\n        elif prefix1.startswith(os.path.sep + \"System\"):\n            prefix2 = prefix1[len(os.path.join(\"\", \"System\")):]\n        yield os.path.join(prefix1, \"h2o_jar\", \"h2o.jar\")\n        yield os.path.join(os.path.abspath(os.sep), \"usr\", \"local\", \"h2o_jar\", \"h2o.jar\")\n        yield os.path.join(prefix1, \"local\", \"h2o_jar\", \"h2o.jar\")\n        yield os.path.join(get_config_var(\"userbase\"), \"h2o_jar\", \"h2o.jar\")\n        yield os.path.join(prefix2, \"h2o_jar\", \"h2o.jar\")", "language": "python", "code": "def _jar_paths():\n        \"\"\"Produce potential paths for an h2o.jar executable.\"\"\"\n\n        # PUBDEV-3534 hook to use arbitrary h2o.jar\n        own_jar = os.getenv(\"H2O_JAR_PATH\", \"\")\n        if own_jar != \"\":\n            if not os.path.isfile(own_jar):\n                raise H2OStartupError(\"Environment variable H2O_JAR_PATH is set to '%d' but file does not exists, unset environment variable or provide valid path to h2o.jar file.\" % own_jar)\n            yield own_jar\n\n        # Check if running from an h2o-3 src folder (or any subfolder), in which case use the freshly-built h2o.jar\n        cwd_chunks = os.path.abspath(\".\").split(os.path.sep)\n        for i in range(len(cwd_chunks), 0, -1):\n            if cwd_chunks[i - 1] == \"h2o-3\":\n                yield os.path.sep.join(cwd_chunks[:i] + [\"build\", \"h2o.jar\"])\n        # Then check the backend/bin folder:\n        # (the following works assuming this code is located in h2o/backend/server.py file)\n        backend_dir = os.path.split(os.path.realpath(__file__))[0]\n        yield os.path.join(backend_dir, \"bin\", \"h2o.jar\")\n\n        # Then try several old locations where h2o.jar might have been installed\n        prefix1 = prefix2 = sys.prefix\n        # On Unix-like systems Python typically gets installed into /Library/... or /System/Library/... If one of\n        # those paths is sys.prefix, then we also build its counterpart.\n        if prefix1.startswith(os.path.sep + \"Library\"):\n            prefix2 = os.path.join(\"\", \"System\", prefix1)\n        elif prefix1.startswith(os.path.sep + \"System\"):\n            prefix2 = prefix1[len(os.path.join(\"\", \"System\")):]\n        yield os.path.join(prefix1, \"h2o_jar\", \"h2o.jar\")\n        yield os.path.join(os.path.abspath(os.sep), \"usr\", \"local\", \"h2o_jar\", \"h2o.jar\")\n        yield os.path.join(prefix1, \"local\", \"h2o_jar\", \"h2o.jar\")\n        yield os.path.join(get_config_var(\"userbase\"), \"h2o_jar\", \"h2o.jar\")\n        yield os.path.join(prefix2, \"h2o_jar\", \"h2o.jar\")", "code_tokens": ["def", "_jar_paths", "(", ")", ":", "# PUBDEV-3534 hook to use arbitrary h2o.jar", "own_jar", "=", "os", ".", "getenv", "(", "\"H2O_JAR_PATH\"", ",", "\"\"", ")", "if", "own_jar", "!=", "\"\"", ":", "if", "not", "os", ".", "path", ".", "isfile", "(", "own_jar", ")", ":", "raise", "H2OStartupError", "(", "\"Environment variable H2O_JAR_PATH is set to '%d' but file does not exists, unset environment variable or provide valid path to h2o.jar file.\"", "%", "own_jar", ")", "yield", "own_jar", "# Check if running from an h2o-3 src folder (or any subfolder), in which case use the freshly-built h2o.jar", "cwd_chunks", "=", "os", ".", "path", ".", "abspath", "(", "\".\"", ")", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "for", "i", "in", "range", "(", "len", "(", "cwd_chunks", ")", ",", "0", ",", "-", "1", ")", ":", "if", "cwd_chunks", "[", "i", "-", "1", "]", "==", "\"h2o-3\"", ":", "yield", "os", ".", "path", ".", "sep", ".", "join", "(", "cwd_chunks", "[", ":", "i", "]", "+", "[", "\"build\"", ",", "\"h2o.jar\"", "]", ")", "# Then check the backend/bin folder:", "# (the following works assuming this code is located in h2o/backend/server.py file)", "backend_dir", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "[", "0", "]", "yield", "os", ".", "path", ".", "join", "(", "backend_dir", ",", "\"bin\"", ",", "\"h2o.jar\"", ")", "# Then try several old locations where h2o.jar might have been installed", "prefix1", "=", "prefix2", "=", "sys", ".", "prefix", "# On Unix-like systems Python typically gets installed into /Library/... or /System/Library/... If one of", "# those paths is sys.prefix, then we also build its counterpart.", "if", "prefix1", ".", "startswith", "(", "os", ".", "path", ".", "sep", "+", "\"Library\"", ")", ":", "prefix2", "=", "os", ".", "path", ".", "join", "(", "\"\"", ",", "\"System\"", ",", "prefix1", ")", "elif", "prefix1", ".", "startswith", "(", "os", ".", "path", ".", "sep", "+", "\"System\"", ")", ":", "prefix2", "=", "prefix1", "[", "len", "(", "os", ".", "path", ".", "join", "(", "\"\"", ",", "\"System\"", ")", ")", ":", "]", "yield", "os", ".", "path", ".", "join", "(", "prefix1", ",", "\"h2o_jar\"", ",", "\"h2o.jar\"", ")", "yield", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "os", ".", "sep", ")", ",", "\"usr\"", ",", "\"local\"", ",", "\"h2o_jar\"", ",", "\"h2o.jar\"", ")", "yield", "os", ".", "path", ".", "join", "(", "prefix1", ",", "\"local\"", ",", "\"h2o_jar\"", ",", "\"h2o.jar\"", ")", "yield", "os", ".", "path", ".", "join", "(", "get_config_var", "(", "\"userbase\"", ")", ",", "\"h2o_jar\"", ",", "\"h2o.jar\"", ")", "yield", "os", ".", "path", ".", "join", "(", "prefix2", ",", "\"h2o_jar\"", ",", "\"h2o.jar\"", ")"], "docstring": "Produce potential paths for an h2o.jar executable.", "docstring_tokens": ["Produce", "potential", "paths", "for", "an", "h2o", ".", "jar", "executable", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/server.py#L231-L263", "partition": "test", "index": 1554, "time": "2016-07-21 23:55:36"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/typechecks.py", "func_name": "assert_is_type", "original_string": "def assert_is_type(var, *types, **kwargs):\n    \"\"\"\n    Assert that the argument has the specified type.\n\n    This function is used to check that the type of the argument is correct, otherwises it raises an H2OTypeError.\n    See more details in the module's help.\n\n    :param var: variable to check\n    :param types: the expected types\n    :param kwargs:\n        message: override the error message\n        skip_frames: how many local frames to skip when printing out the error.\n\n    :raises H2OTypeError: if the argument is not of the desired type.\n    \"\"\"\n    assert types, \"The list of expected types was not provided\"\n    expected_type = types[0] if len(types) == 1 else U(*types)\n    if _check_type(var, expected_type): return\n\n    # Type check failed => Create a nice error message\n    assert set(kwargs).issubset({\"message\", \"skip_frames\"}), \"Unexpected keyword arguments: %r\" % kwargs\n    message = kwargs.get(\"message\", None)\n    skip_frames = kwargs.get(\"skip_frames\", 1)\n    args = _retrieve_assert_arguments()\n    vname = args[0]\n    etn = _get_type_name(expected_type, dump=\", \".join(args[1:]))\n    vtn = _get_type_name(type(var))\n    raise H2OTypeError(var_name=vname, var_value=var, var_type_name=vtn, exp_type_name=etn, message=message,\n                       skip_frames=skip_frames)", "language": "python", "code": "def assert_is_type(var, *types, **kwargs):\n    \"\"\"\n    Assert that the argument has the specified type.\n\n    This function is used to check that the type of the argument is correct, otherwises it raises an H2OTypeError.\n    See more details in the module's help.\n\n    :param var: variable to check\n    :param types: the expected types\n    :param kwargs:\n        message: override the error message\n        skip_frames: how many local frames to skip when printing out the error.\n\n    :raises H2OTypeError: if the argument is not of the desired type.\n    \"\"\"\n    assert types, \"The list of expected types was not provided\"\n    expected_type = types[0] if len(types) == 1 else U(*types)\n    if _check_type(var, expected_type): return\n\n    # Type check failed => Create a nice error message\n    assert set(kwargs).issubset({\"message\", \"skip_frames\"}), \"Unexpected keyword arguments: %r\" % kwargs\n    message = kwargs.get(\"message\", None)\n    skip_frames = kwargs.get(\"skip_frames\", 1)\n    args = _retrieve_assert_arguments()\n    vname = args[0]\n    etn = _get_type_name(expected_type, dump=\", \".join(args[1:]))\n    vtn = _get_type_name(type(var))\n    raise H2OTypeError(var_name=vname, var_value=var, var_type_name=vtn, exp_type_name=etn, message=message,\n                       skip_frames=skip_frames)", "code_tokens": ["def", "assert_is_type", "(", "var", ",", "*", "types", ",", "*", "*", "kwargs", ")", ":", "assert", "types", ",", "\"The list of expected types was not provided\"", "expected_type", "=", "types", "[", "0", "]", "if", "len", "(", "types", ")", "==", "1", "else", "U", "(", "*", "types", ")", "if", "_check_type", "(", "var", ",", "expected_type", ")", ":", "return", "# Type check failed => Create a nice error message", "assert", "set", "(", "kwargs", ")", ".", "issubset", "(", "{", "\"message\"", ",", "\"skip_frames\"", "}", ")", ",", "\"Unexpected keyword arguments: %r\"", "%", "kwargs", "message", "=", "kwargs", ".", "get", "(", "\"message\"", ",", "None", ")", "skip_frames", "=", "kwargs", ".", "get", "(", "\"skip_frames\"", ",", "1", ")", "args", "=", "_retrieve_assert_arguments", "(", ")", "vname", "=", "args", "[", "0", "]", "etn", "=", "_get_type_name", "(", "expected_type", ",", "dump", "=", "\", \"", ".", "join", "(", "args", "[", "1", ":", "]", ")", ")", "vtn", "=", "_get_type_name", "(", "type", "(", "var", ")", ")", "raise", "H2OTypeError", "(", "var_name", "=", "vname", ",", "var_value", "=", "var", ",", "var_type_name", "=", "vtn", ",", "exp_type_name", "=", "etn", ",", "message", "=", "message", ",", "skip_frames", "=", "skip_frames", ")"], "docstring": "Assert that the argument has the specified type.\n\n    This function is used to check that the type of the argument is correct, otherwises it raises an H2OTypeError.\n    See more details in the module's help.\n\n    :param var: variable to check\n    :param types: the expected types\n    :param kwargs:\n        message: override the error message\n        skip_frames: how many local frames to skip when printing out the error.\n\n    :raises H2OTypeError: if the argument is not of the desired type.", "docstring_tokens": ["Assert", "that", "the", "argument", "has", "the", "specified", "type", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/typechecks.py#L429-L457", "partition": "test", "index": 1364, "time": "2016-07-22 14:34:50"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/typechecks.py", "func_name": "_retrieve_assert_arguments", "original_string": "def _retrieve_assert_arguments():\n    \"\"\"\n    Magic variable name retrieval.\n\n    This function is designed as a helper for assert_is_type() function. Typically such assertion is used like this::\n\n        assert_is_type(num_threads, int)\n\n    If the variable `num_threads` turns out to be non-integer, we would like to raise an exception such as\n\n        H2OTypeError(\"`num_threads` is expected to be integer, but got <str>\")\n\n    and in order to compose an error message like that, we need to know that the variables that was passed to\n    assert_is_type() carries a name \"num_threads\". Naturally, the variable itself knows nothing about that.\n\n    This is where this function comes in: we walk up the stack trace until the first frame outside of this\n    file, find the original line that called the assert_is_type() function, and extract the variable name from\n    that line. This is slightly fragile, in particular we assume that only one assert_is_type statement can be per line,\n    or that this statement does not spill over multiple lines, etc.\n    \"\"\"\n    try:\n        raise RuntimeError(\"Catch me!\")\n    except RuntimeError:\n        # Walk up the stacktrace until we are outside of this file\n        tb = sys.exc_info()[2]\n        assert tb.tb_frame.f_code.co_name == \"_retrieve_assert_arguments\"\n        this_filename = tb.tb_frame.f_code.co_filename\n        fr = tb.tb_frame\n        while fr is not None and fr.f_code.co_filename == this_filename:\n            fr = fr.f_back\n\n        # Read the source file and tokenize it, extracting the expressions.\n        try:\n            with io.open(fr.f_code.co_filename, \"r\", encoding=\"utf-8\") as f:\n                # Skip initial lines that are irrelevant\n                for i in range(fr.f_lineno - 1): next(f)\n                # Create tokenizer\n                g = tokenize.generate_tokens(f.readline)\n                step = 0\n                args_tokens = []\n                level = 0\n                for ttt in g:\n                    if step == 0:\n                        if ttt[0] != tokenize.NAME: continue\n                        if not ttt[1].startswith(\"assert_\"): continue\n                        step = 1\n                    elif step == 1:\n                        assert ttt[0] == tokenize.OP and ttt[1] == \"(\"\n                        args_tokens.append([])\n                        step = 2\n                    elif step == 2:\n                        if level == 0 and ttt[0] == tokenize.OP and ttt[1] == \",\":\n                            args_tokens.append([])\n                        elif level == 0 and ttt[0] == tokenize.OP and ttt[1] == \")\":\n                            break\n                        else:\n                            if ttt[0] == tokenize.OP and ttt[1] in \"([{\": level += 1\n                            if ttt[0] == tokenize.OP and ttt[1] in \")]}\": level -= 1\n                            assert level >= 0, \"Parse error: parentheses level became negative\"\n                            args_tokens[-1].append(ttt)\n                args = [tokenize.untokenize(at).strip().replace(\"\\n\", \" \") for at in args_tokens]\n                return args\n        except IOError:\n            return \"arg\",", "language": "python", "code": "def _retrieve_assert_arguments():\n    \"\"\"\n    Magic variable name retrieval.\n\n    This function is designed as a helper for assert_is_type() function. Typically such assertion is used like this::\n\n        assert_is_type(num_threads, int)\n\n    If the variable `num_threads` turns out to be non-integer, we would like to raise an exception such as\n\n        H2OTypeError(\"`num_threads` is expected to be integer, but got <str>\")\n\n    and in order to compose an error message like that, we need to know that the variables that was passed to\n    assert_is_type() carries a name \"num_threads\". Naturally, the variable itself knows nothing about that.\n\n    This is where this function comes in: we walk up the stack trace until the first frame outside of this\n    file, find the original line that called the assert_is_type() function, and extract the variable name from\n    that line. This is slightly fragile, in particular we assume that only one assert_is_type statement can be per line,\n    or that this statement does not spill over multiple lines, etc.\n    \"\"\"\n    try:\n        raise RuntimeError(\"Catch me!\")\n    except RuntimeError:\n        # Walk up the stacktrace until we are outside of this file\n        tb = sys.exc_info()[2]\n        assert tb.tb_frame.f_code.co_name == \"_retrieve_assert_arguments\"\n        this_filename = tb.tb_frame.f_code.co_filename\n        fr = tb.tb_frame\n        while fr is not None and fr.f_code.co_filename == this_filename:\n            fr = fr.f_back\n\n        # Read the source file and tokenize it, extracting the expressions.\n        try:\n            with io.open(fr.f_code.co_filename, \"r\", encoding=\"utf-8\") as f:\n                # Skip initial lines that are irrelevant\n                for i in range(fr.f_lineno - 1): next(f)\n                # Create tokenizer\n                g = tokenize.generate_tokens(f.readline)\n                step = 0\n                args_tokens = []\n                level = 0\n                for ttt in g:\n                    if step == 0:\n                        if ttt[0] != tokenize.NAME: continue\n                        if not ttt[1].startswith(\"assert_\"): continue\n                        step = 1\n                    elif step == 1:\n                        assert ttt[0] == tokenize.OP and ttt[1] == \"(\"\n                        args_tokens.append([])\n                        step = 2\n                    elif step == 2:\n                        if level == 0 and ttt[0] == tokenize.OP and ttt[1] == \",\":\n                            args_tokens.append([])\n                        elif level == 0 and ttt[0] == tokenize.OP and ttt[1] == \")\":\n                            break\n                        else:\n                            if ttt[0] == tokenize.OP and ttt[1] in \"([{\": level += 1\n                            if ttt[0] == tokenize.OP and ttt[1] in \")]}\": level -= 1\n                            assert level >= 0, \"Parse error: parentheses level became negative\"\n                            args_tokens[-1].append(ttt)\n                args = [tokenize.untokenize(at).strip().replace(\"\\n\", \" \") for at in args_tokens]\n                return args\n        except IOError:\n            return \"arg\",", "code_tokens": ["def", "_retrieve_assert_arguments", "(", ")", ":", "try", ":", "raise", "RuntimeError", "(", "\"Catch me!\"", ")", "except", "RuntimeError", ":", "# Walk up the stacktrace until we are outside of this file", "tb", "=", "sys", ".", "exc_info", "(", ")", "[", "2", "]", "assert", "tb", ".", "tb_frame", ".", "f_code", ".", "co_name", "==", "\"_retrieve_assert_arguments\"", "this_filename", "=", "tb", ".", "tb_frame", ".", "f_code", ".", "co_filename", "fr", "=", "tb", ".", "tb_frame", "while", "fr", "is", "not", "None", "and", "fr", ".", "f_code", ".", "co_filename", "==", "this_filename", ":", "fr", "=", "fr", ".", "f_back", "# Read the source file and tokenize it, extracting the expressions.", "try", ":", "with", "io", ".", "open", "(", "fr", ".", "f_code", ".", "co_filename", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "# Skip initial lines that are irrelevant", "for", "i", "in", "range", "(", "fr", ".", "f_lineno", "-", "1", ")", ":", "next", "(", "f", ")", "# Create tokenizer", "g", "=", "tokenize", ".", "generate_tokens", "(", "f", ".", "readline", ")", "step", "=", "0", "args_tokens", "=", "[", "]", "level", "=", "0", "for", "ttt", "in", "g", ":", "if", "step", "==", "0", ":", "if", "ttt", "[", "0", "]", "!=", "tokenize", ".", "NAME", ":", "continue", "if", "not", "ttt", "[", "1", "]", ".", "startswith", "(", "\"assert_\"", ")", ":", "continue", "step", "=", "1", "elif", "step", "==", "1", ":", "assert", "ttt", "[", "0", "]", "==", "tokenize", ".", "OP", "and", "ttt", "[", "1", "]", "==", "\"(\"", "args_tokens", ".", "append", "(", "[", "]", ")", "step", "=", "2", "elif", "step", "==", "2", ":", "if", "level", "==", "0", "and", "ttt", "[", "0", "]", "==", "tokenize", ".", "OP", "and", "ttt", "[", "1", "]", "==", "\",\"", ":", "args_tokens", ".", "append", "(", "[", "]", ")", "elif", "level", "==", "0", "and", "ttt", "[", "0", "]", "==", "tokenize", ".", "OP", "and", "ttt", "[", "1", "]", "==", "\")\"", ":", "break", "else", ":", "if", "ttt", "[", "0", "]", "==", "tokenize", ".", "OP", "and", "ttt", "[", "1", "]", "in", "\"([{\"", ":", "level", "+=", "1", "if", "ttt", "[", "0", "]", "==", "tokenize", ".", "OP", "and", "ttt", "[", "1", "]", "in", "\")]}\"", ":", "level", "-=", "1", "assert", "level", ">=", "0", ",", "\"Parse error: parentheses level became negative\"", "args_tokens", "[", "-", "1", "]", ".", "append", "(", "ttt", ")", "args", "=", "[", "tokenize", ".", "untokenize", "(", "at", ")", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "for", "at", "in", "args_tokens", "]", "return", "args", "except", "IOError", ":", "return", "\"arg\"", ","], "docstring": "Magic variable name retrieval.\n\n    This function is designed as a helper for assert_is_type() function. Typically such assertion is used like this::\n\n        assert_is_type(num_threads, int)\n\n    If the variable `num_threads` turns out to be non-integer, we would like to raise an exception such as\n\n        H2OTypeError(\"`num_threads` is expected to be integer, but got <str>\")\n\n    and in order to compose an error message like that, we need to know that the variables that was passed to\n    assert_is_type() carries a name \"num_threads\". Naturally, the variable itself knows nothing about that.\n\n    This is where this function comes in: we walk up the stack trace until the first frame outside of this\n    file, find the original line that called the assert_is_type() function, and extract the variable name from\n    that line. This is slightly fragile, in particular we assume that only one assert_is_type statement can be per line,\n    or that this statement does not spill over multiple lines, etc.", "docstring_tokens": ["Magic", "variable", "name", "retrieval", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/typechecks.py#L497-L560", "partition": "test", "index": 1367, "time": "2016-07-22 16:51:31"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/typechecks.py", "func_name": "_check_type", "original_string": "def _check_type(var, vtype):\n    \"\"\"\n    Return True if the variable is of the specified type, and False otherwise.\n\n    :param var: variable to check\n    :param vtype: expected variable's type\n    \"\"\"\n    if vtype is None:\n        return var is None\n    if isinstance(vtype, _primitive_type):\n        return var == vtype\n    if vtype is str:\n        return isinstance(var, _str_type)\n    if vtype is int:\n        return isinstance(var, _int_type)\n    if vtype is numeric:\n        return isinstance(var, _num_type)\n    if isinstance(vtype, MagicType):\n        return vtype.check(var)\n    if isinstance(vtype, type):\n        # ``vtype`` is a name of the class, or a built-in type such as \"list\", \"tuple\", etc\n        return isinstance(var, vtype)\n    if isinstance(vtype, list):\n        # ``vtype`` is a list literal\n        elem_type = U(*vtype)\n        return isinstance(var, list) and all(_check_type(item, elem_type) for item in var)\n    if isinstance(vtype, set):\n        # ``vtype`` is a set literal\n        elem_type = U(*vtype)\n        return isinstance(var, set) and all(_check_type(item, elem_type) for item in var)\n    if isinstance(vtype, tuple):\n        # ``vtype`` is a tuple literal\n        return (isinstance(var, tuple) and len(vtype) == len(var) and\n                all(_check_type(var[i], vtype[i]) for i in range(len(vtype))))\n    if isinstance(vtype, dict):\n        # ``vtype`` is a dict literal\n        ttkv = U(*viewitems(vtype))\n        return isinstance(var, dict) and all(_check_type(kv, ttkv) for kv in viewitems(var))\n    if isinstance(vtype, (FunctionType, BuiltinFunctionType)):\n        return vtype(var)\n    raise RuntimeError(\"Ivalid type %r in _check_type()\" % vtype)", "language": "python", "code": "def _check_type(var, vtype):\n    \"\"\"\n    Return True if the variable is of the specified type, and False otherwise.\n\n    :param var: variable to check\n    :param vtype: expected variable's type\n    \"\"\"\n    if vtype is None:\n        return var is None\n    if isinstance(vtype, _primitive_type):\n        return var == vtype\n    if vtype is str:\n        return isinstance(var, _str_type)\n    if vtype is int:\n        return isinstance(var, _int_type)\n    if vtype is numeric:\n        return isinstance(var, _num_type)\n    if isinstance(vtype, MagicType):\n        return vtype.check(var)\n    if isinstance(vtype, type):\n        # ``vtype`` is a name of the class, or a built-in type such as \"list\", \"tuple\", etc\n        return isinstance(var, vtype)\n    if isinstance(vtype, list):\n        # ``vtype`` is a list literal\n        elem_type = U(*vtype)\n        return isinstance(var, list) and all(_check_type(item, elem_type) for item in var)\n    if isinstance(vtype, set):\n        # ``vtype`` is a set literal\n        elem_type = U(*vtype)\n        return isinstance(var, set) and all(_check_type(item, elem_type) for item in var)\n    if isinstance(vtype, tuple):\n        # ``vtype`` is a tuple literal\n        return (isinstance(var, tuple) and len(vtype) == len(var) and\n                all(_check_type(var[i], vtype[i]) for i in range(len(vtype))))\n    if isinstance(vtype, dict):\n        # ``vtype`` is a dict literal\n        ttkv = U(*viewitems(vtype))\n        return isinstance(var, dict) and all(_check_type(kv, ttkv) for kv in viewitems(var))\n    if isinstance(vtype, (FunctionType, BuiltinFunctionType)):\n        return vtype(var)\n    raise RuntimeError(\"Ivalid type %r in _check_type()\" % vtype)", "code_tokens": ["def", "_check_type", "(", "var", ",", "vtype", ")", ":", "if", "vtype", "is", "None", ":", "return", "var", "is", "None", "if", "isinstance", "(", "vtype", ",", "_primitive_type", ")", ":", "return", "var", "==", "vtype", "if", "vtype", "is", "str", ":", "return", "isinstance", "(", "var", ",", "_str_type", ")", "if", "vtype", "is", "int", ":", "return", "isinstance", "(", "var", ",", "_int_type", ")", "if", "vtype", "is", "numeric", ":", "return", "isinstance", "(", "var", ",", "_num_type", ")", "if", "isinstance", "(", "vtype", ",", "MagicType", ")", ":", "return", "vtype", ".", "check", "(", "var", ")", "if", "isinstance", "(", "vtype", ",", "type", ")", ":", "# ``vtype`` is a name of the class, or a built-in type such as \"list\", \"tuple\", etc", "return", "isinstance", "(", "var", ",", "vtype", ")", "if", "isinstance", "(", "vtype", ",", "list", ")", ":", "# ``vtype`` is a list literal", "elem_type", "=", "U", "(", "*", "vtype", ")", "return", "isinstance", "(", "var", ",", "list", ")", "and", "all", "(", "_check_type", "(", "item", ",", "elem_type", ")", "for", "item", "in", "var", ")", "if", "isinstance", "(", "vtype", ",", "set", ")", ":", "# ``vtype`` is a set literal", "elem_type", "=", "U", "(", "*", "vtype", ")", "return", "isinstance", "(", "var", ",", "set", ")", "and", "all", "(", "_check_type", "(", "item", ",", "elem_type", ")", "for", "item", "in", "var", ")", "if", "isinstance", "(", "vtype", ",", "tuple", ")", ":", "# ``vtype`` is a tuple literal", "return", "(", "isinstance", "(", "var", ",", "tuple", ")", "and", "len", "(", "vtype", ")", "==", "len", "(", "var", ")", "and", "all", "(", "_check_type", "(", "var", "[", "i", "]", ",", "vtype", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "vtype", ")", ")", ")", ")", "if", "isinstance", "(", "vtype", ",", "dict", ")", ":", "# ``vtype`` is a dict literal", "ttkv", "=", "U", "(", "*", "viewitems", "(", "vtype", ")", ")", "return", "isinstance", "(", "var", ",", "dict", ")", "and", "all", "(", "_check_type", "(", "kv", ",", "ttkv", ")", "for", "kv", "in", "viewitems", "(", "var", ")", ")", "if", "isinstance", "(", "vtype", ",", "(", "FunctionType", ",", "BuiltinFunctionType", ")", ")", ":", "return", "vtype", "(", "var", ")", "raise", "RuntimeError", "(", "\"Ivalid type %r in _check_type()\"", "%", "vtype", ")"], "docstring": "Return True if the variable is of the specified type, and False otherwise.\n\n    :param var: variable to check\n    :param vtype: expected variable's type", "docstring_tokens": ["Return", "True", "if", "the", "variable", "is", "of", "the", "specified", "type", "and", "False", "otherwise", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/typechecks.py#L563-L603", "partition": "test", "index": 1368, "time": "2016-07-22 16:51:31"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "make_metrics", "original_string": "def make_metrics(predicted, actual, domain=None, distribution=None):\n    \"\"\"\n    Create Model Metrics from predicted and actual values in H2O.\n\n    :param H2OFrame predicted: an H2OFrame containing predictions.\n    :param H2OFrame actuals: an H2OFrame containing actual values.\n    :param domain: list of response factors for classification.\n    :param distribution: distribution for regression.\n    \"\"\"\n    assert_is_type(predicted, H2OFrame)\n    assert_is_type(actual, H2OFrame)\n    # assert predicted.ncol == 1, \"`predicted` frame should have exactly 1 column\"\n    assert actual.ncol == 1, \"`actual` frame should have exactly 1 column\"\n    assert_is_type(distribution, str, None)\n    assert_satisfies(actual.ncol, actual.ncol == 1)\n    if domain is None and any(actual.isfactor()):\n        domain = actual.levels()[0]\n    res = api(\"POST /3/ModelMetrics/predictions_frame/%s/actuals_frame/%s\" % (predicted.frame_id, actual.frame_id),\n              data={\"domain\": domain, \"distribution\": distribution})\n    return res[\"model_metrics\"]", "language": "python", "code": "def make_metrics(predicted, actual, domain=None, distribution=None):\n    \"\"\"\n    Create Model Metrics from predicted and actual values in H2O.\n\n    :param H2OFrame predicted: an H2OFrame containing predictions.\n    :param H2OFrame actuals: an H2OFrame containing actual values.\n    :param domain: list of response factors for classification.\n    :param distribution: distribution for regression.\n    \"\"\"\n    assert_is_type(predicted, H2OFrame)\n    assert_is_type(actual, H2OFrame)\n    # assert predicted.ncol == 1, \"`predicted` frame should have exactly 1 column\"\n    assert actual.ncol == 1, \"`actual` frame should have exactly 1 column\"\n    assert_is_type(distribution, str, None)\n    assert_satisfies(actual.ncol, actual.ncol == 1)\n    if domain is None and any(actual.isfactor()):\n        domain = actual.levels()[0]\n    res = api(\"POST /3/ModelMetrics/predictions_frame/%s/actuals_frame/%s\" % (predicted.frame_id, actual.frame_id),\n              data={\"domain\": domain, \"distribution\": distribution})\n    return res[\"model_metrics\"]", "code_tokens": ["def", "make_metrics", "(", "predicted", ",", "actual", ",", "domain", "=", "None", ",", "distribution", "=", "None", ")", ":", "assert_is_type", "(", "predicted", ",", "H2OFrame", ")", "assert_is_type", "(", "actual", ",", "H2OFrame", ")", "# assert predicted.ncol == 1, \"`predicted` frame should have exactly 1 column\"", "assert", "actual", ".", "ncol", "==", "1", ",", "\"`actual` frame should have exactly 1 column\"", "assert_is_type", "(", "distribution", ",", "str", ",", "None", ")", "assert_satisfies", "(", "actual", ".", "ncol", ",", "actual", ".", "ncol", "==", "1", ")", "if", "domain", "is", "None", "and", "any", "(", "actual", ".", "isfactor", "(", ")", ")", ":", "domain", "=", "actual", ".", "levels", "(", ")", "[", "0", "]", "res", "=", "api", "(", "\"POST /3/ModelMetrics/predictions_frame/%s/actuals_frame/%s\"", "%", "(", "predicted", ".", "frame_id", ",", "actual", ".", "frame_id", ")", ",", "data", "=", "{", "\"domain\"", ":", "domain", ",", "\"distribution\"", ":", "distribution", "}", ")", "return", "res", "[", "\"model_metrics\"", "]"], "docstring": "Create Model Metrics from predicted and actual values in H2O.\n\n    :param H2OFrame predicted: an H2OFrame containing predictions.\n    :param H2OFrame actuals: an H2OFrame containing actual values.\n    :param domain: list of response factors for classification.\n    :param distribution: distribution for regression.", "docstring_tokens": ["Create", "Model", "Metrics", "from", "predicted", "and", "actual", "values", "in", "H2O", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L1358-L1377", "partition": "test", "index": 1473, "time": "2016-07-26 18:53:55"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/connection.py", "func_name": "H2OConnection._print", "original_string": "def _print(self, msg, flush=False, end=\"\\n\"):\n        \"\"\"Helper function to print connection status messages when in verbose mode.\"\"\"\n        if self._verbose:\n            print2(msg, end=end, flush=flush)", "language": "python", "code": "def _print(self, msg, flush=False, end=\"\\n\"):\n        \"\"\"Helper function to print connection status messages when in verbose mode.\"\"\"\n        if self._verbose:\n            print2(msg, end=end, flush=flush)", "code_tokens": ["def", "_print", "(", "self", ",", "msg", ",", "flush", "=", "False", ",", "end", "=", "\"\\n\"", ")", ":", "if", "self", ".", "_verbose", ":", "print2", "(", "msg", ",", "end", "=", "end", ",", "flush", "=", "flush", ")"], "docstring": "Helper function to print connection status messages when in verbose mode.", "docstring_tokens": ["Helper", "function", "to", "print", "connection", "status", "messages", "when", "in", "verbose", "mode", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L758-L761", "partition": "test", "index": 1507, "time": "2016-07-27 12:58:54"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/debugging.py", "func_name": "_get_method_full_name", "original_string": "def _get_method_full_name(func):\n    \"\"\"\n    Return fully qualified function name.\n\n    This method will attempt to find \"full name\" of the given function object. This full name is either of\n    the form \"<class name>.<method name>\" if the function is a class method, or \"<module name>.<func name>\"\n    if it's a regular function. Thus, this is an attempt to back-port func.__qualname__ to Python 2.\n\n    :param func: a function object.\n\n    :returns: string with the function's full name as explained above.\n    \"\"\"\n    # Python 3.3 already has this information available...\n    if hasattr(func, \"__qualname__\"): return func.__qualname__\n\n    module = inspect.getmodule(func)\n    if module is None:\n        return \"?.%s\" % getattr(func, \"__name__\", \"?\")\n    for cls_name in dir(module):\n        cls = getattr(module, cls_name)\n        if not inspect.isclass(cls): continue\n        for method_name in dir(cls):\n            cls_method = getattr(cls, method_name)\n            if cls_method == func:\n                return \"%s.%s\" % (cls_name, method_name)\n    if hasattr(func, \"__name__\"):\n        return \"%s.%s\" % (module.__name__, func.__name__)\n    return \"<unknown>\"", "language": "python", "code": "def _get_method_full_name(func):\n    \"\"\"\n    Return fully qualified function name.\n\n    This method will attempt to find \"full name\" of the given function object. This full name is either of\n    the form \"<class name>.<method name>\" if the function is a class method, or \"<module name>.<func name>\"\n    if it's a regular function. Thus, this is an attempt to back-port func.__qualname__ to Python 2.\n\n    :param func: a function object.\n\n    :returns: string with the function's full name as explained above.\n    \"\"\"\n    # Python 3.3 already has this information available...\n    if hasattr(func, \"__qualname__\"): return func.__qualname__\n\n    module = inspect.getmodule(func)\n    if module is None:\n        return \"?.%s\" % getattr(func, \"__name__\", \"?\")\n    for cls_name in dir(module):\n        cls = getattr(module, cls_name)\n        if not inspect.isclass(cls): continue\n        for method_name in dir(cls):\n            cls_method = getattr(cls, method_name)\n            if cls_method == func:\n                return \"%s.%s\" % (cls_name, method_name)\n    if hasattr(func, \"__name__\"):\n        return \"%s.%s\" % (module.__name__, func.__name__)\n    return \"<unknown>\"", "code_tokens": ["def", "_get_method_full_name", "(", "func", ")", ":", "# Python 3.3 already has this information available...", "if", "hasattr", "(", "func", ",", "\"__qualname__\"", ")", ":", "return", "func", ".", "__qualname__", "module", "=", "inspect", ".", "getmodule", "(", "func", ")", "if", "module", "is", "None", ":", "return", "\"?.%s\"", "%", "getattr", "(", "func", ",", "\"__name__\"", ",", "\"?\"", ")", "for", "cls_name", "in", "dir", "(", "module", ")", ":", "cls", "=", "getattr", "(", "module", ",", "cls_name", ")", "if", "not", "inspect", ".", "isclass", "(", "cls", ")", ":", "continue", "for", "method_name", "in", "dir", "(", "cls", ")", ":", "cls_method", "=", "getattr", "(", "cls", ",", "method_name", ")", "if", "cls_method", "==", "func", ":", "return", "\"%s.%s\"", "%", "(", "cls_name", ",", "method_name", ")", "if", "hasattr", "(", "func", ",", "\"__name__\"", ")", ":", "return", "\"%s.%s\"", "%", "(", "module", ".", "__name__", ",", "func", ".", "__name__", ")", "return", "\"<unknown>\""], "docstring": "Return fully qualified function name.\n\n    This method will attempt to find \"full name\" of the given function object. This full name is either of\n    the form \"<class name>.<method name>\" if the function is a class method, or \"<module name>.<func name>\"\n    if it's a regular function. Thus, this is an attempt to back-port func.__qualname__ to Python 2.\n\n    :param func: a function object.\n\n    :returns: string with the function's full name as explained above.", "docstring_tokens": ["Return", "fully", "qualified", "function", "name", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/debugging.py#L238-L265", "partition": "test", "index": 1341, "time": "2016-07-27 15:55:11"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/debugging.py", "func_name": "_wrap", "original_string": "def _wrap(text, wrap_at=120, indent=4):\n    \"\"\"\n    Return piece of text, wrapped around if needed.\n\n    :param text: text that may be too long and then needs to be wrapped.\n    :param wrap_at: the maximum line length.\n    :param indent: number of spaces to prepend to all subsequent lines after the first.\n    \"\"\"\n    out = \"\"\n    curr_line_length = indent\n    space_needed = False\n    for word in text.split():\n        if curr_line_length + len(word) > wrap_at:\n            out += \"\\n\" + \" \" * indent\n            curr_line_length = indent\n            space_needed = False\n        if space_needed:\n            out += \" \"\n            curr_line_length += 1\n        out += word\n        curr_line_length += len(word)\n        space_needed = True\n    return out", "language": "python", "code": "def _wrap(text, wrap_at=120, indent=4):\n    \"\"\"\n    Return piece of text, wrapped around if needed.\n\n    :param text: text that may be too long and then needs to be wrapped.\n    :param wrap_at: the maximum line length.\n    :param indent: number of spaces to prepend to all subsequent lines after the first.\n    \"\"\"\n    out = \"\"\n    curr_line_length = indent\n    space_needed = False\n    for word in text.split():\n        if curr_line_length + len(word) > wrap_at:\n            out += \"\\n\" + \" \" * indent\n            curr_line_length = indent\n            space_needed = False\n        if space_needed:\n            out += \" \"\n            curr_line_length += 1\n        out += word\n        curr_line_length += len(word)\n        space_needed = True\n    return out", "code_tokens": ["def", "_wrap", "(", "text", ",", "wrap_at", "=", "120", ",", "indent", "=", "4", ")", ":", "out", "=", "\"\"", "curr_line_length", "=", "indent", "space_needed", "=", "False", "for", "word", "in", "text", ".", "split", "(", ")", ":", "if", "curr_line_length", "+", "len", "(", "word", ")", ">", "wrap_at", ":", "out", "+=", "\"\\n\"", "+", "\" \"", "*", "indent", "curr_line_length", "=", "indent", "space_needed", "=", "False", "if", "space_needed", ":", "out", "+=", "\" \"", "curr_line_length", "+=", "1", "out", "+=", "word", "curr_line_length", "+=", "len", "(", "word", ")", "space_needed", "=", "True", "return", "out"], "docstring": "Return piece of text, wrapped around if needed.\n\n    :param text: text that may be too long and then needs to be wrapped.\n    :param wrap_at: the maximum line length.\n    :param indent: number of spaces to prepend to all subsequent lines after the first.", "docstring_tokens": ["Return", "piece", "of", "text", "wrapped", "around", "if", "needed", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/debugging.py#L322-L344", "partition": "test", "index": 1344, "time": "2016-07-28 10:05:18"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/debugging.py", "func_name": "_get_args_str", "original_string": "def _get_args_str(func, highlight=None):\n    \"\"\"\n    Return function's declared arguments as a string.\n\n    For example for this function it returns \"func, highlight=None\"; for the ``_wrap`` function it returns\n    \"text, wrap_at=120, indent=4\". This should usually coincide with the function's declaration (the part\n    which is inside the parentheses).\n    \"\"\"\n    if not func: return \"\"\n    s = str(inspect.signature(func))[1:-1]\n    if highlight:\n        s = re.sub(r\"\\b%s\\b\" % highlight, Style.BRIGHT + Fore.WHITE + highlight + Fore.LIGHTBLACK_EX + Style.NORMAL, s)\n    return s", "language": "python", "code": "def _get_args_str(func, highlight=None):\n    \"\"\"\n    Return function's declared arguments as a string.\n\n    For example for this function it returns \"func, highlight=None\"; for the ``_wrap`` function it returns\n    \"text, wrap_at=120, indent=4\". This should usually coincide with the function's declaration (the part\n    which is inside the parentheses).\n    \"\"\"\n    if not func: return \"\"\n    s = str(inspect.signature(func))[1:-1]\n    if highlight:\n        s = re.sub(r\"\\b%s\\b\" % highlight, Style.BRIGHT + Fore.WHITE + highlight + Fore.LIGHTBLACK_EX + Style.NORMAL, s)\n    return s", "code_tokens": ["def", "_get_args_str", "(", "func", ",", "highlight", "=", "None", ")", ":", "if", "not", "func", ":", "return", "\"\"", "s", "=", "str", "(", "inspect", ".", "signature", "(", "func", ")", ")", "[", "1", ":", "-", "1", "]", "if", "highlight", ":", "s", "=", "re", ".", "sub", "(", "r\"\\b%s\\b\"", "%", "highlight", ",", "Style", ".", "BRIGHT", "+", "Fore", ".", "WHITE", "+", "highlight", "+", "Fore", ".", "LIGHTBLACK_EX", "+", "Style", ".", "NORMAL", ",", "s", ")", "return", "s"], "docstring": "Return function's declared arguments as a string.\n\n    For example for this function it returns \"func, highlight=None\"; for the ``_wrap`` function it returns\n    \"text, wrap_at=120, indent=4\". This should usually coincide with the function's declaration (the part\n    which is inside the parentheses).", "docstring_tokens": ["Return", "function", "s", "declared", "arguments", "as", "a", "string", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/debugging.py#L307-L319", "partition": "test", "index": 1343, "time": "2016-07-28 10:05:18"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/debugging.py", "func_name": "_find_function_from_code", "original_string": "def _find_function_from_code(frame, code):\n    \"\"\"\n    Given a frame and a compiled function code, find the corresponding function object within the frame.\n\n    This function addresses the following problem: when handling a stacktrace, we receive information about\n    which piece of code was being executed in the form of a CodeType object. That objects contains function name,\n    file name, line number, and the compiled bytecode. What it *doesn't* contain is the function object itself.\n\n    So this utility function aims at locating this function object, and it does so by searching through objects\n    in the preceding local frame (i.e. the frame where the function was called from). We expect that the function\n    should usually exist there -- either by itself, or as a method on one of the objects.\n\n    :param types.FrameType frame: local frame where the function ought to be found somewhere.\n    :param types.CodeType code: the compiled code of the function to look for.\n\n    :returns: the function object, or None if not found.\n    \"\"\"\n    def find_code(iterable, depth=0):\n        if depth > 3: return  # Avoid potential infinite loops, or generally objects that are too deep.\n        for item in iterable:\n            if item is None: continue\n            found = None\n            if hasattr(item, \"__code__\") and item.__code__ == code:\n                found = item\n            elif isinstance(item, type) or isinstance(item, ModuleType):  # class / module\n                try:\n                    found = find_code((getattr(item, n, None) for n in dir(item)), depth + 1)\n                except Exception:\n                    # Sometimes merely getting module's attributes may cause an exception. For example :mod:`six.moves`\n                    # is such an offender...\n                    continue\n            elif isinstance(item, (list, tuple, set)):\n                found = find_code(item, depth + 1)\n            elif isinstance(item, dict):\n                found = find_code(item.values(), depth + 1)\n            if found: return found\n    return find_code(frame.f_locals.values()) or find_code(frame.f_globals.values())", "language": "python", "code": "def _find_function_from_code(frame, code):\n    \"\"\"\n    Given a frame and a compiled function code, find the corresponding function object within the frame.\n\n    This function addresses the following problem: when handling a stacktrace, we receive information about\n    which piece of code was being executed in the form of a CodeType object. That objects contains function name,\n    file name, line number, and the compiled bytecode. What it *doesn't* contain is the function object itself.\n\n    So this utility function aims at locating this function object, and it does so by searching through objects\n    in the preceding local frame (i.e. the frame where the function was called from). We expect that the function\n    should usually exist there -- either by itself, or as a method on one of the objects.\n\n    :param types.FrameType frame: local frame where the function ought to be found somewhere.\n    :param types.CodeType code: the compiled code of the function to look for.\n\n    :returns: the function object, or None if not found.\n    \"\"\"\n    def find_code(iterable, depth=0):\n        if depth > 3: return  # Avoid potential infinite loops, or generally objects that are too deep.\n        for item in iterable:\n            if item is None: continue\n            found = None\n            if hasattr(item, \"__code__\") and item.__code__ == code:\n                found = item\n            elif isinstance(item, type) or isinstance(item, ModuleType):  # class / module\n                try:\n                    found = find_code((getattr(item, n, None) for n in dir(item)), depth + 1)\n                except Exception:\n                    # Sometimes merely getting module's attributes may cause an exception. For example :mod:`six.moves`\n                    # is such an offender...\n                    continue\n            elif isinstance(item, (list, tuple, set)):\n                found = find_code(item, depth + 1)\n            elif isinstance(item, dict):\n                found = find_code(item.values(), depth + 1)\n            if found: return found\n    return find_code(frame.f_locals.values()) or find_code(frame.f_globals.values())", "code_tokens": ["def", "_find_function_from_code", "(", "frame", ",", "code", ")", ":", "def", "find_code", "(", "iterable", ",", "depth", "=", "0", ")", ":", "if", "depth", ">", "3", ":", "return", "# Avoid potential infinite loops, or generally objects that are too deep.", "for", "item", "in", "iterable", ":", "if", "item", "is", "None", ":", "continue", "found", "=", "None", "if", "hasattr", "(", "item", ",", "\"__code__\"", ")", "and", "item", ".", "__code__", "==", "code", ":", "found", "=", "item", "elif", "isinstance", "(", "item", ",", "type", ")", "or", "isinstance", "(", "item", ",", "ModuleType", ")", ":", "# class / module", "try", ":", "found", "=", "find_code", "(", "(", "getattr", "(", "item", ",", "n", ",", "None", ")", "for", "n", "in", "dir", "(", "item", ")", ")", ",", "depth", "+", "1", ")", "except", "Exception", ":", "# Sometimes merely getting module's attributes may cause an exception. For example :mod:`six.moves`", "# is such an offender...", "continue", "elif", "isinstance", "(", "item", ",", "(", "list", ",", "tuple", ",", "set", ")", ")", ":", "found", "=", "find_code", "(", "item", ",", "depth", "+", "1", ")", "elif", "isinstance", "(", "item", ",", "dict", ")", ":", "found", "=", "find_code", "(", "item", ".", "values", "(", ")", ",", "depth", "+", "1", ")", "if", "found", ":", "return", "found", "return", "find_code", "(", "frame", ".", "f_locals", ".", "values", "(", ")", ")", "or", "find_code", "(", "frame", ".", "f_globals", ".", "values", "(", ")", ")"], "docstring": "Given a frame and a compiled function code, find the corresponding function object within the frame.\n\n    This function addresses the following problem: when handling a stacktrace, we receive information about\n    which piece of code was being executed in the form of a CodeType object. That objects contains function name,\n    file name, line number, and the compiled bytecode. What it *doesn't* contain is the function object itself.\n\n    So this utility function aims at locating this function object, and it does so by searching through objects\n    in the preceding local frame (i.e. the frame where the function was called from). We expect that the function\n    should usually exist there -- either by itself, or as a method on one of the objects.\n\n    :param types.FrameType frame: local frame where the function ought to be found somewhere.\n    :param types.CodeType code: the compiled code of the function to look for.\n\n    :returns: the function object, or None if not found.", "docstring_tokens": ["Given", "a", "frame", "and", "a", "compiled", "function", "code", "find", "the", "corresponding", "function", "object", "within", "the", "frame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/debugging.py#L268-L304", "partition": "test", "index": 1342, "time": "2016-07-28 10:05:18"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/typechecks.py", "func_name": "assert_matches", "original_string": "def assert_matches(v, regex):\n    \"\"\"\n    Assert that string variable matches the provided regular expression.\n\n    :param v: variable to check.\n    :param regex: regular expression to check against (can be either a string, or compiled regexp).\n    \"\"\"\n    m = re.match(regex, v)\n    if m is None:\n        vn = _retrieve_assert_arguments()[0]\n        message = \"Argument `{var}` (= {val!r}) did not match /{regex}/\".format(var=vn, regex=regex, val=v)\n        raise H2OValueError(message, var_name=vn, skip_frames=1)\n    return m", "language": "python", "code": "def assert_matches(v, regex):\n    \"\"\"\n    Assert that string variable matches the provided regular expression.\n\n    :param v: variable to check.\n    :param regex: regular expression to check against (can be either a string, or compiled regexp).\n    \"\"\"\n    m = re.match(regex, v)\n    if m is None:\n        vn = _retrieve_assert_arguments()[0]\n        message = \"Argument `{var}` (= {val!r}) did not match /{regex}/\".format(var=vn, regex=regex, val=v)\n        raise H2OValueError(message, var_name=vn, skip_frames=1)\n    return m", "code_tokens": ["def", "assert_matches", "(", "v", ",", "regex", ")", ":", "m", "=", "re", ".", "match", "(", "regex", ",", "v", ")", "if", "m", "is", "None", ":", "vn", "=", "_retrieve_assert_arguments", "(", ")", "[", "0", "]", "message", "=", "\"Argument `{var}` (= {val!r}) did not match /{regex}/\"", ".", "format", "(", "var", "=", "vn", ",", "regex", "=", "regex", ",", "val", "=", "v", ")", "raise", "H2OValueError", "(", "message", ",", "var_name", "=", "vn", ",", "skip_frames", "=", "1", ")", "return", "m"], "docstring": "Assert that string variable matches the provided regular expression.\n\n    :param v: variable to check.\n    :param regex: regular expression to check against (can be either a string, or compiled regexp).", "docstring_tokens": ["Assert", "that", "string", "variable", "matches", "the", "provided", "regular", "expression", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/typechecks.py#L461-L473", "partition": "test", "index": 1365, "time": "2016-07-28 14:38:44"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/typechecks.py", "func_name": "assert_satisfies", "original_string": "def assert_satisfies(v, cond, message=None):\n    \"\"\"\n    Assert that variable satisfies the provided condition.\n\n    :param v: variable to check. Its value is only used for error reporting.\n    :param bool cond: condition that must be satisfied. Should be somehow related to the variable ``v``.\n    :param message: message string to use instead of the default.\n    \"\"\"\n    if not cond:\n        vname, vexpr = _retrieve_assert_arguments()\n        if not message:\n            message = \"Argument `{var}` (= {val!r}) does not satisfy the condition {expr}\" \\\n                      .format(var=vname, val=v, expr=vexpr)\n        raise H2OValueError(message=message, var_name=vname, skip_frames=1)", "language": "python", "code": "def assert_satisfies(v, cond, message=None):\n    \"\"\"\n    Assert that variable satisfies the provided condition.\n\n    :param v: variable to check. Its value is only used for error reporting.\n    :param bool cond: condition that must be satisfied. Should be somehow related to the variable ``v``.\n    :param message: message string to use instead of the default.\n    \"\"\"\n    if not cond:\n        vname, vexpr = _retrieve_assert_arguments()\n        if not message:\n            message = \"Argument `{var}` (= {val!r}) does not satisfy the condition {expr}\" \\\n                      .format(var=vname, val=v, expr=vexpr)\n        raise H2OValueError(message=message, var_name=vname, skip_frames=1)", "code_tokens": ["def", "assert_satisfies", "(", "v", ",", "cond", ",", "message", "=", "None", ")", ":", "if", "not", "cond", ":", "vname", ",", "vexpr", "=", "_retrieve_assert_arguments", "(", ")", "if", "not", "message", ":", "message", "=", "\"Argument `{var}` (= {val!r}) does not satisfy the condition {expr}\"", ".", "format", "(", "var", "=", "vname", ",", "val", "=", "v", ",", "expr", "=", "vexpr", ")", "raise", "H2OValueError", "(", "message", "=", "message", ",", "var_name", "=", "vname", ",", "skip_frames", "=", "1", ")"], "docstring": "Assert that variable satisfies the provided condition.\n\n    :param v: variable to check. Its value is only used for error reporting.\n    :param bool cond: condition that must be satisfied. Should be somehow related to the variable ``v``.\n    :param message: message string to use instead of the default.", "docstring_tokens": ["Assert", "that", "variable", "satisfies", "the", "provided", "condition", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/typechecks.py#L476-L489", "partition": "test", "index": 1366, "time": "2016-07-28 15:37:12"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "deep_copy", "original_string": "def deep_copy(data, xid):\n    \"\"\"\n    Create a deep clone of the frame ``data``.\n\n    :param data: an H2OFrame to be cloned\n    :param xid: (internal) id to be assigned to the new frame.\n    :returns: new :class:`H2OFrame` which is the clone of the passed frame.\n    \"\"\"\n    assert_is_type(data, H2OFrame)\n    assert_is_type(xid, str)\n    assert_satisfies(xid, xid != data.frame_id)\n    check_frame_id(xid)\n    duplicate = data.apply(lambda x: x)\n    duplicate._ex = ExprNode(\"assign\", xid, duplicate)._eval_driver(False)\n    duplicate._ex._cache._id = xid\n    duplicate._ex._children = None\n    return duplicate", "language": "python", "code": "def deep_copy(data, xid):\n    \"\"\"\n    Create a deep clone of the frame ``data``.\n\n    :param data: an H2OFrame to be cloned\n    :param xid: (internal) id to be assigned to the new frame.\n    :returns: new :class:`H2OFrame` which is the clone of the passed frame.\n    \"\"\"\n    assert_is_type(data, H2OFrame)\n    assert_is_type(xid, str)\n    assert_satisfies(xid, xid != data.frame_id)\n    check_frame_id(xid)\n    duplicate = data.apply(lambda x: x)\n    duplicate._ex = ExprNode(\"assign\", xid, duplicate)._eval_driver(False)\n    duplicate._ex._cache._id = xid\n    duplicate._ex._children = None\n    return duplicate", "code_tokens": ["def", "deep_copy", "(", "data", ",", "xid", ")", ":", "assert_is_type", "(", "data", ",", "H2OFrame", ")", "assert_is_type", "(", "xid", ",", "str", ")", "assert_satisfies", "(", "xid", ",", "xid", "!=", "data", ".", "frame_id", ")", "check_frame_id", "(", "xid", ")", "duplicate", "=", "data", ".", "apply", "(", "lambda", "x", ":", "x", ")", "duplicate", ".", "_ex", "=", "ExprNode", "(", "\"assign\"", ",", "xid", ",", "duplicate", ")", ".", "_eval_driver", "(", "False", ")", "duplicate", ".", "_ex", ".", "_cache", ".", "_id", "=", "xid", "duplicate", ".", "_ex", ".", "_children", "=", "None", "return", "duplicate"], "docstring": "Create a deep clone of the frame ``data``.\n\n    :param data: an H2OFrame to be cloned\n    :param xid: (internal) id to be assigned to the new frame.\n    :returns: new :class:`H2OFrame` which is the clone of the passed frame.", "docstring_tokens": ["Create", "a", "deep", "clone", "of", "the", "frame", "data", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L773-L789", "partition": "test", "index": 1462, "time": "2016-08-01 16:36:04"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "PBWBar.set_encoding", "original_string": "def set_encoding(self, encoding):\n        \"\"\"Inform the widget about the encoding of the underlying character stream.\"\"\"\n        self._bar_ends = \"[]\"\n        self._bar_symbols = \"#\"\n        if not encoding: return\n        s1 = \"\\u258F\\u258E\\u258D\\u258C\\u258B\\u258A\\u2589\\u2588\"\n        s2 = \"\\u258C\\u2588\"\n        s3 = \"\\u2588\"\n        if self._file_mode:\n            s1 = s2 = None\n        assert len(s3) == 1\n        for s in (s1, s2, s3):\n            if s is None: continue\n            try:\n                s.encode(encoding)\n                self._bar_ends = \"||\"\n                self._bar_symbols = s\n                return\n            except UnicodeEncodeError:\n                pass\n            except LookupError:\n                print(\"Warning: unknown encoding %s\" % encoding)", "language": "python", "code": "def set_encoding(self, encoding):\n        \"\"\"Inform the widget about the encoding of the underlying character stream.\"\"\"\n        self._bar_ends = \"[]\"\n        self._bar_symbols = \"#\"\n        if not encoding: return\n        s1 = \"\\u258F\\u258E\\u258D\\u258C\\u258B\\u258A\\u2589\\u2588\"\n        s2 = \"\\u258C\\u2588\"\n        s3 = \"\\u2588\"\n        if self._file_mode:\n            s1 = s2 = None\n        assert len(s3) == 1\n        for s in (s1, s2, s3):\n            if s is None: continue\n            try:\n                s.encode(encoding)\n                self._bar_ends = \"||\"\n                self._bar_symbols = s\n                return\n            except UnicodeEncodeError:\n                pass\n            except LookupError:\n                print(\"Warning: unknown encoding %s\" % encoding)", "code_tokens": ["def", "set_encoding", "(", "self", ",", "encoding", ")", ":", "self", ".", "_bar_ends", "=", "\"[]\"", "self", ".", "_bar_symbols", "=", "\"#\"", "if", "not", "encoding", ":", "return", "s1", "=", "\"\\u258F\\u258E\\u258D\\u258C\\u258B\\u258A\\u2589\\u2588\"", "s2", "=", "\"\\u258C\\u2588\"", "s3", "=", "\"\\u2588\"", "if", "self", ".", "_file_mode", ":", "s1", "=", "s2", "=", "None", "assert", "len", "(", "s3", ")", "==", "1", "for", "s", "in", "(", "s1", ",", "s2", ",", "s3", ")", ":", "if", "s", "is", "None", ":", "continue", "try", ":", "s", ".", "encode", "(", "encoding", ")", "self", ".", "_bar_ends", "=", "\"||\"", "self", ".", "_bar_symbols", "=", "s", "return", "except", "UnicodeEncodeError", ":", "pass", "except", "LookupError", ":", "print", "(", "\"Warning: unknown encoding %s\"", "%", "encoding", ")"], "docstring": "Inform the widget about the encoding of the underlying character stream.", "docstring_tokens": ["Inform", "the", "widget", "about", "the", "encoding", "of", "the", "underlying", "character", "stream", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L667-L688", "partition": "test", "index": 1386, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "_ProgressBarCompoundWidget._get_terminal_size", "original_string": "def _get_terminal_size():\n        \"\"\"Find current STDOUT's width, in characters.\"\"\"\n        # If output is not terminal but a regular file, assume 100 chars width\n        if not sys.stdout.isatty():\n            return 80\n\n        # Otherwise, first try getting the dimensions from shell command `stty`:\n        try:\n            import subprocess\n            ret = subprocess.check_output([\"stty\", \"size\"]).strip().split(\" \")\n            if len(ret) == 2:\n                return int(ret[1])\n        except:\n            pass\n\n        # Otherwise try using ioctl\n        try:\n            from termios import TIOCGWINSZ\n            from fcntl import ioctl\n            from struct import unpack\n            res = unpack(\"hh\", ioctl(sys.stdout, TIOCGWINSZ, b\"1234\"))\n            return int(res[1])\n        except:\n            pass\n\n        # Finally check the COLUMNS environment variable\n        return int(os.environ.get(\"COLUMNS\", 80))", "language": "python", "code": "def _get_terminal_size():\n        \"\"\"Find current STDOUT's width, in characters.\"\"\"\n        # If output is not terminal but a regular file, assume 100 chars width\n        if not sys.stdout.isatty():\n            return 80\n\n        # Otherwise, first try getting the dimensions from shell command `stty`:\n        try:\n            import subprocess\n            ret = subprocess.check_output([\"stty\", \"size\"]).strip().split(\" \")\n            if len(ret) == 2:\n                return int(ret[1])\n        except:\n            pass\n\n        # Otherwise try using ioctl\n        try:\n            from termios import TIOCGWINSZ\n            from fcntl import ioctl\n            from struct import unpack\n            res = unpack(\"hh\", ioctl(sys.stdout, TIOCGWINSZ, b\"1234\"))\n            return int(res[1])\n        except:\n            pass\n\n        # Finally check the COLUMNS environment variable\n        return int(os.environ.get(\"COLUMNS\", 80))", "code_tokens": ["def", "_get_terminal_size", "(", ")", ":", "# If output is not terminal but a regular file, assume 100 chars width", "if", "not", "sys", ".", "stdout", ".", "isatty", "(", ")", ":", "return", "80", "# Otherwise, first try getting the dimensions from shell command `stty`:", "try", ":", "import", "subprocess", "ret", "=", "subprocess", ".", "check_output", "(", "[", "\"stty\"", ",", "\"size\"", "]", ")", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "if", "len", "(", "ret", ")", "==", "2", ":", "return", "int", "(", "ret", "[", "1", "]", ")", "except", ":", "pass", "# Otherwise try using ioctl", "try", ":", "from", "termios", "import", "TIOCGWINSZ", "from", "fcntl", "import", "ioctl", "from", "struct", "import", "unpack", "res", "=", "unpack", "(", "\"hh\"", ",", "ioctl", "(", "sys", ".", "stdout", ",", "TIOCGWINSZ", ",", "b\"1234\"", ")", ")", "return", "int", "(", "res", "[", "1", "]", ")", "except", ":", "pass", "# Finally check the COLUMNS environment variable", "return", "int", "(", "os", ".", "environ", ".", "get", "(", "\"COLUMNS\"", ",", "80", ")", ")"], "docstring": "Find current STDOUT's width, in characters.", "docstring_tokens": ["Find", "current", "STDOUT", "s", "width", "in", "characters", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L572-L598", "partition": "test", "index": 1385, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "_ProgressBarCompoundWidget._compute_widget_sizes", "original_string": "def _compute_widget_sizes(self):\n        \"\"\"Initial rendering stage, done in order to compute widths of all widgets.\"\"\"\n        wl = [0] * len(self._widgets)\n        flex_count = 0\n\n        # First render all non-flexible widgets\n        for i, widget in enumerate(self._widgets):\n            if isinstance(widget, ProgressBarFlexibleWidget):\n                flex_count += 1\n            else:\n                wl[i] = widget.render(1).length\n\n        remaining_width = self._width - sum(wl)\n        remaining_width -= len(self._widgets) - 1  # account for 1-space interval between widgets\n        if remaining_width < 10 * flex_count:\n            if self._file_mode:\n                remaining_width = 10 * flex_count\n            else:\n                # The window is too small to accomodate the widget: try to split it into several lines, otherwise\n                # switch to \"file mode\". If we don't do this, then rendering the widget will cause it to wrap, and\n                # then when we use \\r to go to the beginning of the line, only part of the widget will be overwritten,\n                # which means we'll have many (possibly hundreds) of progress bar lines in the end.\n                widget0 = self._widgets[0]\n                if isinstance(widget0, PBWString) and remaining_width + widget0.render(0).length >= 10 * flex_count:\n                    remaining_width += widget0.render(0).length + 1\n                    self._to_render = widget0.render(0).rendered + \"\\n\"\n                    self._widgets = self._widgets[1:]\n                if remaining_width < 10 * flex_count:\n                    self._file_mode = True\n                    remaining_width = 10 * flex_count\n\n        remaining_width = max(remaining_width, 10 * flex_count)  # Ensure at least 10 chars per flexible widget\n\n        for i, widget in enumerate(self._widgets):\n            if isinstance(widget, ProgressBarFlexibleWidget):\n                target_length = int(remaining_width / flex_count)\n                result = widget.render(1, target_length)\n                wl[i] = result.length\n                remaining_width -= result.length\n                flex_count -= 1\n\n        return wl", "language": "python", "code": "def _compute_widget_sizes(self):\n        \"\"\"Initial rendering stage, done in order to compute widths of all widgets.\"\"\"\n        wl = [0] * len(self._widgets)\n        flex_count = 0\n\n        # First render all non-flexible widgets\n        for i, widget in enumerate(self._widgets):\n            if isinstance(widget, ProgressBarFlexibleWidget):\n                flex_count += 1\n            else:\n                wl[i] = widget.render(1).length\n\n        remaining_width = self._width - sum(wl)\n        remaining_width -= len(self._widgets) - 1  # account for 1-space interval between widgets\n        if remaining_width < 10 * flex_count:\n            if self._file_mode:\n                remaining_width = 10 * flex_count\n            else:\n                # The window is too small to accomodate the widget: try to split it into several lines, otherwise\n                # switch to \"file mode\". If we don't do this, then rendering the widget will cause it to wrap, and\n                # then when we use \\r to go to the beginning of the line, only part of the widget will be overwritten,\n                # which means we'll have many (possibly hundreds) of progress bar lines in the end.\n                widget0 = self._widgets[0]\n                if isinstance(widget0, PBWString) and remaining_width + widget0.render(0).length >= 10 * flex_count:\n                    remaining_width += widget0.render(0).length + 1\n                    self._to_render = widget0.render(0).rendered + \"\\n\"\n                    self._widgets = self._widgets[1:]\n                if remaining_width < 10 * flex_count:\n                    self._file_mode = True\n                    remaining_width = 10 * flex_count\n\n        remaining_width = max(remaining_width, 10 * flex_count)  # Ensure at least 10 chars per flexible widget\n\n        for i, widget in enumerate(self._widgets):\n            if isinstance(widget, ProgressBarFlexibleWidget):\n                target_length = int(remaining_width / flex_count)\n                result = widget.render(1, target_length)\n                wl[i] = result.length\n                remaining_width -= result.length\n                flex_count -= 1\n\n        return wl", "code_tokens": ["def", "_compute_widget_sizes", "(", "self", ")", ":", "wl", "=", "[", "0", "]", "*", "len", "(", "self", ".", "_widgets", ")", "flex_count", "=", "0", "# First render all non-flexible widgets", "for", "i", ",", "widget", "in", "enumerate", "(", "self", ".", "_widgets", ")", ":", "if", "isinstance", "(", "widget", ",", "ProgressBarFlexibleWidget", ")", ":", "flex_count", "+=", "1", "else", ":", "wl", "[", "i", "]", "=", "widget", ".", "render", "(", "1", ")", ".", "length", "remaining_width", "=", "self", ".", "_width", "-", "sum", "(", "wl", ")", "remaining_width", "-=", "len", "(", "self", ".", "_widgets", ")", "-", "1", "# account for 1-space interval between widgets", "if", "remaining_width", "<", "10", "*", "flex_count", ":", "if", "self", ".", "_file_mode", ":", "remaining_width", "=", "10", "*", "flex_count", "else", ":", "# The window is too small to accomodate the widget: try to split it into several lines, otherwise", "# switch to \"file mode\". If we don't do this, then rendering the widget will cause it to wrap, and", "# then when we use \\r to go to the beginning of the line, only part of the widget will be overwritten,", "# which means we'll have many (possibly hundreds) of progress bar lines in the end.", "widget0", "=", "self", ".", "_widgets", "[", "0", "]", "if", "isinstance", "(", "widget0", ",", "PBWString", ")", "and", "remaining_width", "+", "widget0", ".", "render", "(", "0", ")", ".", "length", ">=", "10", "*", "flex_count", ":", "remaining_width", "+=", "widget0", ".", "render", "(", "0", ")", ".", "length", "+", "1", "self", ".", "_to_render", "=", "widget0", ".", "render", "(", "0", ")", ".", "rendered", "+", "\"\\n\"", "self", ".", "_widgets", "=", "self", ".", "_widgets", "[", "1", ":", "]", "if", "remaining_width", "<", "10", "*", "flex_count", ":", "self", ".", "_file_mode", "=", "True", "remaining_width", "=", "10", "*", "flex_count", "remaining_width", "=", "max", "(", "remaining_width", ",", "10", "*", "flex_count", ")", "# Ensure at least 10 chars per flexible widget", "for", "i", ",", "widget", "in", "enumerate", "(", "self", ".", "_widgets", ")", ":", "if", "isinstance", "(", "widget", ",", "ProgressBarFlexibleWidget", ")", ":", "target_length", "=", "int", "(", "remaining_width", "/", "flex_count", ")", "result", "=", "widget", ".", "render", "(", "1", ",", "target_length", ")", "wl", "[", "i", "]", "=", "result", ".", "length", "remaining_width", "-=", "result", ".", "length", "flex_count", "-=", "1", "return", "wl"], "docstring": "Initial rendering stage, done in order to compute widths of all widgets.", "docstring_tokens": ["Initial", "rendering", "stage", "done", "in", "order", "to", "compute", "widths", "of", "all", "widgets", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L527-L568", "partition": "test", "index": 1384, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "ProgressBar._draw", "original_string": "def _draw(self, txt, final=False):\n        \"\"\"Print the rendered string to the stdout.\"\"\"\n        if not self._file_mode:\n            # If the user presses Ctrl+C this ensures we still start writing from the beginning of the line\n            sys.stdout.write(\"\\r\")\n        sys.stdout.write(txt)\n        if final and not isinstance(self._widget, _HiddenWidget):\n            sys.stdout.write(\"\\n\")\n        else:\n            if not self._file_mode:\n                sys.stdout.write(\"\\r\")\n            sys.stdout.flush()", "language": "python", "code": "def _draw(self, txt, final=False):\n        \"\"\"Print the rendered string to the stdout.\"\"\"\n        if not self._file_mode:\n            # If the user presses Ctrl+C this ensures we still start writing from the beginning of the line\n            sys.stdout.write(\"\\r\")\n        sys.stdout.write(txt)\n        if final and not isinstance(self._widget, _HiddenWidget):\n            sys.stdout.write(\"\\n\")\n        else:\n            if not self._file_mode:\n                sys.stdout.write(\"\\r\")\n            sys.stdout.flush()", "code_tokens": ["def", "_draw", "(", "self", ",", "txt", ",", "final", "=", "False", ")", ":", "if", "not", "self", ".", "_file_mode", ":", "# If the user presses Ctrl+C this ensures we still start writing from the beginning of the line", "sys", ".", "stdout", ".", "write", "(", "\"\\r\"", ")", "sys", ".", "stdout", ".", "write", "(", "txt", ")", "if", "final", "and", "not", "isinstance", "(", "self", ".", "_widget", ",", "_HiddenWidget", ")", ":", "sys", ".", "stdout", ".", "write", "(", "\"\\n\"", ")", "else", ":", "if", "not", "self", ".", "_file_mode", ":", "sys", ".", "stdout", ".", "write", "(", "\"\\r\"", ")", "sys", ".", "stdout", ".", "flush", "(", ")"], "docstring": "Print the rendered string to the stdout.", "docstring_tokens": ["Print", "the", "rendered", "string", "to", "the", "stdout", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L352-L363", "partition": "test", "index": 1383, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "ProgressBar._get_time_at_progress", "original_string": "def _get_time_at_progress(self, x_target):\n        \"\"\"\n        Return the projected time when progress level `x_target` will be reached.\n\n        Since the underlying progress model is nonlinear, we need to do use Newton method to find a numerical solution\n        to the equation x(t) = x_target.\n        \"\"\"\n        t, x, v = self._t0, self._x0, self._v0\n        # The convergence should be achieved in just few iterations, however in unlikely situation that it doesn't\n        # we don't want to loop forever...\n        for _ in range(20):\n            if v == 0: return 1e20\n            # make time prediction assuming the progress will continue at a linear speed ``v``\n            t += (x_target - x) / v\n            # calculate the actual progress at that time\n            x, v = self._compute_progress_at_time(t)\n            # iterate until convergence\n            if abs(x - x_target) < 1e-3: return t\n        return time.time() + 100", "language": "python", "code": "def _get_time_at_progress(self, x_target):\n        \"\"\"\n        Return the projected time when progress level `x_target` will be reached.\n\n        Since the underlying progress model is nonlinear, we need to do use Newton method to find a numerical solution\n        to the equation x(t) = x_target.\n        \"\"\"\n        t, x, v = self._t0, self._x0, self._v0\n        # The convergence should be achieved in just few iterations, however in unlikely situation that it doesn't\n        # we don't want to loop forever...\n        for _ in range(20):\n            if v == 0: return 1e20\n            # make time prediction assuming the progress will continue at a linear speed ``v``\n            t += (x_target - x) / v\n            # calculate the actual progress at that time\n            x, v = self._compute_progress_at_time(t)\n            # iterate until convergence\n            if abs(x - x_target) < 1e-3: return t\n        return time.time() + 100", "code_tokens": ["def", "_get_time_at_progress", "(", "self", ",", "x_target", ")", ":", "t", ",", "x", ",", "v", "=", "self", ".", "_t0", ",", "self", ".", "_x0", ",", "self", ".", "_v0", "# The convergence should be achieved in just few iterations, however in unlikely situation that it doesn't", "# we don't want to loop forever...", "for", "_", "in", "range", "(", "20", ")", ":", "if", "v", "==", "0", ":", "return", "1e20", "# make time prediction assuming the progress will continue at a linear speed ``v``", "t", "+=", "(", "x_target", "-", "x", ")", "/", "v", "# calculate the actual progress at that time", "x", ",", "v", "=", "self", ".", "_compute_progress_at_time", "(", "t", ")", "# iterate until convergence", "if", "abs", "(", "x", "-", "x_target", ")", "<", "1e-3", ":", "return", "t", "return", "time", ".", "time", "(", ")", "+", "100"], "docstring": "Return the projected time when progress level `x_target` will be reached.\n\n        Since the underlying progress model is nonlinear, we need to do use Newton method to find a numerical solution\n        to the equation x(t) = x_target.", "docstring_tokens": ["Return", "the", "projected", "time", "when", "progress", "level", "x_target", "will", "be", "reached", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L331-L349", "partition": "test", "index": 1382, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "ProgressBar._guess_next_poll_interval", "original_string": "def _guess_next_poll_interval(self):\n        \"\"\"\n        Determine when to query the progress status next.\n\n        This function is used if the external progress function did not return time interval for when it should be\n        queried next.\n        \"\"\"\n        time_elapsed = self._progress_data[-1][0] - self._progress_data[0][0]\n        real_progress = self._get_real_progress()\n        return min(0.2 * time_elapsed, 0.5 + (1 - real_progress)**0.5)", "language": "python", "code": "def _guess_next_poll_interval(self):\n        \"\"\"\n        Determine when to query the progress status next.\n\n        This function is used if the external progress function did not return time interval for when it should be\n        queried next.\n        \"\"\"\n        time_elapsed = self._progress_data[-1][0] - self._progress_data[0][0]\n        real_progress = self._get_real_progress()\n        return min(0.2 * time_elapsed, 0.5 + (1 - real_progress)**0.5)", "code_tokens": ["def", "_guess_next_poll_interval", "(", "self", ")", ":", "time_elapsed", "=", "self", ".", "_progress_data", "[", "-", "1", "]", "[", "0", "]", "-", "self", ".", "_progress_data", "[", "0", "]", "[", "0", "]", "real_progress", "=", "self", ".", "_get_real_progress", "(", ")", "return", "min", "(", "0.2", "*", "time_elapsed", ",", "0.5", "+", "(", "1", "-", "real_progress", ")", "**", "0.5", ")"], "docstring": "Determine when to query the progress status next.\n\n        This function is used if the external progress function did not return time interval for when it should be\n        queried next.", "docstring_tokens": ["Determine", "when", "to", "query", "the", "progress", "status", "next", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L306-L315", "partition": "test", "index": 1380, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "ProgressBar._estimate_progress_completion_time", "original_string": "def _estimate_progress_completion_time(self, now):\n        \"\"\"\n        Estimate the moment when the underlying process is expected to reach completion.\n\n        This function should only return future times. Also this function is not allowed to return time moments less\n        than self._next_poll_time if the actual progress is below 100% (this is because we won't know that the\n        process have finished until we poll the external progress function).\n        \"\"\"\n        assert self._next_poll_time >= now\n        tlast, wlast = self._progress_data[-1]\n        # If reached 100%, make sure that we finish as soon as possible, but maybe not immediately\n        if wlast == self._maxval:\n            current_completion_time = (1 - self._x0) / self._v0 + self._t0\n            return clamp(current_completion_time, now, now + self.FINISH_DELAY)\n\n        # Calculate the approximate speed of the raw progress based on recent data\n        tacc, wacc = 0, 0\n        factor = self.GAMMA\n        for t, x in self._progress_data[-2::-1]:\n            tacc += factor * (tlast - t)\n            wacc += factor * (wlast - x)\n            factor *= self.GAMMA\n            if factor < 1e-2: break\n\n        # If there was no progress at all, then just assume it's 5 minutes from now\n        if wacc == 0: return now + 300\n\n        # Estimate the completion time assuming linear progress\n        t_estimate = tlast + tacc * (self._maxval - wlast) / wacc\n\n        # Adjust the estimate if it looks like it may happen too soon\n        if t_estimate <= self._next_poll_time:\n            t_estimate = self._next_poll_time + self.FINISH_DELAY\n\n        return t_estimate", "language": "python", "code": "def _estimate_progress_completion_time(self, now):\n        \"\"\"\n        Estimate the moment when the underlying process is expected to reach completion.\n\n        This function should only return future times. Also this function is not allowed to return time moments less\n        than self._next_poll_time if the actual progress is below 100% (this is because we won't know that the\n        process have finished until we poll the external progress function).\n        \"\"\"\n        assert self._next_poll_time >= now\n        tlast, wlast = self._progress_data[-1]\n        # If reached 100%, make sure that we finish as soon as possible, but maybe not immediately\n        if wlast == self._maxval:\n            current_completion_time = (1 - self._x0) / self._v0 + self._t0\n            return clamp(current_completion_time, now, now + self.FINISH_DELAY)\n\n        # Calculate the approximate speed of the raw progress based on recent data\n        tacc, wacc = 0, 0\n        factor = self.GAMMA\n        for t, x in self._progress_data[-2::-1]:\n            tacc += factor * (tlast - t)\n            wacc += factor * (wlast - x)\n            factor *= self.GAMMA\n            if factor < 1e-2: break\n\n        # If there was no progress at all, then just assume it's 5 minutes from now\n        if wacc == 0: return now + 300\n\n        # Estimate the completion time assuming linear progress\n        t_estimate = tlast + tacc * (self._maxval - wlast) / wacc\n\n        # Adjust the estimate if it looks like it may happen too soon\n        if t_estimate <= self._next_poll_time:\n            t_estimate = self._next_poll_time + self.FINISH_DELAY\n\n        return t_estimate", "code_tokens": ["def", "_estimate_progress_completion_time", "(", "self", ",", "now", ")", ":", "assert", "self", ".", "_next_poll_time", ">=", "now", "tlast", ",", "wlast", "=", "self", ".", "_progress_data", "[", "-", "1", "]", "# If reached 100%, make sure that we finish as soon as possible, but maybe not immediately", "if", "wlast", "==", "self", ".", "_maxval", ":", "current_completion_time", "=", "(", "1", "-", "self", ".", "_x0", ")", "/", "self", ".", "_v0", "+", "self", ".", "_t0", "return", "clamp", "(", "current_completion_time", ",", "now", ",", "now", "+", "self", ".", "FINISH_DELAY", ")", "# Calculate the approximate speed of the raw progress based on recent data", "tacc", ",", "wacc", "=", "0", ",", "0", "factor", "=", "self", ".", "GAMMA", "for", "t", ",", "x", "in", "self", ".", "_progress_data", "[", "-", "2", ":", ":", "-", "1", "]", ":", "tacc", "+=", "factor", "*", "(", "tlast", "-", "t", ")", "wacc", "+=", "factor", "*", "(", "wlast", "-", "x", ")", "factor", "*=", "self", ".", "GAMMA", "if", "factor", "<", "1e-2", ":", "break", "# If there was no progress at all, then just assume it's 5 minutes from now", "if", "wacc", "==", "0", ":", "return", "now", "+", "300", "# Estimate the completion time assuming linear progress", "t_estimate", "=", "tlast", "+", "tacc", "*", "(", "self", ".", "_maxval", "-", "wlast", ")", "/", "wacc", "# Adjust the estimate if it looks like it may happen too soon", "if", "t_estimate", "<=", "self", ".", "_next_poll_time", ":", "t_estimate", "=", "self", ".", "_next_poll_time", "+", "self", ".", "FINISH_DELAY", "return", "t_estimate"], "docstring": "Estimate the moment when the underlying process is expected to reach completion.\n\n        This function should only return future times. Also this function is not allowed to return time moments less\n        than self._next_poll_time if the actual progress is below 100% (this is because we won't know that the\n        process have finished until we poll the external progress function).", "docstring_tokens": ["Estimate", "the", "moment", "when", "the", "underlying", "process", "is", "expected", "to", "reach", "completion", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L269-L303", "partition": "test", "index": 1379, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "ProgressBar._recalculate_model_parameters", "original_string": "def _recalculate_model_parameters(self, now):\n        \"\"\"Compute t0, x0, v0, ve.\"\"\"\n        time_until_end = self._estimate_progress_completion_time(now) - now\n        assert time_until_end >= 0, \"Estimated progress completion cannot be in the past.\"\n        x_real = self._get_real_progress()\n        if x_real == 1:\n            t0, x0, v0, ve = now, 1, 0, 0\n        else:\n            x0, v0 = self._compute_progress_at_time(now)\n            t0 = now\n            if x0 >= 1:\n                # On rare occasion, the model's progress may have reached 100% by ``now``. This can happen if\n                # (1) the progress is close to 100% initially and has high speed, (2) on the previous call we\n                # estimated that the process completion time will be right after the next poll time, and (3)\n                # the polling itself took so much time that the process effectively \"overshoot\".\n                # If this happens, then we adjust x0, v0 to the previous valid data checkpoint.\n                t0, x0, v0 = self._t0, self._x0, self._v0\n                time_until_end += now - t0\n            z = self.BETA * time_until_end\n            max_speed = (1 - x_real**2) / self.FINISH_DELAY\n            ve = v0 + (self.BETA * (1 - x0) - v0 * z) / (z - 1 + math.exp(-z))\n            if ve < 0:\n                # Current speed is too high -- reduce v0 (violate non-smoothness of speed)\n                v0 = self.BETA * (1 - x0) / (1 - math.exp(-z))\n                ve = 0\n            if ve > max_speed:\n                # Current speed is too low: finish later, but do not allow ``ve`` to be higher than ``max_speed``\n                ve = max_speed\n        self._t0, self._x0, self._v0, self._ve = t0, x0, v0, ve", "language": "python", "code": "def _recalculate_model_parameters(self, now):\n        \"\"\"Compute t0, x0, v0, ve.\"\"\"\n        time_until_end = self._estimate_progress_completion_time(now) - now\n        assert time_until_end >= 0, \"Estimated progress completion cannot be in the past.\"\n        x_real = self._get_real_progress()\n        if x_real == 1:\n            t0, x0, v0, ve = now, 1, 0, 0\n        else:\n            x0, v0 = self._compute_progress_at_time(now)\n            t0 = now\n            if x0 >= 1:\n                # On rare occasion, the model's progress may have reached 100% by ``now``. This can happen if\n                # (1) the progress is close to 100% initially and has high speed, (2) on the previous call we\n                # estimated that the process completion time will be right after the next poll time, and (3)\n                # the polling itself took so much time that the process effectively \"overshoot\".\n                # If this happens, then we adjust x0, v0 to the previous valid data checkpoint.\n                t0, x0, v0 = self._t0, self._x0, self._v0\n                time_until_end += now - t0\n            z = self.BETA * time_until_end\n            max_speed = (1 - x_real**2) / self.FINISH_DELAY\n            ve = v0 + (self.BETA * (1 - x0) - v0 * z) / (z - 1 + math.exp(-z))\n            if ve < 0:\n                # Current speed is too high -- reduce v0 (violate non-smoothness of speed)\n                v0 = self.BETA * (1 - x0) / (1 - math.exp(-z))\n                ve = 0\n            if ve > max_speed:\n                # Current speed is too low: finish later, but do not allow ``ve`` to be higher than ``max_speed``\n                ve = max_speed\n        self._t0, self._x0, self._v0, self._ve = t0, x0, v0, ve", "code_tokens": ["def", "_recalculate_model_parameters", "(", "self", ",", "now", ")", ":", "time_until_end", "=", "self", ".", "_estimate_progress_completion_time", "(", "now", ")", "-", "now", "assert", "time_until_end", ">=", "0", ",", "\"Estimated progress completion cannot be in the past.\"", "x_real", "=", "self", ".", "_get_real_progress", "(", ")", "if", "x_real", "==", "1", ":", "t0", ",", "x0", ",", "v0", ",", "ve", "=", "now", ",", "1", ",", "0", ",", "0", "else", ":", "x0", ",", "v0", "=", "self", ".", "_compute_progress_at_time", "(", "now", ")", "t0", "=", "now", "if", "x0", ">=", "1", ":", "# On rare occasion, the model's progress may have reached 100% by ``now``. This can happen if", "# (1) the progress is close to 100% initially and has high speed, (2) on the previous call we", "# estimated that the process completion time will be right after the next poll time, and (3)", "# the polling itself took so much time that the process effectively \"overshoot\".", "# If this happens, then we adjust x0, v0 to the previous valid data checkpoint.", "t0", ",", "x0", ",", "v0", "=", "self", ".", "_t0", ",", "self", ".", "_x0", ",", "self", ".", "_v0", "time_until_end", "+=", "now", "-", "t0", "z", "=", "self", ".", "BETA", "*", "time_until_end", "max_speed", "=", "(", "1", "-", "x_real", "**", "2", ")", "/", "self", ".", "FINISH_DELAY", "ve", "=", "v0", "+", "(", "self", ".", "BETA", "*", "(", "1", "-", "x0", ")", "-", "v0", "*", "z", ")", "/", "(", "z", "-", "1", "+", "math", ".", "exp", "(", "-", "z", ")", ")", "if", "ve", "<", "0", ":", "# Current speed is too high -- reduce v0 (violate non-smoothness of speed)", "v0", "=", "self", ".", "BETA", "*", "(", "1", "-", "x0", ")", "/", "(", "1", "-", "math", ".", "exp", "(", "-", "z", ")", ")", "ve", "=", "0", "if", "ve", ">", "max_speed", ":", "# Current speed is too low: finish later, but do not allow ``ve`` to be higher than ``max_speed``", "ve", "=", "max_speed", "self", ".", "_t0", ",", "self", ".", "_x0", ",", "self", ".", "_v0", ",", "self", ".", "_ve", "=", "t0", ",", "x0", ",", "v0", ",", "ve"], "docstring": "Compute t0, x0, v0, ve.", "docstring_tokens": ["Compute", "t0", "x0", "v0", "ve", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L238-L266", "partition": "test", "index": 1378, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "ProgressBar._compute_progress_at_time", "original_string": "def _compute_progress_at_time(self, t):\n        \"\"\"\n        Calculate the modelled progress state for the given time moment.\n\n        :returns: tuple (x, v) of the progress level and progress speed.\n        \"\"\"\n        t0, x0, v0, ve = self._t0, self._x0, self._v0, self._ve\n        z = (v0 - ve) * math.exp(-self.BETA * (t - t0))\n        vt = ve + z\n        xt = clamp(x0 + ve * (t - t0) + (v0 - ve - z) / self.BETA, 0, 1)\n        return xt, vt", "language": "python", "code": "def _compute_progress_at_time(self, t):\n        \"\"\"\n        Calculate the modelled progress state for the given time moment.\n\n        :returns: tuple (x, v) of the progress level and progress speed.\n        \"\"\"\n        t0, x0, v0, ve = self._t0, self._x0, self._v0, self._ve\n        z = (v0 - ve) * math.exp(-self.BETA * (t - t0))\n        vt = ve + z\n        xt = clamp(x0 + ve * (t - t0) + (v0 - ve - z) / self.BETA, 0, 1)\n        return xt, vt", "code_tokens": ["def", "_compute_progress_at_time", "(", "self", ",", "t", ")", ":", "t0", ",", "x0", ",", "v0", ",", "ve", "=", "self", ".", "_t0", ",", "self", ".", "_x0", ",", "self", ".", "_v0", ",", "self", ".", "_ve", "z", "=", "(", "v0", "-", "ve", ")", "*", "math", ".", "exp", "(", "-", "self", ".", "BETA", "*", "(", "t", "-", "t0", ")", ")", "vt", "=", "ve", "+", "z", "xt", "=", "clamp", "(", "x0", "+", "ve", "*", "(", "t", "-", "t0", ")", "+", "(", "v0", "-", "ve", "-", "z", ")", "/", "self", ".", "BETA", ",", "0", ",", "1", ")", "return", "xt", ",", "vt"], "docstring": "Calculate the modelled progress state for the given time moment.\n\n        :returns: tuple (x, v) of the progress level and progress speed.", "docstring_tokens": ["Calculate", "the", "modelled", "progress", "state", "for", "the", "given", "time", "moment", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L318-L328", "partition": "test", "index": 1381, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "ProgressBar._store_model_progress", "original_string": "def _store_model_progress(self, res, now):\n        \"\"\"\n        Save the current model progress into ``self._progress_data``, and update ``self._next_poll_time``.\n\n        :param res: tuple (progress level, poll delay).\n        :param now: current timestamp.\n        \"\"\"\n        raw_progress, delay = res\n        raw_progress = clamp(raw_progress, 0, self._maxval)\n        self._progress_data.append((now, raw_progress))\n\n        if delay < 0:\n            # calculation of ``_guess_next_poll_interval()`` should be done only *after* we pushed the fresh data to\n            # ``self._progress_data``.\n            delay = self._guess_next_poll_interval()\n        self._next_poll_time = now + clamp(delay, self.MIN_PROGRESS_CHECK_INTERVAL, self.MAX_PROGRESS_CHECK_INTERVAL)", "language": "python", "code": "def _store_model_progress(self, res, now):\n        \"\"\"\n        Save the current model progress into ``self._progress_data``, and update ``self._next_poll_time``.\n\n        :param res: tuple (progress level, poll delay).\n        :param now: current timestamp.\n        \"\"\"\n        raw_progress, delay = res\n        raw_progress = clamp(raw_progress, 0, self._maxval)\n        self._progress_data.append((now, raw_progress))\n\n        if delay < 0:\n            # calculation of ``_guess_next_poll_interval()`` should be done only *after* we pushed the fresh data to\n            # ``self._progress_data``.\n            delay = self._guess_next_poll_interval()\n        self._next_poll_time = now + clamp(delay, self.MIN_PROGRESS_CHECK_INTERVAL, self.MAX_PROGRESS_CHECK_INTERVAL)", "code_tokens": ["def", "_store_model_progress", "(", "self", ",", "res", ",", "now", ")", ":", "raw_progress", ",", "delay", "=", "res", "raw_progress", "=", "clamp", "(", "raw_progress", ",", "0", ",", "self", ".", "_maxval", ")", "self", ".", "_progress_data", ".", "append", "(", "(", "now", ",", "raw_progress", ")", ")", "if", "delay", "<", "0", ":", "# calculation of ``_guess_next_poll_interval()`` should be done only *after* we pushed the fresh data to", "# ``self._progress_data``.", "delay", "=", "self", ".", "_guess_next_poll_interval", "(", ")", "self", ".", "_next_poll_time", "=", "now", "+", "clamp", "(", "delay", ",", "self", ".", "MIN_PROGRESS_CHECK_INTERVAL", ",", "self", ".", "MAX_PROGRESS_CHECK_INTERVAL", ")"], "docstring": "Save the current model progress into ``self._progress_data``, and update ``self._next_poll_time``.\n\n        :param res: tuple (progress level, poll delay).\n        :param now: current timestamp.", "docstring_tokens": ["Save", "the", "current", "model", "progress", "into", "self", ".", "_progress_data", "and", "update", "self", ".", "_next_poll_time", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L220-L235", "partition": "test", "index": 1377, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/progressbar.py", "func_name": "ProgressBar.execute", "original_string": "def execute(self, progress_fn, print_verbose_info=None):\n        \"\"\"\n        Start the progress bar, and return only when the progress reaches 100%.\n\n        :param progress_fn: the executor function (or a generator). This function should take no arguments\n            and return either a single number -- the current progress level, or a tuple (progress level, delay),\n            where delay is the time interval for when the progress should be checked again. This function may at\n            any point raise the ``StopIteration(message)`` exception, which will interrupt the progress bar,\n            display the ``message`` in red font, and then re-raise the exception.\n        :raises StopIteration: if the job is interrupted. The reason for interruption is provided in the exception's\n            message. The message will say \"cancelled\" if the job was interrupted by the user by pressing Ctrl+C.\n        \"\"\"\n        assert_is_type(progress_fn, FunctionType, GeneratorType, MethodType)\n        if isinstance(progress_fn, GeneratorType):\n            # Convert generator to a regular function\n            progress_fn = (lambda g: lambda: next(g))(progress_fn)\n\n        # Initialize the execution context\n        self._next_poll_time = 0\n        self._t0 = time.time()\n        self._x0 = 0\n        self._v0 = 0.01  # corresponds to 100s completion time\n        self._ve = 0.01\n\n        progress = 0\n        status = None  # Status message in case the job gets interrupted.\n        try:\n            while True:\n                # We attempt to synchronize all helper functions, ensuring that each of them has the same idea\n                # for what the current time moment is. Otherwise we could have some corner cases when one method\n                # says that something must happen right now, while the other already sees that moment in the past.\n                now = time.time()\n\n                # Query the progress level, but only if it's time already\n                if self._next_poll_time <= now:\n                    res = progress_fn()  # may raise StopIteration\n                    assert_is_type(res, (numeric, numeric), numeric)\n                    if not isinstance(res, tuple):\n                        res = (res, -1)\n                    # Progress querying could have taken some time, so update the current time moment\n                    now = time.time()\n                    self._store_model_progress(res, now)\n                    self._recalculate_model_parameters(now)\n\n                # Render the widget regardless of whether it's too early or not\n                progress = min(self._compute_progress_at_time(now)[0], 1)\n                if progress == 1 and self._get_real_progress() >= 1:\n                    # Do not exit until both the model and the actual progress reach 100% mark.\n                    break\n                result = self._widget.render(progress)\n                assert_is_type(result, RenderResult)\n                time0 = result.next_time\n                time1 = self._get_time_at_progress(result.next_progress)\n                next_render_time = min(time0, time1)\n                self._draw(result.rendered)\n\n                # Wait until the next rendering/querying cycle\n                wait_time = min(next_render_time, self._next_poll_time) - now\n                if wait_time > 0:\n                    time.sleep(wait_time)\n                    if print_verbose_info is not None:\n                        print_verbose_info(progress)\n        except KeyboardInterrupt:\n            # If the user presses Ctrl+C, we interrupt the progress bar.\n            status = \"cancelled\"\n        except StopIteration as e:\n            # If the generator raises StopIteration before reaching 100%, then the progress display will\n            # reamin incomplete.\n            status = str(e)\n\n        # Do one final rendering before we exit\n        result = self._widget.render(progress=progress, status=status)\n        self._draw(result.rendered, final=True)\n\n        if status == \"cancelled\":\n            # Re-raise the exception, to inform the upstream caller that something unexpected happened.\n            raise StopIteration(status)", "language": "python", "code": "def execute(self, progress_fn, print_verbose_info=None):\n        \"\"\"\n        Start the progress bar, and return only when the progress reaches 100%.\n\n        :param progress_fn: the executor function (or a generator). This function should take no arguments\n            and return either a single number -- the current progress level, or a tuple (progress level, delay),\n            where delay is the time interval for when the progress should be checked again. This function may at\n            any point raise the ``StopIteration(message)`` exception, which will interrupt the progress bar,\n            display the ``message`` in red font, and then re-raise the exception.\n        :raises StopIteration: if the job is interrupted. The reason for interruption is provided in the exception's\n            message. The message will say \"cancelled\" if the job was interrupted by the user by pressing Ctrl+C.\n        \"\"\"\n        assert_is_type(progress_fn, FunctionType, GeneratorType, MethodType)\n        if isinstance(progress_fn, GeneratorType):\n            # Convert generator to a regular function\n            progress_fn = (lambda g: lambda: next(g))(progress_fn)\n\n        # Initialize the execution context\n        self._next_poll_time = 0\n        self._t0 = time.time()\n        self._x0 = 0\n        self._v0 = 0.01  # corresponds to 100s completion time\n        self._ve = 0.01\n\n        progress = 0\n        status = None  # Status message in case the job gets interrupted.\n        try:\n            while True:\n                # We attempt to synchronize all helper functions, ensuring that each of them has the same idea\n                # for what the current time moment is. Otherwise we could have some corner cases when one method\n                # says that something must happen right now, while the other already sees that moment in the past.\n                now = time.time()\n\n                # Query the progress level, but only if it's time already\n                if self._next_poll_time <= now:\n                    res = progress_fn()  # may raise StopIteration\n                    assert_is_type(res, (numeric, numeric), numeric)\n                    if not isinstance(res, tuple):\n                        res = (res, -1)\n                    # Progress querying could have taken some time, so update the current time moment\n                    now = time.time()\n                    self._store_model_progress(res, now)\n                    self._recalculate_model_parameters(now)\n\n                # Render the widget regardless of whether it's too early or not\n                progress = min(self._compute_progress_at_time(now)[0], 1)\n                if progress == 1 and self._get_real_progress() >= 1:\n                    # Do not exit until both the model and the actual progress reach 100% mark.\n                    break\n                result = self._widget.render(progress)\n                assert_is_type(result, RenderResult)\n                time0 = result.next_time\n                time1 = self._get_time_at_progress(result.next_progress)\n                next_render_time = min(time0, time1)\n                self._draw(result.rendered)\n\n                # Wait until the next rendering/querying cycle\n                wait_time = min(next_render_time, self._next_poll_time) - now\n                if wait_time > 0:\n                    time.sleep(wait_time)\n                    if print_verbose_info is not None:\n                        print_verbose_info(progress)\n        except KeyboardInterrupt:\n            # If the user presses Ctrl+C, we interrupt the progress bar.\n            status = \"cancelled\"\n        except StopIteration as e:\n            # If the generator raises StopIteration before reaching 100%, then the progress display will\n            # reamin incomplete.\n            status = str(e)\n\n        # Do one final rendering before we exit\n        result = self._widget.render(progress=progress, status=status)\n        self._draw(result.rendered, final=True)\n\n        if status == \"cancelled\":\n            # Re-raise the exception, to inform the upstream caller that something unexpected happened.\n            raise StopIteration(status)", "code_tokens": ["def", "execute", "(", "self", ",", "progress_fn", ",", "print_verbose_info", "=", "None", ")", ":", "assert_is_type", "(", "progress_fn", ",", "FunctionType", ",", "GeneratorType", ",", "MethodType", ")", "if", "isinstance", "(", "progress_fn", ",", "GeneratorType", ")", ":", "# Convert generator to a regular function", "progress_fn", "=", "(", "lambda", "g", ":", "lambda", ":", "next", "(", "g", ")", ")", "(", "progress_fn", ")", "# Initialize the execution context", "self", ".", "_next_poll_time", "=", "0", "self", ".", "_t0", "=", "time", ".", "time", "(", ")", "self", ".", "_x0", "=", "0", "self", ".", "_v0", "=", "0.01", "# corresponds to 100s completion time", "self", ".", "_ve", "=", "0.01", "progress", "=", "0", "status", "=", "None", "# Status message in case the job gets interrupted.", "try", ":", "while", "True", ":", "# We attempt to synchronize all helper functions, ensuring that each of them has the same idea", "# for what the current time moment is. Otherwise we could have some corner cases when one method", "# says that something must happen right now, while the other already sees that moment in the past.", "now", "=", "time", ".", "time", "(", ")", "# Query the progress level, but only if it's time already", "if", "self", ".", "_next_poll_time", "<=", "now", ":", "res", "=", "progress_fn", "(", ")", "# may raise StopIteration", "assert_is_type", "(", "res", ",", "(", "numeric", ",", "numeric", ")", ",", "numeric", ")", "if", "not", "isinstance", "(", "res", ",", "tuple", ")", ":", "res", "=", "(", "res", ",", "-", "1", ")", "# Progress querying could have taken some time, so update the current time moment", "now", "=", "time", ".", "time", "(", ")", "self", ".", "_store_model_progress", "(", "res", ",", "now", ")", "self", ".", "_recalculate_model_parameters", "(", "now", ")", "# Render the widget regardless of whether it's too early or not", "progress", "=", "min", "(", "self", ".", "_compute_progress_at_time", "(", "now", ")", "[", "0", "]", ",", "1", ")", "if", "progress", "==", "1", "and", "self", ".", "_get_real_progress", "(", ")", ">=", "1", ":", "# Do not exit until both the model and the actual progress reach 100% mark.", "break", "result", "=", "self", ".", "_widget", ".", "render", "(", "progress", ")", "assert_is_type", "(", "result", ",", "RenderResult", ")", "time0", "=", "result", ".", "next_time", "time1", "=", "self", ".", "_get_time_at_progress", "(", "result", ".", "next_progress", ")", "next_render_time", "=", "min", "(", "time0", ",", "time1", ")", "self", ".", "_draw", "(", "result", ".", "rendered", ")", "# Wait until the next rendering/querying cycle", "wait_time", "=", "min", "(", "next_render_time", ",", "self", ".", "_next_poll_time", ")", "-", "now", "if", "wait_time", ">", "0", ":", "time", ".", "sleep", "(", "wait_time", ")", "if", "print_verbose_info", "is", "not", "None", ":", "print_verbose_info", "(", "progress", ")", "except", "KeyboardInterrupt", ":", "# If the user presses Ctrl+C, we interrupt the progress bar.", "status", "=", "\"cancelled\"", "except", "StopIteration", "as", "e", ":", "# If the generator raises StopIteration before reaching 100%, then the progress display will", "# reamin incomplete.", "status", "=", "str", "(", "e", ")", "# Do one final rendering before we exit", "result", "=", "self", ".", "_widget", ".", "render", "(", "progress", "=", "progress", ",", "status", "=", "status", ")", "self", ".", "_draw", "(", "result", ".", "rendered", ",", "final", "=", "True", ")", "if", "status", "==", "\"cancelled\"", ":", "# Re-raise the exception, to inform the upstream caller that something unexpected happened.", "raise", "StopIteration", "(", "status", ")"], "docstring": "Start the progress bar, and return only when the progress reaches 100%.\n\n        :param progress_fn: the executor function (or a generator). This function should take no arguments\n            and return either a single number -- the current progress level, or a tuple (progress level, delay),\n            where delay is the time interval for when the progress should be checked again. This function may at\n            any point raise the ``StopIteration(message)`` exception, which will interrupt the progress bar,\n            display the ``message`` in red font, and then re-raise the exception.\n        :raises StopIteration: if the job is interrupted. The reason for interruption is provided in the exception's\n            message. The message will say \"cancelled\" if the job was interrupted by the user by pressing Ctrl+C.", "docstring_tokens": ["Start", "the", "progress", "bar", "and", "return", "only", "when", "the", "progress", "reaches", "100%", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/progressbar.py#L134-L210", "partition": "test", "index": 1376, "time": "2016-08-02 01:06:29"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/cluster.py", "func_name": "H2OCluster.show_status", "original_string": "def show_status(self, detailed=False):\n        \"\"\"\n        Print current cluster status information.\n\n        :param detailed: if True, then also print detailed information about each node.\n        \"\"\"\n        if self._retrieved_at + self.REFRESH_INTERVAL < time.time():\n            # Info is stale, need to refresh\n            new_info = h2o.api(\"GET /3/Cloud\")\n            self._fill_from_h2ocluster(new_info)\n        ncpus = sum(node[\"num_cpus\"] for node in self.nodes)\n        allowed_cpus = sum(node[\"cpus_allowed\"] for node in self.nodes)\n        free_mem = sum(node[\"free_mem\"] for node in self.nodes)\n        unhealthy_nodes = sum(not node[\"healthy\"] for node in self.nodes)\n        status = \"locked\" if self.locked else \"accepting new members\"\n        if unhealthy_nodes == 0:\n            status += \", healthy\"\n        else:\n            status += \", %d nodes are not healthy\" % unhealthy_nodes\n        api_extensions = self.list_api_extensions()\n        H2ODisplay([\n            [\"H2O cluster uptime:\",        get_human_readable_time(self.cloud_uptime_millis)],\n            [\"H2O cluster timezone:\",      self.cloud_internal_timezone],\n            [\"H2O data parsing timezone:\", self.datafile_parser_timezone],\n            [\"H2O cluster version:\",       self.version],\n            [\"H2O cluster version age:\",   \"{} {}\".format(self.build_age, (\"!!!\" if self.build_too_old else \"\"))],\n            [\"H2O cluster name:\",          self.cloud_name],\n            [\"H2O cluster total nodes:\",   self.cloud_size],\n            [\"H2O cluster free memory:\",   get_human_readable_bytes(free_mem)],\n            [\"H2O cluster total cores:\",   str(ncpus)],\n            [\"H2O cluster allowed cores:\", str(allowed_cpus)],\n            [\"H2O cluster status:\",        status],\n            [\"H2O connection url:\",        h2o.connection().base_url],\n            [\"H2O connection proxy:\",      h2o.connection().proxy],\n            [\"H2O internal security:\",     self.internal_security_enabled],\n            [\"H2O API Extensions:\",        ', '.join(api_extensions)],\n            [\"Python version:\",            \"%d.%d.%d %s\" % tuple(sys.version_info[:4])],\n        ])\n\n        if detailed:\n            keys = [\"h2o\", \"healthy\", \"last_ping\", \"num_cpus\", \"sys_load\", \"mem_value_size\", \"free_mem\", \"pojo_mem\",\n                    \"swap_mem\", \"free_disk\", \"max_disk\", \"pid\", \"num_keys\", \"tcps_active\", \"open_fds\", \"rpcs_active\"]\n            header = [\"Nodes info:\"] + [\"Node %d\" % (i + 1) for i in range(len(self.nodes))]\n            table = [[k] for k in keys]\n            for node in self.nodes:\n                for i, k in enumerate(keys):\n                    table[i].append(node[k])\n            H2ODisplay(table=table, header=header)", "language": "python", "code": "def show_status(self, detailed=False):\n        \"\"\"\n        Print current cluster status information.\n\n        :param detailed: if True, then also print detailed information about each node.\n        \"\"\"\n        if self._retrieved_at + self.REFRESH_INTERVAL < time.time():\n            # Info is stale, need to refresh\n            new_info = h2o.api(\"GET /3/Cloud\")\n            self._fill_from_h2ocluster(new_info)\n        ncpus = sum(node[\"num_cpus\"] for node in self.nodes)\n        allowed_cpus = sum(node[\"cpus_allowed\"] for node in self.nodes)\n        free_mem = sum(node[\"free_mem\"] for node in self.nodes)\n        unhealthy_nodes = sum(not node[\"healthy\"] for node in self.nodes)\n        status = \"locked\" if self.locked else \"accepting new members\"\n        if unhealthy_nodes == 0:\n            status += \", healthy\"\n        else:\n            status += \", %d nodes are not healthy\" % unhealthy_nodes\n        api_extensions = self.list_api_extensions()\n        H2ODisplay([\n            [\"H2O cluster uptime:\",        get_human_readable_time(self.cloud_uptime_millis)],\n            [\"H2O cluster timezone:\",      self.cloud_internal_timezone],\n            [\"H2O data parsing timezone:\", self.datafile_parser_timezone],\n            [\"H2O cluster version:\",       self.version],\n            [\"H2O cluster version age:\",   \"{} {}\".format(self.build_age, (\"!!!\" if self.build_too_old else \"\"))],\n            [\"H2O cluster name:\",          self.cloud_name],\n            [\"H2O cluster total nodes:\",   self.cloud_size],\n            [\"H2O cluster free memory:\",   get_human_readable_bytes(free_mem)],\n            [\"H2O cluster total cores:\",   str(ncpus)],\n            [\"H2O cluster allowed cores:\", str(allowed_cpus)],\n            [\"H2O cluster status:\",        status],\n            [\"H2O connection url:\",        h2o.connection().base_url],\n            [\"H2O connection proxy:\",      h2o.connection().proxy],\n            [\"H2O internal security:\",     self.internal_security_enabled],\n            [\"H2O API Extensions:\",        ', '.join(api_extensions)],\n            [\"Python version:\",            \"%d.%d.%d %s\" % tuple(sys.version_info[:4])],\n        ])\n\n        if detailed:\n            keys = [\"h2o\", \"healthy\", \"last_ping\", \"num_cpus\", \"sys_load\", \"mem_value_size\", \"free_mem\", \"pojo_mem\",\n                    \"swap_mem\", \"free_disk\", \"max_disk\", \"pid\", \"num_keys\", \"tcps_active\", \"open_fds\", \"rpcs_active\"]\n            header = [\"Nodes info:\"] + [\"Node %d\" % (i + 1) for i in range(len(self.nodes))]\n            table = [[k] for k in keys]\n            for node in self.nodes:\n                for i, k in enumerate(keys):\n                    table[i].append(node[k])\n            H2ODisplay(table=table, header=header)", "code_tokens": ["def", "show_status", "(", "self", ",", "detailed", "=", "False", ")", ":", "if", "self", ".", "_retrieved_at", "+", "self", ".", "REFRESH_INTERVAL", "<", "time", ".", "time", "(", ")", ":", "# Info is stale, need to refresh", "new_info", "=", "h2o", ".", "api", "(", "\"GET /3/Cloud\"", ")", "self", ".", "_fill_from_h2ocluster", "(", "new_info", ")", "ncpus", "=", "sum", "(", "node", "[", "\"num_cpus\"", "]", "for", "node", "in", "self", ".", "nodes", ")", "allowed_cpus", "=", "sum", "(", "node", "[", "\"cpus_allowed\"", "]", "for", "node", "in", "self", ".", "nodes", ")", "free_mem", "=", "sum", "(", "node", "[", "\"free_mem\"", "]", "for", "node", "in", "self", ".", "nodes", ")", "unhealthy_nodes", "=", "sum", "(", "not", "node", "[", "\"healthy\"", "]", "for", "node", "in", "self", ".", "nodes", ")", "status", "=", "\"locked\"", "if", "self", ".", "locked", "else", "\"accepting new members\"", "if", "unhealthy_nodes", "==", "0", ":", "status", "+=", "\", healthy\"", "else", ":", "status", "+=", "\", %d nodes are not healthy\"", "%", "unhealthy_nodes", "api_extensions", "=", "self", ".", "list_api_extensions", "(", ")", "H2ODisplay", "(", "[", "[", "\"H2O cluster uptime:\"", ",", "get_human_readable_time", "(", "self", ".", "cloud_uptime_millis", ")", "]", ",", "[", "\"H2O cluster timezone:\"", ",", "self", ".", "cloud_internal_timezone", "]", ",", "[", "\"H2O data parsing timezone:\"", ",", "self", ".", "datafile_parser_timezone", "]", ",", "[", "\"H2O cluster version:\"", ",", "self", ".", "version", "]", ",", "[", "\"H2O cluster version age:\"", ",", "\"{} {}\"", ".", "format", "(", "self", ".", "build_age", ",", "(", "\"!!!\"", "if", "self", ".", "build_too_old", "else", "\"\"", ")", ")", "]", ",", "[", "\"H2O cluster name:\"", ",", "self", ".", "cloud_name", "]", ",", "[", "\"H2O cluster total nodes:\"", ",", "self", ".", "cloud_size", "]", ",", "[", "\"H2O cluster free memory:\"", ",", "get_human_readable_bytes", "(", "free_mem", ")", "]", ",", "[", "\"H2O cluster total cores:\"", ",", "str", "(", "ncpus", ")", "]", ",", "[", "\"H2O cluster allowed cores:\"", ",", "str", "(", "allowed_cpus", ")", "]", ",", "[", "\"H2O cluster status:\"", ",", "status", "]", ",", "[", "\"H2O connection url:\"", ",", "h2o", ".", "connection", "(", ")", ".", "base_url", "]", ",", "[", "\"H2O connection proxy:\"", ",", "h2o", ".", "connection", "(", ")", ".", "proxy", "]", ",", "[", "\"H2O internal security:\"", ",", "self", ".", "internal_security_enabled", "]", ",", "[", "\"H2O API Extensions:\"", ",", "', '", ".", "join", "(", "api_extensions", ")", "]", ",", "[", "\"Python version:\"", ",", "\"%d.%d.%d %s\"", "%", "tuple", "(", "sys", ".", "version_info", "[", ":", "4", "]", ")", "]", ",", "]", ")", "if", "detailed", ":", "keys", "=", "[", "\"h2o\"", ",", "\"healthy\"", ",", "\"last_ping\"", ",", "\"num_cpus\"", ",", "\"sys_load\"", ",", "\"mem_value_size\"", ",", "\"free_mem\"", ",", "\"pojo_mem\"", ",", "\"swap_mem\"", ",", "\"free_disk\"", ",", "\"max_disk\"", ",", "\"pid\"", ",", "\"num_keys\"", ",", "\"tcps_active\"", ",", "\"open_fds\"", ",", "\"rpcs_active\"", "]", "header", "=", "[", "\"Nodes info:\"", "]", "+", "[", "\"Node %d\"", "%", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", "]", "table", "=", "[", "[", "k", "]", "for", "k", "in", "keys", "]", "for", "node", "in", "self", ".", "nodes", ":", "for", "i", ",", "k", "in", "enumerate", "(", "keys", ")", ":", "table", "[", "i", "]", ".", "append", "(", "node", "[", "k", "]", ")", "H2ODisplay", "(", "table", "=", "table", ",", "header", "=", "header", ")"], "docstring": "Print current cluster status information.\n\n        :param detailed: if True, then also print detailed information about each node.", "docstring_tokens": ["Print", "current", "cluster", "status", "information", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/cluster.py#L211-L258", "partition": "test", "index": 1321, "time": "2016-08-03 17:35:58"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/cluster.py", "func_name": "H2OCluster.from_kvs", "original_string": "def from_kvs(keyvals):\n        \"\"\"\n        Create H2OCluster object from a list of key-value pairs.\n\n        TODO: This method should be moved into the base H2OResponse class.\n        \"\"\"\n        obj = H2OCluster()\n        obj._retrieved_at = time.time()\n        for k, v in keyvals:\n            if k in {\"__meta\", \"_exclude_fields\", \"__schema\"}: continue\n            if k in _cloud_v3_valid_keys:\n                obj._props[k] = v\n            else:\n                raise AttributeError(\"Attribute %s cannot be set on H2OCluster (= %r)\" % (k, v))\n        return obj", "language": "python", "code": "def from_kvs(keyvals):\n        \"\"\"\n        Create H2OCluster object from a list of key-value pairs.\n\n        TODO: This method should be moved into the base H2OResponse class.\n        \"\"\"\n        obj = H2OCluster()\n        obj._retrieved_at = time.time()\n        for k, v in keyvals:\n            if k in {\"__meta\", \"_exclude_fields\", \"__schema\"}: continue\n            if k in _cloud_v3_valid_keys:\n                obj._props[k] = v\n            else:\n                raise AttributeError(\"Attribute %s cannot be set on H2OCluster (= %r)\" % (k, v))\n        return obj", "code_tokens": ["def", "from_kvs", "(", "keyvals", ")", ":", "obj", "=", "H2OCluster", "(", ")", "obj", ".", "_retrieved_at", "=", "time", ".", "time", "(", ")", "for", "k", ",", "v", "in", "keyvals", ":", "if", "k", "in", "{", "\"__meta\"", ",", "\"_exclude_fields\"", ",", "\"__schema\"", "}", ":", "continue", "if", "k", "in", "_cloud_v3_valid_keys", ":", "obj", ".", "_props", "[", "k", "]", "=", "v", "else", ":", "raise", "AttributeError", "(", "\"Attribute %s cannot be set on H2OCluster (= %r)\"", "%", "(", "k", ",", "v", ")", ")", "return", "obj"], "docstring": "Create H2OCluster object from a list of key-value pairs.\n\n        TODO: This method should be moved into the base H2OResponse class.", "docstring_tokens": ["Create", "H2OCluster", "object", "from", "a", "list", "of", "key", "-", "value", "pairs", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/cluster.py#L34-L48", "partition": "test", "index": 1318, "time": "2016-08-03 17:35:58"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/cluster.py", "func_name": "H2OCluster._fill_from_h2ocluster", "original_string": "def _fill_from_h2ocluster(self, other):\n        \"\"\"\n        Update information in this object from another H2OCluster instance.\n\n        :param H2OCluster other: source of the new information for this object.\n        \"\"\"\n        self._props = other._props\n        self._retrieved_at = other._retrieved_at\n        other._props = {}\n        other._retrieved_at = None", "language": "python", "code": "def _fill_from_h2ocluster(self, other):\n        \"\"\"\n        Update information in this object from another H2OCluster instance.\n\n        :param H2OCluster other: source of the new information for this object.\n        \"\"\"\n        self._props = other._props\n        self._retrieved_at = other._retrieved_at\n        other._props = {}\n        other._retrieved_at = None", "code_tokens": ["def", "_fill_from_h2ocluster", "(", "self", ",", "other", ")", ":", "self", ".", "_props", "=", "other", ".", "_props", "self", ".", "_retrieved_at", "=", "other", ".", "_retrieved_at", "other", ".", "_props", "=", "{", "}", "other", ".", "_retrieved_at", "=", "None"], "docstring": "Update information in this object from another H2OCluster instance.\n\n        :param H2OCluster other: source of the new information for this object.", "docstring_tokens": ["Update", "information", "in", "this", "object", "from", "another", "H2OCluster", "instance", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/cluster.py#L313-L322", "partition": "test", "index": 1324, "time": "2016-08-04 12:08:14"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/cluster.py", "func_name": "H2OCluster.list_timezones", "original_string": "def list_timezones(self):\n        \"\"\"Return the list of all known timezones.\"\"\"\n        from h2o.expr import ExprNode\n        return h2o.H2OFrame._expr(expr=ExprNode(\"listTimeZones\"))._frame()", "language": "python", "code": "def list_timezones(self):\n        \"\"\"Return the list of all known timezones.\"\"\"\n        from h2o.expr import ExprNode\n        return h2o.H2OFrame._expr(expr=ExprNode(\"listTimeZones\"))._frame()", "code_tokens": ["def", "list_timezones", "(", "self", ")", ":", "from", "h2o", ".", "expr", "import", "ExprNode", "return", "h2o", ".", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"listTimeZones\"", ")", ")", ".", "_frame", "(", ")"], "docstring": "Return the list of all known timezones.", "docstring_tokens": ["Return", "the", "list", "of", "all", "known", "timezones", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/cluster.py#L303-L306", "partition": "test", "index": 1323, "time": "2016-08-04 12:08:14"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/cluster.py", "func_name": "H2OCluster.shutdown", "original_string": "def shutdown(self, prompt=False):\n        \"\"\"\n        Shut down the server.\n\n        This method checks if the H2O cluster is still running, and if it does shuts it down (via a REST API call).\n\n        :param prompt: A logical value indicating whether to prompt the user before shutting down the H2O server.\n        \"\"\"\n        if not self.is_running(): return\n        assert_is_type(prompt, bool)\n        if prompt:\n            question = \"Are you sure you want to shutdown the H2O instance running at %s (Y/N)? \" \\\n                       % h2o.connection().base_url\n            response = input(question)  # works in Py2 & Py3 because redefined in h2o.utils.compatibility module\n        else:\n            response = \"Y\"\n        if response.lower() in {\"y\", \"yes\"}:\n            h2o.api(\"POST /3/Shutdown\")\n            h2o.connection().close()", "language": "python", "code": "def shutdown(self, prompt=False):\n        \"\"\"\n        Shut down the server.\n\n        This method checks if the H2O cluster is still running, and if it does shuts it down (via a REST API call).\n\n        :param prompt: A logical value indicating whether to prompt the user before shutting down the H2O server.\n        \"\"\"\n        if not self.is_running(): return\n        assert_is_type(prompt, bool)\n        if prompt:\n            question = \"Are you sure you want to shutdown the H2O instance running at %s (Y/N)? \" \\\n                       % h2o.connection().base_url\n            response = input(question)  # works in Py2 & Py3 because redefined in h2o.utils.compatibility module\n        else:\n            response = \"Y\"\n        if response.lower() in {\"y\", \"yes\"}:\n            h2o.api(\"POST /3/Shutdown\")\n            h2o.connection().close()", "code_tokens": ["def", "shutdown", "(", "self", ",", "prompt", "=", "False", ")", ":", "if", "not", "self", ".", "is_running", "(", ")", ":", "return", "assert_is_type", "(", "prompt", ",", "bool", ")", "if", "prompt", ":", "question", "=", "\"Are you sure you want to shutdown the H2O instance running at %s (Y/N)? \"", "%", "h2o", ".", "connection", "(", ")", ".", "base_url", "response", "=", "input", "(", "question", ")", "# works in Py2 & Py3 because redefined in h2o.utils.compatibility module", "else", ":", "response", "=", "\"Y\"", "if", "response", ".", "lower", "(", ")", "in", "{", "\"y\"", ",", "\"yes\"", "}", ":", "h2o", ".", "api", "(", "\"POST /3/Shutdown\"", ")", "h2o", ".", "connection", "(", ")", ".", "close", "(", ")"], "docstring": "Shut down the server.\n\n        This method checks if the H2O cluster is still running, and if it does shuts it down (via a REST API call).\n\n        :param prompt: A logical value indicating whether to prompt the user before shutting down the H2O server.", "docstring_tokens": ["Shut", "down", "the", "server", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/cluster.py#L176-L194", "partition": "test", "index": 1319, "time": "2016-08-04 12:08:14"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/cluster.py", "func_name": "H2OCluster.is_running", "original_string": "def is_running(self):\n        \"\"\"\n        Determine if the H2O cluster is running or not.\n\n        :returns: True if the cluster is up; False otherwise\n        \"\"\"\n        try:\n            if h2o.connection().local_server and not h2o.connection().local_server.is_running(): return False\n            h2o.api(\"GET /\")\n            return True\n        except (H2OConnectionError, H2OServerError):\n            return False", "language": "python", "code": "def is_running(self):\n        \"\"\"\n        Determine if the H2O cluster is running or not.\n\n        :returns: True if the cluster is up; False otherwise\n        \"\"\"\n        try:\n            if h2o.connection().local_server and not h2o.connection().local_server.is_running(): return False\n            h2o.api(\"GET /\")\n            return True\n        except (H2OConnectionError, H2OServerError):\n            return False", "code_tokens": ["def", "is_running", "(", "self", ")", ":", "try", ":", "if", "h2o", ".", "connection", "(", ")", ".", "local_server", "and", "not", "h2o", ".", "connection", "(", ")", ".", "local_server", ".", "is_running", "(", ")", ":", "return", "False", "h2o", ".", "api", "(", "\"GET /\"", ")", "return", "True", "except", "(", "H2OConnectionError", ",", "H2OServerError", ")", ":", "return", "False"], "docstring": "Determine if the H2O cluster is running or not.\n\n        :returns: True if the cluster is up; False otherwise", "docstring_tokens": ["Determine", "if", "the", "H2O", "cluster", "is", "running", "or", "not", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/cluster.py#L197-L208", "partition": "test", "index": 1320, "time": "2016-08-04 12:08:14"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "api", "original_string": "def api(endpoint, data=None, json=None, filename=None, save_to=None):\n    \"\"\"\n    Perform a REST API request to a previously connected server.\n\n    This function is mostly for internal purposes, but may occasionally be useful for direct access to\n    the backend H2O server. It has same parameters as :meth:`H2OConnection.request <h2o.backend.H2OConnection.request>`.\n    \"\"\"\n    # type checks are performed in H2OConnection class\n    _check_connection()\n    return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)", "language": "python", "code": "def api(endpoint, data=None, json=None, filename=None, save_to=None):\n    \"\"\"\n    Perform a REST API request to a previously connected server.\n\n    This function is mostly for internal purposes, but may occasionally be useful for direct access to\n    the backend H2O server. It has same parameters as :meth:`H2OConnection.request <h2o.backend.H2OConnection.request>`.\n    \"\"\"\n    # type checks are performed in H2OConnection class\n    _check_connection()\n    return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)", "code_tokens": ["def", "api", "(", "endpoint", ",", "data", "=", "None", ",", "json", "=", "None", ",", "filename", "=", "None", ",", "save_to", "=", "None", ")", ":", "# type checks are performed in H2OConnection class", "_check_connection", "(", ")", "return", "h2oconn", ".", "request", "(", "endpoint", ",", "data", "=", "data", ",", "json", "=", "json", ",", "filename", "=", "filename", ",", "save_to", "=", "save_to", ")"], "docstring": "Perform a REST API request to a previously connected server.\n\n    This function is mostly for internal purposes, but may occasionally be useful for direct access to\n    the backend H2O server. It has same parameters as :meth:`H2OConnection.request <h2o.backend.H2OConnection.request>`.", "docstring_tokens": ["Perform", "a", "REST", "API", "request", "to", "a", "previously", "connected", "server", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L97-L106", "partition": "test", "index": 1453, "time": "2016-08-04 18:31:21"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/typechecks.py", "func_name": "NOT.check", "original_string": "def check(self, var):\n        \"\"\"Return True if the variable does not match any of the types, and False otherwise.\"\"\"\n        return not any(_check_type(var, tt) for tt in self._types)", "language": "python", "code": "def check(self, var):\n        \"\"\"Return True if the variable does not match any of the types, and False otherwise.\"\"\"\n        return not any(_check_type(var, tt) for tt in self._types)", "code_tokens": ["def", "check", "(", "self", ",", "var", ")", ":", "return", "not", "any", "(", "_check_type", "(", "var", ",", "tt", ")", "for", "tt", "in", "self", ".", "_types", ")"], "docstring": "Return True if the variable does not match any of the types, and False otherwise.", "docstring_tokens": ["Return", "True", "if", "the", "variable", "does", "not", "match", "any", "of", "the", "types", "and", "False", "otherwise", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/typechecks.py#L226-L228", "partition": "test", "index": 1371, "time": "2016-08-15 14:47:11"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/typechecks.py", "func_name": "_get_type_name", "original_string": "def _get_type_name(vtype, dump=None):\n    \"\"\"\n    Return the name of the provided type.\n\n        _get_type_name(int) == \"integer\"\n        _get_type_name(str) == \"string\"\n        _get_type_name(tuple) == \"tuple\"\n        _get_type_name(Exception) == \"Exception\"\n        _get_type_name(U(int, float, bool)) == \"integer|float|bool\"\n        _get_type_name(U(H2OFrame, None)) == \"?H2OFrame\"\n    \"\"\"\n    if vtype is None:\n        return \"None\"\n    if vtype is str:\n        return \"string\"\n    if vtype is int:\n        return \"integer\"\n    if vtype is numeric:\n        return \"numeric\"\n    if is_type(vtype, str):\n        return '\"%s\"' % repr(vtype)[1:-1]\n    if is_type(vtype, int):\n        return str(vtype)\n    if isinstance(vtype, MagicType):\n        return vtype.name(dump)\n    if isinstance(vtype, type):\n        return vtype.__name__\n    if isinstance(vtype, list):\n        return \"list(%s)\" % _get_type_name(U(*vtype), dump)\n    if isinstance(vtype, set):\n        return \"set(%s)\" % _get_type_name(U(*vtype), dump)\n    if isinstance(vtype, tuple):\n        return \"(%s)\" % \", \".join(_get_type_name(item, dump) for item in vtype)\n    if isinstance(vtype, dict):\n        return \"dict(%s)\" % \", \".join(\"%s: %s\" % (_get_type_name(tk, dump), _get_type_name(tv, dump))\n                                      for tk, tv in viewitems(vtype))\n    if isinstance(vtype, (FunctionType, BuiltinFunctionType)):\n        if vtype.__name__ == \"<lambda>\":\n            return _get_lambda_source_code(vtype, dump)\n        else:\n            return vtype.__name__\n    raise RuntimeError(\"Unexpected `vtype`: %r\" % vtype)", "language": "python", "code": "def _get_type_name(vtype, dump=None):\n    \"\"\"\n    Return the name of the provided type.\n\n        _get_type_name(int) == \"integer\"\n        _get_type_name(str) == \"string\"\n        _get_type_name(tuple) == \"tuple\"\n        _get_type_name(Exception) == \"Exception\"\n        _get_type_name(U(int, float, bool)) == \"integer|float|bool\"\n        _get_type_name(U(H2OFrame, None)) == \"?H2OFrame\"\n    \"\"\"\n    if vtype is None:\n        return \"None\"\n    if vtype is str:\n        return \"string\"\n    if vtype is int:\n        return \"integer\"\n    if vtype is numeric:\n        return \"numeric\"\n    if is_type(vtype, str):\n        return '\"%s\"' % repr(vtype)[1:-1]\n    if is_type(vtype, int):\n        return str(vtype)\n    if isinstance(vtype, MagicType):\n        return vtype.name(dump)\n    if isinstance(vtype, type):\n        return vtype.__name__\n    if isinstance(vtype, list):\n        return \"list(%s)\" % _get_type_name(U(*vtype), dump)\n    if isinstance(vtype, set):\n        return \"set(%s)\" % _get_type_name(U(*vtype), dump)\n    if isinstance(vtype, tuple):\n        return \"(%s)\" % \", \".join(_get_type_name(item, dump) for item in vtype)\n    if isinstance(vtype, dict):\n        return \"dict(%s)\" % \", \".join(\"%s: %s\" % (_get_type_name(tk, dump), _get_type_name(tv, dump))\n                                      for tk, tv in viewitems(vtype))\n    if isinstance(vtype, (FunctionType, BuiltinFunctionType)):\n        if vtype.__name__ == \"<lambda>\":\n            return _get_lambda_source_code(vtype, dump)\n        else:\n            return vtype.__name__\n    raise RuntimeError(\"Unexpected `vtype`: %r\" % vtype)", "code_tokens": ["def", "_get_type_name", "(", "vtype", ",", "dump", "=", "None", ")", ":", "if", "vtype", "is", "None", ":", "return", "\"None\"", "if", "vtype", "is", "str", ":", "return", "\"string\"", "if", "vtype", "is", "int", ":", "return", "\"integer\"", "if", "vtype", "is", "numeric", ":", "return", "\"numeric\"", "if", "is_type", "(", "vtype", ",", "str", ")", ":", "return", "'\"%s\"'", "%", "repr", "(", "vtype", ")", "[", "1", ":", "-", "1", "]", "if", "is_type", "(", "vtype", ",", "int", ")", ":", "return", "str", "(", "vtype", ")", "if", "isinstance", "(", "vtype", ",", "MagicType", ")", ":", "return", "vtype", ".", "name", "(", "dump", ")", "if", "isinstance", "(", "vtype", ",", "type", ")", ":", "return", "vtype", ".", "__name__", "if", "isinstance", "(", "vtype", ",", "list", ")", ":", "return", "\"list(%s)\"", "%", "_get_type_name", "(", "U", "(", "*", "vtype", ")", ",", "dump", ")", "if", "isinstance", "(", "vtype", ",", "set", ")", ":", "return", "\"set(%s)\"", "%", "_get_type_name", "(", "U", "(", "*", "vtype", ")", ",", "dump", ")", "if", "isinstance", "(", "vtype", ",", "tuple", ")", ":", "return", "\"(%s)\"", "%", "\", \"", ".", "join", "(", "_get_type_name", "(", "item", ",", "dump", ")", "for", "item", "in", "vtype", ")", "if", "isinstance", "(", "vtype", ",", "dict", ")", ":", "return", "\"dict(%s)\"", "%", "\", \"", ".", "join", "(", "\"%s: %s\"", "%", "(", "_get_type_name", "(", "tk", ",", "dump", ")", ",", "_get_type_name", "(", "tv", ",", "dump", ")", ")", "for", "tk", ",", "tv", "in", "viewitems", "(", "vtype", ")", ")", "if", "isinstance", "(", "vtype", ",", "(", "FunctionType", ",", "BuiltinFunctionType", ")", ")", ":", "if", "vtype", ".", "__name__", "==", "\"<lambda>\"", ":", "return", "_get_lambda_source_code", "(", "vtype", ",", "dump", ")", "else", ":", "return", "vtype", ".", "__name__", "raise", "RuntimeError", "(", "\"Unexpected `vtype`: %r\"", "%", "vtype", ")"], "docstring": "Return the name of the provided type.\n\n        _get_type_name(int) == \"integer\"\n        _get_type_name(str) == \"string\"\n        _get_type_name(tuple) == \"tuple\"\n        _get_type_name(Exception) == \"Exception\"\n        _get_type_name(U(int, float, bool)) == \"integer|float|bool\"\n        _get_type_name(U(H2OFrame, None)) == \"?H2OFrame\"", "docstring_tokens": ["Return", "the", "name", "of", "the", "provided", "type", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/typechecks.py#L606-L647", "partition": "test", "index": 1369, "time": "2016-08-15 14:47:11"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.cbind", "original_string": "def cbind(self, data):\n        \"\"\"\n        Append data to this frame column-wise.\n\n        :param H2OFrame data: append columns of frame ``data`` to the current frame. You can also cbind a number,\n            in which case it will get converted into a constant column.\n\n        :returns: new H2OFrame with all frames in ``data`` appended column-wise.\n        \"\"\"\n        assert_is_type(data, H2OFrame, numeric, [H2OFrame, numeric])\n        frames = [data] if not isinstance(data, list) else data\n        new_cols = list(self.columns)\n        new_types = dict(self.types)\n        for frame in frames:\n            if isinstance(frame, H2OFrame):\n                if frame.nrow != self.nrow:\n                    raise H2OValueError(\"Cannot bind a dataframe with %d rows to a data frame with %d rows: \"\n                                        \"the number of rows should match\" % (frame.nrow, self.nrow))\n                new_cols += frame.columns\n                new_types.update(frame.types)\n            else:\n                new_cols += [None]\n        unique_cols = set(new_cols)\n        fr = H2OFrame._expr(expr=ExprNode(\"cbind\", self, *frames), cache=self._ex._cache)\n        fr._ex._cache.ncols = len(new_cols)\n        if len(new_cols) == len(unique_cols) and None not in unique_cols:\n            fr._ex._cache.names = new_cols\n            fr._ex._cache.types = new_types\n        else:\n            # Invalidate names and types since they contain duplicate / unknown names, and the server will choose those.\n            fr._ex._cache.names = None\n            fr._ex._cache.types = None\n        return fr", "language": "python", "code": "def cbind(self, data):\n        \"\"\"\n        Append data to this frame column-wise.\n\n        :param H2OFrame data: append columns of frame ``data`` to the current frame. You can also cbind a number,\n            in which case it will get converted into a constant column.\n\n        :returns: new H2OFrame with all frames in ``data`` appended column-wise.\n        \"\"\"\n        assert_is_type(data, H2OFrame, numeric, [H2OFrame, numeric])\n        frames = [data] if not isinstance(data, list) else data\n        new_cols = list(self.columns)\n        new_types = dict(self.types)\n        for frame in frames:\n            if isinstance(frame, H2OFrame):\n                if frame.nrow != self.nrow:\n                    raise H2OValueError(\"Cannot bind a dataframe with %d rows to a data frame with %d rows: \"\n                                        \"the number of rows should match\" % (frame.nrow, self.nrow))\n                new_cols += frame.columns\n                new_types.update(frame.types)\n            else:\n                new_cols += [None]\n        unique_cols = set(new_cols)\n        fr = H2OFrame._expr(expr=ExprNode(\"cbind\", self, *frames), cache=self._ex._cache)\n        fr._ex._cache.ncols = len(new_cols)\n        if len(new_cols) == len(unique_cols) and None not in unique_cols:\n            fr._ex._cache.names = new_cols\n            fr._ex._cache.types = new_types\n        else:\n            # Invalidate names and types since they contain duplicate / unknown names, and the server will choose those.\n            fr._ex._cache.names = None\n            fr._ex._cache.types = None\n        return fr", "code_tokens": ["def", "cbind", "(", "self", ",", "data", ")", ":", "assert_is_type", "(", "data", ",", "H2OFrame", ",", "numeric", ",", "[", "H2OFrame", ",", "numeric", "]", ")", "frames", "=", "[", "data", "]", "if", "not", "isinstance", "(", "data", ",", "list", ")", "else", "data", "new_cols", "=", "list", "(", "self", ".", "columns", ")", "new_types", "=", "dict", "(", "self", ".", "types", ")", "for", "frame", "in", "frames", ":", "if", "isinstance", "(", "frame", ",", "H2OFrame", ")", ":", "if", "frame", ".", "nrow", "!=", "self", ".", "nrow", ":", "raise", "H2OValueError", "(", "\"Cannot bind a dataframe with %d rows to a data frame with %d rows: \"", "\"the number of rows should match\"", "%", "(", "frame", ".", "nrow", ",", "self", ".", "nrow", ")", ")", "new_cols", "+=", "frame", ".", "columns", "new_types", ".", "update", "(", "frame", ".", "types", ")", "else", ":", "new_cols", "+=", "[", "None", "]", "unique_cols", "=", "set", "(", "new_cols", ")", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"cbind\"", ",", "self", ",", "*", "frames", ")", ",", "cache", "=", "self", ".", "_ex", ".", "_cache", ")", "fr", ".", "_ex", ".", "_cache", ".", "ncols", "=", "len", "(", "new_cols", ")", "if", "len", "(", "new_cols", ")", "==", "len", "(", "unique_cols", ")", "and", "None", "not", "in", "unique_cols", ":", "fr", ".", "_ex", ".", "_cache", ".", "names", "=", "new_cols", "fr", ".", "_ex", ".", "_cache", ".", "types", "=", "new_types", "else", ":", "# Invalidate names and types since they contain duplicate / unknown names, and the server will choose those.", "fr", ".", "_ex", ".", "_cache", ".", "names", "=", "None", "fr", ".", "_ex", ".", "_cache", ".", "types", "=", "None", "return", "fr"], "docstring": "Append data to this frame column-wise.\n\n        :param H2OFrame data: append columns of frame ``data`` to the current frame. You can also cbind a number,\n            in which case it will get converted into a constant column.\n\n        :returns: new H2OFrame with all frames in ``data`` appended column-wise.", "docstring_tokens": ["Append", "data", "to", "this", "frame", "column", "-", "wise", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1695-L1727", "partition": "test", "index": 1411, "time": "2016-08-17 09:35:17"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.get_frame", "original_string": "def get_frame(frame_id, rows=10, rows_offset=0, cols=-1, full_cols=-1, cols_offset=0, light=False):\n        \"\"\"\n        Retrieve an existing H2OFrame from the H2O cluster using the frame's id.\n\n        :param str frame_id: id of the frame to retrieve\n        :param int rows: number of rows to fetch for preview (10 by default)\n        :param int rows_offset: offset to fetch rows from (0 by default)\n        :param int cols: number of columns to fetch (all by default)\n        :param full_cols: number of columns to fetch together with backed data\n        :param int cols_offset: offset to fetch rows from (0 by default)\n        :param bool light: wether to use light frame endpoint or not\n        :returns: an existing H2OFrame with the id provided; or None if such frame doesn't exist.\n        \"\"\"\n        fr = H2OFrame()\n        fr._ex._cache._id = frame_id\n        try:\n            fr._ex._cache.fill(rows=rows, rows_offset=rows_offset, cols=cols, full_cols=full_cols, cols_offset=cols_offset, light=light)\n        except EnvironmentError:\n            return None\n        return fr", "language": "python", "code": "def get_frame(frame_id, rows=10, rows_offset=0, cols=-1, full_cols=-1, cols_offset=0, light=False):\n        \"\"\"\n        Retrieve an existing H2OFrame from the H2O cluster using the frame's id.\n\n        :param str frame_id: id of the frame to retrieve\n        :param int rows: number of rows to fetch for preview (10 by default)\n        :param int rows_offset: offset to fetch rows from (0 by default)\n        :param int cols: number of columns to fetch (all by default)\n        :param full_cols: number of columns to fetch together with backed data\n        :param int cols_offset: offset to fetch rows from (0 by default)\n        :param bool light: wether to use light frame endpoint or not\n        :returns: an existing H2OFrame with the id provided; or None if such frame doesn't exist.\n        \"\"\"\n        fr = H2OFrame()\n        fr._ex._cache._id = frame_id\n        try:\n            fr._ex._cache.fill(rows=rows, rows_offset=rows_offset, cols=cols, full_cols=full_cols, cols_offset=cols_offset, light=light)\n        except EnvironmentError:\n            return None\n        return fr", "code_tokens": ["def", "get_frame", "(", "frame_id", ",", "rows", "=", "10", ",", "rows_offset", "=", "0", ",", "cols", "=", "-", "1", ",", "full_cols", "=", "-", "1", ",", "cols_offset", "=", "0", ",", "light", "=", "False", ")", ":", "fr", "=", "H2OFrame", "(", ")", "fr", ".", "_ex", ".", "_cache", ".", "_id", "=", "frame_id", "try", ":", "fr", ".", "_ex", ".", "_cache", ".", "fill", "(", "rows", "=", "rows", ",", "rows_offset", "=", "rows_offset", ",", "cols", "=", "cols", ",", "full_cols", "=", "full_cols", ",", "cols_offset", "=", "cols_offset", ",", "light", "=", "light", ")", "except", "EnvironmentError", ":", "return", "None", "return", "fr"], "docstring": "Retrieve an existing H2OFrame from the H2O cluster using the frame's id.\n\n        :param str frame_id: id of the frame to retrieve\n        :param int rows: number of rows to fetch for preview (10 by default)\n        :param int rows_offset: offset to fetch rows from (0 by default)\n        :param int cols: number of columns to fetch (all by default)\n        :param full_cols: number of columns to fetch together with backed data\n        :param int cols_offset: offset to fetch rows from (0 by default)\n        :param bool light: wether to use light frame endpoint or not\n        :returns: an existing H2OFrame with the id provided; or None if such frame doesn't exist.", "docstring_tokens": ["Retrieve", "an", "existing", "H2OFrame", "from", "the", "H2O", "cluster", "using", "the", "frame", "s", "id", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L194-L213", "partition": "test", "index": 1388, "time": "2016-08-17 09:35:17"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/typechecks.py", "func_name": "_get_lambda_source_code", "original_string": "def _get_lambda_source_code(lambda_fn, src):\n    \"\"\"Attempt to find the source code of the ``lambda_fn`` within the string ``src``.\"\"\"\n    def gen_lambdas():\n        def gen():\n            yield src + \"\\n\"\n\n        g = gen()\n        step = 0\n        tokens = []\n        for tok in tokenize.generate_tokens(getattr(g, \"next\", getattr(g, \"__next__\", None))):\n            if step == 0:\n                if tok[0] == tokenize.NAME and tok[1] == \"lambda\":\n                    step = 1\n                    tokens = [tok]\n                    level = 0\n            elif step == 1:\n                if tok[0] == tokenize.NAME:\n                    tokens.append(tok)\n                    step = 2\n                else:\n                    step = 0\n            elif step == 2:\n                if tok[0] == tokenize.OP and tok[1] == \":\":\n                    tokens.append(tok)\n                    step = 3\n                else:\n                    step = 0\n            elif step == 3:\n                if level == 0 and (tok[0] == tokenize.OP and tok[1] in \",)\" or tok[0] == tokenize.ENDMARKER):\n                    yield tokenize.untokenize(tokens).strip()\n                    step = 0\n                else:\n                    tokens.append(tok)\n                    if tok[0] == tokenize.OP:\n                        if tok[1] in \"[({\": level += 1\n                        if tok[1] in \"])}\": level -= 1\n        assert not tokens\n\n    actual_code = lambda_fn.__code__.co_code\n    for lambda_src in gen_lambdas():\n        try:\n            fn = eval(lambda_src, globals(), locals())\n            if fn.__code__.co_code == actual_code:\n                return lambda_src.split(\":\", 1)[1].strip()\n        except Exception:\n            pass\n    return \"<lambda>\"", "language": "python", "code": "def _get_lambda_source_code(lambda_fn, src):\n    \"\"\"Attempt to find the source code of the ``lambda_fn`` within the string ``src``.\"\"\"\n    def gen_lambdas():\n        def gen():\n            yield src + \"\\n\"\n\n        g = gen()\n        step = 0\n        tokens = []\n        for tok in tokenize.generate_tokens(getattr(g, \"next\", getattr(g, \"__next__\", None))):\n            if step == 0:\n                if tok[0] == tokenize.NAME and tok[1] == \"lambda\":\n                    step = 1\n                    tokens = [tok]\n                    level = 0\n            elif step == 1:\n                if tok[0] == tokenize.NAME:\n                    tokens.append(tok)\n                    step = 2\n                else:\n                    step = 0\n            elif step == 2:\n                if tok[0] == tokenize.OP and tok[1] == \":\":\n                    tokens.append(tok)\n                    step = 3\n                else:\n                    step = 0\n            elif step == 3:\n                if level == 0 and (tok[0] == tokenize.OP and tok[1] in \",)\" or tok[0] == tokenize.ENDMARKER):\n                    yield tokenize.untokenize(tokens).strip()\n                    step = 0\n                else:\n                    tokens.append(tok)\n                    if tok[0] == tokenize.OP:\n                        if tok[1] in \"[({\": level += 1\n                        if tok[1] in \"])}\": level -= 1\n        assert not tokens\n\n    actual_code = lambda_fn.__code__.co_code\n    for lambda_src in gen_lambdas():\n        try:\n            fn = eval(lambda_src, globals(), locals())\n            if fn.__code__.co_code == actual_code:\n                return lambda_src.split(\":\", 1)[1].strip()\n        except Exception:\n            pass\n    return \"<lambda>\"", "code_tokens": ["def", "_get_lambda_source_code", "(", "lambda_fn", ",", "src", ")", ":", "def", "gen_lambdas", "(", ")", ":", "def", "gen", "(", ")", ":", "yield", "src", "+", "\"\\n\"", "g", "=", "gen", "(", ")", "step", "=", "0", "tokens", "=", "[", "]", "for", "tok", "in", "tokenize", ".", "generate_tokens", "(", "getattr", "(", "g", ",", "\"next\"", ",", "getattr", "(", "g", ",", "\"__next__\"", ",", "None", ")", ")", ")", ":", "if", "step", "==", "0", ":", "if", "tok", "[", "0", "]", "==", "tokenize", ".", "NAME", "and", "tok", "[", "1", "]", "==", "\"lambda\"", ":", "step", "=", "1", "tokens", "=", "[", "tok", "]", "level", "=", "0", "elif", "step", "==", "1", ":", "if", "tok", "[", "0", "]", "==", "tokenize", ".", "NAME", ":", "tokens", ".", "append", "(", "tok", ")", "step", "=", "2", "else", ":", "step", "=", "0", "elif", "step", "==", "2", ":", "if", "tok", "[", "0", "]", "==", "tokenize", ".", "OP", "and", "tok", "[", "1", "]", "==", "\":\"", ":", "tokens", ".", "append", "(", "tok", ")", "step", "=", "3", "else", ":", "step", "=", "0", "elif", "step", "==", "3", ":", "if", "level", "==", "0", "and", "(", "tok", "[", "0", "]", "==", "tokenize", ".", "OP", "and", "tok", "[", "1", "]", "in", "\",)\"", "or", "tok", "[", "0", "]", "==", "tokenize", ".", "ENDMARKER", ")", ":", "yield", "tokenize", ".", "untokenize", "(", "tokens", ")", ".", "strip", "(", ")", "step", "=", "0", "else", ":", "tokens", ".", "append", "(", "tok", ")", "if", "tok", "[", "0", "]", "==", "tokenize", ".", "OP", ":", "if", "tok", "[", "1", "]", "in", "\"[({\"", ":", "level", "+=", "1", "if", "tok", "[", "1", "]", "in", "\"])}\"", ":", "level", "-=", "1", "assert", "not", "tokens", "actual_code", "=", "lambda_fn", ".", "__code__", ".", "co_code", "for", "lambda_src", "in", "gen_lambdas", "(", ")", ":", "try", ":", "fn", "=", "eval", "(", "lambda_src", ",", "globals", "(", ")", ",", "locals", "(", ")", ")", "if", "fn", ".", "__code__", ".", "co_code", "==", "actual_code", ":", "return", "lambda_src", ".", "split", "(", "\":\"", ",", "1", ")", "[", "1", "]", ".", "strip", "(", ")", "except", "Exception", ":", "pass", "return", "\"<lambda>\""], "docstring": "Attempt to find the source code of the ``lambda_fn`` within the string ``src``.", "docstring_tokens": ["Attempt", "to", "find", "the", "source", "code", "of", "the", "lambda_fn", "within", "the", "string", "src", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/typechecks.py#L650-L696", "partition": "test", "index": 1370, "time": "2016-08-17 10:13:24"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.default_params", "original_string": "def default_params(self):\n        \"\"\"Dictionary of the default parameters of the model.\"\"\"\n        params = {}\n        for p in self.parms:\n            params[p] = self.parms[p][\"default_value\"]\n        return params", "language": "python", "code": "def default_params(self):\n        \"\"\"Dictionary of the default parameters of the model.\"\"\"\n        params = {}\n        for p in self.parms:\n            params[p] = self.parms[p][\"default_value\"]\n        return params", "code_tokens": ["def", "default_params", "(", "self", ")", ":", "params", "=", "{", "}", "for", "p", "in", "self", ".", "parms", ":", "params", "[", "p", "]", "=", "self", ".", "parms", "[", "p", "]", "[", "\"default_value\"", "]", "return", "params"], "docstring": "Dictionary of the default parameters of the model.", "docstring_tokens": ["Dictionary", "of", "the", "default", "parameters", "of", "the", "model", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L68-L73", "partition": "test", "index": 1533, "time": "2016-08-19 17:11:24"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.actual_params", "original_string": "def actual_params(self):\n        \"\"\"Dictionary of actual parameters of the model.\"\"\"\n        params_to_select = {\"model_id\": \"name\",\n                            \"response_column\": \"column_name\",\n                            \"training_frame\": \"name\",\n                            \"validation_frame\": \"name\"}\n        params = {}\n        for p in self.parms:\n            if p in params_to_select.keys():\n                params[p] = self.parms[p][\"actual_value\"].get(params_to_select[p], None)\n            else:\n                params[p] = self.parms[p][\"actual_value\"]\n        return params", "language": "python", "code": "def actual_params(self):\n        \"\"\"Dictionary of actual parameters of the model.\"\"\"\n        params_to_select = {\"model_id\": \"name\",\n                            \"response_column\": \"column_name\",\n                            \"training_frame\": \"name\",\n                            \"validation_frame\": \"name\"}\n        params = {}\n        for p in self.parms:\n            if p in params_to_select.keys():\n                params[p] = self.parms[p][\"actual_value\"].get(params_to_select[p], None)\n            else:\n                params[p] = self.parms[p][\"actual_value\"]\n        return params", "code_tokens": ["def", "actual_params", "(", "self", ")", ":", "params_to_select", "=", "{", "\"model_id\"", ":", "\"name\"", ",", "\"response_column\"", ":", "\"column_name\"", ",", "\"training_frame\"", ":", "\"name\"", ",", "\"validation_frame\"", ":", "\"name\"", "}", "params", "=", "{", "}", "for", "p", "in", "self", ".", "parms", ":", "if", "p", "in", "params_to_select", ".", "keys", "(", ")", ":", "params", "[", "p", "]", "=", "self", ".", "parms", "[", "p", "]", "[", "\"actual_value\"", "]", ".", "get", "(", "params_to_select", "[", "p", "]", ",", "None", ")", "else", ":", "params", "[", "p", "]", "=", "self", ".", "parms", "[", "p", "]", "[", "\"actual_value\"", "]", "return", "params"], "docstring": "Dictionary of actual parameters of the model.", "docstring_tokens": ["Dictionary", "of", "actual", "parameters", "of", "the", "model", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L77-L89", "partition": "test", "index": 1534, "time": "2016-08-19 17:11:24"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/pymagic.py", "func_name": "main", "original_string": "def main():\n    \"\"\"Executed when script is run as-is.\"\"\"\n    # magic_files = {}\n    for filename in locate_files(ROOT_DIR):\n        print(\"Processing %s\" % filename)\n        with open(filename, \"rt\") as f:\n            tokens = list(tokenize.generate_tokens(f.readline))\n            text1 = tokenize.untokenize(tokens)\n            ntokens = normalize_tokens(tokens)\n            text2 = tokenize.untokenize(ntokens)\n            assert text1 == text2", "language": "python", "code": "def main():\n    \"\"\"Executed when script is run as-is.\"\"\"\n    # magic_files = {}\n    for filename in locate_files(ROOT_DIR):\n        print(\"Processing %s\" % filename)\n        with open(filename, \"rt\") as f:\n            tokens = list(tokenize.generate_tokens(f.readline))\n            text1 = tokenize.untokenize(tokens)\n            ntokens = normalize_tokens(tokens)\n            text2 = tokenize.untokenize(ntokens)\n            assert text1 == text2", "code_tokens": ["def", "main", "(", ")", ":", "# magic_files = {}", "for", "filename", "in", "locate_files", "(", "ROOT_DIR", ")", ":", "print", "(", "\"Processing %s\"", "%", "filename", ")", "with", "open", "(", "filename", ",", "\"rt\"", ")", "as", "f", ":", "tokens", "=", "list", "(", "tokenize", ".", "generate_tokens", "(", "f", ".", "readline", ")", ")", "text1", "=", "tokenize", ".", "untokenize", "(", "tokens", ")", "ntokens", "=", "normalize_tokens", "(", "tokens", ")", "text2", "=", "tokenize", ".", "untokenize", "(", "ntokens", ")", "assert", "text1", "==", "text2"], "docstring": "Executed when script is run as-is.", "docstring_tokens": ["Executed", "when", "script", "is", "run", "as", "-", "is", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/pymagic.py#L70-L80", "partition": "test", "index": 1575, "time": "2016-08-24 15:16:21"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/pyparser.py", "func_name": "ParsedBase.unparse", "original_string": "def unparse(self):\n        \"\"\"Convert the parsed representation back into the source code.\"\"\"\n        ut = Untokenizer(start_row=self._tokens[0].start_row)\n        self._unparse(ut)\n        return ut.result()", "language": "python", "code": "def unparse(self):\n        \"\"\"Convert the parsed representation back into the source code.\"\"\"\n        ut = Untokenizer(start_row=self._tokens[0].start_row)\n        self._unparse(ut)\n        return ut.result()", "code_tokens": ["def", "unparse", "(", "self", ")", ":", "ut", "=", "Untokenizer", "(", "start_row", "=", "self", ".", "_tokens", "[", "0", "]", ".", "start_row", ")", "self", ".", "_unparse", "(", "ut", ")", "return", "ut", ".", "result", "(", ")"], "docstring": "Convert the parsed representation back into the source code.", "docstring_tokens": ["Convert", "the", "parsed", "representation", "back", "into", "the", "source", "code", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/pyparser.py#L365-L369", "partition": "test", "index": 1448, "time": "2016-08-24 15:16:21"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/pyparser.py", "func_name": "Token.move", "original_string": "def move(self, drow, dcol=0):\n        \"\"\"Move the token by `drow` rows and `dcol` columns.\"\"\"\n        self._start_row += drow\n        self._start_col += dcol\n        self._end_row += drow\n        self._end_col += dcol", "language": "python", "code": "def move(self, drow, dcol=0):\n        \"\"\"Move the token by `drow` rows and `dcol` columns.\"\"\"\n        self._start_row += drow\n        self._start_col += dcol\n        self._end_row += drow\n        self._end_col += dcol", "code_tokens": ["def", "move", "(", "self", ",", "drow", ",", "dcol", "=", "0", ")", ":", "self", ".", "_start_row", "+=", "drow", "self", ".", "_start_col", "+=", "dcol", "self", ".", "_end_row", "+=", "drow", "self", ".", "_end_col", "+=", "dcol"], "docstring": "Move the token by `drow` rows and `dcol` columns.", "docstring_tokens": ["Move", "the", "token", "by", "drow", "rows", "and", "dcol", "columns", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/pyparser.py#L246-L251", "partition": "test", "index": 1447, "time": "2016-08-24 15:16:21"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/pymagic.py", "func_name": "find_magic_in_file", "original_string": "def find_magic_in_file(filename):\n    \"\"\"\n    Search the file for any magic incantations.\n\n    :param filename: file to search\n    :returns: a tuple containing the spell and then maybe some extra words (or None if no magic present)\n    \"\"\"\n    with open(filename, \"rt\", encoding=\"utf-8\") as f:\n        for line in f:\n            if line.startswith(\"#\"):\n                comment = line[1:].strip()\n                if comment.startswith(\"~~~~* \") or comment.startswith(\"----* \") or comment.startswith(\"====* \"):\n                    spell = comment[5:].strip()\n                    return tuple(spell.split())\n            else:\n                break\n    return None", "language": "python", "code": "def find_magic_in_file(filename):\n    \"\"\"\n    Search the file for any magic incantations.\n\n    :param filename: file to search\n    :returns: a tuple containing the spell and then maybe some extra words (or None if no magic present)\n    \"\"\"\n    with open(filename, \"rt\", encoding=\"utf-8\") as f:\n        for line in f:\n            if line.startswith(\"#\"):\n                comment = line[1:].strip()\n                if comment.startswith(\"~~~~* \") or comment.startswith(\"----* \") or comment.startswith(\"====* \"):\n                    spell = comment[5:].strip()\n                    return tuple(spell.split())\n            else:\n                break\n    return None", "code_tokens": ["def", "find_magic_in_file", "(", "filename", ")", ":", "with", "open", "(", "filename", ",", "\"rt\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "for", "line", "in", "f", ":", "if", "line", ".", "startswith", "(", "\"#\"", ")", ":", "comment", "=", "line", "[", "1", ":", "]", ".", "strip", "(", ")", "if", "comment", ".", "startswith", "(", "\"~~~~* \"", ")", "or", "comment", ".", "startswith", "(", "\"----* \"", ")", "or", "comment", ".", "startswith", "(", "\"====* \"", ")", ":", "spell", "=", "comment", "[", "5", ":", "]", ".", "strip", "(", ")", "return", "tuple", "(", "spell", ".", "split", "(", ")", ")", "else", ":", "break", "return", "None"], "docstring": "Search the file for any magic incantations.\n\n    :param filename: file to search\n    :returns: a tuple containing the spell and then maybe some extra words (or None if no magic present)", "docstring_tokens": ["Search", "the", "file", "for", "any", "magic", "incantations", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/pymagic.py#L36-L52", "partition": "test", "index": 1574, "time": "2016-08-24 15:16:21"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/pyparser.py", "func_name": "parse_file", "original_string": "def parse_file(filename):\n    \"\"\"Parse the provided file, and return Code object.\"\"\"\n    assert isinstance(filename, _str_type), \"`filename` parameter should be a string, got %r\" % type(filename)\n    with open(filename, \"rt\", encoding=\"utf-8\") as f:\n        return Code(_tokenize(f.readline))", "language": "python", "code": "def parse_file(filename):\n    \"\"\"Parse the provided file, and return Code object.\"\"\"\n    assert isinstance(filename, _str_type), \"`filename` parameter should be a string, got %r\" % type(filename)\n    with open(filename, \"rt\", encoding=\"utf-8\") as f:\n        return Code(_tokenize(f.readline))", "code_tokens": ["def", "parse_file", "(", "filename", ")", ":", "assert", "isinstance", "(", "filename", ",", "_str_type", ")", ",", "\"`filename` parameter should be a string, got %r\"", "%", "type", "(", "filename", ")", "with", "open", "(", "filename", ",", "\"rt\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "return", "Code", "(", "_tokenize", "(", "f", ".", "readline", ")", ")"], "docstring": "Parse the provided file, and return Code object.", "docstring_tokens": ["Parse", "the", "provided", "file", "and", "return", "Code", "object", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/pyparser.py#L50-L54", "partition": "test", "index": 1446, "time": "2016-08-24 15:16:21"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/pyparser.py", "func_name": "parse_text", "original_string": "def parse_text(text):\n    \"\"\"Parse code from a string of text.\"\"\"\n    assert isinstance(text, _str_type), \"`text` parameter should be a string, got %r\" % type(text)\n    gen = iter(text.splitlines(True))  # True = keep newlines\n    readline = gen.next if hasattr(gen, \"next\") else gen.__next__\n    return Code(_tokenize(readline))", "language": "python", "code": "def parse_text(text):\n    \"\"\"Parse code from a string of text.\"\"\"\n    assert isinstance(text, _str_type), \"`text` parameter should be a string, got %r\" % type(text)\n    gen = iter(text.splitlines(True))  # True = keep newlines\n    readline = gen.next if hasattr(gen, \"next\") else gen.__next__\n    return Code(_tokenize(readline))", "code_tokens": ["def", "parse_text", "(", "text", ")", ":", "assert", "isinstance", "(", "text", ",", "_str_type", ")", ",", "\"`text` parameter should be a string, got %r\"", "%", "type", "(", "text", ")", "gen", "=", "iter", "(", "text", ".", "splitlines", "(", "True", ")", ")", "# True = keep newlines", "readline", "=", "gen", ".", "next", "if", "hasattr", "(", "gen", ",", "\"next\"", ")", "else", "gen", ".", "__next__", "return", "Code", "(", "_tokenize", "(", "readline", ")", ")"], "docstring": "Parse code from a string of text.", "docstring_tokens": ["Parse", "code", "from", "a", "string", "of", "text", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/pyparser.py#L42-L47", "partition": "test", "index": 1445, "time": "2016-08-24 15:16:21"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/pymagic.py", "func_name": "locate_files", "original_string": "def locate_files(root_dir):\n    \"\"\"Find all python files in the given directory and all subfolders.\"\"\"\n    all_files = []\n    root_dir = os.path.abspath(root_dir)\n    for dir_name, subdirs, files in os.walk(root_dir):\n        for f in files:\n            if f.endswith(\".py\"):\n                all_files.append(os.path.join(dir_name, f))\n    return all_files", "language": "python", "code": "def locate_files(root_dir):\n    \"\"\"Find all python files in the given directory and all subfolders.\"\"\"\n    all_files = []\n    root_dir = os.path.abspath(root_dir)\n    for dir_name, subdirs, files in os.walk(root_dir):\n        for f in files:\n            if f.endswith(\".py\"):\n                all_files.append(os.path.join(dir_name, f))\n    return all_files", "code_tokens": ["def", "locate_files", "(", "root_dir", ")", ":", "all_files", "=", "[", "]", "root_dir", "=", "os", ".", "path", ".", "abspath", "(", "root_dir", ")", "for", "dir_name", ",", "subdirs", ",", "files", "in", "os", ".", "walk", "(", "root_dir", ")", ":", "for", "f", "in", "files", ":", "if", "f", ".", "endswith", "(", "\".py\"", ")", ":", "all_files", ".", "append", "(", "os", ".", "path", ".", "join", "(", "dir_name", ",", "f", ")", ")", "return", "all_files"], "docstring": "Find all python files in the given directory and all subfolders.", "docstring_tokens": ["Find", "all", "python", "files", "in", "the", "given", "directory", "and", "all", "subfolders", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/pymagic.py#L24-L32", "partition": "test", "index": 1573, "time": "2016-08-24 15:16:21"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/estimators/estimator_base.py", "func_name": "H2OEstimator.get_params", "original_string": "def get_params(self, deep=True):\n        \"\"\"\n        Obtain parameters for this estimator.\n\n        Used primarily for sklearn Pipelines and sklearn grid search.\n\n        :param deep: If True, return parameters of all sub-objects that are estimators.\n\n        :returns: A dict of parameters\n        \"\"\"\n        out = dict()\n        for key, value in self.parms.items():\n            if deep and isinstance(value, H2OEstimator):\n                deep_items = list(value.get_params().items())\n                out.update((key + \"__\" + k, val) for k, val in deep_items)\n            out[key] = value\n        return out", "language": "python", "code": "def get_params(self, deep=True):\n        \"\"\"\n        Obtain parameters for this estimator.\n\n        Used primarily for sklearn Pipelines and sklearn grid search.\n\n        :param deep: If True, return parameters of all sub-objects that are estimators.\n\n        :returns: A dict of parameters\n        \"\"\"\n        out = dict()\n        for key, value in self.parms.items():\n            if deep and isinstance(value, H2OEstimator):\n                deep_items = list(value.get_params().items())\n                out.update((key + \"__\" + k, val) for k, val in deep_items)\n            out[key] = value\n        return out", "code_tokens": ["def", "get_params", "(", "self", ",", "deep", "=", "True", ")", ":", "out", "=", "dict", "(", ")", "for", "key", ",", "value", "in", "self", ".", "parms", ".", "items", "(", ")", ":", "if", "deep", "and", "isinstance", "(", "value", ",", "H2OEstimator", ")", ":", "deep_items", "=", "list", "(", "value", ".", "get_params", "(", ")", ".", "items", "(", ")", ")", "out", ".", "update", "(", "(", "key", "+", "\"__\"", "+", "k", ",", "val", ")", "for", "k", ",", "val", "in", "deep_items", ")", "out", "[", "key", "]", "=", "value", "return", "out"], "docstring": "Obtain parameters for this estimator.\n\n        Used primarily for sklearn Pipelines and sklearn grid search.\n\n        :param deep: If True, return parameters of all sub-objects that are estimators.\n\n        :returns: A dict of parameters", "docstring_tokens": ["Obtain", "parameters", "for", "this", "estimator", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/estimators/estimator_base.py#L353-L369", "partition": "test", "index": 1348, "time": "2016-08-25 15:32:40"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/estimators/estimator_base.py", "func_name": "H2OEstimator.train", "original_string": "def train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None,\n              weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None,\n              model_id=None, verbose=False):\n        \"\"\"\n        Train the H2O model.\n\n        :param x: A list of column names or indices indicating the predictor columns.\n        :param y: An index or a column name indicating the response column.\n        :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n            additional columns specified by fold, offset, and weights).\n        :param offset_column: The name or index of the column in training_frame that holds the offsets.\n        :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n            assignments.\n        :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n        :param validation_frame: H2OFrame with validation data to be scored on while training.\n        :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n        :param bool verbose: Print scoring history to stdout. Defaults to False.\n        \"\"\"\n        self._train(x=x, y=y, training_frame=training_frame, offset_column=offset_column, fold_column=fold_column,\n                    weights_column=weights_column, validation_frame=validation_frame, max_runtime_secs=max_runtime_secs, \n                    ignored_columns=ignored_columns, model_id=model_id, verbose=verbose)", "language": "python", "code": "def train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None,\n              weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None,\n              model_id=None, verbose=False):\n        \"\"\"\n        Train the H2O model.\n\n        :param x: A list of column names or indices indicating the predictor columns.\n        :param y: An index or a column name indicating the response column.\n        :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n            additional columns specified by fold, offset, and weights).\n        :param offset_column: The name or index of the column in training_frame that holds the offsets.\n        :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n            assignments.\n        :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n        :param validation_frame: H2OFrame with validation data to be scored on while training.\n        :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n        :param bool verbose: Print scoring history to stdout. Defaults to False.\n        \"\"\"\n        self._train(x=x, y=y, training_frame=training_frame, offset_column=offset_column, fold_column=fold_column,\n                    weights_column=weights_column, validation_frame=validation_frame, max_runtime_secs=max_runtime_secs, \n                    ignored_columns=ignored_columns, model_id=model_id, verbose=verbose)", "code_tokens": ["def", "train", "(", "self", ",", "x", "=", "None", ",", "y", "=", "None", ",", "training_frame", "=", "None", ",", "offset_column", "=", "None", ",", "fold_column", "=", "None", ",", "weights_column", "=", "None", ",", "validation_frame", "=", "None", ",", "max_runtime_secs", "=", "None", ",", "ignored_columns", "=", "None", ",", "model_id", "=", "None", ",", "verbose", "=", "False", ")", ":", "self", ".", "_train", "(", "x", "=", "x", ",", "y", "=", "y", ",", "training_frame", "=", "training_frame", ",", "offset_column", "=", "offset_column", ",", "fold_column", "=", "fold_column", ",", "weights_column", "=", "weights_column", ",", "validation_frame", "=", "validation_frame", ",", "max_runtime_secs", "=", "max_runtime_secs", ",", "ignored_columns", "=", "ignored_columns", ",", "model_id", "=", "model_id", ",", "verbose", "=", "verbose", ")"], "docstring": "Train the H2O model.\n\n        :param x: A list of column names or indices indicating the predictor columns.\n        :param y: An index or a column name indicating the response column.\n        :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n            additional columns specified by fold, offset, and weights).\n        :param offset_column: The name or index of the column in training_frame that holds the offsets.\n        :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n            assignments.\n        :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n        :param validation_frame: H2OFrame with validation data to be scored on while training.\n        :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n        :param bool verbose: Print scoring history to stdout. Defaults to False.", "docstring_tokens": ["Train", "the", "H2O", "model", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/estimators/estimator_base.py#L89-L109", "partition": "test", "index": 1346, "time": "2016-08-25 15:32:40"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/estimators/estimator_base.py", "func_name": "H2OEstimator.join", "original_string": "def join(self):\n        \"\"\"Wait until job's completion.\"\"\"\n        self._future = False\n        self._job.poll()\n        model_key = self._job.dest_key\n        self._job = None\n        model_json = h2o.api(\"GET /%d/Models/%s\" % (self._rest_version, model_key))[\"models\"][0]\n        self._resolve_model(model_key, model_json)", "language": "python", "code": "def join(self):\n        \"\"\"Wait until job's completion.\"\"\"\n        self._future = False\n        self._job.poll()\n        model_key = self._job.dest_key\n        self._job = None\n        model_json = h2o.api(\"GET /%d/Models/%s\" % (self._rest_version, model_key))[\"models\"][0]\n        self._resolve_model(model_key, model_json)", "code_tokens": ["def", "join", "(", "self", ")", ":", "self", ".", "_future", "=", "False", "self", ".", "_job", ".", "poll", "(", ")", "model_key", "=", "self", ".", "_job", ".", "dest_key", "self", ".", "_job", "=", "None", "model_json", "=", "h2o", ".", "api", "(", "\"GET /%d/Models/%s\"", "%", "(", "self", ".", "_rest_version", ",", "model_key", ")", ")", "[", "\"models\"", "]", "[", "0", "]", "self", ".", "_resolve_model", "(", "model_key", ",", "model_json", ")"], "docstring": "Wait until job's completion.", "docstring_tokens": ["Wait", "until", "job", "s", "completion", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/estimators/estimator_base.py#L79-L86", "partition": "test", "index": 1345, "time": "2016-08-25 15:32:40"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/estimators/estimator_base.py", "func_name": "H2OEstimator.fit", "original_string": "def fit(self, X, y=None, **params):\n        \"\"\"\n        Fit an H2O model as part of a scikit-learn pipeline or grid search.\n\n        A warning will be issued if a caller other than sklearn attempts to use this method.\n\n        :param H2OFrame X: An H2OFrame consisting of the predictor variables.\n        :param H2OFrame y: An H2OFrame consisting of the response variable.\n        :param params: Extra arguments.\n        :returns: The current instance of H2OEstimator for method chaining.\n        \"\"\"\n        stk = inspect.stack()[1:]\n        warn = True\n        for s in stk:\n            mod = inspect.getmodule(s[0])\n            if mod:\n                warn = \"sklearn\" not in mod.__name__\n                if not warn: break\n        if warn:\n            warnings.warn(\"\\n\\n\\t`fit` is not recommended outside of the sklearn framework. Use `train` instead.\",\n                          UserWarning, stacklevel=2)\n        training_frame = X.cbind(y) if y is not None else X\n        x = X.names\n        y = y.names[0] if y is not None else None\n        self.train(x, y, training_frame, **params)\n        return self", "language": "python", "code": "def fit(self, X, y=None, **params):\n        \"\"\"\n        Fit an H2O model as part of a scikit-learn pipeline or grid search.\n\n        A warning will be issued if a caller other than sklearn attempts to use this method.\n\n        :param H2OFrame X: An H2OFrame consisting of the predictor variables.\n        :param H2OFrame y: An H2OFrame consisting of the response variable.\n        :param params: Extra arguments.\n        :returns: The current instance of H2OEstimator for method chaining.\n        \"\"\"\n        stk = inspect.stack()[1:]\n        warn = True\n        for s in stk:\n            mod = inspect.getmodule(s[0])\n            if mod:\n                warn = \"sklearn\" not in mod.__name__\n                if not warn: break\n        if warn:\n            warnings.warn(\"\\n\\n\\t`fit` is not recommended outside of the sklearn framework. Use `train` instead.\",\n                          UserWarning, stacklevel=2)\n        training_frame = X.cbind(y) if y is not None else X\n        x = X.names\n        y = y.names[0] if y is not None else None\n        self.train(x, y, training_frame, **params)\n        return self", "code_tokens": ["def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ",", "*", "*", "params", ")", ":", "stk", "=", "inspect", ".", "stack", "(", ")", "[", "1", ":", "]", "warn", "=", "True", "for", "s", "in", "stk", ":", "mod", "=", "inspect", ".", "getmodule", "(", "s", "[", "0", "]", ")", "if", "mod", ":", "warn", "=", "\"sklearn\"", "not", "in", "mod", ".", "__name__", "if", "not", "warn", ":", "break", "if", "warn", ":", "warnings", ".", "warn", "(", "\"\\n\\n\\t`fit` is not recommended outside of the sklearn framework. Use `train` instead.\"", ",", "UserWarning", ",", "stacklevel", "=", "2", ")", "training_frame", "=", "X", ".", "cbind", "(", "y", ")", "if", "y", "is", "not", "None", "else", "X", "x", "=", "X", ".", "names", "y", "=", "y", ".", "names", "[", "0", "]", "if", "y", "is", "not", "None", "else", "None", "self", ".", "train", "(", "x", ",", "y", ",", "training_frame", ",", "*", "*", "params", ")", "return", "self"], "docstring": "Fit an H2O model as part of a scikit-learn pipeline or grid search.\n\n        A warning will be issued if a caller other than sklearn attempts to use this method.\n\n        :param H2OFrame X: An H2OFrame consisting of the predictor variables.\n        :param H2OFrame y: An H2OFrame consisting of the response variable.\n        :param params: Extra arguments.\n        :returns: The current instance of H2OEstimator for method chaining.", "docstring_tokens": ["Fit", "an", "H2O", "model", "as", "part", "of", "a", "scikit", "-", "learn", "pipeline", "or", "grid", "search", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/estimators/estimator_base.py#L325-L350", "partition": "test", "index": 1347, "time": "2016-08-25 15:32:40"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/estimators/deepwater.py", "func_name": "H2ODeepWaterEstimator.available", "original_string": "def available():\n        \"\"\"Returns True if a deep water model can be built, or False otherwise.\"\"\"\n        builder_json = h2o.api(\"GET /3/ModelBuilders\", data={\"algo\": \"deepwater\"})\n        visibility = builder_json[\"model_builders\"][\"deepwater\"][\"visibility\"]\n        if visibility == \"Experimental\":\n            print(\"Cannot build a Deep Water model - no backend found.\")\n            return False\n        else:\n            return True", "language": "python", "code": "def available():\n        \"\"\"Returns True if a deep water model can be built, or False otherwise.\"\"\"\n        builder_json = h2o.api(\"GET /3/ModelBuilders\", data={\"algo\": \"deepwater\"})\n        visibility = builder_json[\"model_builders\"][\"deepwater\"][\"visibility\"]\n        if visibility == \"Experimental\":\n            print(\"Cannot build a Deep Water model - no backend found.\")\n            return False\n        else:\n            return True", "code_tokens": ["def", "available", "(", ")", ":", "builder_json", "=", "h2o", ".", "api", "(", "\"GET /3/ModelBuilders\"", ",", "data", "=", "{", "\"algo\"", ":", "\"deepwater\"", "}", ")", "visibility", "=", "builder_json", "[", "\"model_builders\"", "]", "[", "\"deepwater\"", "]", "[", "\"visibility\"", "]", "if", "visibility", "==", "\"Experimental\"", ":", "print", "(", "\"Cannot build a Deep Water model - no backend found.\"", ")", "return", "False", "else", ":", "return", "True"], "docstring": "Returns True if a deep water model can be built, or False otherwise.", "docstring_tokens": ["Returns", "True", "if", "a", "deep", "water", "model", "can", "be", "built", "or", "False", "otherwise", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/estimators/deepwater.py#L1024-L1032", "partition": "test", "index": 1581, "time": "2016-09-01 21:49:49"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.difflag1", "original_string": "def difflag1(self):\n        \"\"\"\n        Conduct a diff-1 transform on a numeric frame column.\n\n        :returns: an H2OFrame where each element is equal to the corresponding element in the source\n            frame minus the previous-row element in the same frame.\n        \"\"\"\n        if self.ncols > 1:\n            raise H2OValueError(\"Only single-column frames supported\")\n        if self.types[self.columns[0]] not in {\"real\", \"int\", \"bool\"}:\n            raise H2OValueError(\"Numeric column expected\")\n        fr = H2OFrame._expr(expr=ExprNode(\"difflag1\", self), cache=self._ex._cache)\n        return fr", "language": "python", "code": "def difflag1(self):\n        \"\"\"\n        Conduct a diff-1 transform on a numeric frame column.\n\n        :returns: an H2OFrame where each element is equal to the corresponding element in the source\n            frame minus the previous-row element in the same frame.\n        \"\"\"\n        if self.ncols > 1:\n            raise H2OValueError(\"Only single-column frames supported\")\n        if self.types[self.columns[0]] not in {\"real\", \"int\", \"bool\"}:\n            raise H2OValueError(\"Numeric column expected\")\n        fr = H2OFrame._expr(expr=ExprNode(\"difflag1\", self), cache=self._ex._cache)\n        return fr", "code_tokens": ["def", "difflag1", "(", "self", ")", ":", "if", "self", ".", "ncols", ">", "1", ":", "raise", "H2OValueError", "(", "\"Only single-column frames supported\"", ")", "if", "self", ".", "types", "[", "self", ".", "columns", "[", "0", "]", "]", "not", "in", "{", "\"real\"", ",", "\"int\"", ",", "\"bool\"", "}", ":", "raise", "H2OValueError", "(", "\"Numeric column expected\"", ")", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"difflag1\"", ",", "self", ")", ",", "cache", "=", "self", ".", "_ex", ".", "_cache", ")", "return", "fr"], "docstring": "Conduct a diff-1 transform on a numeric frame column.\n\n        :returns: an H2OFrame where each element is equal to the corresponding element in the source\n            frame minus the previous-row element in the same frame.", "docstring_tokens": ["Conduct", "a", "diff", "-", "1", "transform", "on", "a", "numeric", "frame", "column", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L3041-L3053", "partition": "test", "index": 1437, "time": "2016-09-02 18:52:52"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.download_mojo", "original_string": "def download_mojo(self, path=\".\", get_genmodel_jar=False, genmodel_name=\"\"):\n        \"\"\"\n        Download the model in MOJO format.\n\n        :param path: the path where MOJO file should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the MOJO file written.\n        \"\"\"\n        assert_is_type(path, str)\n        assert_is_type(get_genmodel_jar, bool)\n\n        if not self.have_mojo:\n            raise H2OValueError(\"Export to MOJO not supported\")\n\n        if get_genmodel_jar:\n            if genmodel_name == \"\":\n                h2o.api(\"GET /3/h2o-genmodel.jar\", save_to=os.path.join(path, \"h2o-genmodel.jar\"))\n            else:\n                h2o.api(\"GET /3/h2o-genmodel.jar\", save_to=os.path.join(path, genmodel_name))\n        return h2o.api(\"GET /3/Models/%s/mojo\" % self.model_id, save_to=path)", "language": "python", "code": "def download_mojo(self, path=\".\", get_genmodel_jar=False, genmodel_name=\"\"):\n        \"\"\"\n        Download the model in MOJO format.\n\n        :param path: the path where MOJO file should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the MOJO file written.\n        \"\"\"\n        assert_is_type(path, str)\n        assert_is_type(get_genmodel_jar, bool)\n\n        if not self.have_mojo:\n            raise H2OValueError(\"Export to MOJO not supported\")\n\n        if get_genmodel_jar:\n            if genmodel_name == \"\":\n                h2o.api(\"GET /3/h2o-genmodel.jar\", save_to=os.path.join(path, \"h2o-genmodel.jar\"))\n            else:\n                h2o.api(\"GET /3/h2o-genmodel.jar\", save_to=os.path.join(path, genmodel_name))\n        return h2o.api(\"GET /3/Models/%s/mojo\" % self.model_id, save_to=path)", "code_tokens": ["def", "download_mojo", "(", "self", ",", "path", "=", "\".\"", ",", "get_genmodel_jar", "=", "False", ",", "genmodel_name", "=", "\"\"", ")", ":", "assert_is_type", "(", "path", ",", "str", ")", "assert_is_type", "(", "get_genmodel_jar", ",", "bool", ")", "if", "not", "self", ".", "have_mojo", ":", "raise", "H2OValueError", "(", "\"Export to MOJO not supported\"", ")", "if", "get_genmodel_jar", ":", "if", "genmodel_name", "==", "\"\"", ":", "h2o", ".", "api", "(", "\"GET /3/h2o-genmodel.jar\"", ",", "save_to", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"h2o-genmodel.jar\"", ")", ")", "else", ":", "h2o", ".", "api", "(", "\"GET /3/h2o-genmodel.jar\"", ",", "save_to", "=", "os", ".", "path", ".", "join", "(", "path", ",", "genmodel_name", ")", ")", "return", "h2o", ".", "api", "(", "\"GET /3/Models/%s/mojo\"", "%", "self", ".", "model_id", ",", "save_to", "=", "path", ")"], "docstring": "Download the model in MOJO format.\n\n        :param path: the path where MOJO file should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the MOJO file written.", "docstring_tokens": ["Download", "the", "model", "in", "MOJO", "format", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L801-L821", "partition": "test", "index": 1542, "time": "2016-09-16 13:38:10"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/gen_python.py", "func_name": "normalize_enum_constant", "original_string": "def normalize_enum_constant(s):\n    \"\"\"Return enum constant `s` converted to a canonical snake-case.\"\"\"\n    if s.islower(): return s\n    if s.isupper(): return s.lower()\n    return \"\".join(ch if ch.islower() else \"_\" + ch.lower() for ch in s).strip(\"_\")", "language": "python", "code": "def normalize_enum_constant(s):\n    \"\"\"Return enum constant `s` converted to a canonical snake-case.\"\"\"\n    if s.islower(): return s\n    if s.isupper(): return s.lower()\n    return \"\".join(ch if ch.islower() else \"_\" + ch.lower() for ch in s).strip(\"_\")", "code_tokens": ["def", "normalize_enum_constant", "(", "s", ")", ":", "if", "s", ".", "islower", "(", ")", ":", "return", "s", "if", "s", ".", "isupper", "(", ")", ":", "return", "s", ".", "lower", "(", ")", "return", "\"\"", ".", "join", "(", "ch", "if", "ch", ".", "islower", "(", ")", "else", "\"_\"", "+", "ch", ".", "lower", "(", ")", "for", "ch", "in", "s", ")", ".", "strip", "(", "\"_\"", ")"], "docstring": "Return enum constant `s` converted to a canonical snake-case.", "docstring_tokens": ["Return", "enum", "constant", "s", "converted", "to", "a", "canonical", "snake", "-", "case", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/gen_python.py#L66-L70", "partition": "test", "index": 1527, "time": "2016-09-16 17:25:35"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/typechecks.py", "func_name": "Enum.check", "original_string": "def check(self, var):\n        \"\"\"Check whether the provided value is a valid enum constant.\"\"\"\n        if not isinstance(var, _str_type): return False\n        return _enum_mangle(var) in self._consts", "language": "python", "code": "def check(self, var):\n        \"\"\"Check whether the provided value is a valid enum constant.\"\"\"\n        if not isinstance(var, _str_type): return False\n        return _enum_mangle(var) in self._consts", "code_tokens": ["def", "check", "(", "self", ",", "var", ")", ":", "if", "not", "isinstance", "(", "var", ",", "_str_type", ")", ":", "return", "False", "return", "_enum_mangle", "(", "var", ")", "in", "self", ".", "_consts"], "docstring": "Check whether the provided value is a valid enum constant.", "docstring_tokens": ["Check", "whether", "the", "provided", "value", "is", "a", "valid", "enum", "constant", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/typechecks.py#L403-L406", "partition": "test", "index": 1372, "time": "2016-09-16 17:25:35"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.columns_by_type", "original_string": "def columns_by_type(self, coltype=\"numeric\"):\n        \"\"\"\n        Extract columns of the specified type from the frame.\n\n        :param str coltype: A character string indicating which column type to filter by. This must be\n            one of the following:\n\n            - ``\"numeric\"``      - Numeric, but not categorical or time\n            - ``\"categorical\"``  - Integer, with a categorical/factor String mapping\n            - ``\"string\"``       - String column\n            - ``\"time\"``         - Long msec since the Unix Epoch - with a variety of display/parse options\n            - ``\"uuid\"``         - UUID\n            - ``\"bad\"``          - No none-NA rows (triple negative! all NAs or zero rows)\n\n        :returns: list of indices of columns that have the requested type\n        \"\"\"\n        assert_is_type(coltype, \"numeric\", \"categorical\", \"string\", \"time\", \"uuid\", \"bad\")\n        assert_is_type(self, H2OFrame)\n        return ExprNode(\"columnsByType\", self, coltype)._eager_scalar()", "language": "python", "code": "def columns_by_type(self, coltype=\"numeric\"):\n        \"\"\"\n        Extract columns of the specified type from the frame.\n\n        :param str coltype: A character string indicating which column type to filter by. This must be\n            one of the following:\n\n            - ``\"numeric\"``      - Numeric, but not categorical or time\n            - ``\"categorical\"``  - Integer, with a categorical/factor String mapping\n            - ``\"string\"``       - String column\n            - ``\"time\"``         - Long msec since the Unix Epoch - with a variety of display/parse options\n            - ``\"uuid\"``         - UUID\n            - ``\"bad\"``          - No none-NA rows (triple negative! all NAs or zero rows)\n\n        :returns: list of indices of columns that have the requested type\n        \"\"\"\n        assert_is_type(coltype, \"numeric\", \"categorical\", \"string\", \"time\", \"uuid\", \"bad\")\n        assert_is_type(self, H2OFrame)\n        return ExprNode(\"columnsByType\", self, coltype)._eager_scalar()", "code_tokens": ["def", "columns_by_type", "(", "self", ",", "coltype", "=", "\"numeric\"", ")", ":", "assert_is_type", "(", "coltype", ",", "\"numeric\"", ",", "\"categorical\"", ",", "\"string\"", ",", "\"time\"", ",", "\"uuid\"", ",", "\"bad\"", ")", "assert_is_type", "(", "self", ",", "H2OFrame", ")", "return", "ExprNode", "(", "\"columnsByType\"", ",", "self", ",", "coltype", ")", ".", "_eager_scalar", "(", ")"], "docstring": "Extract columns of the specified type from the frame.\n\n        :param str coltype: A character string indicating which column type to filter by. This must be\n            one of the following:\n\n            - ``\"numeric\"``      - Numeric, but not categorical or time\n            - ``\"categorical\"``  - Integer, with a categorical/factor String mapping\n            - ``\"string\"``       - String column\n            - ``\"time\"``         - Long msec since the Unix Epoch - with a variety of display/parse options\n            - ``\"uuid\"``         - UUID\n            - ``\"bad\"``          - No none-NA rows (triple negative! all NAs or zero rows)\n\n        :returns: list of indices of columns that have the requested type", "docstring_tokens": ["Extract", "columns", "of", "the", "specified", "type", "from", "the", "frame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L379-L397", "partition": "test", "index": 1391, "time": "2016-09-19 18:32:09"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.refresh", "original_string": "def refresh(self):\n        \"\"\"Reload frame information from the backend H2O server.\"\"\"\n        self._ex._cache.flush()\n        self._frame(fill_cache=True)", "language": "python", "code": "def refresh(self):\n        \"\"\"Reload frame information from the backend H2O server.\"\"\"\n        self._ex._cache.flush()\n        self._frame(fill_cache=True)", "code_tokens": ["def", "refresh", "(", "self", ")", ":", "self", ".", "_ex", ".", "_cache", ".", "flush", "(", ")", "self", ".", "_frame", "(", "fill_cache", "=", "True", ")"], "docstring": "Reload frame information from the backend H2O server.", "docstring_tokens": ["Reload", "frame", "information", "from", "the", "backend", "H2O", "server", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L216-L219", "partition": "test", "index": 1389, "time": "2016-09-23 15:59:46"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/config.py", "func_name": "H2OConfigReader._read_config", "original_string": "def _read_config(self):\n        \"\"\"Find and parse config file, storing all variables in ``self._config``.\"\"\"\n        self._config_loaded = True\n        conf = []\n        for f in self._candidate_log_files():\n            if os.path.isfile(f):\n                self._logger.info(\"Reading config file %s\" % f)\n                section_rx = re.compile(r\"^\\[(\\w+)\\]$\")\n                keyvalue_rx = re.compile(r\"^(\\w+:)?([\\w.]+)\\s*=(.*)$\")\n                with io.open(f, \"rt\", encoding=\"utf-8\") as config_file:\n                    section_name = None\n                    for lineno, line in enumerate(config_file):\n                        line = line.strip()\n                        if line == \"\" or line.startswith(\"#\"): continue\n                        m1 = section_rx.match(line)\n                        if m1:\n                            section_name = m1.group(1)\n                            continue\n                        m2 = keyvalue_rx.match(line)\n                        if m2:\n                            lng = m2.group(1)\n                            key = m2.group(2)\n                            val = m2.group(3).strip()\n                            if lng and lng.lower() != \"py:\": continue\n                            if section_name:\n                                key = section_name + \".\" + key\n                            if key in H2OConfigReader._allowed_config_keys:\n                                conf.append((key, val))\n                            else:\n                                self._logger.error(\"Key %s is not a valid config key\" % key)\n                            continue\n                        self._logger.error(\"Syntax error in config file line %d: %s\" % (lineno, line))\n                self._config = dict(conf)\n                return", "language": "python", "code": "def _read_config(self):\n        \"\"\"Find and parse config file, storing all variables in ``self._config``.\"\"\"\n        self._config_loaded = True\n        conf = []\n        for f in self._candidate_log_files():\n            if os.path.isfile(f):\n                self._logger.info(\"Reading config file %s\" % f)\n                section_rx = re.compile(r\"^\\[(\\w+)\\]$\")\n                keyvalue_rx = re.compile(r\"^(\\w+:)?([\\w.]+)\\s*=(.*)$\")\n                with io.open(f, \"rt\", encoding=\"utf-8\") as config_file:\n                    section_name = None\n                    for lineno, line in enumerate(config_file):\n                        line = line.strip()\n                        if line == \"\" or line.startswith(\"#\"): continue\n                        m1 = section_rx.match(line)\n                        if m1:\n                            section_name = m1.group(1)\n                            continue\n                        m2 = keyvalue_rx.match(line)\n                        if m2:\n                            lng = m2.group(1)\n                            key = m2.group(2)\n                            val = m2.group(3).strip()\n                            if lng and lng.lower() != \"py:\": continue\n                            if section_name:\n                                key = section_name + \".\" + key\n                            if key in H2OConfigReader._allowed_config_keys:\n                                conf.append((key, val))\n                            else:\n                                self._logger.error(\"Key %s is not a valid config key\" % key)\n                            continue\n                        self._logger.error(\"Syntax error in config file line %d: %s\" % (lineno, line))\n                self._config = dict(conf)\n                return", "code_tokens": ["def", "_read_config", "(", "self", ")", ":", "self", ".", "_config_loaded", "=", "True", "conf", "=", "[", "]", "for", "f", "in", "self", ".", "_candidate_log_files", "(", ")", ":", "if", "os", ".", "path", ".", "isfile", "(", "f", ")", ":", "self", ".", "_logger", ".", "info", "(", "\"Reading config file %s\"", "%", "f", ")", "section_rx", "=", "re", ".", "compile", "(", "r\"^\\[(\\w+)\\]$\"", ")", "keyvalue_rx", "=", "re", ".", "compile", "(", "r\"^(\\w+:)?([\\w.]+)\\s*=(.*)$\"", ")", "with", "io", ".", "open", "(", "f", ",", "\"rt\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "config_file", ":", "section_name", "=", "None", "for", "lineno", ",", "line", "in", "enumerate", "(", "config_file", ")", ":", "line", "=", "line", ".", "strip", "(", ")", "if", "line", "==", "\"\"", "or", "line", ".", "startswith", "(", "\"#\"", ")", ":", "continue", "m1", "=", "section_rx", ".", "match", "(", "line", ")", "if", "m1", ":", "section_name", "=", "m1", ".", "group", "(", "1", ")", "continue", "m2", "=", "keyvalue_rx", ".", "match", "(", "line", ")", "if", "m2", ":", "lng", "=", "m2", ".", "group", "(", "1", ")", "key", "=", "m2", ".", "group", "(", "2", ")", "val", "=", "m2", ".", "group", "(", "3", ")", ".", "strip", "(", ")", "if", "lng", "and", "lng", ".", "lower", "(", ")", "!=", "\"py:\"", ":", "continue", "if", "section_name", ":", "key", "=", "section_name", "+", "\".\"", "+", "key", "if", "key", "in", "H2OConfigReader", ".", "_allowed_config_keys", ":", "conf", ".", "append", "(", "(", "key", ",", "val", ")", ")", "else", ":", "self", ".", "_logger", ".", "error", "(", "\"Key %s is not a valid config key\"", "%", "key", ")", "continue", "self", ".", "_logger", ".", "error", "(", "\"Syntax error in config file line %d: %s\"", "%", "(", "lineno", ",", "line", ")", ")", "self", ".", "_config", "=", "dict", "(", "conf", ")", "return"], "docstring": "Find and parse config file, storing all variables in ``self._config``.", "docstring_tokens": ["Find", "and", "parse", "config", "file", "storing", "all", "variables", "in", "self", ".", "_config", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/config.py#L56-L89", "partition": "test", "index": 1374, "time": "2016-09-27 12:18:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/config.py", "func_name": "H2OConfigReader.get_config", "original_string": "def get_config():\n        \"\"\"Retrieve the config as a dictionary of key-value pairs.\"\"\"\n        self = H2OConfigReader._get_instance()\n        if not self._config_loaded:\n            self._read_config()\n        return self._config", "language": "python", "code": "def get_config():\n        \"\"\"Retrieve the config as a dictionary of key-value pairs.\"\"\"\n        self = H2OConfigReader._get_instance()\n        if not self._config_loaded:\n            self._read_config()\n        return self._config", "code_tokens": ["def", "get_config", "(", ")", ":", "self", "=", "H2OConfigReader", ".", "_get_instance", "(", ")", "if", "not", "self", ".", "_config_loaded", ":", "self", ".", "_read_config", "(", ")", "return", "self", ".", "_config"], "docstring": "Retrieve the config as a dictionary of key-value pairs.", "docstring_tokens": ["Retrieve", "the", "config", "as", "a", "dictionary", "of", "key", "-", "value", "pairs", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/config.py#L24-L29", "partition": "test", "index": 1373, "time": "2016-09-27 12:18:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/config.py", "func_name": "H2OConfigReader._candidate_log_files", "original_string": "def _candidate_log_files():\n        \"\"\"Return possible locations for the .h2oconfig file, one at a time.\"\"\"\n        # Search for .h2oconfig in the current directory and all parent directories\n        relpath = \".h2oconfig\"\n        prevpath = None\n        while True:\n            abspath = os.path.abspath(relpath)\n            if abspath == prevpath: break\n            prevpath = abspath\n            relpath = \"../\" + relpath\n            yield abspath\n        # Also check if .h2oconfig exists in the user's directory\n        yield os.path.expanduser(\"~/.h2oconfig\")", "language": "python", "code": "def _candidate_log_files():\n        \"\"\"Return possible locations for the .h2oconfig file, one at a time.\"\"\"\n        # Search for .h2oconfig in the current directory and all parent directories\n        relpath = \".h2oconfig\"\n        prevpath = None\n        while True:\n            abspath = os.path.abspath(relpath)\n            if abspath == prevpath: break\n            prevpath = abspath\n            relpath = \"../\" + relpath\n            yield abspath\n        # Also check if .h2oconfig exists in the user's directory\n        yield os.path.expanduser(\"~/.h2oconfig\")", "code_tokens": ["def", "_candidate_log_files", "(", ")", ":", "# Search for .h2oconfig in the current directory and all parent directories", "relpath", "=", "\".h2oconfig\"", "prevpath", "=", "None", "while", "True", ":", "abspath", "=", "os", ".", "path", ".", "abspath", "(", "relpath", ")", "if", "abspath", "==", "prevpath", ":", "break", "prevpath", "=", "abspath", "relpath", "=", "\"../\"", "+", "relpath", "yield", "abspath", "# Also check if .h2oconfig exists in the user's directory", "yield", "os", ".", "path", ".", "expanduser", "(", "\"~/.h2oconfig\"", ")"], "docstring": "Return possible locations for the .h2oconfig file, one at a time.", "docstring_tokens": ["Return", "possible", "locations", "for", "the", ".", "h2oconfig", "file", "one", "at", "a", "time", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/config.py#L92-L104", "partition": "test", "index": 1375, "time": "2016-09-27 12:18:26"}
{"repo": "h2oai/h2o-3", "path": "h2o-bindings/bin/gen_java.py", "func_name": "dedent", "original_string": "def dedent(ind, text):\n    \"\"\"\n    Dedent text to the specific indentation level.\n\n    :param ind: common indentation level for the resulting text (number of spaces to append to every line)\n    :param text: text that should be transformed.\n    :return: ``text`` with all common indentation removed, and then the specified amount of indentation added.\n    \"\"\"\n    text2 = textwrap.dedent(text)\n    if ind == 0:\n        return text2\n    indent_str = \" \" * ind\n    return \"\\n\".join(indent_str + line for line in text2.split(\"\\n\"))", "language": "python", "code": "def dedent(ind, text):\n    \"\"\"\n    Dedent text to the specific indentation level.\n\n    :param ind: common indentation level for the resulting text (number of spaces to append to every line)\n    :param text: text that should be transformed.\n    :return: ``text`` with all common indentation removed, and then the specified amount of indentation added.\n    \"\"\"\n    text2 = textwrap.dedent(text)\n    if ind == 0:\n        return text2\n    indent_str = \" \" * ind\n    return \"\\n\".join(indent_str + line for line in text2.split(\"\\n\"))", "code_tokens": ["def", "dedent", "(", "ind", ",", "text", ")", ":", "text2", "=", "textwrap", ".", "dedent", "(", "text", ")", "if", "ind", "==", "0", ":", "return", "text2", "indent_str", "=", "\" \"", "*", "ind", "return", "\"\\n\"", ".", "join", "(", "indent_str", "+", "line", "for", "line", "in", "text2", ".", "split", "(", "\"\\n\"", ")", ")"], "docstring": "Dedent text to the specific indentation level.\n\n    :param ind: common indentation level for the resulting text (number of spaces to append to every line)\n    :param text: text that should be transformed.\n    :return: ``text`` with all common indentation removed, and then the specified amount of indentation added.", "docstring_tokens": ["Dedent", "text", "to", "the", "specific", "indentation", "level", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/gen_java.py#L71-L83", "partition": "test", "index": 1495, "time": "2016-10-14 15:53:43"}
{"repo": "h2oai/h2o-3", "path": "scripts/extractGLRMRuntimeJavaLog.py", "func_name": "main", "original_string": "def main(argv):\n    \"\"\"\n    Main program.  Take user input, parse it and call other functions to execute the commands\n    and extract run summary and store run result in json file\n\n    @return: none\n    \"\"\"\n    global g_test_root_dir\n    global g_temp_filename\n\n    if len(argv) < 2:\n        print(\"invoke this script as python extractGLRMRuntimeJavaLog.py javatextlog.\\n\")\n        sys.exit(1)\n    else:   # we may be in business\n        javaLogText = argv[1]         # filename while java log is stored\n\n        print(\"your java text is {0}\".format(javaLogText))\n        extractRunInto(javaLogText)", "language": "python", "code": "def main(argv):\n    \"\"\"\n    Main program.  Take user input, parse it and call other functions to execute the commands\n    and extract run summary and store run result in json file\n\n    @return: none\n    \"\"\"\n    global g_test_root_dir\n    global g_temp_filename\n\n    if len(argv) < 2:\n        print(\"invoke this script as python extractGLRMRuntimeJavaLog.py javatextlog.\\n\")\n        sys.exit(1)\n    else:   # we may be in business\n        javaLogText = argv[1]         # filename while java log is stored\n\n        print(\"your java text is {0}\".format(javaLogText))\n        extractRunInto(javaLogText)", "code_tokens": ["def", "main", "(", "argv", ")", ":", "global", "g_test_root_dir", "global", "g_temp_filename", "if", "len", "(", "argv", ")", "<", "2", ":", "print", "(", "\"invoke this script as python extractGLRMRuntimeJavaLog.py javatextlog.\\n\"", ")", "sys", ".", "exit", "(", "1", ")", "else", ":", "# we may be in business", "javaLogText", "=", "argv", "[", "1", "]", "# filename while java log is stored", "print", "(", "\"your java text is {0}\"", ".", "format", "(", "javaLogText", ")", ")", "extractRunInto", "(", "javaLogText", ")"], "docstring": "Main program.  Take user input, parse it and call other functions to execute the commands\n    and extract run summary and store run result in json file\n\n    @return: none", "docstring_tokens": ["Main", "program", ".", "Take", "user", "input", "parse", "it", "and", "call", "other", "functions", "to", "execute", "the", "commands", "and", "extract", "run", "summary", "and", "store", "run", "result", "in", "json", "file"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/extractGLRMRuntimeJavaLog.py#L115-L132", "partition": "test", "index": 1497, "time": "2016-10-18 16:23:53"}
{"repo": "h2oai/h2o-3", "path": "scripts/extractGLRMRuntimeJavaLog.py", "func_name": "extractRunInto", "original_string": "def extractRunInto(javaLogText):\n    \"\"\"\n    This function will extract the various operation time for GLRM model building iterations.\n\n    :param javaLogText:\n    :return:\n    \"\"\"\n    global g_initialXY\n    global g_reguarlize_Y\n    global g_regularize_X_objective\n    global g_updateX\n    global g_updateY\n    global g_objective\n    global g_stepsize\n    global g_history\n\n\n    if os.path.isfile(javaLogText):\n\n        run_result = dict()\n        run_result[\"total time (ms)\"] = []\n        run_result[\"initialXY (ms)\"] = []\n        run_result[\"regularize Y (ms)\"] = []\n        run_result[\"regularize X and objective (ms)\"] = []\n        run_result[\"update X (ms)\"] = []\n        run_result[\"update Y (ms)\"] = []\n        run_result[\"objective (ms)\"] = []\n        run_result[\"step size (ms)\"] = []\n        run_result[\"update history (ms)\"] = []\n\n        total_run_time = -1\n        val = 0.0\n        with open(javaLogText, 'r') as thefile:   # go into tempfile and grab test run info\n            for each_line in thefile:\n                temp_string = each_line.split()\n\n                if len(temp_string) > 0:\n                    val = temp_string[-1].replace('\\\\','')\n\n                if g_initialXY in each_line:    # start of a new file\n                    if total_run_time > 0:  # update total run time\n                        run_result[\"total time (ms)\"].append(total_run_time)\n                        total_run_time = 0.0\n                    else:\n                        total_run_time = 0.0\n\n                    run_result[\"initialXY (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_reguarlize_Y in each_line:\n                    run_result[\"regularize Y (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_regularize_X_objective in each_line:\n                    run_result[\"regularize X and objective (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_updateX in each_line:\n                    run_result[\"update X (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_updateY in each_line:\n                    run_result[\"update Y (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_objective in each_line:\n                    run_result[\"objective (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_stepsize in each_line:\n                    run_result[\"step size (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_history in each_line:\n                    run_result[\"update history (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n        run_result[\"total time (ms)\"].append(total_run_time)    # save the last one\n        print(\"Run result summary: \\n {0}\".format(run_result))\n\n    else:\n        print(\"Cannot find your java log file.  Nothing is done.\\n\")", "language": "python", "code": "def extractRunInto(javaLogText):\n    \"\"\"\n    This function will extract the various operation time for GLRM model building iterations.\n\n    :param javaLogText:\n    :return:\n    \"\"\"\n    global g_initialXY\n    global g_reguarlize_Y\n    global g_regularize_X_objective\n    global g_updateX\n    global g_updateY\n    global g_objective\n    global g_stepsize\n    global g_history\n\n\n    if os.path.isfile(javaLogText):\n\n        run_result = dict()\n        run_result[\"total time (ms)\"] = []\n        run_result[\"initialXY (ms)\"] = []\n        run_result[\"regularize Y (ms)\"] = []\n        run_result[\"regularize X and objective (ms)\"] = []\n        run_result[\"update X (ms)\"] = []\n        run_result[\"update Y (ms)\"] = []\n        run_result[\"objective (ms)\"] = []\n        run_result[\"step size (ms)\"] = []\n        run_result[\"update history (ms)\"] = []\n\n        total_run_time = -1\n        val = 0.0\n        with open(javaLogText, 'r') as thefile:   # go into tempfile and grab test run info\n            for each_line in thefile:\n                temp_string = each_line.split()\n\n                if len(temp_string) > 0:\n                    val = temp_string[-1].replace('\\\\','')\n\n                if g_initialXY in each_line:    # start of a new file\n                    if total_run_time > 0:  # update total run time\n                        run_result[\"total time (ms)\"].append(total_run_time)\n                        total_run_time = 0.0\n                    else:\n                        total_run_time = 0.0\n\n                    run_result[\"initialXY (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_reguarlize_Y in each_line:\n                    run_result[\"regularize Y (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_regularize_X_objective in each_line:\n                    run_result[\"regularize X and objective (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_updateX in each_line:\n                    run_result[\"update X (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_updateY in each_line:\n                    run_result[\"update Y (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_objective in each_line:\n                    run_result[\"objective (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_stepsize in each_line:\n                    run_result[\"step size (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n                if g_history in each_line:\n                    run_result[\"update history (ms)\"].append(float(val))\n                    total_run_time = total_run_time+float(val)\n\n        run_result[\"total time (ms)\"].append(total_run_time)    # save the last one\n        print(\"Run result summary: \\n {0}\".format(run_result))\n\n    else:\n        print(\"Cannot find your java log file.  Nothing is done.\\n\")", "code_tokens": ["def", "extractRunInto", "(", "javaLogText", ")", ":", "global", "g_initialXY", "global", "g_reguarlize_Y", "global", "g_regularize_X_objective", "global", "g_updateX", "global", "g_updateY", "global", "g_objective", "global", "g_stepsize", "global", "g_history", "if", "os", ".", "path", ".", "isfile", "(", "javaLogText", ")", ":", "run_result", "=", "dict", "(", ")", "run_result", "[", "\"total time (ms)\"", "]", "=", "[", "]", "run_result", "[", "\"initialXY (ms)\"", "]", "=", "[", "]", "run_result", "[", "\"regularize Y (ms)\"", "]", "=", "[", "]", "run_result", "[", "\"regularize X and objective (ms)\"", "]", "=", "[", "]", "run_result", "[", "\"update X (ms)\"", "]", "=", "[", "]", "run_result", "[", "\"update Y (ms)\"", "]", "=", "[", "]", "run_result", "[", "\"objective (ms)\"", "]", "=", "[", "]", "run_result", "[", "\"step size (ms)\"", "]", "=", "[", "]", "run_result", "[", "\"update history (ms)\"", "]", "=", "[", "]", "total_run_time", "=", "-", "1", "val", "=", "0.0", "with", "open", "(", "javaLogText", ",", "'r'", ")", "as", "thefile", ":", "# go into tempfile and grab test run info", "for", "each_line", "in", "thefile", ":", "temp_string", "=", "each_line", ".", "split", "(", ")", "if", "len", "(", "temp_string", ")", ">", "0", ":", "val", "=", "temp_string", "[", "-", "1", "]", ".", "replace", "(", "'\\\\'", ",", "''", ")", "if", "g_initialXY", "in", "each_line", ":", "# start of a new file", "if", "total_run_time", ">", "0", ":", "# update total run time", "run_result", "[", "\"total time (ms)\"", "]", ".", "append", "(", "total_run_time", ")", "total_run_time", "=", "0.0", "else", ":", "total_run_time", "=", "0.0", "run_result", "[", "\"initialXY (ms)\"", "]", ".", "append", "(", "float", "(", "val", ")", ")", "total_run_time", "=", "total_run_time", "+", "float", "(", "val", ")", "if", "g_reguarlize_Y", "in", "each_line", ":", "run_result", "[", "\"regularize Y (ms)\"", "]", ".", "append", "(", "float", "(", "val", ")", ")", "total_run_time", "=", "total_run_time", "+", "float", "(", "val", ")", "if", "g_regularize_X_objective", "in", "each_line", ":", "run_result", "[", "\"regularize X and objective (ms)\"", "]", ".", "append", "(", "float", "(", "val", ")", ")", "total_run_time", "=", "total_run_time", "+", "float", "(", "val", ")", "if", "g_updateX", "in", "each_line", ":", "run_result", "[", "\"update X (ms)\"", "]", ".", "append", "(", "float", "(", "val", ")", ")", "total_run_time", "=", "total_run_time", "+", "float", "(", "val", ")", "if", "g_updateY", "in", "each_line", ":", "run_result", "[", "\"update Y (ms)\"", "]", ".", "append", "(", "float", "(", "val", ")", ")", "total_run_time", "=", "total_run_time", "+", "float", "(", "val", ")", "if", "g_objective", "in", "each_line", ":", "run_result", "[", "\"objective (ms)\"", "]", ".", "append", "(", "float", "(", "val", ")", ")", "total_run_time", "=", "total_run_time", "+", "float", "(", "val", ")", "if", "g_stepsize", "in", "each_line", ":", "run_result", "[", "\"step size (ms)\"", "]", ".", "append", "(", "float", "(", "val", ")", ")", "total_run_time", "=", "total_run_time", "+", "float", "(", "val", ")", "if", "g_history", "in", "each_line", ":", "run_result", "[", "\"update history (ms)\"", "]", ".", "append", "(", "float", "(", "val", ")", ")", "total_run_time", "=", "total_run_time", "+", "float", "(", "val", ")", "run_result", "[", "\"total time (ms)\"", "]", ".", "append", "(", "total_run_time", ")", "# save the last one", "print", "(", "\"Run result summary: \\n {0}\"", ".", "format", "(", "run_result", ")", ")", "else", ":", "print", "(", "\"Cannot find your java log file.  Nothing is done.\\n\"", ")"], "docstring": "This function will extract the various operation time for GLRM model building iterations.\n\n    :param javaLogText:\n    :return:", "docstring_tokens": ["This", "function", "will", "extract", "the", "various", "operation", "time", "for", "GLRM", "model", "building", "iterations", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/extractGLRMRuntimeJavaLog.py#L31-L112", "partition": "test", "index": 1496, "time": "2016-10-18 16:23:53"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/shared_utils.py", "func_name": "normalize_slice", "original_string": "def normalize_slice(s, total):\n    \"\"\"\n    Return a \"canonical\" version of slice ``s``.\n\n    :param slice s: the original slice expression\n    :param total int: total number of elements in the collection sliced by ``s``\n    :return slice: a slice equivalent to ``s`` but not containing any negative indices or Nones.\n    \"\"\"\n    newstart = 0 if s.start is None else max(0, s.start + total) if s.start < 0 else min(s.start, total)\n    newstop = total if s.stop is None else max(0, s.stop + total) if s.stop < 0 else min(s.stop, total)\n    newstep = 1 if s.step is None else s.step\n    return slice(newstart, newstop, newstep)", "language": "python", "code": "def normalize_slice(s, total):\n    \"\"\"\n    Return a \"canonical\" version of slice ``s``.\n\n    :param slice s: the original slice expression\n    :param total int: total number of elements in the collection sliced by ``s``\n    :return slice: a slice equivalent to ``s`` but not containing any negative indices or Nones.\n    \"\"\"\n    newstart = 0 if s.start is None else max(0, s.start + total) if s.start < 0 else min(s.start, total)\n    newstop = total if s.stop is None else max(0, s.stop + total) if s.stop < 0 else min(s.stop, total)\n    newstep = 1 if s.step is None else s.step\n    return slice(newstart, newstop, newstep)", "code_tokens": ["def", "normalize_slice", "(", "s", ",", "total", ")", ":", "newstart", "=", "0", "if", "s", ".", "start", "is", "None", "else", "max", "(", "0", ",", "s", ".", "start", "+", "total", ")", "if", "s", ".", "start", "<", "0", "else", "min", "(", "s", ".", "start", ",", "total", ")", "newstop", "=", "total", "if", "s", ".", "stop", "is", "None", "else", "max", "(", "0", ",", "s", ".", "stop", "+", "total", ")", "if", "s", ".", "stop", "<", "0", "else", "min", "(", "s", ".", "stop", ",", "total", ")", "newstep", "=", "1", "if", "s", ".", "step", "is", "None", "else", "s", ".", "step", "return", "slice", "(", "newstart", ",", "newstop", ",", "newstep", ")"], "docstring": "Return a \"canonical\" version of slice ``s``.\n\n    :param slice s: the original slice expression\n    :param total int: total number of elements in the collection sliced by ``s``\n    :return slice: a slice equivalent to ``s`` but not containing any negative indices or Nones.", "docstring_tokens": ["Return", "a", "canonical", "version", "of", "slice", "s", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/shared_utils.py#L341-L352", "partition": "test", "index": 1478, "time": "2016-11-04 17:39:23"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/shared_utils.py", "func_name": "slice_is_normalized", "original_string": "def slice_is_normalized(s):\n    \"\"\"Return True if slice ``s`` in \"normalized\" form.\"\"\"\n    return (s.start is not None and s.stop is not None and s.step is not None and s.start <= s.stop)", "language": "python", "code": "def slice_is_normalized(s):\n    \"\"\"Return True if slice ``s`` in \"normalized\" form.\"\"\"\n    return (s.start is not None and s.stop is not None and s.step is not None and s.start <= s.stop)", "code_tokens": ["def", "slice_is_normalized", "(", "s", ")", ":", "return", "(", "s", ".", "start", "is", "not", "None", "and", "s", ".", "stop", "is", "not", "None", "and", "s", ".", "step", "is", "not", "None", "and", "s", ".", "start", "<=", "s", ".", "stop", ")"], "docstring": "Return True if slice ``s`` in \"normalized\" form.", "docstring_tokens": ["Return", "True", "if", "slice", "s", "in", "normalized", "form", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/shared_utils.py#L355-L357", "partition": "test", "index": 1479, "time": "2016-11-04 17:39:23"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/shared_utils.py", "func_name": "check_frame_id", "original_string": "def check_frame_id(frame_id):\n    \"\"\"Check that the provided frame id is valid in Rapids language.\"\"\"\n    if frame_id is None:\n        return\n    if frame_id.strip() == \"\":\n        raise H2OValueError(\"Frame id cannot be an empty string: %r\" % frame_id)\n    for i, ch in enumerate(frame_id):\n        # '$' character has special meaning at the beginning of the string; and prohibited anywhere else\n        if ch == \"$\" and i == 0: continue\n        if ch not in _id_allowed_characters:\n            raise H2OValueError(\"Character '%s' is illegal in frame id: %s\" % (ch, frame_id))\n    if re.match(r\"-?[0-9]\", frame_id):\n        raise H2OValueError(\"Frame id cannot start with a number: %s\" % frame_id)", "language": "python", "code": "def check_frame_id(frame_id):\n    \"\"\"Check that the provided frame id is valid in Rapids language.\"\"\"\n    if frame_id is None:\n        return\n    if frame_id.strip() == \"\":\n        raise H2OValueError(\"Frame id cannot be an empty string: %r\" % frame_id)\n    for i, ch in enumerate(frame_id):\n        # '$' character has special meaning at the beginning of the string; and prohibited anywhere else\n        if ch == \"$\" and i == 0: continue\n        if ch not in _id_allowed_characters:\n            raise H2OValueError(\"Character '%s' is illegal in frame id: %s\" % (ch, frame_id))\n    if re.match(r\"-?[0-9]\", frame_id):\n        raise H2OValueError(\"Frame id cannot start with a number: %s\" % frame_id)", "code_tokens": ["def", "check_frame_id", "(", "frame_id", ")", ":", "if", "frame_id", "is", "None", ":", "return", "if", "frame_id", ".", "strip", "(", ")", "==", "\"\"", ":", "raise", "H2OValueError", "(", "\"Frame id cannot be an empty string: %r\"", "%", "frame_id", ")", "for", "i", ",", "ch", "in", "enumerate", "(", "frame_id", ")", ":", "# '$' character has special meaning at the beginning of the string; and prohibited anywhere else", "if", "ch", "==", "\"$\"", "and", "i", "==", "0", ":", "continue", "if", "ch", "not", "in", "_id_allowed_characters", ":", "raise", "H2OValueError", "(", "\"Character '%s' is illegal in frame id: %s\"", "%", "(", "ch", ",", "frame_id", ")", ")", "if", "re", ".", "match", "(", "r\"-?[0-9]\"", ",", "frame_id", ")", ":", "raise", "H2OValueError", "(", "\"Frame id cannot start with a number: %s\"", "%", "frame_id", ")"], "docstring": "Check that the provided frame id is valid in Rapids language.", "docstring_tokens": ["Check", "that", "the", "provided", "frame", "id", "is", "valid", "in", "Rapids", "language", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/shared_utils.py#L46-L58", "partition": "test", "index": 1476, "time": "2016-11-04 19:13:04"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.type", "original_string": "def type(self, col):\n        \"\"\"\n        The type for the given column.\n\n        :param col: either a name, or an index of the column to look up\n        :returns: type of the column, one of: ``str``, ``int``, ``real``, ``enum``, ``time``, ``bool``.\n        :raises H2OValueError: if such column does not exist in the frame.\n        \"\"\"\n        assert_is_type(col, int, str)\n        if not self._ex._cache.types_valid() or not self._ex._cache.names_valid():\n            self._ex._cache.flush()\n            self._frame(fill_cache=True)\n        types = self._ex._cache.types\n        if is_type(col, str):\n            if col in types:\n                return types[col]\n        else:\n            names = self._ex._cache.names\n            if -len(names) <= col < len(names):\n                return types[names[col]]\n        raise H2OValueError(\"Column '%r' does not exist in the frame\" % col)", "language": "python", "code": "def type(self, col):\n        \"\"\"\n        The type for the given column.\n\n        :param col: either a name, or an index of the column to look up\n        :returns: type of the column, one of: ``str``, ``int``, ``real``, ``enum``, ``time``, ``bool``.\n        :raises H2OValueError: if such column does not exist in the frame.\n        \"\"\"\n        assert_is_type(col, int, str)\n        if not self._ex._cache.types_valid() or not self._ex._cache.names_valid():\n            self._ex._cache.flush()\n            self._frame(fill_cache=True)\n        types = self._ex._cache.types\n        if is_type(col, str):\n            if col in types:\n                return types[col]\n        else:\n            names = self._ex._cache.names\n            if -len(names) <= col < len(names):\n                return types[names[col]]\n        raise H2OValueError(\"Column '%r' does not exist in the frame\" % col)", "code_tokens": ["def", "type", "(", "self", ",", "col", ")", ":", "assert_is_type", "(", "col", ",", "int", ",", "str", ")", "if", "not", "self", ".", "_ex", ".", "_cache", ".", "types_valid", "(", ")", "or", "not", "self", ".", "_ex", ".", "_cache", ".", "names_valid", "(", ")", ":", "self", ".", "_ex", ".", "_cache", ".", "flush", "(", ")", "self", ".", "_frame", "(", "fill_cache", "=", "True", ")", "types", "=", "self", ".", "_ex", ".", "_cache", ".", "types", "if", "is_type", "(", "col", ",", "str", ")", ":", "if", "col", "in", "types", ":", "return", "types", "[", "col", "]", "else", ":", "names", "=", "self", ".", "_ex", ".", "_cache", ".", "names", "if", "-", "len", "(", "names", ")", "<=", "col", "<", "len", "(", "names", ")", ":", "return", "types", "[", "names", "[", "col", "]", "]", "raise", "H2OValueError", "(", "\"Column '%r' does not exist in the frame\"", "%", "col", ")"], "docstring": "The type for the given column.\n\n        :param col: either a name, or an index of the column to look up\n        :returns: type of the column, one of: ``str``, ``int``, ``real``, ``enum``, ``time``, ``bool``.\n        :raises H2OValueError: if such column does not exist in the frame.", "docstring_tokens": ["The", "type", "for", "the", "given", "column", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L289-L309", "partition": "test", "index": 1390, "time": "2016-11-23 15:05:04"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/word_embedding.py", "func_name": "H2OWordEmbeddingModel.find_synonyms", "original_string": "def find_synonyms(self, word, count=20):\n        \"\"\"\n        Find synonyms using a word2vec model.\n\n        :param str word: A single word to find synonyms for.\n        :param int count: The first \"count\" synonyms will be returned.\n\n        :returns: the approximate reconstruction of the training data.\n        \"\"\"\n        j = h2o.api(\"GET /3/Word2VecSynonyms\", data={'model': self.model_id, 'word': word, 'count': count})\n        return OrderedDict(sorted(zip(j['synonyms'], j['scores']), key=lambda t: t[1], reverse=True))", "language": "python", "code": "def find_synonyms(self, word, count=20):\n        \"\"\"\n        Find synonyms using a word2vec model.\n\n        :param str word: A single word to find synonyms for.\n        :param int count: The first \"count\" synonyms will be returned.\n\n        :returns: the approximate reconstruction of the training data.\n        \"\"\"\n        j = h2o.api(\"GET /3/Word2VecSynonyms\", data={'model': self.model_id, 'word': word, 'count': count})\n        return OrderedDict(sorted(zip(j['synonyms'], j['scores']), key=lambda t: t[1], reverse=True))", "code_tokens": ["def", "find_synonyms", "(", "self", ",", "word", ",", "count", "=", "20", ")", ":", "j", "=", "h2o", ".", "api", "(", "\"GET /3/Word2VecSynonyms\"", ",", "data", "=", "{", "'model'", ":", "self", ".", "model_id", ",", "'word'", ":", "word", ",", "'count'", ":", "count", "}", ")", "return", "OrderedDict", "(", "sorted", "(", "zip", "(", "j", "[", "'synonyms'", "]", ",", "j", "[", "'scores'", "]", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "1", "]", ",", "reverse", "=", "True", ")", ")"], "docstring": "Find synonyms using a word2vec model.\n\n        :param str word: A single word to find synonyms for.\n        :param int count: The first \"count\" synonyms will be returned.\n\n        :returns: the approximate reconstruction of the training data.", "docstring_tokens": ["Find", "synonyms", "using", "a", "word2vec", "model", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/word_embedding.py#L17-L27", "partition": "test", "index": 1528, "time": "2017-01-06 16:37:08"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.minute", "original_string": "def minute(self):\n        \"\"\"\n        Extract the \"minute\" part from a date column.\n\n        :returns: a single-column H2OFrame containing the \"minute\" part from the source frame.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"minute\", self), cache=self._ex._cache)\n        if fr._ex._cache.types_valid():\n            fr._ex._cache.types = {k: \"int\" for k in self._ex._cache.types.keys()}\n        return fr", "language": "python", "code": "def minute(self):\n        \"\"\"\n        Extract the \"minute\" part from a date column.\n\n        :returns: a single-column H2OFrame containing the \"minute\" part from the source frame.\n        \"\"\"\n        fr = H2OFrame._expr(expr=ExprNode(\"minute\", self), cache=self._ex._cache)\n        if fr._ex._cache.types_valid():\n            fr._ex._cache.types = {k: \"int\" for k in self._ex._cache.types.keys()}\n        return fr", "code_tokens": ["def", "minute", "(", "self", ")", ":", "fr", "=", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"minute\"", ",", "self", ")", ",", "cache", "=", "self", ".", "_ex", ".", "_cache", ")", "if", "fr", ".", "_ex", ".", "_cache", ".", "types_valid", "(", ")", ":", "fr", ".", "_ex", ".", "_cache", ".", "types", "=", "{", "k", ":", "\"int\"", "for", "k", "in", "self", ".", "_ex", ".", "_cache", ".", "types", ".", "keys", "(", ")", "}", "return", "fr"], "docstring": "Extract the \"minute\" part from a date column.\n\n        :returns: a single-column H2OFrame containing the \"minute\" part from the source frame.", "docstring_tokens": ["Extract", "the", "minute", "part", "from", "a", "date", "column", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L3143-L3152", "partition": "test", "index": 1439, "time": "2017-01-19 17:45:19"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/model_base.py", "func_name": "ModelBase.save_model_details", "original_string": "def save_model_details(self, path=\"\", force=False):\n        \"\"\"\n        Save Model Details of an H2O Model in JSON Format to disk.\n\n        :param model: The model object to save.\n        :param path: a path to save the model details at (hdfs, s3, local)\n        :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n\n        :returns str: the path of the saved model details\n        \"\"\"\n        assert_is_type(path, str)\n        assert_is_type(force, bool)\n        path = os.path.join(os.getcwd() if path == \"\" else path, self.model_id + \".json\")\n        return h2o.api(\"GET /99/Models/%s/json\" % self.model_id, data={\"dir\": path, \"force\": force})[\"dir\"]", "language": "python", "code": "def save_model_details(self, path=\"\", force=False):\n        \"\"\"\n        Save Model Details of an H2O Model in JSON Format to disk.\n\n        :param model: The model object to save.\n        :param path: a path to save the model details at (hdfs, s3, local)\n        :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n\n        :returns str: the path of the saved model details\n        \"\"\"\n        assert_is_type(path, str)\n        assert_is_type(force, bool)\n        path = os.path.join(os.getcwd() if path == \"\" else path, self.model_id + \".json\")\n        return h2o.api(\"GET /99/Models/%s/json\" % self.model_id, data={\"dir\": path, \"force\": force})[\"dir\"]", "code_tokens": ["def", "save_model_details", "(", "self", ",", "path", "=", "\"\"", ",", "force", "=", "False", ")", ":", "assert_is_type", "(", "path", ",", "str", ")", "assert_is_type", "(", "force", ",", "bool", ")", "path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", "if", "path", "==", "\"\"", "else", "path", ",", "self", ".", "model_id", "+", "\".json\"", ")", "return", "h2o", ".", "api", "(", "\"GET /99/Models/%s/json\"", "%", "self", ".", "model_id", ",", "data", "=", "{", "\"dir\"", ":", "path", ",", "\"force\"", ":", "force", "}", ")", "[", "\"dir\"", "]"], "docstring": "Save Model Details of an H2O Model in JSON Format to disk.\n\n        :param model: The model object to save.\n        :param path: a path to save the model details at (hdfs, s3, local)\n        :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n\n        :returns str: the path of the saved model details", "docstring_tokens": ["Save", "Model", "Details", "of", "an", "H2O", "Model", "in", "JSON", "Format", "to", "disk", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/model_base.py#L840-L853", "partition": "test", "index": 1543, "time": "2017-02-01 16:15:11"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.distance", "original_string": "def distance(self, y, measure=None):\n        \"\"\"\n        Compute a pairwise distance measure between all rows of two numeric H2OFrames.\n\n        :param H2OFrame y: Frame containing queries (small)\n        :param str use: A string indicating what distance measure to use. Must be one of:\n\n            - ``\"l1\"``:        Absolute distance (L1-norm, >=0)\n            - ``\"l2\"``:        Euclidean distance (L2-norm, >=0)\n            - ``\"cosine\"``:    Cosine similarity (-1...1)\n            - ``\"cosine_sq\"``: Squared Cosine similarity (0...1)\n\n        :examples:\n          >>>\n          >>> iris_h2o = h2o.import_file(path=pyunit_utils.locate(\"smalldata/iris/iris.csv\"))\n          >>> references = iris_h2o[10:150,0:4\n          >>> queries    = iris_h2o[0:10,0:4]\n          >>> A = references.distance(queries, \"l1\")\n          >>> B = references.distance(queries, \"l2\")\n          >>> C = references.distance(queries, \"cosine\")\n          >>> D = references.distance(queries, \"cosine_sq\")\n          >>> E = queries.distance(references, \"l1\")\n          >>> (E.transpose() == A).all()\n\n        :returns: An H2OFrame of the matrix containing pairwise distance / similarity between the \n            rows of this frame (N x p) and ``y`` (M x p), with dimensions (N x M).\n        \"\"\"\n        assert_is_type(y, H2OFrame)\n        if measure is None: measure = \"l2\"\n        return H2OFrame._expr(expr=ExprNode(\"distance\", self, y, measure))._frame()", "language": "python", "code": "def distance(self, y, measure=None):\n        \"\"\"\n        Compute a pairwise distance measure between all rows of two numeric H2OFrames.\n\n        :param H2OFrame y: Frame containing queries (small)\n        :param str use: A string indicating what distance measure to use. Must be one of:\n\n            - ``\"l1\"``:        Absolute distance (L1-norm, >=0)\n            - ``\"l2\"``:        Euclidean distance (L2-norm, >=0)\n            - ``\"cosine\"``:    Cosine similarity (-1...1)\n            - ``\"cosine_sq\"``: Squared Cosine similarity (0...1)\n\n        :examples:\n          >>>\n          >>> iris_h2o = h2o.import_file(path=pyunit_utils.locate(\"smalldata/iris/iris.csv\"))\n          >>> references = iris_h2o[10:150,0:4\n          >>> queries    = iris_h2o[0:10,0:4]\n          >>> A = references.distance(queries, \"l1\")\n          >>> B = references.distance(queries, \"l2\")\n          >>> C = references.distance(queries, \"cosine\")\n          >>> D = references.distance(queries, \"cosine_sq\")\n          >>> E = queries.distance(references, \"l1\")\n          >>> (E.transpose() == A).all()\n\n        :returns: An H2OFrame of the matrix containing pairwise distance / similarity between the \n            rows of this frame (N x p) and ``y`` (M x p), with dimensions (N x M).\n        \"\"\"\n        assert_is_type(y, H2OFrame)\n        if measure is None: measure = \"l2\"\n        return H2OFrame._expr(expr=ExprNode(\"distance\", self, y, measure))._frame()", "code_tokens": ["def", "distance", "(", "self", ",", "y", ",", "measure", "=", "None", ")", ":", "assert_is_type", "(", "y", ",", "H2OFrame", ")", "if", "measure", "is", "None", ":", "measure", "=", "\"l2\"", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"distance\"", ",", "self", ",", "y", ",", "measure", ")", ")", ".", "_frame", "(", ")"], "docstring": "Compute a pairwise distance measure between all rows of two numeric H2OFrames.\n\n        :param H2OFrame y: Frame containing queries (small)\n        :param str use: A string indicating what distance measure to use. Must be one of:\n\n            - ``\"l1\"``:        Absolute distance (L1-norm, >=0)\n            - ``\"l2\"``:        Euclidean distance (L2-norm, >=0)\n            - ``\"cosine\"``:    Cosine similarity (-1...1)\n            - ``\"cosine_sq\"``: Squared Cosine similarity (0...1)\n\n        :examples:\n          >>>\n          >>> iris_h2o = h2o.import_file(path=pyunit_utils.locate(\"smalldata/iris/iris.csv\"))\n          >>> references = iris_h2o[10:150,0:4\n          >>> queries    = iris_h2o[0:10,0:4]\n          >>> A = references.distance(queries, \"l1\")\n          >>> B = references.distance(queries, \"l2\")\n          >>> C = references.distance(queries, \"cosine\")\n          >>> D = references.distance(queries, \"cosine_sq\")\n          >>> E = queries.distance(references, \"l1\")\n          >>> (E.transpose() == A).all()\n\n        :returns: An H2OFrame of the matrix containing pairwise distance / similarity between the \n            rows of this frame (N x p) and ``y`` (M x p), with dimensions (N x M).", "docstring_tokens": ["Compute", "a", "pairwise", "distance", "measure", "between", "all", "rows", "of", "two", "numeric", "H2OFrames", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2214-L2243", "partition": "test", "index": 1422, "time": "2017-03-15 18:50:55"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.idxmax", "original_string": "def idxmax(self,skipna=True, axis=0):\n        \"\"\"\n        Get the index of the max value in a column or row\n\n        :param bool skipna: If True (default), then NAs are ignored during the search. Otherwise presence\n            of NAs renders the entire result NA.\n        :param int axis: Direction of finding the max index. If 0 (default), then the max index is searched columnwise, and the\n            result is a frame with 1 row and number of columns as in the original frame. If 1, then the max index is searched\n            rowwise and the result is a frame with 1 column, and number of rows equal to the number of rows in the original frame.\n        :returns: either a list of max index values per-column or an H2OFrame containing max index values\n                  per-row from the original frame.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"which.max\", self, skipna, axis))", "language": "python", "code": "def idxmax(self,skipna=True, axis=0):\n        \"\"\"\n        Get the index of the max value in a column or row\n\n        :param bool skipna: If True (default), then NAs are ignored during the search. Otherwise presence\n            of NAs renders the entire result NA.\n        :param int axis: Direction of finding the max index. If 0 (default), then the max index is searched columnwise, and the\n            result is a frame with 1 row and number of columns as in the original frame. If 1, then the max index is searched\n            rowwise and the result is a frame with 1 column, and number of rows equal to the number of rows in the original frame.\n        :returns: either a list of max index values per-column or an H2OFrame containing max index values\n                  per-row from the original frame.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"which.max\", self, skipna, axis))", "code_tokens": ["def", "idxmax", "(", "self", ",", "skipna", "=", "True", ",", "axis", "=", "0", ")", ":", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"which.max\"", ",", "self", ",", "skipna", ",", "axis", ")", ")"], "docstring": "Get the index of the max value in a column or row\n\n        :param bool skipna: If True (default), then NAs are ignored during the search. Otherwise presence\n            of NAs renders the entire result NA.\n        :param int axis: Direction of finding the max index. If 0 (default), then the max index is searched columnwise, and the\n            result is a frame with 1 row and number of columns as in the original frame. If 1, then the max index is searched\n            rowwise and the result is a frame with 1 column, and number of rows equal to the number of rows in the original frame.\n        :returns: either a list of max index values per-column or an H2OFrame containing max index values\n                  per-row from the original frame.", "docstring_tokens": ["Get", "the", "index", "of", "the", "max", "value", "in", "a", "column", "or", "row"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L3256-L3268", "partition": "test", "index": 1443, "time": "2017-03-16 19:19:22"}
{"repo": "h2oai/h2o-3", "path": "scripts/scrapeForIntermittents.py", "func_name": "trim_data_back_to", "original_string": "def trim_data_back_to(monthToKeep):\n    \"\"\"\n    This method will remove data from the summary text file and the dictionary file for tests that occurs before\n    the number of months specified by monthToKeep.\n\n    :param monthToKeep:\n    :return:\n    \"\"\"\n    global g_failed_tests_info_dict\n    current_time = time.time()      # unit in seconds\n\n    oldest_time_allowed = current_time - monthToKeep*30*24*3600 # in seconds\n\n    clean_up_failed_test_dict(oldest_time_allowed)\n    clean_up_summary_text(oldest_time_allowed)", "language": "python", "code": "def trim_data_back_to(monthToKeep):\n    \"\"\"\n    This method will remove data from the summary text file and the dictionary file for tests that occurs before\n    the number of months specified by monthToKeep.\n\n    :param monthToKeep:\n    :return:\n    \"\"\"\n    global g_failed_tests_info_dict\n    current_time = time.time()      # unit in seconds\n\n    oldest_time_allowed = current_time - monthToKeep*30*24*3600 # in seconds\n\n    clean_up_failed_test_dict(oldest_time_allowed)\n    clean_up_summary_text(oldest_time_allowed)", "code_tokens": ["def", "trim_data_back_to", "(", "monthToKeep", ")", ":", "global", "g_failed_tests_info_dict", "current_time", "=", "time", ".", "time", "(", ")", "# unit in seconds", "oldest_time_allowed", "=", "current_time", "-", "monthToKeep", "*", "30", "*", "24", "*", "3600", "# in seconds", "clean_up_failed_test_dict", "(", "oldest_time_allowed", ")", "clean_up_summary_text", "(", "oldest_time_allowed", ")"], "docstring": "This method will remove data from the summary text file and the dictionary file for tests that occurs before\n    the number of months specified by monthToKeep.\n\n    :param monthToKeep:\n    :return:", "docstring_tokens": ["This", "method", "will", "remove", "data", "from", "the", "summary", "text", "file", "and", "the", "dictionary", "file", "for", "tests", "that", "occurs", "before", "the", "number", "of", "months", "specified", "by", "monthToKeep", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/scrapeForIntermittents.py#L231-L245", "partition": "test", "index": 1582, "time": "2017-03-29 09:53:43"}
{"repo": "h2oai/h2o-3", "path": "scripts/summarizeIntermittens.py", "func_name": "extractPrintSaveIntermittens", "original_string": "def extractPrintSaveIntermittens():\n    \"\"\"\n    This function will print out the intermittents onto the screen for casual viewing.  It will also print out\n    where the giant summary dictionary is going to be stored.\n\n    :return: None\n    \"\"\"\n    # extract intermittents from collected failed tests\n    global g_summary_dict_intermittents\n\n    localtz = time.tzname[0]\n\n\n    for ind in range(len(g_summary_dict_all[\"TestName\"])):\n        if g_summary_dict_all[\"TestInfo\"][ind][\"FailureCount\"] >= g_threshold_failure:\n            addFailedTests(g_summary_dict_intermittents, g_summary_dict_all, ind)\n\n    # save dict in file\n    if len(g_summary_dict_intermittents[\"TestName\"]) > 0:\n        json.dump(g_summary_dict_intermittents, open(g_summary_dict_name, 'w'))\n\n        with open(g_summary_csv_filename, 'w') as summaryFile:\n            for ind in range(len(g_summary_dict_intermittents[\"TestName\"])):\n                testName = g_summary_dict_intermittents[\"TestName\"][ind]\n                numberFailure = g_summary_dict_intermittents[\"TestInfo\"][ind][\"FailureCount\"]\n                firstFailedTS  = parser.parse(time.ctime(min(g_summary_dict_intermittents[\"TestInfo\"][ind][\"Timestamp\"]))+\n                                              ' '+localtz)\n                firstFailedStr = firstFailedTS.strftime(\"%a %b %d %H:%M:%S %Y %Z\")\n                recentFail = parser.parse(time.ctime(max(g_summary_dict_intermittents[\"TestInfo\"][ind][\"Timestamp\"]))+\n                                          ' '+localtz)\n                recentFailStr = recentFail.strftime(\"%a %b %d %H:%M:%S %Y %Z\")\n                eachTest = \"{0}, {1}, {2}, {3}\\n\".format(testName, recentFailStr, numberFailure,\n                                                       g_summary_dict_intermittents[\"TestInfo\"][ind][\"TestCategory\"][0])\n                summaryFile.write(eachTest)\n                print(\"Intermittent: {0}, Last failed: {1}, Failed {2} times since \"\n                      \"{3}\".format(testName, recentFailStr, numberFailure, firstFailedStr))", "language": "python", "code": "def extractPrintSaveIntermittens():\n    \"\"\"\n    This function will print out the intermittents onto the screen for casual viewing.  It will also print out\n    where the giant summary dictionary is going to be stored.\n\n    :return: None\n    \"\"\"\n    # extract intermittents from collected failed tests\n    global g_summary_dict_intermittents\n\n    localtz = time.tzname[0]\n\n\n    for ind in range(len(g_summary_dict_all[\"TestName\"])):\n        if g_summary_dict_all[\"TestInfo\"][ind][\"FailureCount\"] >= g_threshold_failure:\n            addFailedTests(g_summary_dict_intermittents, g_summary_dict_all, ind)\n\n    # save dict in file\n    if len(g_summary_dict_intermittents[\"TestName\"]) > 0:\n        json.dump(g_summary_dict_intermittents, open(g_summary_dict_name, 'w'))\n\n        with open(g_summary_csv_filename, 'w') as summaryFile:\n            for ind in range(len(g_summary_dict_intermittents[\"TestName\"])):\n                testName = g_summary_dict_intermittents[\"TestName\"][ind]\n                numberFailure = g_summary_dict_intermittents[\"TestInfo\"][ind][\"FailureCount\"]\n                firstFailedTS  = parser.parse(time.ctime(min(g_summary_dict_intermittents[\"TestInfo\"][ind][\"Timestamp\"]))+\n                                              ' '+localtz)\n                firstFailedStr = firstFailedTS.strftime(\"%a %b %d %H:%M:%S %Y %Z\")\n                recentFail = parser.parse(time.ctime(max(g_summary_dict_intermittents[\"TestInfo\"][ind][\"Timestamp\"]))+\n                                          ' '+localtz)\n                recentFailStr = recentFail.strftime(\"%a %b %d %H:%M:%S %Y %Z\")\n                eachTest = \"{0}, {1}, {2}, {3}\\n\".format(testName, recentFailStr, numberFailure,\n                                                       g_summary_dict_intermittents[\"TestInfo\"][ind][\"TestCategory\"][0])\n                summaryFile.write(eachTest)\n                print(\"Intermittent: {0}, Last failed: {1}, Failed {2} times since \"\n                      \"{3}\".format(testName, recentFailStr, numberFailure, firstFailedStr))", "code_tokens": ["def", "extractPrintSaveIntermittens", "(", ")", ":", "# extract intermittents from collected failed tests", "global", "g_summary_dict_intermittents", "localtz", "=", "time", ".", "tzname", "[", "0", "]", "for", "ind", "in", "range", "(", "len", "(", "g_summary_dict_all", "[", "\"TestName\"", "]", ")", ")", ":", "if", "g_summary_dict_all", "[", "\"TestInfo\"", "]", "[", "ind", "]", "[", "\"FailureCount\"", "]", ">=", "g_threshold_failure", ":", "addFailedTests", "(", "g_summary_dict_intermittents", ",", "g_summary_dict_all", ",", "ind", ")", "# save dict in file", "if", "len", "(", "g_summary_dict_intermittents", "[", "\"TestName\"", "]", ")", ">", "0", ":", "json", ".", "dump", "(", "g_summary_dict_intermittents", ",", "open", "(", "g_summary_dict_name", ",", "'w'", ")", ")", "with", "open", "(", "g_summary_csv_filename", ",", "'w'", ")", "as", "summaryFile", ":", "for", "ind", "in", "range", "(", "len", "(", "g_summary_dict_intermittents", "[", "\"TestName\"", "]", ")", ")", ":", "testName", "=", "g_summary_dict_intermittents", "[", "\"TestName\"", "]", "[", "ind", "]", "numberFailure", "=", "g_summary_dict_intermittents", "[", "\"TestInfo\"", "]", "[", "ind", "]", "[", "\"FailureCount\"", "]", "firstFailedTS", "=", "parser", ".", "parse", "(", "time", ".", "ctime", "(", "min", "(", "g_summary_dict_intermittents", "[", "\"TestInfo\"", "]", "[", "ind", "]", "[", "\"Timestamp\"", "]", ")", ")", "+", "' '", "+", "localtz", ")", "firstFailedStr", "=", "firstFailedTS", ".", "strftime", "(", "\"%a %b %d %H:%M:%S %Y %Z\"", ")", "recentFail", "=", "parser", ".", "parse", "(", "time", ".", "ctime", "(", "max", "(", "g_summary_dict_intermittents", "[", "\"TestInfo\"", "]", "[", "ind", "]", "[", "\"Timestamp\"", "]", ")", ")", "+", "' '", "+", "localtz", ")", "recentFailStr", "=", "recentFail", ".", "strftime", "(", "\"%a %b %d %H:%M:%S %Y %Z\"", ")", "eachTest", "=", "\"{0}, {1}, {2}, {3}\\n\"", ".", "format", "(", "testName", ",", "recentFailStr", ",", "numberFailure", ",", "g_summary_dict_intermittents", "[", "\"TestInfo\"", "]", "[", "ind", "]", "[", "\"TestCategory\"", "]", "[", "0", "]", ")", "summaryFile", ".", "write", "(", "eachTest", ")", "print", "(", "\"Intermittent: {0}, Last failed: {1}, Failed {2} times since \"", "\"{3}\"", ".", "format", "(", "testName", ",", "recentFailStr", ",", "numberFailure", ",", "firstFailedStr", ")", ")"], "docstring": "This function will print out the intermittents onto the screen for casual viewing.  It will also print out\n    where the giant summary dictionary is going to be stored.\n\n    :return: None", "docstring_tokens": ["This", "function", "will", "print", "out", "the", "intermittents", "onto", "the", "screen", "for", "casual", "viewing", ".", "It", "will", "also", "print", "out", "where", "the", "giant", "summary", "dictionary", "is", "going", "to", "be", "stored", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/summarizeIntermittens.py#L144-L179", "partition": "test", "index": 1578, "time": "2017-03-29 09:53:43"}
{"repo": "h2oai/h2o-3", "path": "scripts/summarizeIntermittens.py", "func_name": "summarizeFailedRuns", "original_string": "def summarizeFailedRuns():\n    \"\"\"\n    This function will look at the local directory and pick out files that have the correct start name and\n    summarize the results into one giant dict.\n\n    :return: None\n    \"\"\"\n    global g_summary_dict_all\n\n    onlyFiles = [x for x in listdir(g_test_root_dir) if isfile(join(g_test_root_dir, x))]   # grab files\n\n    for f in onlyFiles:\n        for fileStart in g_file_start:\n            if (fileStart in f) and (os.path.getsize(f) > 10):  # found the file containing failed tests\n                fFullPath = os.path.join(g_test_root_dir, f)\n                try:\n                    temp_dict = json.load(open(fFullPath,'r'))\n\n                    # scrape through temp_dict and see if we need to add the test to intermittents\n                    for ind in range(len(temp_dict[\"TestName\"])):\n                        addFailedTests(g_summary_dict_all, temp_dict, ind)\n                except:\n                    continue\n                break", "language": "python", "code": "def summarizeFailedRuns():\n    \"\"\"\n    This function will look at the local directory and pick out files that have the correct start name and\n    summarize the results into one giant dict.\n\n    :return: None\n    \"\"\"\n    global g_summary_dict_all\n\n    onlyFiles = [x for x in listdir(g_test_root_dir) if isfile(join(g_test_root_dir, x))]   # grab files\n\n    for f in onlyFiles:\n        for fileStart in g_file_start:\n            if (fileStart in f) and (os.path.getsize(f) > 10):  # found the file containing failed tests\n                fFullPath = os.path.join(g_test_root_dir, f)\n                try:\n                    temp_dict = json.load(open(fFullPath,'r'))\n\n                    # scrape through temp_dict and see if we need to add the test to intermittents\n                    for ind in range(len(temp_dict[\"TestName\"])):\n                        addFailedTests(g_summary_dict_all, temp_dict, ind)\n                except:\n                    continue\n                break", "code_tokens": ["def", "summarizeFailedRuns", "(", ")", ":", "global", "g_summary_dict_all", "onlyFiles", "=", "[", "x", "for", "x", "in", "listdir", "(", "g_test_root_dir", ")", "if", "isfile", "(", "join", "(", "g_test_root_dir", ",", "x", ")", ")", "]", "# grab files", "for", "f", "in", "onlyFiles", ":", "for", "fileStart", "in", "g_file_start", ":", "if", "(", "fileStart", "in", "f", ")", "and", "(", "os", ".", "path", ".", "getsize", "(", "f", ")", ">", "10", ")", ":", "# found the file containing failed tests", "fFullPath", "=", "os", ".", "path", ".", "join", "(", "g_test_root_dir", ",", "f", ")", "try", ":", "temp_dict", "=", "json", ".", "load", "(", "open", "(", "fFullPath", ",", "'r'", ")", ")", "# scrape through temp_dict and see if we need to add the test to intermittents", "for", "ind", "in", "range", "(", "len", "(", "temp_dict", "[", "\"TestName\"", "]", ")", ")", ":", "addFailedTests", "(", "g_summary_dict_all", ",", "temp_dict", ",", "ind", ")", "except", ":", "continue", "break"], "docstring": "This function will look at the local directory and pick out files that have the correct start name and\n    summarize the results into one giant dict.\n\n    :return: None", "docstring_tokens": ["This", "function", "will", "look", "at", "the", "local", "directory", "and", "pick", "out", "files", "that", "have", "the", "correct", "start", "name", "and", "summarize", "the", "results", "into", "one", "giant", "dict", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/summarizeIntermittens.py#L69-L92", "partition": "test", "index": 1577, "time": "2017-03-29 09:53:43"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.grep", "original_string": "def grep(self,pattern, ignore_case = False, invert = False, output_logical = False):\n        \"\"\"\n        Searches for matches to argument `pattern` within each element\n        of a string column.\n\n        Default behavior is to return indices of the elements matching the pattern. Parameter\n        `output_logical` can be used to return a logical vector indicating if the element matches\n        the pattern (1) or not (0).\n\n        :param str pattern: A character string containing a regular expression.\n        :param bool ignore_case: If True, then case is ignored during matching.\n        :param bool invert:  If True, then identify elements that do not match the pattern.\n        :param bool output_logical: If True, then return logical vector of indicators instead of list of matching positions\n        :return: H2OFrame holding the matching positions or a logical list if `output_logical` is enabled.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"grep\", self, pattern, ignore_case, invert, output_logical))", "language": "python", "code": "def grep(self,pattern, ignore_case = False, invert = False, output_logical = False):\n        \"\"\"\n        Searches for matches to argument `pattern` within each element\n        of a string column.\n\n        Default behavior is to return indices of the elements matching the pattern. Parameter\n        `output_logical` can be used to return a logical vector indicating if the element matches\n        the pattern (1) or not (0).\n\n        :param str pattern: A character string containing a regular expression.\n        :param bool ignore_case: If True, then case is ignored during matching.\n        :param bool invert:  If True, then identify elements that do not match the pattern.\n        :param bool output_logical: If True, then return logical vector of indicators instead of list of matching positions\n        :return: H2OFrame holding the matching positions or a logical list if `output_logical` is enabled.\n        \"\"\"\n        return H2OFrame._expr(expr=ExprNode(\"grep\", self, pattern, ignore_case, invert, output_logical))", "code_tokens": ["def", "grep", "(", "self", ",", "pattern", ",", "ignore_case", "=", "False", ",", "invert", "=", "False", ",", "output_logical", "=", "False", ")", ":", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"grep\"", ",", "self", ",", "pattern", ",", "ignore_case", ",", "invert", ",", "output_logical", ")", ")"], "docstring": "Searches for matches to argument `pattern` within each element\n        of a string column.\n\n        Default behavior is to return indices of the elements matching the pattern. Parameter\n        `output_logical` can be used to return a logical vector indicating if the element matches\n        the pattern (1) or not (0).\n\n        :param str pattern: A character string containing a regular expression.\n        :param bool ignore_case: If True, then case is ignored during matching.\n        :param bool invert:  If True, then identify elements that do not match the pattern.\n        :param bool output_logical: If True, then return logical vector of indicators instead of list of matching positions\n        :return: H2OFrame holding the matching positions or a logical list if `output_logical` is enabled.", "docstring_tokens": ["Searches", "for", "matches", "to", "argument", "pattern", "within", "each", "element", "of", "a", "string", "column", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2932-L2947", "partition": "test", "index": 1435, "time": "2017-04-06 10:31:10"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/model/dim_reduction.py", "func_name": "H2ODimReductionModel.varimp", "original_string": "def varimp(self, use_pandas=False):\n        \"\"\"\n        Return the Importance of components associcated with a pca model.\n\n        use_pandas: ``bool``  (default: ``False``).\n        \"\"\"\n        model = self._model_json[\"output\"]\n        if \"importance\" in list(model.keys()) and model[\"importance\"]:\n            vals = model[\"importance\"].cell_values\n            header = model[\"importance\"].col_header\n            if use_pandas and can_use_pandas():\n                import pandas\n                return pandas.DataFrame(vals, columns=header)\n            else:\n                return vals\n        else:\n            print(\"Warning: This model doesn't have importances of components.\")", "language": "python", "code": "def varimp(self, use_pandas=False):\n        \"\"\"\n        Return the Importance of components associcated with a pca model.\n\n        use_pandas: ``bool``  (default: ``False``).\n        \"\"\"\n        model = self._model_json[\"output\"]\n        if \"importance\" in list(model.keys()) and model[\"importance\"]:\n            vals = model[\"importance\"].cell_values\n            header = model[\"importance\"].col_header\n            if use_pandas and can_use_pandas():\n                import pandas\n                return pandas.DataFrame(vals, columns=header)\n            else:\n                return vals\n        else:\n            print(\"Warning: This model doesn't have importances of components.\")", "code_tokens": ["def", "varimp", "(", "self", ",", "use_pandas", "=", "False", ")", ":", "model", "=", "self", ".", "_model_json", "[", "\"output\"", "]", "if", "\"importance\"", "in", "list", "(", "model", ".", "keys", "(", ")", ")", "and", "model", "[", "\"importance\"", "]", ":", "vals", "=", "model", "[", "\"importance\"", "]", ".", "cell_values", "header", "=", "model", "[", "\"importance\"", "]", ".", "col_header", "if", "use_pandas", "and", "can_use_pandas", "(", ")", ":", "import", "pandas", "return", "pandas", ".", "DataFrame", "(", "vals", ",", "columns", "=", "header", ")", "else", ":", "return", "vals", "else", ":", "print", "(", "\"Warning: This model doesn't have importances of components.\"", ")"], "docstring": "Return the Importance of components associcated with a pca model.\n\n        use_pandas: ``bool``  (default: ``False``).", "docstring_tokens": ["Return", "the", "Importance", "of", "components", "associcated", "with", "a", "pca", "model", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/model/dim_reduction.py#L17-L33", "partition": "test", "index": 1491, "time": "2017-05-09 10:08:52"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.fillna", "original_string": "def fillna(self,method=\"forward\",axis=0,maxlen=1):\n        \"\"\"\n        Return a new Frame that fills NA along a given axis and along a given direction with a maximum fill length\n\n        :param method: ``\"forward\"`` or ``\"backward\"``\n        :param axis:  0 for columnar-wise or 1 for row-wise fill\n        :param maxlen: Max number of consecutive NA's to fill\n        \n        :return: \n        \"\"\"\n        assert_is_type(axis, 0, 1)\n        assert_is_type(method,str)\n        assert_is_type(maxlen, int)\n        return H2OFrame._expr(expr=ExprNode(\"h2o.fillna\",self,method,axis,maxlen))", "language": "python", "code": "def fillna(self,method=\"forward\",axis=0,maxlen=1):\n        \"\"\"\n        Return a new Frame that fills NA along a given axis and along a given direction with a maximum fill length\n\n        :param method: ``\"forward\"`` or ``\"backward\"``\n        :param axis:  0 for columnar-wise or 1 for row-wise fill\n        :param maxlen: Max number of consecutive NA's to fill\n        \n        :return: \n        \"\"\"\n        assert_is_type(axis, 0, 1)\n        assert_is_type(method,str)\n        assert_is_type(maxlen, int)\n        return H2OFrame._expr(expr=ExprNode(\"h2o.fillna\",self,method,axis,maxlen))", "code_tokens": ["def", "fillna", "(", "self", ",", "method", "=", "\"forward\"", ",", "axis", "=", "0", ",", "maxlen", "=", "1", ")", ":", "assert_is_type", "(", "axis", ",", "0", ",", "1", ")", "assert_is_type", "(", "method", ",", "str", ")", "assert_is_type", "(", "maxlen", ",", "int", ")", "return", "H2OFrame", ".", "_expr", "(", "expr", "=", "ExprNode", "(", "\"h2o.fillna\"", ",", "self", ",", "method", ",", "axis", ",", "maxlen", ")", ")"], "docstring": "Return a new Frame that fills NA along a given axis and along a given direction with a maximum fill length\n\n        :param method: ``\"forward\"`` or ``\"backward\"``\n        :param axis:  0 for columnar-wise or 1 for row-wise fill\n        :param maxlen: Max number of consecutive NA's to fill\n        \n        :return:", "docstring_tokens": ["Return", "a", "new", "Frame", "that", "fills", "NA", "along", "a", "given", "axis", "and", "along", "a", "given", "direction", "with", "a", "maximum", "fill", "length"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1868-L1881", "partition": "test", "index": 1415, "time": "2017-06-03 23:45:31"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "upload_custom_metric", "original_string": "def upload_custom_metric(func, func_file=\"metrics.py\", func_name=None, class_name=None, source_provider=None):\n    \"\"\"\n    Upload given metrics function into H2O cluster.\n\n    The metrics can have different representation:\n      - class: needs to implement map(pred, act, weight, offset, model), reduce(l, r) and metric(l) methods\n      - string: the same as in class case, but the class is given as a string\n\n    :param func:  metric representation: string, class\n    :param func_file:  internal name of file to save given metrics representation\n    :param func_name:  name for h2o key under which the given metric is saved\n    :param class_name: name of class wrapping the metrics function (when supplied as string)\n    :param source_provider: a function which provides a source code for given function\n    :return: reference to uploaded metrics function\n\n    :examples:\n        >>> class CustomMaeFunc:\n        >>>     def map(self, pred, act, w, o, model):\n        >>>         return [abs(act[0] - pred[0]), 1]\n        >>>\n        >>>     def reduce(self, l, r):\n        >>>         return [l[0] + r[0], l[1] + r[1]]\n        >>>\n        >>>     def metric(self, l):\n        >>>         return l[0] / l[1]\n        >>>\n        >>>\n        >>> h2o.upload_custom_metric(CustomMaeFunc, func_name=\"mae\")\n        >>>\n        >>> custom_func_str = '''class CustomMaeFunc:\n        >>>     def map(self, pred, act, w, o, model):\n        >>>         return [abs(act[0] - pred[0]), 1]\n        >>>\n        >>>     def reduce(self, l, r):\n        >>>         return [l[0] + r[0], l[1] + r[1]]\n        >>>\n        >>>     def metric(self, l):\n        >>>         return l[0] / l[1]'''\n        >>>\n        >>>\n        >>> h2o.upload_custom_metric(custom_func_str, class_name=\"CustomMaeFunc\", func_name=\"mae\")\n    \"\"\"\n    import tempfile\n    import inspect\n\n    # Use default source provider\n    if not source_provider:\n        source_provider = _default_source_provider\n\n    # The template wraps given metrics representation\n    _CFUNC_CODE_TEMPLATE = \"\"\"# Generated code\nimport water.udf.CMetricFunc as MetricFunc\n\n# User given metric function as a class implementing\n# 3 methods defined by interface CMetricFunc\n{}\n\n# Generated user metric which satisfies the interface\n# of Java MetricFunc\nclass {}Wrapper({}, MetricFunc, object):\n    pass\n\n\"\"\"\n\n    assert_satisfies(func, inspect.isclass(func) or isinstance(func, str),\n                     \"The argument func needs to be string or class !\")\n    assert_satisfies(func_file, func_file is not None,\n                     \"The argument func_file is missing!\")\n    assert_satisfies(func_file, func_file.endswith('.py'),\n                     \"The argument func_file needs to end with '.py'\")\n    code = None\n    derived_func_name = None\n    module_name = func_file[:-3]\n    if isinstance(func, str):\n        assert_satisfies(class_name, class_name is not None,\n                         \"The argument class_name is missing! \" +\n                         \"It needs to reference the class in given string!\")\n        code = _CFUNC_CODE_TEMPLATE.format(func, class_name, class_name)\n        derived_func_name = \"metrics_{}\".format(class_name)\n        class_name = \"{}.{}Wrapper\".format(module_name, class_name)\n    else:\n        assert_satisfies(func, inspect.isclass(func), \"The parameter `func` should be str or class\")\n        for method in ['map', 'reduce', 'metric']:\n            assert_satisfies(func, method in func.__dict__, \"The class `func` needs to define method `{}`\".format(method))\n\n        assert_satisfies(class_name, class_name is None,\n                         \"If class is specified then class_name parameter needs to be None\")\n\n        class_name = \"{}.{}Wrapper\".format(module_name, func.__name__)\n        derived_func_name = \"metrics_{}\".format(func.__name__)\n        code = _CFUNC_CODE_TEMPLATE.format(source_provider(func), func.__name__, func.__name__)\n\n    # If the func name is not given, use whatever we can derived from given definition\n    if not func_name:\n        func_name = derived_func_name\n    # Saved into jar file\n    tmpdir = tempfile.mkdtemp(prefix=\"h2o-func\")\n    func_arch_file = _create_zip_file(\"{}/func.jar\".format(tmpdir), (func_file, code))\n    # Upload into K/V\n    dest_key = _put_key(func_arch_file, dest_key=func_name)\n    # Reference\n    return \"python:{}={}\".format(dest_key, class_name)", "language": "python", "code": "def upload_custom_metric(func, func_file=\"metrics.py\", func_name=None, class_name=None, source_provider=None):\n    \"\"\"\n    Upload given metrics function into H2O cluster.\n\n    The metrics can have different representation:\n      - class: needs to implement map(pred, act, weight, offset, model), reduce(l, r) and metric(l) methods\n      - string: the same as in class case, but the class is given as a string\n\n    :param func:  metric representation: string, class\n    :param func_file:  internal name of file to save given metrics representation\n    :param func_name:  name for h2o key under which the given metric is saved\n    :param class_name: name of class wrapping the metrics function (when supplied as string)\n    :param source_provider: a function which provides a source code for given function\n    :return: reference to uploaded metrics function\n\n    :examples:\n        >>> class CustomMaeFunc:\n        >>>     def map(self, pred, act, w, o, model):\n        >>>         return [abs(act[0] - pred[0]), 1]\n        >>>\n        >>>     def reduce(self, l, r):\n        >>>         return [l[0] + r[0], l[1] + r[1]]\n        >>>\n        >>>     def metric(self, l):\n        >>>         return l[0] / l[1]\n        >>>\n        >>>\n        >>> h2o.upload_custom_metric(CustomMaeFunc, func_name=\"mae\")\n        >>>\n        >>> custom_func_str = '''class CustomMaeFunc:\n        >>>     def map(self, pred, act, w, o, model):\n        >>>         return [abs(act[0] - pred[0]), 1]\n        >>>\n        >>>     def reduce(self, l, r):\n        >>>         return [l[0] + r[0], l[1] + r[1]]\n        >>>\n        >>>     def metric(self, l):\n        >>>         return l[0] / l[1]'''\n        >>>\n        >>>\n        >>> h2o.upload_custom_metric(custom_func_str, class_name=\"CustomMaeFunc\", func_name=\"mae\")\n    \"\"\"\n    import tempfile\n    import inspect\n\n    # Use default source provider\n    if not source_provider:\n        source_provider = _default_source_provider\n\n    # The template wraps given metrics representation\n    _CFUNC_CODE_TEMPLATE = \"\"\"# Generated code\nimport water.udf.CMetricFunc as MetricFunc\n\n# User given metric function as a class implementing\n# 3 methods defined by interface CMetricFunc\n{}\n\n# Generated user metric which satisfies the interface\n# of Java MetricFunc\nclass {}Wrapper({}, MetricFunc, object):\n    pass\n\n\"\"\"\n\n    assert_satisfies(func, inspect.isclass(func) or isinstance(func, str),\n                     \"The argument func needs to be string or class !\")\n    assert_satisfies(func_file, func_file is not None,\n                     \"The argument func_file is missing!\")\n    assert_satisfies(func_file, func_file.endswith('.py'),\n                     \"The argument func_file needs to end with '.py'\")\n    code = None\n    derived_func_name = None\n    module_name = func_file[:-3]\n    if isinstance(func, str):\n        assert_satisfies(class_name, class_name is not None,\n                         \"The argument class_name is missing! \" +\n                         \"It needs to reference the class in given string!\")\n        code = _CFUNC_CODE_TEMPLATE.format(func, class_name, class_name)\n        derived_func_name = \"metrics_{}\".format(class_name)\n        class_name = \"{}.{}Wrapper\".format(module_name, class_name)\n    else:\n        assert_satisfies(func, inspect.isclass(func), \"The parameter `func` should be str or class\")\n        for method in ['map', 'reduce', 'metric']:\n            assert_satisfies(func, method in func.__dict__, \"The class `func` needs to define method `{}`\".format(method))\n\n        assert_satisfies(class_name, class_name is None,\n                         \"If class is specified then class_name parameter needs to be None\")\n\n        class_name = \"{}.{}Wrapper\".format(module_name, func.__name__)\n        derived_func_name = \"metrics_{}\".format(func.__name__)\n        code = _CFUNC_CODE_TEMPLATE.format(source_provider(func), func.__name__, func.__name__)\n\n    # If the func name is not given, use whatever we can derived from given definition\n    if not func_name:\n        func_name = derived_func_name\n    # Saved into jar file\n    tmpdir = tempfile.mkdtemp(prefix=\"h2o-func\")\n    func_arch_file = _create_zip_file(\"{}/func.jar\".format(tmpdir), (func_file, code))\n    # Upload into K/V\n    dest_key = _put_key(func_arch_file, dest_key=func_name)\n    # Reference\n    return \"python:{}={}\".format(dest_key, class_name)", "code_tokens": ["def", "upload_custom_metric", "(", "func", ",", "func_file", "=", "\"metrics.py\"", ",", "func_name", "=", "None", ",", "class_name", "=", "None", ",", "source_provider", "=", "None", ")", ":", "import", "tempfile", "import", "inspect", "# Use default source provider", "if", "not", "source_provider", ":", "source_provider", "=", "_default_source_provider", "# The template wraps given metrics representation", "_CFUNC_CODE_TEMPLATE", "=", "\"\"\"# Generated code\nimport water.udf.CMetricFunc as MetricFunc\n\n# User given metric function as a class implementing\n# 3 methods defined by interface CMetricFunc\n{}\n\n# Generated user metric which satisfies the interface\n# of Java MetricFunc\nclass {}Wrapper({}, MetricFunc, object):\n    pass\n\n\"\"\"", "assert_satisfies", "(", "func", ",", "inspect", ".", "isclass", "(", "func", ")", "or", "isinstance", "(", "func", ",", "str", ")", ",", "\"The argument func needs to be string or class !\"", ")", "assert_satisfies", "(", "func_file", ",", "func_file", "is", "not", "None", ",", "\"The argument func_file is missing!\"", ")", "assert_satisfies", "(", "func_file", ",", "func_file", ".", "endswith", "(", "'.py'", ")", ",", "\"The argument func_file needs to end with '.py'\"", ")", "code", "=", "None", "derived_func_name", "=", "None", "module_name", "=", "func_file", "[", ":", "-", "3", "]", "if", "isinstance", "(", "func", ",", "str", ")", ":", "assert_satisfies", "(", "class_name", ",", "class_name", "is", "not", "None", ",", "\"The argument class_name is missing! \"", "+", "\"It needs to reference the class in given string!\"", ")", "code", "=", "_CFUNC_CODE_TEMPLATE", ".", "format", "(", "func", ",", "class_name", ",", "class_name", ")", "derived_func_name", "=", "\"metrics_{}\"", ".", "format", "(", "class_name", ")", "class_name", "=", "\"{}.{}Wrapper\"", ".", "format", "(", "module_name", ",", "class_name", ")", "else", ":", "assert_satisfies", "(", "func", ",", "inspect", ".", "isclass", "(", "func", ")", ",", "\"The parameter `func` should be str or class\"", ")", "for", "method", "in", "[", "'map'", ",", "'reduce'", ",", "'metric'", "]", ":", "assert_satisfies", "(", "func", ",", "method", "in", "func", ".", "__dict__", ",", "\"The class `func` needs to define method `{}`\"", ".", "format", "(", "method", ")", ")", "assert_satisfies", "(", "class_name", ",", "class_name", "is", "None", ",", "\"If class is specified then class_name parameter needs to be None\"", ")", "class_name", "=", "\"{}.{}Wrapper\"", ".", "format", "(", "module_name", ",", "func", ".", "__name__", ")", "derived_func_name", "=", "\"metrics_{}\"", ".", "format", "(", "func", ".", "__name__", ")", "code", "=", "_CFUNC_CODE_TEMPLATE", ".", "format", "(", "source_provider", "(", "func", ")", ",", "func", ".", "__name__", ",", "func", ".", "__name__", ")", "# If the func name is not given, use whatever we can derived from given definition", "if", "not", "func_name", ":", "func_name", "=", "derived_func_name", "# Saved into jar file", "tmpdir", "=", "tempfile", ".", "mkdtemp", "(", "prefix", "=", "\"h2o-func\"", ")", "func_arch_file", "=", "_create_zip_file", "(", "\"{}/func.jar\"", ".", "format", "(", "tmpdir", ")", ",", "(", "func_file", ",", "code", ")", ")", "# Upload into K/V", "dest_key", "=", "_put_key", "(", "func_arch_file", ",", "dest_key", "=", "func_name", ")", "# Reference", "return", "\"python:{}={}\"", ".", "format", "(", "dest_key", ",", "class_name", ")"], "docstring": "Upload given metrics function into H2O cluster.\n\n    The metrics can have different representation:\n      - class: needs to implement map(pred, act, weight, offset, model), reduce(l, r) and metric(l) methods\n      - string: the same as in class case, but the class is given as a string\n\n    :param func:  metric representation: string, class\n    :param func_file:  internal name of file to save given metrics representation\n    :param func_name:  name for h2o key under which the given metric is saved\n    :param class_name: name of class wrapping the metrics function (when supplied as string)\n    :param source_provider: a function which provides a source code for given function\n    :return: reference to uploaded metrics function\n\n    :examples:\n        >>> class CustomMaeFunc:\n        >>>     def map(self, pred, act, w, o, model):\n        >>>         return [abs(act[0] - pred[0]), 1]\n        >>>\n        >>>     def reduce(self, l, r):\n        >>>         return [l[0] + r[0], l[1] + r[1]]\n        >>>\n        >>>     def metric(self, l):\n        >>>         return l[0] / l[1]\n        >>>\n        >>>\n        >>> h2o.upload_custom_metric(CustomMaeFunc, func_name=\"mae\")\n        >>>\n        >>> custom_func_str = '''class CustomMaeFunc:\n        >>>     def map(self, pred, act, w, o, model):\n        >>>         return [abs(act[0] - pred[0]), 1]\n        >>>\n        >>>     def reduce(self, l, r):\n        >>>         return [l[0] + r[0], l[1] + r[1]]\n        >>>\n        >>>     def metric(self, l):\n        >>>         return l[0] / l[1]'''\n        >>>\n        >>>\n        >>> h2o.upload_custom_metric(custom_func_str, class_name=\"CustomMaeFunc\", func_name=\"mae\")", "docstring_tokens": ["Upload", "given", "metrics", "function", "into", "H2O", "cluster", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L1430-L1531", "partition": "test", "index": 1475, "time": "2017-11-22 17:20:18"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "_put_key", "original_string": "def _put_key(file_path, dest_key=None, overwrite=True):\n    \"\"\"\n    Upload given file into DKV and save it under give key as raw object.\n\n    :param dest_key:  name of destination key in DKV\n    :param file_path:  path to file to upload\n    :return: key name if object was uploaded successfully\n    \"\"\"\n    ret = api(\"POST /3/PutKey?destination_key={}&overwrite={}\".format(dest_key if dest_key else '', overwrite),\n              filename=file_path)\n    return ret[\"destination_key\"]", "language": "python", "code": "def _put_key(file_path, dest_key=None, overwrite=True):\n    \"\"\"\n    Upload given file into DKV and save it under give key as raw object.\n\n    :param dest_key:  name of destination key in DKV\n    :param file_path:  path to file to upload\n    :return: key name if object was uploaded successfully\n    \"\"\"\n    ret = api(\"POST /3/PutKey?destination_key={}&overwrite={}\".format(dest_key if dest_key else '', overwrite),\n              filename=file_path)\n    return ret[\"destination_key\"]", "code_tokens": ["def", "_put_key", "(", "file_path", ",", "dest_key", "=", "None", ",", "overwrite", "=", "True", ")", ":", "ret", "=", "api", "(", "\"POST /3/PutKey?destination_key={}&overwrite={}\"", ".", "format", "(", "dest_key", "if", "dest_key", "else", "''", ",", "overwrite", ")", ",", "filename", "=", "file_path", ")", "return", "ret", "[", "\"destination_key\"", "]"], "docstring": "Upload given file into DKV and save it under give key as raw object.\n\n    :param dest_key:  name of destination key in DKV\n    :param file_path:  path to file to upload\n    :return: key name if object was uploaded successfully", "docstring_tokens": ["Upload", "given", "file", "into", "DKV", "and", "save", "it", "under", "give", "key", "as", "raw", "object", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L1388-L1398", "partition": "test", "index": 1474, "time": "2017-11-22 17:20:18"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/estimators/word2vec.py", "func_name": "H2OWord2vecEstimator._determine_vec_size", "original_string": "def _determine_vec_size(self):\n        \"\"\"\n        Determines vec_size for a pre-trained model after basic model verification.\n        \"\"\"\n        first_column = self.pre_trained.types[self.pre_trained.columns[0]]\n\n        if first_column != 'string':\n            raise H2OValueError(\"First column of given pre_trained model %s is required to be a String\",\n                                self.pre_trained.frame_id)\n\n        if list(self.pre_trained.types.values()).count('string') > 1:\n            raise H2OValueError(\"There are multiple columns in given pre_trained model %s with a String type.\",\n                                self.pre_trained.frame_id)\n\n        self.vec_size = self.pre_trained.dim[1] - 1;", "language": "python", "code": "def _determine_vec_size(self):\n        \"\"\"\n        Determines vec_size for a pre-trained model after basic model verification.\n        \"\"\"\n        first_column = self.pre_trained.types[self.pre_trained.columns[0]]\n\n        if first_column != 'string':\n            raise H2OValueError(\"First column of given pre_trained model %s is required to be a String\",\n                                self.pre_trained.frame_id)\n\n        if list(self.pre_trained.types.values()).count('string') > 1:\n            raise H2OValueError(\"There are multiple columns in given pre_trained model %s with a String type.\",\n                                self.pre_trained.frame_id)\n\n        self.vec_size = self.pre_trained.dim[1] - 1;", "code_tokens": ["def", "_determine_vec_size", "(", "self", ")", ":", "first_column", "=", "self", ".", "pre_trained", ".", "types", "[", "self", ".", "pre_trained", ".", "columns", "[", "0", "]", "]", "if", "first_column", "!=", "'string'", ":", "raise", "H2OValueError", "(", "\"First column of given pre_trained model %s is required to be a String\"", ",", "self", ".", "pre_trained", ".", "frame_id", ")", "if", "list", "(", "self", ".", "pre_trained", ".", "types", ".", "values", "(", ")", ")", ".", "count", "(", "'string'", ")", ">", "1", ":", "raise", "H2OValueError", "(", "\"There are multiple columns in given pre_trained model %s with a String type.\"", ",", "self", ".", "pre_trained", ".", "frame_id", ")", "self", ".", "vec_size", "=", "self", ".", "pre_trained", ".", "dim", "[", "1", "]", "-", "1"], "docstring": "Determines vec_size for a pre-trained model after basic model verification.", "docstring_tokens": ["Determines", "vec_size", "for", "a", "pre", "-", "trained", "model", "after", "basic", "model", "verification", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/estimators/word2vec.py#L244-L258", "partition": "test", "index": 1359, "time": "2018-01-13 15:56:42"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/estimators/stackedensemble.py", "func_name": "H2OStackedEnsembleEstimator.metalearner_params", "original_string": "def metalearner_params(self):\n        \"\"\"\n        Parameters for metalearner algorithm\n\n        Type: ``dict``  (default: ``None``).\n        Example: metalearner_gbm_params = {'max_depth': 2, 'col_sample_rate': 0.3}\n        \"\"\"\n        if self._parms.get(\"metalearner_params\") != None:\n            metalearner_params_dict =  ast.literal_eval(self._parms.get(\"metalearner_params\"))\n            for k in metalearner_params_dict:\n                if len(metalearner_params_dict[k]) == 1: #single parameter\n                    metalearner_params_dict[k] = metalearner_params_dict[k][0]\n            return metalearner_params_dict\n        else:\n            return self._parms.get(\"metalearner_params\")", "language": "python", "code": "def metalearner_params(self):\n        \"\"\"\n        Parameters for metalearner algorithm\n\n        Type: ``dict``  (default: ``None``).\n        Example: metalearner_gbm_params = {'max_depth': 2, 'col_sample_rate': 0.3}\n        \"\"\"\n        if self._parms.get(\"metalearner_params\") != None:\n            metalearner_params_dict =  ast.literal_eval(self._parms.get(\"metalearner_params\"))\n            for k in metalearner_params_dict:\n                if len(metalearner_params_dict[k]) == 1: #single parameter\n                    metalearner_params_dict[k] = metalearner_params_dict[k][0]\n            return metalearner_params_dict\n        else:\n            return self._parms.get(\"metalearner_params\")", "code_tokens": ["def", "metalearner_params", "(", "self", ")", ":", "if", "self", ".", "_parms", ".", "get", "(", "\"metalearner_params\"", ")", "!=", "None", ":", "metalearner_params_dict", "=", "ast", ".", "literal_eval", "(", "self", ".", "_parms", ".", "get", "(", "\"metalearner_params\"", ")", ")", "for", "k", "in", "metalearner_params_dict", ":", "if", "len", "(", "metalearner_params_dict", "[", "k", "]", ")", "==", "1", ":", "#single parameter", "metalearner_params_dict", "[", "k", "]", "=", "metalearner_params_dict", "[", "k", "]", "[", "0", "]", "return", "metalearner_params_dict", "else", ":", "return", "self", ".", "_parms", ".", "get", "(", "\"metalearner_params\"", ")"], "docstring": "Parameters for metalearner algorithm\n\n        Type: ``dict``  (default: ``None``).\n        Example: metalearner_gbm_params = {'max_depth': 2, 'col_sample_rate': 0.3}", "docstring_tokens": ["Parameters", "for", "metalearner", "algorithm"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/estimators/stackedensemble.py#L216-L230", "partition": "test", "index": 1325, "time": "2018-02-01 16:33:18"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/frame.py", "func_name": "H2OFrame.rename", "original_string": "def rename(self, columns=None):\n        \"\"\"\n        Change names of columns in the frame.\n\n        Dict key is an index or name of the column whose name is to be set.\n        Dict value is the new name of the column.\n\n        :param columns: dict-like transformations to apply to the column names\n        \"\"\"\n        assert_is_type(columns, None, dict)\n        new_names = self.names\n        ncols = self.ncols\n\n        for col, name in columns.items():\n            col_index = None\n            if is_type(col, int) and (-ncols <= col < ncols):\n                col_index = (col + ncols) % ncols  # handle negative indices\n            elif is_type(col, str) and col in self.names:\n                col_index = self.names.index(col)  # lookup the name\n\n            if col_index is not None:\n                new_names[col_index] = name\n\n        return self.set_names(new_names)", "language": "python", "code": "def rename(self, columns=None):\n        \"\"\"\n        Change names of columns in the frame.\n\n        Dict key is an index or name of the column whose name is to be set.\n        Dict value is the new name of the column.\n\n        :param columns: dict-like transformations to apply to the column names\n        \"\"\"\n        assert_is_type(columns, None, dict)\n        new_names = self.names\n        ncols = self.ncols\n\n        for col, name in columns.items():\n            col_index = None\n            if is_type(col, int) and (-ncols <= col < ncols):\n                col_index = (col + ncols) % ncols  # handle negative indices\n            elif is_type(col, str) and col in self.names:\n                col_index = self.names.index(col)  # lookup the name\n\n            if col_index is not None:\n                new_names[col_index] = name\n\n        return self.set_names(new_names)", "code_tokens": ["def", "rename", "(", "self", ",", "columns", "=", "None", ")", ":", "assert_is_type", "(", "columns", ",", "None", ",", "dict", ")", "new_names", "=", "self", ".", "names", "ncols", "=", "self", ".", "ncols", "for", "col", ",", "name", "in", "columns", ".", "items", "(", ")", ":", "col_index", "=", "None", "if", "is_type", "(", "col", ",", "int", ")", "and", "(", "-", "ncols", "<=", "col", "<", "ncols", ")", ":", "col_index", "=", "(", "col", "+", "ncols", ")", "%", "ncols", "# handle negative indices", "elif", "is_type", "(", "col", ",", "str", ")", "and", "col", "in", "self", ".", "names", ":", "col_index", "=", "self", ".", "names", ".", "index", "(", "col", ")", "# lookup the name", "if", "col_index", "is", "not", "None", ":", "new_names", "[", "col_index", "]", "=", "name", "return", "self", ".", "set_names", "(", "new_names", ")"], "docstring": "Change names of columns in the frame.\n\n        Dict key is an index or name of the column whose name is to be set.\n        Dict value is the new name of the column.\n\n        :param columns: dict-like transformations to apply to the column names", "docstring_tokens": ["Change", "names", "of", "columns", "in", "the", "frame", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1035-L1058", "partition": "test", "index": 1400, "time": "2018-02-23 19:01:14"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/shared_utils.py", "func_name": "mojo_predict_pandas", "original_string": "def mojo_predict_pandas(dataframe, mojo_zip_path, genmodel_jar_path=None, classpath=None, java_options=None, verbose=False):\n    \"\"\"\n    MOJO scoring function to take a Pandas frame and use MOJO model as zip file to score.\n\n    :param dataframe: Pandas frame to score.\n    :param mojo_zip_path: Path to MOJO zip downloaded from H2O.\n    :param genmodel_jar_path: Optional, path to genmodel jar file. If None (default) then the h2o-genmodel.jar in the same\n        folder as the MOJO zip will be used.\n    :param classpath: Optional, specifies custom user defined classpath which will be used when scoring. If None\n        (default) then the default classpath for this MOJO model will be used.\n    :param java_options: Optional, custom user defined options for Java. By default ``-Xmx4g`` is used.\n    :param verbose: Optional, if True, then additional debug information will be printed. False by default.\n    :return: Pandas frame with predictions\n    \"\"\"\n    tmp_dir = tempfile.mkdtemp()\n    try:\n        if not can_use_pandas():\n            raise RuntimeException('Cannot import pandas')\n        import pandas\n        assert_is_type(dataframe, pandas.DataFrame)\n        input_csv_path = os.path.join(tmp_dir, 'input.csv')\n        prediction_csv_path = os.path.join(tmp_dir, 'prediction.csv')\n        dataframe.to_csv(input_csv_path)\n        mojo_predict_csv(input_csv_path=input_csv_path, mojo_zip_path=mojo_zip_path,\n                         output_csv_path=prediction_csv_path, genmodel_jar_path=genmodel_jar_path,\n                         classpath=classpath, java_options=java_options, verbose=verbose)\n        return pandas.read_csv(prediction_csv_path)\n    finally:\n        shutil.rmtree(tmp_dir)", "language": "python", "code": "def mojo_predict_pandas(dataframe, mojo_zip_path, genmodel_jar_path=None, classpath=None, java_options=None, verbose=False):\n    \"\"\"\n    MOJO scoring function to take a Pandas frame and use MOJO model as zip file to score.\n\n    :param dataframe: Pandas frame to score.\n    :param mojo_zip_path: Path to MOJO zip downloaded from H2O.\n    :param genmodel_jar_path: Optional, path to genmodel jar file. If None (default) then the h2o-genmodel.jar in the same\n        folder as the MOJO zip will be used.\n    :param classpath: Optional, specifies custom user defined classpath which will be used when scoring. If None\n        (default) then the default classpath for this MOJO model will be used.\n    :param java_options: Optional, custom user defined options for Java. By default ``-Xmx4g`` is used.\n    :param verbose: Optional, if True, then additional debug information will be printed. False by default.\n    :return: Pandas frame with predictions\n    \"\"\"\n    tmp_dir = tempfile.mkdtemp()\n    try:\n        if not can_use_pandas():\n            raise RuntimeException('Cannot import pandas')\n        import pandas\n        assert_is_type(dataframe, pandas.DataFrame)\n        input_csv_path = os.path.join(tmp_dir, 'input.csv')\n        prediction_csv_path = os.path.join(tmp_dir, 'prediction.csv')\n        dataframe.to_csv(input_csv_path)\n        mojo_predict_csv(input_csv_path=input_csv_path, mojo_zip_path=mojo_zip_path,\n                         output_csv_path=prediction_csv_path, genmodel_jar_path=genmodel_jar_path,\n                         classpath=classpath, java_options=java_options, verbose=verbose)\n        return pandas.read_csv(prediction_csv_path)\n    finally:\n        shutil.rmtree(tmp_dir)", "code_tokens": ["def", "mojo_predict_pandas", "(", "dataframe", ",", "mojo_zip_path", ",", "genmodel_jar_path", "=", "None", ",", "classpath", "=", "None", ",", "java_options", "=", "None", ",", "verbose", "=", "False", ")", ":", "tmp_dir", "=", "tempfile", ".", "mkdtemp", "(", ")", "try", ":", "if", "not", "can_use_pandas", "(", ")", ":", "raise", "RuntimeException", "(", "'Cannot import pandas'", ")", "import", "pandas", "assert_is_type", "(", "dataframe", ",", "pandas", ".", "DataFrame", ")", "input_csv_path", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'input.csv'", ")", "prediction_csv_path", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'prediction.csv'", ")", "dataframe", ".", "to_csv", "(", "input_csv_path", ")", "mojo_predict_csv", "(", "input_csv_path", "=", "input_csv_path", ",", "mojo_zip_path", "=", "mojo_zip_path", ",", "output_csv_path", "=", "prediction_csv_path", ",", "genmodel_jar_path", "=", "genmodel_jar_path", ",", "classpath", "=", "classpath", ",", "java_options", "=", "java_options", ",", "verbose", "=", "verbose", ")", "return", "pandas", ".", "read_csv", "(", "prediction_csv_path", ")", "finally", ":", "shutil", ".", "rmtree", "(", "tmp_dir", ")"], "docstring": "MOJO scoring function to take a Pandas frame and use MOJO model as zip file to score.\n\n    :param dataframe: Pandas frame to score.\n    :param mojo_zip_path: Path to MOJO zip downloaded from H2O.\n    :param genmodel_jar_path: Optional, path to genmodel jar file. If None (default) then the h2o-genmodel.jar in the same\n        folder as the MOJO zip will be used.\n    :param classpath: Optional, specifies custom user defined classpath which will be used when scoring. If None\n        (default) then the default classpath for this MOJO model will be used.\n    :param java_options: Optional, custom user defined options for Java. By default ``-Xmx4g`` is used.\n    :param verbose: Optional, if True, then additional debug information will be printed. False by default.\n    :return: Pandas frame with predictions", "docstring_tokens": ["MOJO", "scoring", "function", "to", "take", "a", "Pandas", "frame", "and", "use", "MOJO", "model", "as", "zip", "file", "to", "score", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/shared_utils.py#L379-L407", "partition": "test", "index": 1480, "time": "2018-03-16 13:42:47"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/utils/shared_utils.py", "func_name": "mojo_predict_csv", "original_string": "def mojo_predict_csv(input_csv_path, mojo_zip_path, output_csv_path=None, genmodel_jar_path=None, classpath=None, java_options=None, verbose=False):\n    \"\"\"\n    MOJO scoring function to take a CSV file and use MOJO model as zip file to score.\n\n    :param input_csv_path: Path to input CSV file.\n    :param mojo_zip_path: Path to MOJO zip downloaded from H2O.\n    :param output_csv_path: Optional, name of the output CSV file with computed predictions. If None (default), then\n        predictions will be saved as prediction.csv in the same folder as the MOJO zip.\n    :param genmodel_jar_path: Optional, path to genmodel jar file. If None (default) then the h2o-genmodel.jar in the same\n        folder as the MOJO zip will be used.\n    :param classpath: Optional, specifies custom user defined classpath which will be used when scoring. If None\n        (default) then the default classpath for this MOJO model will be used.\n    :param java_options: Optional, custom user defined options for Java. By default ``-Xmx4g -XX:ReservedCodeCacheSize=256m`` is used.\n    :param verbose: Optional, if True, then additional debug information will be printed. False by default.\n    :return: List of computed predictions\n    \"\"\"\n    default_java_options = '-Xmx4g -XX:ReservedCodeCacheSize=256m'\n    prediction_output_file = 'prediction.csv'\n\n    # Checking java\n    java = H2OLocalServer._find_java()\n    H2OLocalServer._check_java(java=java, verbose=verbose)\n\n    # Ensure input_csv exists\n    if verbose:\n        print(\"input_csv:\\t%s\" % input_csv_path)\n    if not os.path.isfile(input_csv_path):\n        raise RuntimeError(\"Input csv cannot be found at %s\" % input_csv_path)\n\n    # Ensure mojo_zip exists\n    mojo_zip_path = os.path.abspath(mojo_zip_path)\n    if verbose:\n        print(\"mojo_zip:\\t%s\" % mojo_zip_path)\n    if not os.path.isfile(mojo_zip_path):\n        raise RuntimeError(\"MOJO zip cannot be found at %s\" % mojo_zip_path)\n\n    parent_dir = os.path.dirname(mojo_zip_path)\n\n    # Set output_csv if necessary\n    if output_csv_path is None:\n        output_csv_path = os.path.join(parent_dir, prediction_output_file)\n\n    # Set path to h2o-genmodel.jar if necessary and check it's valid\n    if genmodel_jar_path is None:\n        genmodel_jar_path = os.path.join(parent_dir, gen_model_file_name)\n    if verbose:\n        print(\"genmodel_jar:\\t%s\" % genmodel_jar_path)\n    if not os.path.isfile(genmodel_jar_path):\n        raise RuntimeError(\"Genmodel jar cannot be found at %s\" % genmodel_jar_path)\n\n    if verbose and output_csv_path is not None:\n        print(\"output_csv:\\t%s\" % output_csv_path)\n\n    # Set classpath if necessary\n    if classpath is None:\n        classpath = genmodel_jar_path\n    if verbose:\n        print(\"classpath:\\t%s\" % classpath)\n\n    # Set java_options if necessary\n    if java_options is None:\n        java_options = default_java_options\n    if verbose:\n        print(\"java_options:\\t%s\" % java_options)\n\n    # Construct command to invoke java\n    cmd = [java]\n    for option in java_options.split(' '):\n        cmd += [option]\n    cmd += [\"-cp\", classpath, h2o_predictor_class, \"--mojo\", mojo_zip_path, \"--input\", input_csv_path,\n            '--output', output_csv_path, '--decimal']\n    if verbose:\n        cmd_str = \" \".join(cmd)\n        print(\"java cmd:\\t%s\" % cmd_str)\n\n    # invoke the command\n    subprocess.check_call(cmd, shell=False)\n\n    # load predictions in form of a dict\n    with open(output_csv_path) as csv_file:\n        result = list(csv.DictReader(csv_file))\n    return result", "language": "python", "code": "def mojo_predict_csv(input_csv_path, mojo_zip_path, output_csv_path=None, genmodel_jar_path=None, classpath=None, java_options=None, verbose=False):\n    \"\"\"\n    MOJO scoring function to take a CSV file and use MOJO model as zip file to score.\n\n    :param input_csv_path: Path to input CSV file.\n    :param mojo_zip_path: Path to MOJO zip downloaded from H2O.\n    :param output_csv_path: Optional, name of the output CSV file with computed predictions. If None (default), then\n        predictions will be saved as prediction.csv in the same folder as the MOJO zip.\n    :param genmodel_jar_path: Optional, path to genmodel jar file. If None (default) then the h2o-genmodel.jar in the same\n        folder as the MOJO zip will be used.\n    :param classpath: Optional, specifies custom user defined classpath which will be used when scoring. If None\n        (default) then the default classpath for this MOJO model will be used.\n    :param java_options: Optional, custom user defined options for Java. By default ``-Xmx4g -XX:ReservedCodeCacheSize=256m`` is used.\n    :param verbose: Optional, if True, then additional debug information will be printed. False by default.\n    :return: List of computed predictions\n    \"\"\"\n    default_java_options = '-Xmx4g -XX:ReservedCodeCacheSize=256m'\n    prediction_output_file = 'prediction.csv'\n\n    # Checking java\n    java = H2OLocalServer._find_java()\n    H2OLocalServer._check_java(java=java, verbose=verbose)\n\n    # Ensure input_csv exists\n    if verbose:\n        print(\"input_csv:\\t%s\" % input_csv_path)\n    if not os.path.isfile(input_csv_path):\n        raise RuntimeError(\"Input csv cannot be found at %s\" % input_csv_path)\n\n    # Ensure mojo_zip exists\n    mojo_zip_path = os.path.abspath(mojo_zip_path)\n    if verbose:\n        print(\"mojo_zip:\\t%s\" % mojo_zip_path)\n    if not os.path.isfile(mojo_zip_path):\n        raise RuntimeError(\"MOJO zip cannot be found at %s\" % mojo_zip_path)\n\n    parent_dir = os.path.dirname(mojo_zip_path)\n\n    # Set output_csv if necessary\n    if output_csv_path is None:\n        output_csv_path = os.path.join(parent_dir, prediction_output_file)\n\n    # Set path to h2o-genmodel.jar if necessary and check it's valid\n    if genmodel_jar_path is None:\n        genmodel_jar_path = os.path.join(parent_dir, gen_model_file_name)\n    if verbose:\n        print(\"genmodel_jar:\\t%s\" % genmodel_jar_path)\n    if not os.path.isfile(genmodel_jar_path):\n        raise RuntimeError(\"Genmodel jar cannot be found at %s\" % genmodel_jar_path)\n\n    if verbose and output_csv_path is not None:\n        print(\"output_csv:\\t%s\" % output_csv_path)\n\n    # Set classpath if necessary\n    if classpath is None:\n        classpath = genmodel_jar_path\n    if verbose:\n        print(\"classpath:\\t%s\" % classpath)\n\n    # Set java_options if necessary\n    if java_options is None:\n        java_options = default_java_options\n    if verbose:\n        print(\"java_options:\\t%s\" % java_options)\n\n    # Construct command to invoke java\n    cmd = [java]\n    for option in java_options.split(' '):\n        cmd += [option]\n    cmd += [\"-cp\", classpath, h2o_predictor_class, \"--mojo\", mojo_zip_path, \"--input\", input_csv_path,\n            '--output', output_csv_path, '--decimal']\n    if verbose:\n        cmd_str = \" \".join(cmd)\n        print(\"java cmd:\\t%s\" % cmd_str)\n\n    # invoke the command\n    subprocess.check_call(cmd, shell=False)\n\n    # load predictions in form of a dict\n    with open(output_csv_path) as csv_file:\n        result = list(csv.DictReader(csv_file))\n    return result", "code_tokens": ["def", "mojo_predict_csv", "(", "input_csv_path", ",", "mojo_zip_path", ",", "output_csv_path", "=", "None", ",", "genmodel_jar_path", "=", "None", ",", "classpath", "=", "None", ",", "java_options", "=", "None", ",", "verbose", "=", "False", ")", ":", "default_java_options", "=", "'-Xmx4g -XX:ReservedCodeCacheSize=256m'", "prediction_output_file", "=", "'prediction.csv'", "# Checking java", "java", "=", "H2OLocalServer", ".", "_find_java", "(", ")", "H2OLocalServer", ".", "_check_java", "(", "java", "=", "java", ",", "verbose", "=", "verbose", ")", "# Ensure input_csv exists", "if", "verbose", ":", "print", "(", "\"input_csv:\\t%s\"", "%", "input_csv_path", ")", "if", "not", "os", ".", "path", ".", "isfile", "(", "input_csv_path", ")", ":", "raise", "RuntimeError", "(", "\"Input csv cannot be found at %s\"", "%", "input_csv_path", ")", "# Ensure mojo_zip exists", "mojo_zip_path", "=", "os", ".", "path", ".", "abspath", "(", "mojo_zip_path", ")", "if", "verbose", ":", "print", "(", "\"mojo_zip:\\t%s\"", "%", "mojo_zip_path", ")", "if", "not", "os", ".", "path", ".", "isfile", "(", "mojo_zip_path", ")", ":", "raise", "RuntimeError", "(", "\"MOJO zip cannot be found at %s\"", "%", "mojo_zip_path", ")", "parent_dir", "=", "os", ".", "path", ".", "dirname", "(", "mojo_zip_path", ")", "# Set output_csv if necessary", "if", "output_csv_path", "is", "None", ":", "output_csv_path", "=", "os", ".", "path", ".", "join", "(", "parent_dir", ",", "prediction_output_file", ")", "# Set path to h2o-genmodel.jar if necessary and check it's valid", "if", "genmodel_jar_path", "is", "None", ":", "genmodel_jar_path", "=", "os", ".", "path", ".", "join", "(", "parent_dir", ",", "gen_model_file_name", ")", "if", "verbose", ":", "print", "(", "\"genmodel_jar:\\t%s\"", "%", "genmodel_jar_path", ")", "if", "not", "os", ".", "path", ".", "isfile", "(", "genmodel_jar_path", ")", ":", "raise", "RuntimeError", "(", "\"Genmodel jar cannot be found at %s\"", "%", "genmodel_jar_path", ")", "if", "verbose", "and", "output_csv_path", "is", "not", "None", ":", "print", "(", "\"output_csv:\\t%s\"", "%", "output_csv_path", ")", "# Set classpath if necessary", "if", "classpath", "is", "None", ":", "classpath", "=", "genmodel_jar_path", "if", "verbose", ":", "print", "(", "\"classpath:\\t%s\"", "%", "classpath", ")", "# Set java_options if necessary", "if", "java_options", "is", "None", ":", "java_options", "=", "default_java_options", "if", "verbose", ":", "print", "(", "\"java_options:\\t%s\"", "%", "java_options", ")", "# Construct command to invoke java", "cmd", "=", "[", "java", "]", "for", "option", "in", "java_options", ".", "split", "(", "' '", ")", ":", "cmd", "+=", "[", "option", "]", "cmd", "+=", "[", "\"-cp\"", ",", "classpath", ",", "h2o_predictor_class", ",", "\"--mojo\"", ",", "mojo_zip_path", ",", "\"--input\"", ",", "input_csv_path", ",", "'--output'", ",", "output_csv_path", ",", "'--decimal'", "]", "if", "verbose", ":", "cmd_str", "=", "\" \"", ".", "join", "(", "cmd", ")", "print", "(", "\"java cmd:\\t%s\"", "%", "cmd_str", ")", "# invoke the command", "subprocess", ".", "check_call", "(", "cmd", ",", "shell", "=", "False", ")", "# load predictions in form of a dict", "with", "open", "(", "output_csv_path", ")", "as", "csv_file", ":", "result", "=", "list", "(", "csv", ".", "DictReader", "(", "csv_file", ")", ")", "return", "result"], "docstring": "MOJO scoring function to take a CSV file and use MOJO model as zip file to score.\n\n    :param input_csv_path: Path to input CSV file.\n    :param mojo_zip_path: Path to MOJO zip downloaded from H2O.\n    :param output_csv_path: Optional, name of the output CSV file with computed predictions. If None (default), then\n        predictions will be saved as prediction.csv in the same folder as the MOJO zip.\n    :param genmodel_jar_path: Optional, path to genmodel jar file. If None (default) then the h2o-genmodel.jar in the same\n        folder as the MOJO zip will be used.\n    :param classpath: Optional, specifies custom user defined classpath which will be used when scoring. If None\n        (default) then the default classpath for this MOJO model will be used.\n    :param java_options: Optional, custom user defined options for Java. By default ``-Xmx4g -XX:ReservedCodeCacheSize=256m`` is used.\n    :param verbose: Optional, if True, then additional debug information will be printed. False by default.\n    :return: List of computed predictions", "docstring_tokens": ["MOJO", "scoring", "function", "to", "take", "a", "CSV", "file", "and", "use", "MOJO", "model", "as", "zip", "file", "to", "score", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/shared_utils.py#L410-L491", "partition": "test", "index": 1481, "time": "2018-03-16 13:42:47"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/automl/autoh2o.py", "func_name": "H2OAutoML.download_mojo", "original_string": "def download_mojo(self, path=\".\", get_genmodel_jar=False, genmodel_name=\"\"):\n        \"\"\"\n        Download the leader model in AutoML in MOJO format.\n\n        :param path: the path where MOJO file should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the MOJO file written.\n        \"\"\"\n\n        return ModelBase.download_mojo(self.leader, path, get_genmodel_jar, genmodel_name)", "language": "python", "code": "def download_mojo(self, path=\".\", get_genmodel_jar=False, genmodel_name=\"\"):\n        \"\"\"\n        Download the leader model in AutoML in MOJO format.\n\n        :param path: the path where MOJO file should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the MOJO file written.\n        \"\"\"\n\n        return ModelBase.download_mojo(self.leader, path, get_genmodel_jar, genmodel_name)", "code_tokens": ["def", "download_mojo", "(", "self", ",", "path", "=", "\".\"", ",", "get_genmodel_jar", "=", "False", ",", "genmodel_name", "=", "\"\"", ")", ":", "return", "ModelBase", ".", "download_mojo", "(", "self", ".", "leader", ",", "path", ",", "get_genmodel_jar", ",", "genmodel_name", ")"], "docstring": "Download the leader model in AutoML in MOJO format.\n\n        :param path: the path where MOJO file should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the MOJO file written.", "docstring_tokens": ["Download", "the", "leader", "model", "in", "AutoML", "in", "MOJO", "format", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/automl/autoh2o.py#L457-L467", "partition": "test", "index": 1510, "time": "2018-04-11 17:35:20"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/automl/autoh2o.py", "func_name": "H2OAutoML.download_pojo", "original_string": "def download_pojo(self, path=\"\", get_genmodel_jar=False, genmodel_name=\"\"):\n        \"\"\"\n        Download the POJO for the leader model in AutoML to the directory specified by path.\n\n        If path is an empty string, then dump the output to screen.\n\n        :param path:  An absolute path to the directory where POJO should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the POJO file written.\n        \"\"\"\n\n        return h2o.download_pojo(self.leader, path, get_jar=get_genmodel_jar, jar_name=genmodel_name)", "language": "python", "code": "def download_pojo(self, path=\"\", get_genmodel_jar=False, genmodel_name=\"\"):\n        \"\"\"\n        Download the POJO for the leader model in AutoML to the directory specified by path.\n\n        If path is an empty string, then dump the output to screen.\n\n        :param path:  An absolute path to the directory where POJO should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the POJO file written.\n        \"\"\"\n\n        return h2o.download_pojo(self.leader, path, get_jar=get_genmodel_jar, jar_name=genmodel_name)", "code_tokens": ["def", "download_pojo", "(", "self", ",", "path", "=", "\"\"", ",", "get_genmodel_jar", "=", "False", ",", "genmodel_name", "=", "\"\"", ")", ":", "return", "h2o", ".", "download_pojo", "(", "self", ".", "leader", ",", "path", ",", "get_jar", "=", "get_genmodel_jar", ",", "jar_name", "=", "genmodel_name", ")"], "docstring": "Download the POJO for the leader model in AutoML to the directory specified by path.\n\n        If path is an empty string, then dump the output to screen.\n\n        :param path:  An absolute path to the directory where POJO should be saved.\n        :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n        :param genmodel_name Custom name of genmodel jar\n        :returns: name of the POJO file written.", "docstring_tokens": ["Download", "the", "POJO", "for", "the", "leader", "model", "in", "AutoML", "to", "the", "directory", "specified", "by", "path", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/automl/autoh2o.py#L443-L455", "partition": "test", "index": 1509, "time": "2018-04-11 17:35:20"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/automl/autoh2o.py", "func_name": "get_automl", "original_string": "def get_automl(project_name):\n    \"\"\"\n    Retrieve information about an AutoML instance.\n\n    :param str project_name:  A string indicating the project_name of the automl instance to retrieve.\n    :returns: A dictionary containing the project_name, leader model, and leaderboard.\n    \"\"\"\n    automl_json = h2o.api(\"GET /99/AutoML/%s\" % project_name)\n    project_name = automl_json[\"project_name\"]\n    leaderboard_list = [key[\"name\"] for key in automl_json['leaderboard']['models']]\n\n    if leaderboard_list is not None and len(leaderboard_list) > 0:\n        leader_id = leaderboard_list[0]\n    else:\n        leader_id = None\n\n    leader = h2o.get_model(leader_id)\n    # Intentionally mask the progress bar here since showing multiple progress bars is confusing to users.\n    # If any failure happens, revert back to user's original setting for progress and display the error message.\n    is_progress = H2OJob.__PROGRESS_BAR__\n    h2o.no_progress()\n    try:\n        # Parse leaderboard H2OTwoDimTable & return as an H2OFrame\n        leaderboard = h2o.H2OFrame(\n            automl_json[\"leaderboard_table\"].cell_values,\n            column_names=automl_json[\"leaderboard_table\"].col_header)\n    except Exception as ex:\n        raise ex\n    finally:\n        if is_progress is True:\n            h2o.show_progress()\n\n    leaderboard = leaderboard[1:]\n    automl_dict = {'project_name': project_name, \"leader\": leader, \"leaderboard\": leaderboard}\n    return automl_dict", "language": "python", "code": "def get_automl(project_name):\n    \"\"\"\n    Retrieve information about an AutoML instance.\n\n    :param str project_name:  A string indicating the project_name of the automl instance to retrieve.\n    :returns: A dictionary containing the project_name, leader model, and leaderboard.\n    \"\"\"\n    automl_json = h2o.api(\"GET /99/AutoML/%s\" % project_name)\n    project_name = automl_json[\"project_name\"]\n    leaderboard_list = [key[\"name\"] for key in automl_json['leaderboard']['models']]\n\n    if leaderboard_list is not None and len(leaderboard_list) > 0:\n        leader_id = leaderboard_list[0]\n    else:\n        leader_id = None\n\n    leader = h2o.get_model(leader_id)\n    # Intentionally mask the progress bar here since showing multiple progress bars is confusing to users.\n    # If any failure happens, revert back to user's original setting for progress and display the error message.\n    is_progress = H2OJob.__PROGRESS_BAR__\n    h2o.no_progress()\n    try:\n        # Parse leaderboard H2OTwoDimTable & return as an H2OFrame\n        leaderboard = h2o.H2OFrame(\n            automl_json[\"leaderboard_table\"].cell_values,\n            column_names=automl_json[\"leaderboard_table\"].col_header)\n    except Exception as ex:\n        raise ex\n    finally:\n        if is_progress is True:\n            h2o.show_progress()\n\n    leaderboard = leaderboard[1:]\n    automl_dict = {'project_name': project_name, \"leader\": leader, \"leaderboard\": leaderboard}\n    return automl_dict", "code_tokens": ["def", "get_automl", "(", "project_name", ")", ":", "automl_json", "=", "h2o", ".", "api", "(", "\"GET /99/AutoML/%s\"", "%", "project_name", ")", "project_name", "=", "automl_json", "[", "\"project_name\"", "]", "leaderboard_list", "=", "[", "key", "[", "\"name\"", "]", "for", "key", "in", "automl_json", "[", "'leaderboard'", "]", "[", "'models'", "]", "]", "if", "leaderboard_list", "is", "not", "None", "and", "len", "(", "leaderboard_list", ")", ">", "0", ":", "leader_id", "=", "leaderboard_list", "[", "0", "]", "else", ":", "leader_id", "=", "None", "leader", "=", "h2o", ".", "get_model", "(", "leader_id", ")", "# Intentionally mask the progress bar here since showing multiple progress bars is confusing to users.", "# If any failure happens, revert back to user's original setting for progress and display the error message.", "is_progress", "=", "H2OJob", ".", "__PROGRESS_BAR__", "h2o", ".", "no_progress", "(", ")", "try", ":", "# Parse leaderboard H2OTwoDimTable & return as an H2OFrame", "leaderboard", "=", "h2o", ".", "H2OFrame", "(", "automl_json", "[", "\"leaderboard_table\"", "]", ".", "cell_values", ",", "column_names", "=", "automl_json", "[", "\"leaderboard_table\"", "]", ".", "col_header", ")", "except", "Exception", "as", "ex", ":", "raise", "ex", "finally", ":", "if", "is_progress", "is", "True", ":", "h2o", ".", "show_progress", "(", ")", "leaderboard", "=", "leaderboard", "[", "1", ":", "]", "automl_dict", "=", "{", "'project_name'", ":", "project_name", ",", "\"leader\"", ":", "leader", ",", "\"leaderboard\"", ":", "leaderboard", "}", "return", "automl_dict"], "docstring": "Retrieve information about an AutoML instance.\n\n    :param str project_name:  A string indicating the project_name of the automl instance to retrieve.\n    :returns: A dictionary containing the project_name, leader model, and leaderboard.", "docstring_tokens": ["Retrieve", "information", "about", "an", "AutoML", "instance", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/automl/autoh2o.py#L503-L537", "partition": "test", "index": 1508, "time": "2018-05-25 16:12:44"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/targetencoder.py", "func_name": "TargetEncoder.fit", "original_string": "def fit(self, frame = None):\n        \"\"\"\n        Returns encoding map as an object that maps 'column_name' -> 'frame_with_encoding_map_for_this_column_name'\n\n        :param frame frame: An H2OFrame object with which to create the target encoding map\n        \"\"\"\n        self._teColumns = list(map(lambda i: frame.names[i], self._teColumns)) if all(isinstance(n, int) for n in self._teColumns) else self._teColumns\n        self._responseColumnName = frame.names[self._responseColumnName] if isinstance(self._responseColumnName, int) else self._responseColumnName\n        self._foldColumnName = frame.names[self._foldColumnName] if isinstance(self._foldColumnName, int) else self._foldColumnName\n        \n        self._encodingMap = ExprNode(\"target.encoder.fit\", frame, self._teColumns, self._responseColumnName,\n                                     self._foldColumnName)._eager_map_frame()\n\n        return self._encodingMap", "language": "python", "code": "def fit(self, frame = None):\n        \"\"\"\n        Returns encoding map as an object that maps 'column_name' -> 'frame_with_encoding_map_for_this_column_name'\n\n        :param frame frame: An H2OFrame object with which to create the target encoding map\n        \"\"\"\n        self._teColumns = list(map(lambda i: frame.names[i], self._teColumns)) if all(isinstance(n, int) for n in self._teColumns) else self._teColumns\n        self._responseColumnName = frame.names[self._responseColumnName] if isinstance(self._responseColumnName, int) else self._responseColumnName\n        self._foldColumnName = frame.names[self._foldColumnName] if isinstance(self._foldColumnName, int) else self._foldColumnName\n        \n        self._encodingMap = ExprNode(\"target.encoder.fit\", frame, self._teColumns, self._responseColumnName,\n                                     self._foldColumnName)._eager_map_frame()\n\n        return self._encodingMap", "code_tokens": ["def", "fit", "(", "self", ",", "frame", "=", "None", ")", ":", "self", ".", "_teColumns", "=", "list", "(", "map", "(", "lambda", "i", ":", "frame", ".", "names", "[", "i", "]", ",", "self", ".", "_teColumns", ")", ")", "if", "all", "(", "isinstance", "(", "n", ",", "int", ")", "for", "n", "in", "self", ".", "_teColumns", ")", "else", "self", ".", "_teColumns", "self", ".", "_responseColumnName", "=", "frame", ".", "names", "[", "self", ".", "_responseColumnName", "]", "if", "isinstance", "(", "self", ".", "_responseColumnName", ",", "int", ")", "else", "self", ".", "_responseColumnName", "self", ".", "_foldColumnName", "=", "frame", ".", "names", "[", "self", ".", "_foldColumnName", "]", "if", "isinstance", "(", "self", ".", "_foldColumnName", ",", "int", ")", "else", "self", ".", "_foldColumnName", "self", ".", "_encodingMap", "=", "ExprNode", "(", "\"target.encoder.fit\"", ",", "frame", ",", "self", ".", "_teColumns", ",", "self", ".", "_responseColumnName", ",", "self", ".", "_foldColumnName", ")", ".", "_eager_map_frame", "(", ")", "return", "self", ".", "_encodingMap"], "docstring": "Returns encoding map as an object that maps 'column_name' -> 'frame_with_encoding_map_for_this_column_name'\n\n        :param frame frame: An H2OFrame object with which to create the target encoding map", "docstring_tokens": ["Returns", "encoding", "map", "as", "an", "object", "that", "maps", "column_name", "-", ">", "frame_with_encoding_map_for_this_column_name"], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/targetencoder.py#L78-L91", "partition": "test", "index": 1387, "time": "2018-10-17 19:43:33"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/pipeline/mojo_pipeline.py", "func_name": "H2OMojoPipeline.transform", "original_string": "def transform(self, data, allow_timestamps=False):\n        \"\"\"\n        Transform H2OFrame using a MOJO Pipeline.\n\n        :param data: Frame to be transformed.\n        :param allow_timestamps: Allows datetime columns to be used directly with MOJO pipelines. It is recommended\n        to parse your datetime columns as Strings when using pipelines because pipelines can interpret certain datetime\n        formats in a different way. If your H2OFrame is parsed from a binary file format (eg. Parquet) instead of CSV\n        it is safe to turn this option on and use datetime columns directly.\n\n        :returns: A new H2OFrame.\n        \"\"\"\n        assert_is_type(data, H2OFrame)\n        assert_is_type(allow_timestamps, bool)\n        return H2OFrame._expr(ExprNode(\"mojo.pipeline.transform\", self.pipeline_id[0], data, allow_timestamps))", "language": "python", "code": "def transform(self, data, allow_timestamps=False):\n        \"\"\"\n        Transform H2OFrame using a MOJO Pipeline.\n\n        :param data: Frame to be transformed.\n        :param allow_timestamps: Allows datetime columns to be used directly with MOJO pipelines. It is recommended\n        to parse your datetime columns as Strings when using pipelines because pipelines can interpret certain datetime\n        formats in a different way. If your H2OFrame is parsed from a binary file format (eg. Parquet) instead of CSV\n        it is safe to turn this option on and use datetime columns directly.\n\n        :returns: A new H2OFrame.\n        \"\"\"\n        assert_is_type(data, H2OFrame)\n        assert_is_type(allow_timestamps, bool)\n        return H2OFrame._expr(ExprNode(\"mojo.pipeline.transform\", self.pipeline_id[0], data, allow_timestamps))", "code_tokens": ["def", "transform", "(", "self", ",", "data", ",", "allow_timestamps", "=", "False", ")", ":", "assert_is_type", "(", "data", ",", "H2OFrame", ")", "assert_is_type", "(", "allow_timestamps", ",", "bool", ")", "return", "H2OFrame", ".", "_expr", "(", "ExprNode", "(", "\"mojo.pipeline.transform\"", ",", "self", ".", "pipeline_id", "[", "0", "]", ",", "data", ",", "allow_timestamps", ")", ")"], "docstring": "Transform H2OFrame using a MOJO Pipeline.\n\n        :param data: Frame to be transformed.\n        :param allow_timestamps: Allows datetime columns to be used directly with MOJO pipelines. It is recommended\n        to parse your datetime columns as Strings when using pipelines because pipelines can interpret certain datetime\n        formats in a different way. If your H2OFrame is parsed from a binary file format (eg. Parquet) instead of CSV\n        it is safe to turn this option on and use datetime columns directly.\n\n        :returns: A new H2OFrame.", "docstring_tokens": ["Transform", "H2OFrame", "using", "a", "MOJO", "Pipeline", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/pipeline/mojo_pipeline.py#L39-L53", "partition": "test", "index": 1576, "time": "2018-12-17 14:17:51"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/h2o.py", "func_name": "import_hive_table", "original_string": "def import_hive_table(database=None, table=None, partitions=None, allow_multi_format=False):\n    \"\"\"\n    Import Hive table to H2OFrame in memory.\n\n    Make sure to start H2O with Hive on classpath. Uses hive-site.xml on classpath to connect to Hive.\n\n    :param database: Name of Hive database (default database will be used by default)\n    :param table: name of Hive table to import\n    :param partitions: a list of lists of strings - partition key column values of partitions you want to import.\n    :param allow_multi_format: enable import of partitioned tables with different storage formats used. WARNING:\n        this may fail on out-of-memory for tables with a large number of small partitions.\n\n    :returns: an :class:`H2OFrame` containing data of the specified Hive table.\n\n    :examples:\n        >>> my_citibike_data = h2o.import_hive_table(\"default\", \"table\", [[\"2017\", \"01\"], [\"2017\", \"02\"]])\n    \"\"\"    \n    assert_is_type(database, str, None)\n    assert_is_type(table, str)\n    assert_is_type(partitions, [[str]], None)\n    p = { \"database\": database, \"table\": table, \"partitions\": partitions, \"allow_multi_format\": allow_multi_format }\n    j = H2OJob(api(\"POST /3/ImportHiveTable\", data=p), \"Import Hive Table\").poll()\n    return get_frame(j.dest_key)", "language": "python", "code": "def import_hive_table(database=None, table=None, partitions=None, allow_multi_format=False):\n    \"\"\"\n    Import Hive table to H2OFrame in memory.\n\n    Make sure to start H2O with Hive on classpath. Uses hive-site.xml on classpath to connect to Hive.\n\n    :param database: Name of Hive database (default database will be used by default)\n    :param table: name of Hive table to import\n    :param partitions: a list of lists of strings - partition key column values of partitions you want to import.\n    :param allow_multi_format: enable import of partitioned tables with different storage formats used. WARNING:\n        this may fail on out-of-memory for tables with a large number of small partitions.\n\n    :returns: an :class:`H2OFrame` containing data of the specified Hive table.\n\n    :examples:\n        >>> my_citibike_data = h2o.import_hive_table(\"default\", \"table\", [[\"2017\", \"01\"], [\"2017\", \"02\"]])\n    \"\"\"    \n    assert_is_type(database, str, None)\n    assert_is_type(table, str)\n    assert_is_type(partitions, [[str]], None)\n    p = { \"database\": database, \"table\": table, \"partitions\": partitions, \"allow_multi_format\": allow_multi_format }\n    j = H2OJob(api(\"POST /3/ImportHiveTable\", data=p), \"Import Hive Table\").poll()\n    return get_frame(j.dest_key)", "code_tokens": ["def", "import_hive_table", "(", "database", "=", "None", ",", "table", "=", "None", ",", "partitions", "=", "None", ",", "allow_multi_format", "=", "False", ")", ":", "assert_is_type", "(", "database", ",", "str", ",", "None", ")", "assert_is_type", "(", "table", ",", "str", ")", "assert_is_type", "(", "partitions", ",", "[", "[", "str", "]", "]", ",", "None", ")", "p", "=", "{", "\"database\"", ":", "database", ",", "\"table\"", ":", "table", ",", "\"partitions\"", ":", "partitions", ",", "\"allow_multi_format\"", ":", "allow_multi_format", "}", "j", "=", "H2OJob", "(", "api", "(", "\"POST /3/ImportHiveTable\"", ",", "data", "=", "p", ")", ",", "\"Import Hive Table\"", ")", ".", "poll", "(", ")", "return", "get_frame", "(", "j", ".", "dest_key", ")"], "docstring": "Import Hive table to H2OFrame in memory.\n\n    Make sure to start H2O with Hive on classpath. Uses hive-site.xml on classpath to connect to Hive.\n\n    :param database: Name of Hive database (default database will be used by default)\n    :param table: name of Hive table to import\n    :param partitions: a list of lists of strings - partition key column values of partitions you want to import.\n    :param allow_multi_format: enable import of partitioned tables with different storage formats used. WARNING:\n        this may fail on out-of-memory for tables with a large number of small partitions.\n\n    :returns: an :class:`H2OFrame` containing data of the specified Hive table.\n\n    :examples:\n        >>> my_citibike_data = h2o.import_hive_table(\"default\", \"table\", [[\"2017\", \"01\"], [\"2017\", \"02\"]])", "docstring_tokens": ["Import", "Hive", "table", "to", "H2OFrame", "in", "memory", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L440-L462", "partition": "test", "index": 1458, "time": "2019-02-06 19:20:04"}
{"repo": "h2oai/h2o-3", "path": "h2o-py/h2o/backend/cluster.py", "func_name": "H2OCluster.list_jobs", "original_string": "def list_jobs(self):\n        \"\"\"List all jobs performed by the cluster.\"\"\"\n        res = h2o.api(\"GET /3/Jobs\")\n        table = [[\"type\"], [\"dest\"], [\"description\"], [\"status\"]]\n        for job in res[\"jobs\"]:\n            job_dest = job[\"dest\"]\n            table[0].append(self._translate_job_type(job_dest[\"type\"]))\n            table[1].append(job_dest[\"name\"])\n            table[2].append(job[\"description\"])\n            table[3].append(job[\"status\"])\n        return table", "language": "python", "code": "def list_jobs(self):\n        \"\"\"List all jobs performed by the cluster.\"\"\"\n        res = h2o.api(\"GET /3/Jobs\")\n        table = [[\"type\"], [\"dest\"], [\"description\"], [\"status\"]]\n        for job in res[\"jobs\"]:\n            job_dest = job[\"dest\"]\n            table[0].append(self._translate_job_type(job_dest[\"type\"]))\n            table[1].append(job_dest[\"name\"])\n            table[2].append(job[\"description\"])\n            table[3].append(job[\"status\"])\n        return table", "code_tokens": ["def", "list_jobs", "(", "self", ")", ":", "res", "=", "h2o", ".", "api", "(", "\"GET /3/Jobs\"", ")", "table", "=", "[", "[", "\"type\"", "]", ",", "[", "\"dest\"", "]", ",", "[", "\"description\"", "]", ",", "[", "\"status\"", "]", "]", "for", "job", "in", "res", "[", "\"jobs\"", "]", ":", "job_dest", "=", "job", "[", "\"dest\"", "]", "table", "[", "0", "]", ".", "append", "(", "self", ".", "_translate_job_type", "(", "job_dest", "[", "\"type\"", "]", ")", ")", "table", "[", "1", "]", ".", "append", "(", "job_dest", "[", "\"name\"", "]", ")", "table", "[", "2", "]", ".", "append", "(", "job", "[", "\"description\"", "]", ")", "table", "[", "3", "]", ".", "append", "(", "job", "[", "\"status\"", "]", ")", "return", "table"], "docstring": "List all jobs performed by the cluster.", "docstring_tokens": ["List", "all", "jobs", "performed", "by", "the", "cluster", "."], "sha": "dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8", "url": "https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/cluster.py#L266-L276", "partition": "test", "index": 1322, "time": "2019-04-18 23:06:04"}
