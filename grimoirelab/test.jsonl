{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitParser.parse", "original_string": "def parse(self):\n        \"\"\"Parse the Git log stream.\"\"\"\n\n        for line in self.stream:\n            line = line.rstrip('\\n')\n            parsed = False\n            self.nline += 1\n\n            while not parsed:\n                parsed = self.handlers[self.state](line)\n\n                if self.state == self.COMMIT and self.commit:\n                    commit = self._build_commit()\n                    logger.debug(\"Commit %s parsed\", commit['commit'])\n                    yield commit\n\n        # Return the last commit, if any\n        if self.commit:\n            commit = self._build_commit()\n            logger.debug(\"Commit %s parsed\", commit['commit'])\n            yield commit", "language": "python", "code": "def parse(self):\n        \"\"\"Parse the Git log stream.\"\"\"\n\n        for line in self.stream:\n            line = line.rstrip('\\n')\n            parsed = False\n            self.nline += 1\n\n            while not parsed:\n                parsed = self.handlers[self.state](line)\n\n                if self.state == self.COMMIT and self.commit:\n                    commit = self._build_commit()\n                    logger.debug(\"Commit %s parsed\", commit['commit'])\n                    yield commit\n\n        # Return the last commit, if any\n        if self.commit:\n            commit = self._build_commit()\n            logger.debug(\"Commit %s parsed\", commit['commit'])\n            yield commit", "code_tokens": ["def", "parse", "(", "self", ")", ":", "for", "line", "in", "self", ".", "stream", ":", "line", "=", "line", ".", "rstrip", "(", "'\\n'", ")", "parsed", "=", "False", "self", ".", "nline", "+=", "1", "while", "not", "parsed", ":", "parsed", "=", "self", ".", "handlers", "[", "self", ".", "state", "]", "(", "line", ")", "if", "self", ".", "state", "==", "self", ".", "COMMIT", "and", "self", ".", "commit", ":", "commit", "=", "self", ".", "_build_commit", "(", ")", "logger", ".", "debug", "(", "\"Commit %s parsed\"", ",", "commit", "[", "'commit'", "]", ")", "yield", "commit", "# Return the last commit, if any", "if", "self", ".", "commit", ":", "commit", "=", "self", ".", "_build_commit", "(", ")", "logger", ".", "debug", "(", "\"Commit %s parsed\"", ",", "commit", "[", "'commit'", "]", ")", "yield", "commit"], "docstring": "Parse the Git log stream.", "docstring_tokens": ["Parse", "the", "Git", "log", "stream", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L525-L545", "partition": "test", "index": 3269, "time": "2016-01-03 17:38:49"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "Git.parse_git_log_from_file", "original_string": "def parse_git_log_from_file(filepath):\n        \"\"\"Parse a Git log file.\n\n        The method parses the Git log file and returns an iterator of\n        dictionaries. Each one of this, contains a commit.\n\n        :param filepath: path to the log file\n\n        :returns: a generator of parsed commits\n\n        :raises ParseError: raised when the format of the Git log file\n            is invalid\n        :raises OSError: raised when an error occurs reading the\n            given file\n        \"\"\"\n        with open(filepath, 'r', errors='surrogateescape',\n                  newline=os.linesep) as f:\n            parser = GitParser(f)\n\n            for commit in parser.parse():\n                yield commit", "language": "python", "code": "def parse_git_log_from_file(filepath):\n        \"\"\"Parse a Git log file.\n\n        The method parses the Git log file and returns an iterator of\n        dictionaries. Each one of this, contains a commit.\n\n        :param filepath: path to the log file\n\n        :returns: a generator of parsed commits\n\n        :raises ParseError: raised when the format of the Git log file\n            is invalid\n        :raises OSError: raised when an error occurs reading the\n            given file\n        \"\"\"\n        with open(filepath, 'r', errors='surrogateescape',\n                  newline=os.linesep) as f:\n            parser = GitParser(f)\n\n            for commit in parser.parse():\n                yield commit", "code_tokens": ["def", "parse_git_log_from_file", "(", "filepath", ")", ":", "with", "open", "(", "filepath", ",", "'r'", ",", "errors", "=", "'surrogateescape'", ",", "newline", "=", "os", ".", "linesep", ")", "as", "f", ":", "parser", "=", "GitParser", "(", "f", ")", "for", "commit", "in", "parser", ".", "parse", "(", ")", ":", "yield", "commit"], "docstring": "Parse a Git log file.\n\n        The method parses the Git log file and returns an iterator of\n        dictionaries. Each one of this, contains a commit.\n\n        :param filepath: path to the log file\n\n        :returns: a generator of parsed commits\n\n        :raises ParseError: raised when the format of the Git log file\n            is invalid\n        :raises OSError: raised when an error occurs reading the\n            given file", "docstring_tokens": ["Parse", "a", "Git", "log", "file", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L215-L235", "partition": "test", "index": 3266, "time": "2016-01-03 20:20:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "Git.fetch", "original_string": "def fetch(self, category=CATEGORY_COMMIT, from_date=DEFAULT_DATETIME, to_date=DEFAULT_LAST_DATETIME,\n              branches=None, latest_items=False, no_update=False):\n        \"\"\"Fetch commits.\n\n        The method retrieves from a Git repository or a log file\n        a list of commits. Commits are returned in the same order\n        they were obtained.\n\n        When `from_date` parameter is given it returns items commited\n        since the given date.\n\n        The list of `branches` is a list of strings, with the names of\n        the branches to fetch. If the list of branches is empty, no\n        commit is fetched. If the list of branches is None, all commits\n        for all branches will be fetched.\n\n        The parameter `latest_items` returns only those commits which\n        are new since the last time this method was called.\n\n        The parameter `no_update` returns all commits without performing\n        an update of the repository before.\n\n        Take into account that `from_date` and `branches` are ignored\n        when the commits are fetched from a Git log file or when\n        `latest_items` flag is set.\n\n        The class raises a `RepositoryError` exception when an error\n        occurs accessing the repository.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain commits newer than a specific date\n            (inclusive)\n        :param to_date: obtain commits older than a specific date\n        :param branches: names of branches to fetch from (default: None)\n        :param latest_items: sync with the repository to fetch only the\n            newest commits\n        :param no_update: if enabled, don't update the repo with the latest changes\n\n        :returns: a generator of commits\n        \"\"\"\n        if not from_date:\n            from_date = DEFAULT_DATETIME\n        if not to_date:\n            to_date = DEFAULT_LAST_DATETIME\n\n        kwargs = {\n            'from_date': from_date,\n            'to_date': to_date,\n            'branches': branches,\n            'latest_items': latest_items,\n            'no_update': no_update\n        }\n        items = super().fetch(category, **kwargs)\n\n        return items", "language": "python", "code": "def fetch(self, category=CATEGORY_COMMIT, from_date=DEFAULT_DATETIME, to_date=DEFAULT_LAST_DATETIME,\n              branches=None, latest_items=False, no_update=False):\n        \"\"\"Fetch commits.\n\n        The method retrieves from a Git repository or a log file\n        a list of commits. Commits are returned in the same order\n        they were obtained.\n\n        When `from_date` parameter is given it returns items commited\n        since the given date.\n\n        The list of `branches` is a list of strings, with the names of\n        the branches to fetch. If the list of branches is empty, no\n        commit is fetched. If the list of branches is None, all commits\n        for all branches will be fetched.\n\n        The parameter `latest_items` returns only those commits which\n        are new since the last time this method was called.\n\n        The parameter `no_update` returns all commits without performing\n        an update of the repository before.\n\n        Take into account that `from_date` and `branches` are ignored\n        when the commits are fetched from a Git log file or when\n        `latest_items` flag is set.\n\n        The class raises a `RepositoryError` exception when an error\n        occurs accessing the repository.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain commits newer than a specific date\n            (inclusive)\n        :param to_date: obtain commits older than a specific date\n        :param branches: names of branches to fetch from (default: None)\n        :param latest_items: sync with the repository to fetch only the\n            newest commits\n        :param no_update: if enabled, don't update the repo with the latest changes\n\n        :returns: a generator of commits\n        \"\"\"\n        if not from_date:\n            from_date = DEFAULT_DATETIME\n        if not to_date:\n            to_date = DEFAULT_LAST_DATETIME\n\n        kwargs = {\n            'from_date': from_date,\n            'to_date': to_date,\n            'branches': branches,\n            'latest_items': latest_items,\n            'no_update': no_update\n        }\n        items = super().fetch(category, **kwargs)\n\n        return items", "code_tokens": ["def", "fetch", "(", "self", ",", "category", "=", "CATEGORY_COMMIT", ",", "from_date", "=", "DEFAULT_DATETIME", ",", "to_date", "=", "DEFAULT_LAST_DATETIME", ",", "branches", "=", "None", ",", "latest_items", "=", "False", ",", "no_update", "=", "False", ")", ":", "if", "not", "from_date", ":", "from_date", "=", "DEFAULT_DATETIME", "if", "not", "to_date", ":", "to_date", "=", "DEFAULT_LAST_DATETIME", "kwargs", "=", "{", "'from_date'", ":", "from_date", ",", "'to_date'", ":", "to_date", ",", "'branches'", ":", "branches", ",", "'latest_items'", ":", "latest_items", ",", "'no_update'", ":", "no_update", "}", "items", "=", "super", "(", ")", ".", "fetch", "(", "category", ",", "*", "*", "kwargs", ")", "return", "items"], "docstring": "Fetch commits.\n\n        The method retrieves from a Git repository or a log file\n        a list of commits. Commits are returned in the same order\n        they were obtained.\n\n        When `from_date` parameter is given it returns items commited\n        since the given date.\n\n        The list of `branches` is a list of strings, with the names of\n        the branches to fetch. If the list of branches is empty, no\n        commit is fetched. If the list of branches is None, all commits\n        for all branches will be fetched.\n\n        The parameter `latest_items` returns only those commits which\n        are new since the last time this method was called.\n\n        The parameter `no_update` returns all commits without performing\n        an update of the repository before.\n\n        Take into account that `from_date` and `branches` are ignored\n        when the commits are fetched from a Git log file or when\n        `latest_items` flag is set.\n\n        The class raises a `RepositoryError` exception when an error\n        occurs accessing the repository.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain commits newer than a specific date\n            (inclusive)\n        :param to_date: obtain commits older than a specific date\n        :param branches: names of branches to fetch from (default: None)\n        :param latest_items: sync with the repository to fetch only the\n            newest commits\n        :param no_update: if enabled, don't update the repo with the latest changes\n\n        :returns: a generator of commits", "docstring_tokens": ["Fetch", "commits", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L78-L132", "partition": "test", "index": 3264, "time": "2016-01-03 20:20:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitCommand.setup_cmd_parser", "original_string": "def setup_cmd_parser(cls):\n        \"\"\"Returns the Git argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              from_date=True,\n                                              to_date=True)\n\n        # Optional arguments\n        group = parser.parser.add_argument_group('Git arguments')\n        group.add_argument('--branches', dest='branches',\n                           nargs='+', type=str, default=None,\n                           help=\"Fetch commits only from these branches\")\n\n        # Mutual exclusive parameters\n        exgroup = group.add_mutually_exclusive_group()\n        exgroup.add_argument('--git-path', dest='git_path',\n                             help=\"Path where the Git repository will be cloned\")\n        exgroup.add_argument('--git-log', dest='git_log',\n                             help=\"Path to the Git log file\")\n\n        exgroup_fetch = group.add_mutually_exclusive_group()\n        exgroup_fetch.add_argument('--latest-items', dest='latest_items',\n                                   action='store_true',\n                                   help=\"Fetch latest commits added to the repository\")\n        exgroup_fetch.add_argument('--no-update', dest='no_update',\n                                   action='store_true',\n                                   help=\"Fetch all commits without updating the repository\")\n\n        # Required arguments\n        parser.parser.add_argument('uri',\n                                   help=\"URI of the Git log repository\")\n\n        return parser", "language": "python", "code": "def setup_cmd_parser(cls):\n        \"\"\"Returns the Git argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              from_date=True,\n                                              to_date=True)\n\n        # Optional arguments\n        group = parser.parser.add_argument_group('Git arguments')\n        group.add_argument('--branches', dest='branches',\n                           nargs='+', type=str, default=None,\n                           help=\"Fetch commits only from these branches\")\n\n        # Mutual exclusive parameters\n        exgroup = group.add_mutually_exclusive_group()\n        exgroup.add_argument('--git-path', dest='git_path',\n                             help=\"Path where the Git repository will be cloned\")\n        exgroup.add_argument('--git-log', dest='git_log',\n                             help=\"Path to the Git log file\")\n\n        exgroup_fetch = group.add_mutually_exclusive_group()\n        exgroup_fetch.add_argument('--latest-items', dest='latest_items',\n                                   action='store_true',\n                                   help=\"Fetch latest commits added to the repository\")\n        exgroup_fetch.add_argument('--no-update', dest='no_update',\n                                   action='store_true',\n                                   help=\"Fetch all commits without updating the repository\")\n\n        # Required arguments\n        parser.parser.add_argument('uri',\n                                   help=\"URI of the Git log repository\")\n\n        return parser", "code_tokens": ["def", "setup_cmd_parser", "(", "cls", ")", ":", "parser", "=", "BackendCommandArgumentParser", "(", "cls", ".", "BACKEND", ".", "CATEGORIES", ",", "from_date", "=", "True", ",", "to_date", "=", "True", ")", "# Optional arguments", "group", "=", "parser", ".", "parser", ".", "add_argument_group", "(", "'Git arguments'", ")", "group", ".", "add_argument", "(", "'--branches'", ",", "dest", "=", "'branches'", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Fetch commits only from these branches\"", ")", "# Mutual exclusive parameters", "exgroup", "=", "group", ".", "add_mutually_exclusive_group", "(", ")", "exgroup", ".", "add_argument", "(", "'--git-path'", ",", "dest", "=", "'git_path'", ",", "help", "=", "\"Path where the Git repository will be cloned\"", ")", "exgroup", ".", "add_argument", "(", "'--git-log'", ",", "dest", "=", "'git_log'", ",", "help", "=", "\"Path to the Git log file\"", ")", "exgroup_fetch", "=", "group", ".", "add_mutually_exclusive_group", "(", ")", "exgroup_fetch", ".", "add_argument", "(", "'--latest-items'", ",", "dest", "=", "'latest_items'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Fetch latest commits added to the repository\"", ")", "exgroup_fetch", ".", "add_argument", "(", "'--no-update'", ",", "dest", "=", "'no_update'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Fetch all commits without updating the repository\"", ")", "# Required arguments", "parser", ".", "parser", ".", "add_argument", "(", "'uri'", ",", "help", "=", "\"URI of the Git log repository\"", ")", "return", "parser"], "docstring": "Returns the Git argument parser.", "docstring_tokens": ["Returns", "the", "Git", "argument", "parser", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L345-L377", "partition": "test", "index": 3268, "time": "2016-01-04 02:04:52"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitCommand._pre_init", "original_string": "def _pre_init(self):\n        \"\"\"Initialize repositories directory path\"\"\"\n\n        if self.parsed_args.git_log:\n            git_path = self.parsed_args.git_log\n        elif not self.parsed_args.git_path:\n            base_path = os.path.expanduser('~/.perceval/repositories/')\n            processed_uri = self.parsed_args.uri.lstrip('/')\n            git_path = os.path.join(base_path, processed_uri) + '-git'\n        else:\n            git_path = self.parsed_args.git_path\n\n        setattr(self.parsed_args, 'gitpath', git_path)", "language": "python", "code": "def _pre_init(self):\n        \"\"\"Initialize repositories directory path\"\"\"\n\n        if self.parsed_args.git_log:\n            git_path = self.parsed_args.git_log\n        elif not self.parsed_args.git_path:\n            base_path = os.path.expanduser('~/.perceval/repositories/')\n            processed_uri = self.parsed_args.uri.lstrip('/')\n            git_path = os.path.join(base_path, processed_uri) + '-git'\n        else:\n            git_path = self.parsed_args.git_path\n\n        setattr(self.parsed_args, 'gitpath', git_path)", "code_tokens": ["def", "_pre_init", "(", "self", ")", ":", "if", "self", ".", "parsed_args", ".", "git_log", ":", "git_path", "=", "self", ".", "parsed_args", ".", "git_log", "elif", "not", "self", ".", "parsed_args", ".", "git_path", ":", "base_path", "=", "os", ".", "path", ".", "expanduser", "(", "'~/.perceval/repositories/'", ")", "processed_uri", "=", "self", ".", "parsed_args", ".", "uri", ".", "lstrip", "(", "'/'", ")", "git_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "processed_uri", ")", "+", "'-git'", "else", ":", "git_path", "=", "self", ".", "parsed_args", ".", "git_path", "setattr", "(", "self", ".", "parsed_args", ",", "'gitpath'", ",", "git_path", ")"], "docstring": "Initialize repositories directory path", "docstring_tokens": ["Initialize", "repositories", "directory", "path"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L330-L342", "partition": "test", "index": 3267, "time": "2016-01-04 02:04:52"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.__get_user", "original_string": "def __get_user(self, login):\n        \"\"\"Get user and org data for the login\"\"\"\n\n        user = {}\n\n        if not login:\n            return user\n\n        user_raw = self.client.user(login)\n        user = json.loads(user_raw)\n        user_orgs_raw = \\\n            self.client.user_orgs(login)\n        user['organizations'] = json.loads(user_orgs_raw)\n\n        return user", "language": "python", "code": "def __get_user(self, login):\n        \"\"\"Get user and org data for the login\"\"\"\n\n        user = {}\n\n        if not login:\n            return user\n\n        user_raw = self.client.user(login)\n        user = json.loads(user_raw)\n        user_orgs_raw = \\\n            self.client.user_orgs(login)\n        user['organizations'] = json.loads(user_orgs_raw)\n\n        return user", "code_tokens": ["def", "__get_user", "(", "self", ",", "login", ")", ":", "user", "=", "{", "}", "if", "not", "login", ":", "return", "user", "user_raw", "=", "self", ".", "client", ".", "user", "(", "login", ")", "user", "=", "json", ".", "loads", "(", "user_raw", ")", "user_orgs_raw", "=", "self", ".", "client", ".", "user_orgs", "(", "login", ")", "user", "[", "'organizations'", "]", "=", "json", ".", "loads", "(", "user_orgs_raw", ")", "return", "user"], "docstring": "Get user and org data for the login", "docstring_tokens": ["Get", "user", "and", "org", "data", "for", "the", "login"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L447-L461", "partition": "test", "index": 3304, "time": "2016-01-21 20:53:56"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/utils.py", "func_name": "check_compressed_file_type", "original_string": "def check_compressed_file_type(filepath):\n    \"\"\"Check if filename is a compressed file supported by the tool.\n\n    This function uses magic numbers (first four bytes) to determine\n    the type of the file. Supported types are 'gz' and 'bz2'. When\n    the filetype is not supported, the function returns `None`.\n\n    :param filepath: path to the file\n\n    :returns: 'gz' or 'bz2'; `None` if the type is not supported\n    \"\"\"\n    def compressed_file_type(content):\n        magic_dict = {\n            b'\\x1f\\x8b\\x08': 'gz',\n            b'\\x42\\x5a\\x68': 'bz2',\n            b'PK\\x03\\x04': 'zip'\n        }\n\n        for magic, filetype in magic_dict.items():\n            if content.startswith(magic):\n                return filetype\n\n        return None\n\n    with open(filepath, mode='rb') as f:\n        magic_number = f.read(4)\n    return compressed_file_type(magic_number)", "language": "python", "code": "def check_compressed_file_type(filepath):\n    \"\"\"Check if filename is a compressed file supported by the tool.\n\n    This function uses magic numbers (first four bytes) to determine\n    the type of the file. Supported types are 'gz' and 'bz2'. When\n    the filetype is not supported, the function returns `None`.\n\n    :param filepath: path to the file\n\n    :returns: 'gz' or 'bz2'; `None` if the type is not supported\n    \"\"\"\n    def compressed_file_type(content):\n        magic_dict = {\n            b'\\x1f\\x8b\\x08': 'gz',\n            b'\\x42\\x5a\\x68': 'bz2',\n            b'PK\\x03\\x04': 'zip'\n        }\n\n        for magic, filetype in magic_dict.items():\n            if content.startswith(magic):\n                return filetype\n\n        return None\n\n    with open(filepath, mode='rb') as f:\n        magic_number = f.read(4)\n    return compressed_file_type(magic_number)", "code_tokens": ["def", "check_compressed_file_type", "(", "filepath", ")", ":", "def", "compressed_file_type", "(", "content", ")", ":", "magic_dict", "=", "{", "b'\\x1f\\x8b\\x08'", ":", "'gz'", ",", "b'\\x42\\x5a\\x68'", ":", "'bz2'", ",", "b'PK\\x03\\x04'", ":", "'zip'", "}", "for", "magic", ",", "filetype", "in", "magic_dict", ".", "items", "(", ")", ":", "if", "content", ".", "startswith", "(", "magic", ")", ":", "return", "filetype", "return", "None", "with", "open", "(", "filepath", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "magic_number", "=", "f", ".", "read", "(", "4", ")", "return", "compressed_file_type", "(", "magic_number", ")"], "docstring": "Check if filename is a compressed file supported by the tool.\n\n    This function uses magic numbers (first four bytes) to determine\n    the type of the file. Supported types are 'gz' and 'bz2'. When\n    the filetype is not supported, the function returns `None`.\n\n    :param filepath: path to the file\n\n    :returns: 'gz' or 'bz2'; `None` if the type is not supported", "docstring_tokens": ["Check", "if", "filename", "is", "a", "compressed", "file", "supported", "by", "the", "tool", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/utils.py#L50-L76", "partition": "test", "index": 3332, "time": "2016-02-03 17:17:40"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/utils.py", "func_name": "remove_invalid_xml_chars", "original_string": "def remove_invalid_xml_chars(raw_xml):\n    \"\"\"Remove control and invalid characters from an xml stream.\n\n    Looks for invalid characters and subtitutes them with whitespaces.\n    This solution is based on these two posts: Olemis Lang's reponse\n    on StackOverflow (http://stackoverflow.com/questions/1707890) and\n    lawlesst's on GitHub Gist (https://gist.github.com/lawlesst/4110923),\n    that is based on the previous answer.\n\n    :param xml: XML stream\n\n    :returns: a purged XML stream\n    \"\"\"\n    illegal_unichrs = [(0x00, 0x08), (0x0B, 0x1F),\n                       (0x7F, 0x84), (0x86, 0x9F)]\n\n    illegal_ranges = ['%s-%s' % (chr(low), chr(high))\n                      for (low, high) in illegal_unichrs\n                      if low < sys.maxunicode]\n\n    illegal_xml_re = re.compile('[%s]' % ''.join(illegal_ranges))\n\n    purged_xml = ''\n\n    for c in raw_xml:\n        if illegal_xml_re.search(c) is not None:\n            c = ' '\n        purged_xml += c\n\n    return purged_xml", "language": "python", "code": "def remove_invalid_xml_chars(raw_xml):\n    \"\"\"Remove control and invalid characters from an xml stream.\n\n    Looks for invalid characters and subtitutes them with whitespaces.\n    This solution is based on these two posts: Olemis Lang's reponse\n    on StackOverflow (http://stackoverflow.com/questions/1707890) and\n    lawlesst's on GitHub Gist (https://gist.github.com/lawlesst/4110923),\n    that is based on the previous answer.\n\n    :param xml: XML stream\n\n    :returns: a purged XML stream\n    \"\"\"\n    illegal_unichrs = [(0x00, 0x08), (0x0B, 0x1F),\n                       (0x7F, 0x84), (0x86, 0x9F)]\n\n    illegal_ranges = ['%s-%s' % (chr(low), chr(high))\n                      for (low, high) in illegal_unichrs\n                      if low < sys.maxunicode]\n\n    illegal_xml_re = re.compile('[%s]' % ''.join(illegal_ranges))\n\n    purged_xml = ''\n\n    for c in raw_xml:\n        if illegal_xml_re.search(c) is not None:\n            c = ' '\n        purged_xml += c\n\n    return purged_xml", "code_tokens": ["def", "remove_invalid_xml_chars", "(", "raw_xml", ")", ":", "illegal_unichrs", "=", "[", "(", "0x00", ",", "0x08", ")", ",", "(", "0x0B", ",", "0x1F", ")", ",", "(", "0x7F", ",", "0x84", ")", ",", "(", "0x86", ",", "0x9F", ")", "]", "illegal_ranges", "=", "[", "'%s-%s'", "%", "(", "chr", "(", "low", ")", ",", "chr", "(", "high", ")", ")", "for", "(", "low", ",", "high", ")", "in", "illegal_unichrs", "if", "low", "<", "sys", ".", "maxunicode", "]", "illegal_xml_re", "=", "re", ".", "compile", "(", "'[%s]'", "%", "''", ".", "join", "(", "illegal_ranges", ")", ")", "purged_xml", "=", "''", "for", "c", "in", "raw_xml", ":", "if", "illegal_xml_re", ".", "search", "(", "c", ")", "is", "not", "None", ":", "c", "=", "' '", "purged_xml", "+=", "c", "return", "purged_xml"], "docstring": "Remove control and invalid characters from an xml stream.\n\n    Looks for invalid characters and subtitutes them with whitespaces.\n    This solution is based on these two posts: Olemis Lang's reponse\n    on StackOverflow (http://stackoverflow.com/questions/1707890) and\n    lawlesst's on GitHub Gist (https://gist.github.com/lawlesst/4110923),\n    that is based on the previous answer.\n\n    :param xml: XML stream\n\n    :returns: a purged XML stream", "docstring_tokens": ["Remove", "control", "and", "invalid", "characters", "from", "an", "xml", "stream", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/utils.py#L192-L221", "partition": "test", "index": 3335, "time": "2016-02-04 19:26:15"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/stackexchange.py", "func_name": "StackExchangeClient.get_questions", "original_string": "def get_questions(self, from_date):\n        \"\"\"Retrieve all the questions from a given date.\n\n        :param from_date: obtain questions updated since this date\n        \"\"\"\n\n        page = 1\n        url = urijoin(self.base_url, self.VERSION_API, \"questions\")\n\n        req = self.fetch(url, payload=self.__build_payload(page, from_date))\n        questions = req.text\n\n        data = req.json()\n        tquestions = data['total']\n        nquestions = data['page_size']\n\n        self.__log_status(data['quota_remaining'],\n                          data['quota_max'],\n                          nquestions,\n                          tquestions)\n\n        while questions:\n            yield questions\n            questions = None\n\n            if data['has_more']:\n                page += 1\n\n                backoff = data.get('backoff', None)\n                if backoff:\n                    logger.debug(\"Expensive query. Wait %s secs to send a new request\",\n                                 backoff)\n                    time.sleep(float(backoff))\n\n                req = self.fetch(url, payload=self.__build_payload(page, from_date))\n                data = req.json()\n                questions = req.text\n                nquestions += data['page_size']\n                self.__log_status(data['quota_remaining'],\n                                  data['quota_max'],\n                                  nquestions,\n                                  tquestions)", "language": "python", "code": "def get_questions(self, from_date):\n        \"\"\"Retrieve all the questions from a given date.\n\n        :param from_date: obtain questions updated since this date\n        \"\"\"\n\n        page = 1\n        url = urijoin(self.base_url, self.VERSION_API, \"questions\")\n\n        req = self.fetch(url, payload=self.__build_payload(page, from_date))\n        questions = req.text\n\n        data = req.json()\n        tquestions = data['total']\n        nquestions = data['page_size']\n\n        self.__log_status(data['quota_remaining'],\n                          data['quota_max'],\n                          nquestions,\n                          tquestions)\n\n        while questions:\n            yield questions\n            questions = None\n\n            if data['has_more']:\n                page += 1\n\n                backoff = data.get('backoff', None)\n                if backoff:\n                    logger.debug(\"Expensive query. Wait %s secs to send a new request\",\n                                 backoff)\n                    time.sleep(float(backoff))\n\n                req = self.fetch(url, payload=self.__build_payload(page, from_date))\n                data = req.json()\n                questions = req.text\n                nquestions += data['page_size']\n                self.__log_status(data['quota_remaining'],\n                                  data['quota_max'],\n                                  nquestions,\n                                  tquestions)", "code_tokens": ["def", "get_questions", "(", "self", ",", "from_date", ")", ":", "page", "=", "1", "url", "=", "urijoin", "(", "self", ".", "base_url", ",", "self", ".", "VERSION_API", ",", "\"questions\"", ")", "req", "=", "self", ".", "fetch", "(", "url", ",", "payload", "=", "self", ".", "__build_payload", "(", "page", ",", "from_date", ")", ")", "questions", "=", "req", ".", "text", "data", "=", "req", ".", "json", "(", ")", "tquestions", "=", "data", "[", "'total'", "]", "nquestions", "=", "data", "[", "'page_size'", "]", "self", ".", "__log_status", "(", "data", "[", "'quota_remaining'", "]", ",", "data", "[", "'quota_max'", "]", ",", "nquestions", ",", "tquestions", ")", "while", "questions", ":", "yield", "questions", "questions", "=", "None", "if", "data", "[", "'has_more'", "]", ":", "page", "+=", "1", "backoff", "=", "data", ".", "get", "(", "'backoff'", ",", "None", ")", "if", "backoff", ":", "logger", ".", "debug", "(", "\"Expensive query. Wait %s secs to send a new request\"", ",", "backoff", ")", "time", ".", "sleep", "(", "float", "(", "backoff", ")", ")", "req", "=", "self", ".", "fetch", "(", "url", ",", "payload", "=", "self", ".", "__build_payload", "(", "page", ",", "from_date", ")", ")", "data", "=", "req", ".", "json", "(", ")", "questions", "=", "req", ".", "text", "nquestions", "+=", "data", "[", "'page_size'", "]", "self", ".", "__log_status", "(", "data", "[", "'quota_remaining'", "]", ",", "data", "[", "'quota_max'", "]", ",", "nquestions", ",", "tquestions", ")"], "docstring": "Retrieve all the questions from a given date.\n\n        :param from_date: obtain questions updated since this date", "docstring_tokens": ["Retrieve", "all", "the", "questions", "from", "a", "given", "date", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/stackexchange.py#L214-L255", "partition": "test", "index": 3356, "time": "2016-02-09 15:56:45"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/stackexchange.py", "func_name": "StackExchange.parse_questions", "original_string": "def parse_questions(raw_page):\n        \"\"\"Parse a StackExchange API raw response.\n\n        The method parses the API response retrieving the\n        questions from the received items\n\n        :param items: items from where to parse the questions\n\n        :returns: a generator of questions\n        \"\"\"\n        raw_questions = json.loads(raw_page)\n        questions = raw_questions['items']\n        for question in questions:\n            yield question", "language": "python", "code": "def parse_questions(raw_page):\n        \"\"\"Parse a StackExchange API raw response.\n\n        The method parses the API response retrieving the\n        questions from the received items\n\n        :param items: items from where to parse the questions\n\n        :returns: a generator of questions\n        \"\"\"\n        raw_questions = json.loads(raw_page)\n        questions = raw_questions['items']\n        for question in questions:\n            yield question", "code_tokens": ["def", "parse_questions", "(", "raw_page", ")", ":", "raw_questions", "=", "json", ".", "loads", "(", "raw_page", ")", "questions", "=", "raw_questions", "[", "'items'", "]", "for", "question", "in", "questions", ":", "yield", "question"], "docstring": "Parse a StackExchange API raw response.\n\n        The method parses the API response retrieving the\n        questions from the received items\n\n        :param items: items from where to parse the questions\n\n        :returns: a generator of questions", "docstring_tokens": ["Parse", "a", "StackExchange", "API", "raw", "response", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/stackexchange.py#L160-L173", "partition": "test", "index": 3355, "time": "2016-02-09 15:56:45"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/stackexchange.py", "func_name": "StackExchangeCommand.setup_cmd_parser", "original_string": "def setup_cmd_parser(cls):\n        \"\"\"Returns the StackExchange argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              from_date=True,\n                                              token_auth=True,\n                                              archive=True)\n\n        # StackExchange options\n        group = parser.parser.add_argument_group('StackExchange arguments')\n        group.add_argument('--site', dest='site',\n                           required=True,\n                           help=\"StackExchange site\")\n        group.add_argument('--tagged', dest='tagged',\n                           help=\"filter items by question Tag\")\n        group.add_argument('--max-questions', dest='max_questions',\n                           type=int, default=MAX_QUESTIONS,\n                           help=\"Maximum number of questions requested in the same query\")\n\n        return parser", "language": "python", "code": "def setup_cmd_parser(cls):\n        \"\"\"Returns the StackExchange argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              from_date=True,\n                                              token_auth=True,\n                                              archive=True)\n\n        # StackExchange options\n        group = parser.parser.add_argument_group('StackExchange arguments')\n        group.add_argument('--site', dest='site',\n                           required=True,\n                           help=\"StackExchange site\")\n        group.add_argument('--tagged', dest='tagged',\n                           help=\"filter items by question Tag\")\n        group.add_argument('--max-questions', dest='max_questions',\n                           type=int, default=MAX_QUESTIONS,\n                           help=\"Maximum number of questions requested in the same query\")\n\n        return parser", "code_tokens": ["def", "setup_cmd_parser", "(", "cls", ")", ":", "parser", "=", "BackendCommandArgumentParser", "(", "cls", ".", "BACKEND", ".", "CATEGORIES", ",", "from_date", "=", "True", ",", "token_auth", "=", "True", ",", "archive", "=", "True", ")", "# StackExchange options", "group", "=", "parser", ".", "parser", ".", "add_argument_group", "(", "'StackExchange arguments'", ")", "group", ".", "add_argument", "(", "'--site'", ",", "dest", "=", "'site'", ",", "required", "=", "True", ",", "help", "=", "\"StackExchange site\"", ")", "group", ".", "add_argument", "(", "'--tagged'", ",", "dest", "=", "'tagged'", ",", "help", "=", "\"filter items by question Tag\"", ")", "group", ".", "add_argument", "(", "'--max-questions'", ",", "dest", "=", "'max_questions'", ",", "type", "=", "int", ",", "default", "=", "MAX_QUESTIONS", ",", "help", "=", "\"Maximum number of questions requested in the same query\"", ")", "return", "parser"], "docstring": "Returns the StackExchange argument parser.", "docstring_tokens": ["Returns", "the", "StackExchange", "argument", "parser", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/stackexchange.py#L305-L324", "partition": "test", "index": 3357, "time": "2016-02-09 15:56:45"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mbox.py", "func_name": "MBox._fetch_and_parse_messages", "original_string": "def _fetch_and_parse_messages(self, mailing_list, from_date):\n        \"\"\"Fetch and parse the messages from a mailing list\"\"\"\n\n        from_date = datetime_to_utc(from_date)\n\n        nmsgs, imsgs, tmsgs = (0, 0, 0)\n\n        for mbox in mailing_list.mboxes:\n            tmp_path = None\n\n            try:\n                tmp_path = self._copy_mbox(mbox)\n\n                for message in self.parse_mbox(tmp_path):\n                    tmsgs += 1\n\n                    if not self._validate_message(message):\n                        imsgs += 1\n                        continue\n\n                    # Ignore those messages sent before the given date\n                    dt = str_to_datetime(message[MBox.DATE_FIELD])\n\n                    if dt < from_date:\n                        logger.debug(\"Message %s sent before %s; skipped\",\n                                     message['unixfrom'], str(from_date))\n                        tmsgs -= 1\n                        continue\n\n                    # Convert 'CaseInsensitiveDict' to dict\n                    message = self._casedict_to_dict(message)\n\n                    nmsgs += 1\n                    logger.debug(\"Message %s parsed\", message['unixfrom'])\n\n                    yield message\n            except (OSError, EOFError) as e:\n                logger.warning(\"Ignoring %s mbox due to: %s\", mbox.filepath, str(e))\n            except Exception as e:\n                if tmp_path and os.path.exists(tmp_path):\n                    os.remove(tmp_path)\n                raise e\n            finally:\n                if tmp_path and os.path.exists(tmp_path):\n                    os.remove(tmp_path)\n\n        logger.info(\"Done. %s/%s messages fetched; %s ignored\",\n                    nmsgs, tmsgs, imsgs)", "language": "python", "code": "def _fetch_and_parse_messages(self, mailing_list, from_date):\n        \"\"\"Fetch and parse the messages from a mailing list\"\"\"\n\n        from_date = datetime_to_utc(from_date)\n\n        nmsgs, imsgs, tmsgs = (0, 0, 0)\n\n        for mbox in mailing_list.mboxes:\n            tmp_path = None\n\n            try:\n                tmp_path = self._copy_mbox(mbox)\n\n                for message in self.parse_mbox(tmp_path):\n                    tmsgs += 1\n\n                    if not self._validate_message(message):\n                        imsgs += 1\n                        continue\n\n                    # Ignore those messages sent before the given date\n                    dt = str_to_datetime(message[MBox.DATE_FIELD])\n\n                    if dt < from_date:\n                        logger.debug(\"Message %s sent before %s; skipped\",\n                                     message['unixfrom'], str(from_date))\n                        tmsgs -= 1\n                        continue\n\n                    # Convert 'CaseInsensitiveDict' to dict\n                    message = self._casedict_to_dict(message)\n\n                    nmsgs += 1\n                    logger.debug(\"Message %s parsed\", message['unixfrom'])\n\n                    yield message\n            except (OSError, EOFError) as e:\n                logger.warning(\"Ignoring %s mbox due to: %s\", mbox.filepath, str(e))\n            except Exception as e:\n                if tmp_path and os.path.exists(tmp_path):\n                    os.remove(tmp_path)\n                raise e\n            finally:\n                if tmp_path and os.path.exists(tmp_path):\n                    os.remove(tmp_path)\n\n        logger.info(\"Done. %s/%s messages fetched; %s ignored\",\n                    nmsgs, tmsgs, imsgs)", "code_tokens": ["def", "_fetch_and_parse_messages", "(", "self", ",", "mailing_list", ",", "from_date", ")", ":", "from_date", "=", "datetime_to_utc", "(", "from_date", ")", "nmsgs", ",", "imsgs", ",", "tmsgs", "=", "(", "0", ",", "0", ",", "0", ")", "for", "mbox", "in", "mailing_list", ".", "mboxes", ":", "tmp_path", "=", "None", "try", ":", "tmp_path", "=", "self", ".", "_copy_mbox", "(", "mbox", ")", "for", "message", "in", "self", ".", "parse_mbox", "(", "tmp_path", ")", ":", "tmsgs", "+=", "1", "if", "not", "self", ".", "_validate_message", "(", "message", ")", ":", "imsgs", "+=", "1", "continue", "# Ignore those messages sent before the given date", "dt", "=", "str_to_datetime", "(", "message", "[", "MBox", ".", "DATE_FIELD", "]", ")", "if", "dt", "<", "from_date", ":", "logger", ".", "debug", "(", "\"Message %s sent before %s; skipped\"", ",", "message", "[", "'unixfrom'", "]", ",", "str", "(", "from_date", ")", ")", "tmsgs", "-=", "1", "continue", "# Convert 'CaseInsensitiveDict' to dict", "message", "=", "self", ".", "_casedict_to_dict", "(", "message", ")", "nmsgs", "+=", "1", "logger", ".", "debug", "(", "\"Message %s parsed\"", ",", "message", "[", "'unixfrom'", "]", ")", "yield", "message", "except", "(", "OSError", ",", "EOFError", ")", "as", "e", ":", "logger", ".", "warning", "(", "\"Ignoring %s mbox due to: %s\"", ",", "mbox", ".", "filepath", ",", "str", "(", "e", ")", ")", "except", "Exception", "as", "e", ":", "if", "tmp_path", "and", "os", ".", "path", ".", "exists", "(", "tmp_path", ")", ":", "os", ".", "remove", "(", "tmp_path", ")", "raise", "e", "finally", ":", "if", "tmp_path", "and", "os", ".", "path", ".", "exists", "(", "tmp_path", ")", ":", "os", ".", "remove", "(", "tmp_path", ")", "logger", ".", "info", "(", "\"Done. %s/%s messages fetched; %s ignored\"", ",", "nmsgs", ",", "tmsgs", ",", "imsgs", ")"], "docstring": "Fetch and parse the messages from a mailing list", "docstring_tokens": ["Fetch", "and", "parse", "the", "messages", "from", "a", "mailing", "list"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mbox.py#L189-L236", "partition": "test", "index": 3259, "time": "2016-02-12 19:26:01"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mbox.py", "func_name": "MBox._validate_message", "original_string": "def _validate_message(self, message):\n        \"\"\"Check if the given message has the mandatory fields\"\"\"\n\n        # This check is \"case insensitive\" because we're\n        # using 'CaseInsensitiveDict' from requests.structures\n        # module to store the contents of a message.\n        if self.MESSAGE_ID_FIELD not in message:\n            logger.warning(\"Field 'Message-ID' not found in message %s; ignoring\",\n                           message['unixfrom'])\n            return False\n\n        if not message[self.MESSAGE_ID_FIELD]:\n            logger.warning(\"Field 'Message-ID' is empty in message %s; ignoring\",\n                           message['unixfrom'])\n            return False\n\n        if self.DATE_FIELD not in message:\n            logger.warning(\"Field 'Date' not found in message %s; ignoring\",\n                           message['unixfrom'])\n            return False\n\n        if not message[self.DATE_FIELD]:\n            logger.warning(\"Field 'Date' is empty in message %s; ignoring\",\n                           message['unixfrom'])\n            return False\n\n        try:\n            str_to_datetime(message[self.DATE_FIELD])\n        except InvalidDateError:\n            logger.warning(\"Invalid date %s in message %s; ignoring\",\n                           message[self.DATE_FIELD], message['unixfrom'])\n            return False\n\n        return True", "language": "python", "code": "def _validate_message(self, message):\n        \"\"\"Check if the given message has the mandatory fields\"\"\"\n\n        # This check is \"case insensitive\" because we're\n        # using 'CaseInsensitiveDict' from requests.structures\n        # module to store the contents of a message.\n        if self.MESSAGE_ID_FIELD not in message:\n            logger.warning(\"Field 'Message-ID' not found in message %s; ignoring\",\n                           message['unixfrom'])\n            return False\n\n        if not message[self.MESSAGE_ID_FIELD]:\n            logger.warning(\"Field 'Message-ID' is empty in message %s; ignoring\",\n                           message['unixfrom'])\n            return False\n\n        if self.DATE_FIELD not in message:\n            logger.warning(\"Field 'Date' not found in message %s; ignoring\",\n                           message['unixfrom'])\n            return False\n\n        if not message[self.DATE_FIELD]:\n            logger.warning(\"Field 'Date' is empty in message %s; ignoring\",\n                           message['unixfrom'])\n            return False\n\n        try:\n            str_to_datetime(message[self.DATE_FIELD])\n        except InvalidDateError:\n            logger.warning(\"Invalid date %s in message %s; ignoring\",\n                           message[self.DATE_FIELD], message['unixfrom'])\n            return False\n\n        return True", "code_tokens": ["def", "_validate_message", "(", "self", ",", "message", ")", ":", "# This check is \"case insensitive\" because we're", "# using 'CaseInsensitiveDict' from requests.structures", "# module to store the contents of a message.", "if", "self", ".", "MESSAGE_ID_FIELD", "not", "in", "message", ":", "logger", ".", "warning", "(", "\"Field 'Message-ID' not found in message %s; ignoring\"", ",", "message", "[", "'unixfrom'", "]", ")", "return", "False", "if", "not", "message", "[", "self", ".", "MESSAGE_ID_FIELD", "]", ":", "logger", ".", "warning", "(", "\"Field 'Message-ID' is empty in message %s; ignoring\"", ",", "message", "[", "'unixfrom'", "]", ")", "return", "False", "if", "self", ".", "DATE_FIELD", "not", "in", "message", ":", "logger", ".", "warning", "(", "\"Field 'Date' not found in message %s; ignoring\"", ",", "message", "[", "'unixfrom'", "]", ")", "return", "False", "if", "not", "message", "[", "self", ".", "DATE_FIELD", "]", ":", "logger", ".", "warning", "(", "\"Field 'Date' is empty in message %s; ignoring\"", ",", "message", "[", "'unixfrom'", "]", ")", "return", "False", "try", ":", "str_to_datetime", "(", "message", "[", "self", ".", "DATE_FIELD", "]", ")", "except", "InvalidDateError", ":", "logger", ".", "warning", "(", "\"Invalid date %s in message %s; ignoring\"", ",", "message", "[", "self", ".", "DATE_FIELD", "]", ",", "message", "[", "'unixfrom'", "]", ")", "return", "False", "return", "True"], "docstring": "Check if the given message has the mandatory fields", "docstring_tokens": ["Check", "if", "the", "given", "message", "has", "the", "mandatory", "fields"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mbox.py#L249-L282", "partition": "test", "index": 3261, "time": "2016-02-15 19:42:11"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mbox.py", "func_name": "MBox._copy_mbox", "original_string": "def _copy_mbox(self, mbox):\n        \"\"\"Copy the contents of a mbox to a temporary file\"\"\"\n\n        tmp_path = tempfile.mktemp(prefix='perceval_')\n\n        with mbox.container as f_in:\n            with open(tmp_path, mode='wb') as f_out:\n                for l in f_in:\n                    f_out.write(l)\n        return tmp_path", "language": "python", "code": "def _copy_mbox(self, mbox):\n        \"\"\"Copy the contents of a mbox to a temporary file\"\"\"\n\n        tmp_path = tempfile.mktemp(prefix='perceval_')\n\n        with mbox.container as f_in:\n            with open(tmp_path, mode='wb') as f_out:\n                for l in f_in:\n                    f_out.write(l)\n        return tmp_path", "code_tokens": ["def", "_copy_mbox", "(", "self", ",", "mbox", ")", ":", "tmp_path", "=", "tempfile", ".", "mktemp", "(", "prefix", "=", "'perceval_'", ")", "with", "mbox", ".", "container", "as", "f_in", ":", "with", "open", "(", "tmp_path", ",", "mode", "=", "'wb'", ")", "as", "f_out", ":", "for", "l", "in", "f_in", ":", "f_out", ".", "write", "(", "l", ")", "return", "tmp_path"], "docstring": "Copy the contents of a mbox to a temporary file", "docstring_tokens": ["Copy", "the", "contents", "of", "a", "mbox", "to", "a", "temporary", "file"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mbox.py#L238-L247", "partition": "test", "index": 3260, "time": "2016-02-18 18:24:24"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/jira.py", "func_name": "Jira.parse_issues", "original_string": "def parse_issues(raw_page):\n        \"\"\"Parse a JIRA API raw response.\n\n        The method parses the API response retrieving the\n        issues from the received items\n\n        :param items: items from where to parse the issues\n\n        :returns: a generator of issues\n        \"\"\"\n        raw_issues = json.loads(raw_page)\n        issues = raw_issues['issues']\n        for issue in issues:\n            yield issue", "language": "python", "code": "def parse_issues(raw_page):\n        \"\"\"Parse a JIRA API raw response.\n\n        The method parses the API response retrieving the\n        issues from the received items\n\n        :param items: items from where to parse the issues\n\n        :returns: a generator of issues\n        \"\"\"\n        raw_issues = json.loads(raw_page)\n        issues = raw_issues['issues']\n        for issue in issues:\n            yield issue", "code_tokens": ["def", "parse_issues", "(", "raw_page", ")", ":", "raw_issues", "=", "json", ".", "loads", "(", "raw_page", ")", "issues", "=", "raw_issues", "[", "'issues'", "]", "for", "issue", "in", "issues", ":", "yield", "issue"], "docstring": "Parse a JIRA API raw response.\n\n        The method parses the API response retrieving the\n        issues from the received items\n\n        :param items: items from where to parse the issues\n\n        :returns: a generator of issues", "docstring_tokens": ["Parse", "a", "JIRA", "API", "raw", "response", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/jira.py#L221-L234", "partition": "test", "index": 3347, "time": "2016-02-23 18:27:37"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository.clone", "original_string": "def clone(cls, uri, dirpath):\n        \"\"\"Clone a Git repository.\n\n        Make a bare copy of the repository stored in `uri` into `dirpath`.\n        The repository would be either local or remote.\n\n        :param uri: URI of the repository\n        :param dirtpath: directory where the repository will be cloned\n\n        :returns: a `GitRepository` class having cloned the repository\n\n        :raises RepositoryError: when an error occurs cloning the given\n            repository\n        \"\"\"\n        cmd = ['git', 'clone', '--bare', uri, dirpath]\n        env = {\n            'LANG': 'C',\n            'HOME': os.getenv('HOME', '')\n        }\n\n        cls._exec(cmd, env=env)\n\n        logger.debug(\"Git %s repository cloned into %s\",\n                     uri, dirpath)\n\n        return cls(uri, dirpath)", "language": "python", "code": "def clone(cls, uri, dirpath):\n        \"\"\"Clone a Git repository.\n\n        Make a bare copy of the repository stored in `uri` into `dirpath`.\n        The repository would be either local or remote.\n\n        :param uri: URI of the repository\n        :param dirtpath: directory where the repository will be cloned\n\n        :returns: a `GitRepository` class having cloned the repository\n\n        :raises RepositoryError: when an error occurs cloning the given\n            repository\n        \"\"\"\n        cmd = ['git', 'clone', '--bare', uri, dirpath]\n        env = {\n            'LANG': 'C',\n            'HOME': os.getenv('HOME', '')\n        }\n\n        cls._exec(cmd, env=env)\n\n        logger.debug(\"Git %s repository cloned into %s\",\n                     uri, dirpath)\n\n        return cls(uri, dirpath)", "code_tokens": ["def", "clone", "(", "cls", ",", "uri", ",", "dirpath", ")", ":", "cmd", "=", "[", "'git'", ",", "'clone'", ",", "'--bare'", ",", "uri", ",", "dirpath", "]", "env", "=", "{", "'LANG'", ":", "'C'", ",", "'HOME'", ":", "os", ".", "getenv", "(", "'HOME'", ",", "''", ")", "}", "cls", ".", "_exec", "(", "cmd", ",", "env", "=", "env", ")", "logger", ".", "debug", "(", "\"Git %s repository cloned into %s\"", ",", "uri", ",", "dirpath", ")", "return", "cls", "(", "uri", ",", "dirpath", ")"], "docstring": "Clone a Git repository.\n\n        Make a bare copy of the repository stored in `uri` into `dirpath`.\n        The repository would be either local or remote.\n\n        :param uri: URI of the repository\n        :param dirtpath: directory where the repository will be cloned\n\n        :returns: a `GitRepository` class having cloned the repository\n\n        :raises RepositoryError: when an error occurs cloning the given\n            repository", "docstring_tokens": ["Clone", "a", "Git", "repository", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L804-L829", "partition": "test", "index": 3270, "time": "2016-02-23 18:29:11"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository.update", "original_string": "def update(self):\n        \"\"\"Update repository from its remote.\n\n        Calling this method, the repository will be synchronized with\n        the remote repository using 'fetch' command for 'heads' refs.\n        Any commit stored in the local copy will be removed; refs\n        will be overwritten.\n\n        :raises RepositoryError: when an error occurs updating the\n            repository\n        \"\"\"\n        cmd_update = ['git', 'fetch', 'origin', '+refs/heads/*:refs/heads/*', '--prune']\n        self._exec(cmd_update, cwd=self.dirpath, env=self.gitenv)\n\n        logger.debug(\"Git %s repository updated into %s\",\n                     self.uri, self.dirpath)", "language": "python", "code": "def update(self):\n        \"\"\"Update repository from its remote.\n\n        Calling this method, the repository will be synchronized with\n        the remote repository using 'fetch' command for 'heads' refs.\n        Any commit stored in the local copy will be removed; refs\n        will be overwritten.\n\n        :raises RepositoryError: when an error occurs updating the\n            repository\n        \"\"\"\n        cmd_update = ['git', 'fetch', 'origin', '+refs/heads/*:refs/heads/*', '--prune']\n        self._exec(cmd_update, cwd=self.dirpath, env=self.gitenv)\n\n        logger.debug(\"Git %s repository updated into %s\",\n                     self.uri, self.dirpath)", "code_tokens": ["def", "update", "(", "self", ")", ":", "cmd_update", "=", "[", "'git'", ",", "'fetch'", ",", "'origin'", ",", "'+refs/heads/*:refs/heads/*'", ",", "'--prune'", "]", "self", ".", "_exec", "(", "cmd_update", ",", "cwd", "=", "self", ".", "dirpath", ",", "env", "=", "self", ".", "gitenv", ")", "logger", ".", "debug", "(", "\"Git %s repository updated into %s\"", ",", "self", ".", "uri", ",", "self", ".", "dirpath", ")"], "docstring": "Update repository from its remote.\n\n        Calling this method, the repository will be synchronized with\n        the remote repository using 'fetch' command for 'heads' refs.\n        Any commit stored in the local copy will be removed; refs\n        will be overwritten.\n\n        :raises RepositoryError: when an error occurs updating the\n            repository", "docstring_tokens": ["Update", "repository", "from", "its", "remote", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L895-L910", "partition": "test", "index": 3273, "time": "2016-02-24 02:04:59"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository._exec", "original_string": "def _exec(cmd, cwd=None, env=None, ignored_error_codes=None,\n              encoding='utf-8'):\n        \"\"\"Run a command.\n\n        Execute `cmd` command in the directory set by `cwd`. Environment\n        variables can be set using the `env` dictionary. The output\n        data is returned as encoded bytes.\n\n        Commands which their returning status codes are non-zero will\n        be treated as failed. Error codes considered as valid can be\n        ignored giving them in the `ignored_error_codes` list.\n\n        :returns: the output of the command as encoded bytes\n\n        :raises RepositoryError: when an error occurs running the command\n        \"\"\"\n        if ignored_error_codes is None:\n            ignored_error_codes = []\n\n        logger.debug(\"Running command %s (cwd: %s, env: %s)\",\n                     ' '.join(cmd), cwd, str(env))\n\n        try:\n            proc = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n                                    stderr=subprocess.PIPE,\n                                    cwd=cwd, env=env)\n            (outs, errs) = proc.communicate()\n        except OSError as e:\n            raise RepositoryError(cause=str(e))\n\n        if proc.returncode != 0 and proc.returncode not in ignored_error_codes:\n            err = errs.decode(encoding, errors='surrogateescape')\n            cause = \"git command - %s\" % err\n            raise RepositoryError(cause=cause)\n        else:\n            logger.debug(errs.decode(encoding, errors='surrogateescape'))\n\n        return outs", "language": "python", "code": "def _exec(cmd, cwd=None, env=None, ignored_error_codes=None,\n              encoding='utf-8'):\n        \"\"\"Run a command.\n\n        Execute `cmd` command in the directory set by `cwd`. Environment\n        variables can be set using the `env` dictionary. The output\n        data is returned as encoded bytes.\n\n        Commands which their returning status codes are non-zero will\n        be treated as failed. Error codes considered as valid can be\n        ignored giving them in the `ignored_error_codes` list.\n\n        :returns: the output of the command as encoded bytes\n\n        :raises RepositoryError: when an error occurs running the command\n        \"\"\"\n        if ignored_error_codes is None:\n            ignored_error_codes = []\n\n        logger.debug(\"Running command %s (cwd: %s, env: %s)\",\n                     ' '.join(cmd), cwd, str(env))\n\n        try:\n            proc = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n                                    stderr=subprocess.PIPE,\n                                    cwd=cwd, env=env)\n            (outs, errs) = proc.communicate()\n        except OSError as e:\n            raise RepositoryError(cause=str(e))\n\n        if proc.returncode != 0 and proc.returncode not in ignored_error_codes:\n            err = errs.decode(encoding, errors='surrogateescape')\n            cause = \"git command - %s\" % err\n            raise RepositoryError(cause=cause)\n        else:\n            logger.debug(errs.decode(encoding, errors='surrogateescape'))\n\n        return outs", "code_tokens": ["def", "_exec", "(", "cmd", ",", "cwd", "=", "None", ",", "env", "=", "None", ",", "ignored_error_codes", "=", "None", ",", "encoding", "=", "'utf-8'", ")", ":", "if", "ignored_error_codes", "is", "None", ":", "ignored_error_codes", "=", "[", "]", "logger", ".", "debug", "(", "\"Running command %s (cwd: %s, env: %s)\"", ",", "' '", ".", "join", "(", "cmd", ")", ",", "cwd", ",", "str", "(", "env", ")", ")", "try", ":", "proc", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", ",", "cwd", "=", "cwd", ",", "env", "=", "env", ")", "(", "outs", ",", "errs", ")", "=", "proc", ".", "communicate", "(", ")", "except", "OSError", "as", "e", ":", "raise", "RepositoryError", "(", "cause", "=", "str", "(", "e", ")", ")", "if", "proc", ".", "returncode", "!=", "0", "and", "proc", ".", "returncode", "not", "in", "ignored_error_codes", ":", "err", "=", "errs", ".", "decode", "(", "encoding", ",", "errors", "=", "'surrogateescape'", ")", "cause", "=", "\"git command - %s\"", "%", "err", "raise", "RepositoryError", "(", "cause", "=", "cause", ")", "else", ":", "logger", ".", "debug", "(", "errs", ".", "decode", "(", "encoding", ",", "errors", "=", "'surrogateescape'", ")", ")", "return", "outs"], "docstring": "Run a command.\n\n        Execute `cmd` command in the directory set by `cwd`. Environment\n        variables can be set using the `env` dictionary. The output\n        data is returned as encoded bytes.\n\n        Commands which their returning status codes are non-zero will\n        be treated as failed. Error codes considered as valid can be\n        ignored giving them in the `ignored_error_codes` list.\n\n        :returns: the output of the command as encoded bytes\n\n        :raises RepositoryError: when an error occurs running the command", "docstring_tokens": ["Run", "a", "command", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L1296-L1333", "partition": "test", "index": 3285, "time": "2016-02-24 11:51:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository.log", "original_string": "def log(self, from_date=None, to_date=None, branches=None, encoding='utf-8'):\n        \"\"\"Read the commit log from the repository.\n\n        The method returns the Git log of the repository using the\n        following options:\n\n            git log --raw --numstat --pretty=fuller --decorate=full\n                --all --reverse --topo-order --parents -M -C -c\n                --remotes=origin\n\n        When `from_date` is given, it gets the commits equal or older\n        than that date. This date is given in a datetime object.\n\n        The list of branches is a list of strings, with the names of the\n        branches to fetch. If the list of branches is empty, no commit\n        is fetched. If the list of branches is None, all commits\n        for all branches will be fetched.\n\n        :param from_date: fetch commits newer than a specific\n            date (inclusive)\n        :param branches: names of branches to fetch from (default: None)\n        :param encoding: encode the log using this format\n\n        :returns: a generator where each item is a line from the log\n\n        :raises EmptyRepositoryError: when the repository is empty and\n            the action cannot be performed\n        :raises RepositoryError: when an error occurs fetching the log\n        \"\"\"\n        if self.is_empty():\n            logger.warning(\"Git %s repository is empty; unable to get the log\",\n                           self.uri)\n            raise EmptyRepositoryError(repository=self.uri)\n\n        cmd_log = ['git', 'log', '--reverse', '--topo-order']\n        cmd_log.extend(self.GIT_PRETTY_OUTPUT_OPTS)\n\n        if from_date:\n            dt = from_date.strftime(\"%Y-%m-%d %H:%M:%S %z\")\n            cmd_log.append('--since=' + dt)\n\n        if to_date:\n            dt = to_date.strftime(\"%Y-%m-%d %H:%M:%S %z\")\n            cmd_log.append('--until=' + dt)\n\n        if branches is None:\n            cmd_log.extend(['--branches', '--tags', '--remotes=origin'])\n        elif len(branches) == 0:\n            cmd_log.append('--max-count=0')\n        else:\n            branches = ['refs/heads/' + branch for branch in branches]\n            cmd_log.extend(branches)\n\n        for line in self._exec_nb(cmd_log, cwd=self.dirpath, env=self.gitenv):\n            yield line\n\n        logger.debug(\"Git log fetched from %s repository (%s)\",\n                     self.uri, self.dirpath)", "language": "python", "code": "def log(self, from_date=None, to_date=None, branches=None, encoding='utf-8'):\n        \"\"\"Read the commit log from the repository.\n\n        The method returns the Git log of the repository using the\n        following options:\n\n            git log --raw --numstat --pretty=fuller --decorate=full\n                --all --reverse --topo-order --parents -M -C -c\n                --remotes=origin\n\n        When `from_date` is given, it gets the commits equal or older\n        than that date. This date is given in a datetime object.\n\n        The list of branches is a list of strings, with the names of the\n        branches to fetch. If the list of branches is empty, no commit\n        is fetched. If the list of branches is None, all commits\n        for all branches will be fetched.\n\n        :param from_date: fetch commits newer than a specific\n            date (inclusive)\n        :param branches: names of branches to fetch from (default: None)\n        :param encoding: encode the log using this format\n\n        :returns: a generator where each item is a line from the log\n\n        :raises EmptyRepositoryError: when the repository is empty and\n            the action cannot be performed\n        :raises RepositoryError: when an error occurs fetching the log\n        \"\"\"\n        if self.is_empty():\n            logger.warning(\"Git %s repository is empty; unable to get the log\",\n                           self.uri)\n            raise EmptyRepositoryError(repository=self.uri)\n\n        cmd_log = ['git', 'log', '--reverse', '--topo-order']\n        cmd_log.extend(self.GIT_PRETTY_OUTPUT_OPTS)\n\n        if from_date:\n            dt = from_date.strftime(\"%Y-%m-%d %H:%M:%S %z\")\n            cmd_log.append('--since=' + dt)\n\n        if to_date:\n            dt = to_date.strftime(\"%Y-%m-%d %H:%M:%S %z\")\n            cmd_log.append('--until=' + dt)\n\n        if branches is None:\n            cmd_log.extend(['--branches', '--tags', '--remotes=origin'])\n        elif len(branches) == 0:\n            cmd_log.append('--max-count=0')\n        else:\n            branches = ['refs/heads/' + branch for branch in branches]\n            cmd_log.extend(branches)\n\n        for line in self._exec_nb(cmd_log, cwd=self.dirpath, env=self.gitenv):\n            yield line\n\n        logger.debug(\"Git log fetched from %s repository (%s)\",\n                     self.uri, self.dirpath)", "code_tokens": ["def", "log", "(", "self", ",", "from_date", "=", "None", ",", "to_date", "=", "None", ",", "branches", "=", "None", ",", "encoding", "=", "'utf-8'", ")", ":", "if", "self", ".", "is_empty", "(", ")", ":", "logger", ".", "warning", "(", "\"Git %s repository is empty; unable to get the log\"", ",", "self", ".", "uri", ")", "raise", "EmptyRepositoryError", "(", "repository", "=", "self", ".", "uri", ")", "cmd_log", "=", "[", "'git'", ",", "'log'", ",", "'--reverse'", ",", "'--topo-order'", "]", "cmd_log", ".", "extend", "(", "self", ".", "GIT_PRETTY_OUTPUT_OPTS", ")", "if", "from_date", ":", "dt", "=", "from_date", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S %z\"", ")", "cmd_log", ".", "append", "(", "'--since='", "+", "dt", ")", "if", "to_date", ":", "dt", "=", "to_date", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S %z\"", ")", "cmd_log", ".", "append", "(", "'--until='", "+", "dt", ")", "if", "branches", "is", "None", ":", "cmd_log", ".", "extend", "(", "[", "'--branches'", ",", "'--tags'", ",", "'--remotes=origin'", "]", ")", "elif", "len", "(", "branches", ")", "==", "0", ":", "cmd_log", ".", "append", "(", "'--max-count=0'", ")", "else", ":", "branches", "=", "[", "'refs/heads/'", "+", "branch", "for", "branch", "in", "branches", "]", "cmd_log", ".", "extend", "(", "branches", ")", "for", "line", "in", "self", ".", "_exec_nb", "(", "cmd_log", ",", "cwd", "=", "self", ".", "dirpath", ",", "env", "=", "self", ".", "gitenv", ")", ":", "yield", "line", "logger", ".", "debug", "(", "\"Git log fetched from %s repository (%s)\"", ",", "self", ".", "uri", ",", "self", ".", "dirpath", ")"], "docstring": "Read the commit log from the repository.\n\n        The method returns the Git log of the repository using the\n        following options:\n\n            git log --raw --numstat --pretty=fuller --decorate=full\n                --all --reverse --topo-order --parents -M -C -c\n                --remotes=origin\n\n        When `from_date` is given, it gets the commits equal or older\n        than that date. This date is given in a datetime object.\n\n        The list of branches is a list of strings, with the names of the\n        branches to fetch. If the list of branches is empty, no commit\n        is fetched. If the list of branches is None, all commits\n        for all branches will be fetched.\n\n        :param from_date: fetch commits newer than a specific\n            date (inclusive)\n        :param branches: names of branches to fetch from (default: None)\n        :param encoding: encode the log using this format\n\n        :returns: a generator where each item is a line from the log\n\n        :raises EmptyRepositoryError: when the repository is empty and\n            the action cannot be performed\n        :raises RepositoryError: when an error occurs fetching the log", "docstring_tokens": ["Read", "the", "commit", "log", "from", "the", "repository", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L984-L1041", "partition": "test", "index": 3276, "time": "2016-02-24 11:51:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository._exec_nb", "original_string": "def _exec_nb(self, cmd, cwd=None, env=None, encoding='utf-8'):\n        \"\"\"Run a command with a non blocking call.\n\n        Execute `cmd` command with a non blocking call. The command will\n        be run in the directory set by `cwd`. Enviroment variables can be\n        set using the `env` dictionary. The output data is returned\n        as encoded bytes in an iterator. Each item will be a line of the\n        output.\n\n        :returns: an iterator with the output of the command as encoded bytes\n\n        :raises RepositoryError: when an error occurs running the command\n        \"\"\"\n        self.failed_message = None\n\n        logger.debug(\"Running command %s (cwd: %s, env: %s)\",\n                     ' '.join(cmd), cwd, str(env))\n\n        try:\n            self.proc = subprocess.Popen(cmd,\n                                         stdout=subprocess.PIPE,\n                                         stderr=subprocess.PIPE,\n                                         cwd=cwd,\n                                         env=env)\n            err_thread = threading.Thread(target=self._read_stderr,\n                                          kwargs={'encoding': encoding},\n                                          daemon=True)\n            err_thread.start()\n            for line in self.proc.stdout:\n                yield line.decode(encoding, errors='surrogateescape')\n            err_thread.join()\n\n            self.proc.communicate()\n            self.proc.stdout.close()\n            self.proc.stderr.close()\n        except OSError as e:\n            err_thread.join()\n            raise RepositoryError(cause=str(e))\n\n        if self.proc.returncode != 0:\n            cause = \"git command - %s (return code: %d)\" % \\\n                (self.failed_message, self.proc.returncode)\n            raise RepositoryError(cause=cause)", "language": "python", "code": "def _exec_nb(self, cmd, cwd=None, env=None, encoding='utf-8'):\n        \"\"\"Run a command with a non blocking call.\n\n        Execute `cmd` command with a non blocking call. The command will\n        be run in the directory set by `cwd`. Enviroment variables can be\n        set using the `env` dictionary. The output data is returned\n        as encoded bytes in an iterator. Each item will be a line of the\n        output.\n\n        :returns: an iterator with the output of the command as encoded bytes\n\n        :raises RepositoryError: when an error occurs running the command\n        \"\"\"\n        self.failed_message = None\n\n        logger.debug(\"Running command %s (cwd: %s, env: %s)\",\n                     ' '.join(cmd), cwd, str(env))\n\n        try:\n            self.proc = subprocess.Popen(cmd,\n                                         stdout=subprocess.PIPE,\n                                         stderr=subprocess.PIPE,\n                                         cwd=cwd,\n                                         env=env)\n            err_thread = threading.Thread(target=self._read_stderr,\n                                          kwargs={'encoding': encoding},\n                                          daemon=True)\n            err_thread.start()\n            for line in self.proc.stdout:\n                yield line.decode(encoding, errors='surrogateescape')\n            err_thread.join()\n\n            self.proc.communicate()\n            self.proc.stdout.close()\n            self.proc.stderr.close()\n        except OSError as e:\n            err_thread.join()\n            raise RepositoryError(cause=str(e))\n\n        if self.proc.returncode != 0:\n            cause = \"git command - %s (return code: %d)\" % \\\n                (self.failed_message, self.proc.returncode)\n            raise RepositoryError(cause=cause)", "code_tokens": ["def", "_exec_nb", "(", "self", ",", "cmd", ",", "cwd", "=", "None", ",", "env", "=", "None", ",", "encoding", "=", "'utf-8'", ")", ":", "self", ".", "failed_message", "=", "None", "logger", ".", "debug", "(", "\"Running command %s (cwd: %s, env: %s)\"", ",", "' '", ".", "join", "(", "cmd", ")", ",", "cwd", ",", "str", "(", "env", ")", ")", "try", ":", "self", ".", "proc", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", ",", "cwd", "=", "cwd", ",", "env", "=", "env", ")", "err_thread", "=", "threading", ".", "Thread", "(", "target", "=", "self", ".", "_read_stderr", ",", "kwargs", "=", "{", "'encoding'", ":", "encoding", "}", ",", "daemon", "=", "True", ")", "err_thread", ".", "start", "(", ")", "for", "line", "in", "self", ".", "proc", ".", "stdout", ":", "yield", "line", ".", "decode", "(", "encoding", ",", "errors", "=", "'surrogateescape'", ")", "err_thread", ".", "join", "(", ")", "self", ".", "proc", ".", "communicate", "(", ")", "self", ".", "proc", ".", "stdout", ".", "close", "(", ")", "self", ".", "proc", ".", "stderr", ".", "close", "(", ")", "except", "OSError", "as", "e", ":", "err_thread", ".", "join", "(", ")", "raise", "RepositoryError", "(", "cause", "=", "str", "(", "e", ")", ")", "if", "self", ".", "proc", ".", "returncode", "!=", "0", ":", "cause", "=", "\"git command - %s (return code: %d)\"", "%", "(", "self", ".", "failed_message", ",", "self", ".", "proc", ".", "returncode", ")", "raise", "RepositoryError", "(", "cause", "=", "cause", ")"], "docstring": "Run a command with a non blocking call.\n\n        Execute `cmd` command with a non blocking call. The command will\n        be run in the directory set by `cwd`. Enviroment variables can be\n        set using the `env` dictionary. The output data is returned\n        as encoded bytes in an iterator. Each item will be a line of the\n        output.\n\n        :returns: an iterator with the output of the command as encoded bytes\n\n        :raises RepositoryError: when an error occurs running the command", "docstring_tokens": ["Run", "a", "command", "with", "a", "non", "blocking", "call", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L1225-L1267", "partition": "test", "index": 3283, "time": "2016-02-24 17:01:50"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/discourse.py", "func_name": "Discourse.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the topics\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n\n        from_date = kwargs['from_date']\n\n        logger.info(\"Looking for topics at '%s', updated from '%s'\",\n                    self.url, str(from_date))\n\n        ntopics = 0\n\n        topics_ids = self.__fetch_and_parse_topics_ids(from_date)\n\n        for topic_id in topics_ids:\n            topic = self.__fetch_and_parse_topic(topic_id)\n            ntopics += 1\n            yield topic\n\n        logger.info(\"Fetch process completed: %s topics fetched\",\n                    ntopics)", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the topics\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n\n        from_date = kwargs['from_date']\n\n        logger.info(\"Looking for topics at '%s', updated from '%s'\",\n                    self.url, str(from_date))\n\n        ntopics = 0\n\n        topics_ids = self.__fetch_and_parse_topics_ids(from_date)\n\n        for topic_id in topics_ids:\n            topic = self.__fetch_and_parse_topic(topic_id)\n            ntopics += 1\n            yield topic\n\n        logger.info(\"Fetch process completed: %s topics fetched\",\n                    ntopics)", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "from_date", "=", "kwargs", "[", "'from_date'", "]", "logger", ".", "info", "(", "\"Looking for topics at '%s', updated from '%s'\"", ",", "self", ".", "url", ",", "str", "(", "from_date", ")", ")", "ntopics", "=", "0", "topics_ids", "=", "self", ".", "__fetch_and_parse_topics_ids", "(", "from_date", ")", "for", "topic_id", "in", "topics_ids", ":", "topic", "=", "self", ".", "__fetch_and_parse_topic", "(", "topic_id", ")", "ntopics", "+=", "1", "yield", "topic", "logger", ".", "info", "(", "\"Fetch process completed: %s topics fetched\"", ",", "ntopics", ")"], "docstring": "Fetch the topics\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "the", "topics"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/discourse.py#L99-L123", "partition": "test", "index": 3384, "time": "2016-03-05 08:04:02"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/discourse.py", "func_name": "DiscourseClient.topic", "original_string": "def topic(self, topic_id):\n        \"\"\"Retrive the topic with `topic_id` identifier.\n\n        :param topic_id: identifier of the topic to retrieve\n        \"\"\"\n        params = {\n            self.PKEY: self.api_key\n        }\n\n        # http://example.com/t/8.json\n        response = self._call(self.TOPIC, topic_id,\n                              params=params)\n\n        return response", "language": "python", "code": "def topic(self, topic_id):\n        \"\"\"Retrive the topic with `topic_id` identifier.\n\n        :param topic_id: identifier of the topic to retrieve\n        \"\"\"\n        params = {\n            self.PKEY: self.api_key\n        }\n\n        # http://example.com/t/8.json\n        response = self._call(self.TOPIC, topic_id,\n                              params=params)\n\n        return response", "code_tokens": ["def", "topic", "(", "self", ",", "topic_id", ")", ":", "params", "=", "{", "self", ".", "PKEY", ":", "self", ".", "api_key", "}", "# http://example.com/t/8.json", "response", "=", "self", ".", "_call", "(", "self", ".", "TOPIC", ",", "topic_id", ",", "params", "=", "params", ")", "return", "response"], "docstring": "Retrive the topic with `topic_id` identifier.\n\n        :param topic_id: identifier of the topic to retrieve", "docstring_tokens": ["Retrive", "the", "topic", "with", "topic_id", "identifier", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/discourse.py#L330-L343", "partition": "test", "index": 3386, "time": "2016-03-05 08:04:02"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/bugzilla.py", "func_name": "BugzillaClient.logout", "original_string": "def logout(self):\n        \"\"\"Logout from the server.\"\"\"\n\n        params = {\n            self.PLOGOUT: '1'\n        }\n\n        self.call(self.CGI_LOGIN, params)\n        self._close_http_session()\n\n        logger.debug(\"Bugzilla user logged out from %s\",\n                     self.base_url)", "language": "python", "code": "def logout(self):\n        \"\"\"Logout from the server.\"\"\"\n\n        params = {\n            self.PLOGOUT: '1'\n        }\n\n        self.call(self.CGI_LOGIN, params)\n        self._close_http_session()\n\n        logger.debug(\"Bugzilla user logged out from %s\",\n                     self.base_url)", "code_tokens": ["def", "logout", "(", "self", ")", ":", "params", "=", "{", "self", ".", "PLOGOUT", ":", "'1'", "}", "self", ".", "call", "(", "self", ".", "CGI_LOGIN", ",", "params", ")", "self", ".", "_close_http_session", "(", ")", "logger", ".", "debug", "(", "\"Bugzilla user logged out from %s\"", ",", "self", ".", "base_url", ")"], "docstring": "Logout from the server.", "docstring_tokens": ["Logout", "from", "the", "server", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/bugzilla.py#L465-L476", "partition": "test", "index": 3200, "time": "2016-03-09 13:34:00"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/bugzilla.py", "func_name": "Bugzilla.metadata_updated_on", "original_string": "def metadata_updated_on(item):\n        \"\"\"Extracts and coverts the update time from a Bugzilla item.\n\n        The timestamp is extracted from 'delta_ts' field. This date is\n        converted to UNIX timestamp format. Due Bugzilla servers ignore\n        the timezone on HTTP requests, it will be ignored during the\n        conversion, too.\n\n        :param item: item generated by the backend\n\n        :returns: a UNIX timestamp\n        \"\"\"\n        ts = item['delta_ts'][0]['__text__']\n        ts = str_to_datetime(ts)\n        ts = ts.replace(tzinfo=dateutil.tz.tzutc())\n\n        return ts.timestamp()", "language": "python", "code": "def metadata_updated_on(item):\n        \"\"\"Extracts and coverts the update time from a Bugzilla item.\n\n        The timestamp is extracted from 'delta_ts' field. This date is\n        converted to UNIX timestamp format. Due Bugzilla servers ignore\n        the timezone on HTTP requests, it will be ignored during the\n        conversion, too.\n\n        :param item: item generated by the backend\n\n        :returns: a UNIX timestamp\n        \"\"\"\n        ts = item['delta_ts'][0]['__text__']\n        ts = str_to_datetime(ts)\n        ts = ts.replace(tzinfo=dateutil.tz.tzutc())\n\n        return ts.timestamp()", "code_tokens": ["def", "metadata_updated_on", "(", "item", ")", ":", "ts", "=", "item", "[", "'delta_ts'", "]", "[", "0", "]", "[", "'__text__'", "]", "ts", "=", "str_to_datetime", "(", "ts", ")", "ts", "=", "ts", ".", "replace", "(", "tzinfo", "=", "dateutil", ".", "tz", ".", "tzutc", "(", ")", ")", "return", "ts", ".", "timestamp", "(", ")"], "docstring": "Extracts and coverts the update time from a Bugzilla item.\n\n        The timestamp is extracted from 'delta_ts' field. This date is\n        converted to UNIX timestamp format. Due Bugzilla servers ignore\n        the timezone on HTTP requests, it will be ignored during the\n        conversion, too.\n\n        :param item: item generated by the backend\n\n        :returns: a UNIX timestamp", "docstring_tokens": ["Extracts", "and", "coverts", "the", "update", "time", "from", "a", "Bugzilla", "item", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/bugzilla.py#L157-L173", "partition": "test", "index": 3196, "time": "2016-03-10 13:16:15"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "uuid", "original_string": "def uuid(*args):\n    \"\"\"Generate a UUID based on the given parameters.\n\n    The UUID will be the SHA1 of the concatenation of the values\n    from the list. The separator bewteedn these values is ':'.\n    Each value must be a non-empty string, otherwise, the function\n    will raise an exception.\n\n    :param *args: list of arguments used to generate the UUID\n\n    :returns: a universal unique identifier\n\n    :raises ValueError: when anyone of the values is not a string,\n        is empty or `None`.\n    \"\"\"\n    def check_value(v):\n        if not isinstance(v, str):\n            raise ValueError(\"%s value is not a string instance\" % str(v))\n        elif not v:\n            raise ValueError(\"value cannot be None or empty\")\n        else:\n            return v\n\n    s = ':'.join(map(check_value, args))\n\n    sha1 = hashlib.sha1(s.encode('utf-8', errors='surrogateescape'))\n    uuid_sha1 = sha1.hexdigest()\n\n    return uuid_sha1", "language": "python", "code": "def uuid(*args):\n    \"\"\"Generate a UUID based on the given parameters.\n\n    The UUID will be the SHA1 of the concatenation of the values\n    from the list. The separator bewteedn these values is ':'.\n    Each value must be a non-empty string, otherwise, the function\n    will raise an exception.\n\n    :param *args: list of arguments used to generate the UUID\n\n    :returns: a universal unique identifier\n\n    :raises ValueError: when anyone of the values is not a string,\n        is empty or `None`.\n    \"\"\"\n    def check_value(v):\n        if not isinstance(v, str):\n            raise ValueError(\"%s value is not a string instance\" % str(v))\n        elif not v:\n            raise ValueError(\"value cannot be None or empty\")\n        else:\n            return v\n\n    s = ':'.join(map(check_value, args))\n\n    sha1 = hashlib.sha1(s.encode('utf-8', errors='surrogateescape'))\n    uuid_sha1 = sha1.hexdigest()\n\n    return uuid_sha1", "code_tokens": ["def", "uuid", "(", "*", "args", ")", ":", "def", "check_value", "(", "v", ")", ":", "if", "not", "isinstance", "(", "v", ",", "str", ")", ":", "raise", "ValueError", "(", "\"%s value is not a string instance\"", "%", "str", "(", "v", ")", ")", "elif", "not", "v", ":", "raise", "ValueError", "(", "\"value cannot be None or empty\"", ")", "else", ":", "return", "v", "s", "=", "':'", ".", "join", "(", "map", "(", "check_value", ",", "args", ")", ")", "sha1", "=", "hashlib", ".", "sha1", "(", "s", ".", "encode", "(", "'utf-8'", ",", "errors", "=", "'surrogateescape'", ")", ")", "uuid_sha1", "=", "sha1", ".", "hexdigest", "(", ")", "return", "uuid_sha1"], "docstring": "Generate a UUID based on the given parameters.\n\n    The UUID will be the SHA1 of the concatenation of the values\n    from the list. The separator bewteedn these values is ':'.\n    Each value must be a non-empty string, otherwise, the function\n    will raise an exception.\n\n    :param *args: list of arguments used to generate the UUID\n\n    :returns: a universal unique identifier\n\n    :raises ValueError: when anyone of the values is not a string,\n        is empty or `None`.", "docstring_tokens": ["Generate", "a", "UUID", "based", "on", "the", "given", "parameters", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L514-L542", "partition": "test", "index": 3244, "time": "2016-03-10 14:00:43"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mbox.py", "func_name": "MBox._casedict_to_dict", "original_string": "def _casedict_to_dict(self, message):\n        \"\"\"Convert a message in CaseInsensitiveDict to dict.\n\n        This method also converts well known problematic headers,\n        such as Message-ID and Date to a common name.\n        \"\"\"\n        message_id = message.pop(self.MESSAGE_ID_FIELD)\n        date = message.pop(self.DATE_FIELD)\n\n        msg = {k: v for k, v in message.items()}\n        msg[self.MESSAGE_ID_FIELD] = message_id\n        msg[self.DATE_FIELD] = date\n\n        return msg", "language": "python", "code": "def _casedict_to_dict(self, message):\n        \"\"\"Convert a message in CaseInsensitiveDict to dict.\n\n        This method also converts well known problematic headers,\n        such as Message-ID and Date to a common name.\n        \"\"\"\n        message_id = message.pop(self.MESSAGE_ID_FIELD)\n        date = message.pop(self.DATE_FIELD)\n\n        msg = {k: v for k, v in message.items()}\n        msg[self.MESSAGE_ID_FIELD] = message_id\n        msg[self.DATE_FIELD] = date\n\n        return msg", "code_tokens": ["def", "_casedict_to_dict", "(", "self", ",", "message", ")", ":", "message_id", "=", "message", ".", "pop", "(", "self", ".", "MESSAGE_ID_FIELD", ")", "date", "=", "message", ".", "pop", "(", "self", ".", "DATE_FIELD", ")", "msg", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "message", ".", "items", "(", ")", "}", "msg", "[", "self", ".", "MESSAGE_ID_FIELD", "]", "=", "message_id", "msg", "[", "self", ".", "DATE_FIELD", "]", "=", "date", "return", "msg"], "docstring": "Convert a message in CaseInsensitiveDict to dict.\n\n        This method also converts well known problematic headers,\n        such as Message-ID and Date to a common name.", "docstring_tokens": ["Convert", "a", "message", "in", "CaseInsensitiveDict", "to", "dict", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mbox.py#L284-L297", "partition": "test", "index": 3262, "time": "2016-03-14 13:33:33"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository._read_stderr", "original_string": "def _read_stderr(self, encoding='utf-8'):\n        \"\"\"Reads self.proc.stderr.\n\n        Usually, this should be read in a thread, to prevent blocking\n        the read from stdout of the stderr buffer is filled, and this\n        function is not called becuase the program is busy in the\n        stderr reading loop.\n\n        Reads self.proc.stderr (self.proc is the subprocess running\n        the git command), and reads / writes self.failed_message\n        (the message sent to stderr when git fails, usually one line).\n        \"\"\"\n        for line in self.proc.stderr:\n            err_line = line.decode(encoding, errors='surrogateescape')\n\n            if self.proc.returncode != 0:\n                # If the subprocess didn't finish successfully, we expect\n                # the last line in stderr to provide the cause\n                if self.failed_message is not None:\n                    # We had a message, there is a newer line, print it\n                    logger.debug(\"Git log stderr: \" + self.failed_message)\n                self.failed_message = err_line\n            else:\n                # The subprocess is successfully up to now, print the line\n                logger.debug(\"Git log stderr: \" + err_line)", "language": "python", "code": "def _read_stderr(self, encoding='utf-8'):\n        \"\"\"Reads self.proc.stderr.\n\n        Usually, this should be read in a thread, to prevent blocking\n        the read from stdout of the stderr buffer is filled, and this\n        function is not called becuase the program is busy in the\n        stderr reading loop.\n\n        Reads self.proc.stderr (self.proc is the subprocess running\n        the git command), and reads / writes self.failed_message\n        (the message sent to stderr when git fails, usually one line).\n        \"\"\"\n        for line in self.proc.stderr:\n            err_line = line.decode(encoding, errors='surrogateescape')\n\n            if self.proc.returncode != 0:\n                # If the subprocess didn't finish successfully, we expect\n                # the last line in stderr to provide the cause\n                if self.failed_message is not None:\n                    # We had a message, there is a newer line, print it\n                    logger.debug(\"Git log stderr: \" + self.failed_message)\n                self.failed_message = err_line\n            else:\n                # The subprocess is successfully up to now, print the line\n                logger.debug(\"Git log stderr: \" + err_line)", "code_tokens": ["def", "_read_stderr", "(", "self", ",", "encoding", "=", "'utf-8'", ")", ":", "for", "line", "in", "self", ".", "proc", ".", "stderr", ":", "err_line", "=", "line", ".", "decode", "(", "encoding", ",", "errors", "=", "'surrogateescape'", ")", "if", "self", ".", "proc", ".", "returncode", "!=", "0", ":", "# If the subprocess didn't finish successfully, we expect", "# the last line in stderr to provide the cause", "if", "self", ".", "failed_message", "is", "not", "None", ":", "# We had a message, there is a newer line, print it", "logger", ".", "debug", "(", "\"Git log stderr: \"", "+", "self", ".", "failed_message", ")", "self", ".", "failed_message", "=", "err_line", "else", ":", "# The subprocess is successfully up to now, print the line", "logger", ".", "debug", "(", "\"Git log stderr: \"", "+", "err_line", ")"], "docstring": "Reads self.proc.stderr.\n\n        Usually, this should be read in a thread, to prevent blocking\n        the read from stdout of the stderr buffer is filled, and this\n        function is not called becuase the program is busy in the\n        stderr reading loop.\n\n        Reads self.proc.stderr (self.proc is the subprocess running\n        the git command), and reads / writes self.failed_message\n        (the message sent to stderr when git fails, usually one line).", "docstring_tokens": ["Reads", "self", ".", "proc", ".", "stderr", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L1269-L1293", "partition": "test", "index": 3284, "time": "2016-03-19 20:49:35"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gerrit.py", "func_name": "Gerrit._fetch_gerrit28", "original_string": "def _fetch_gerrit28(self, from_date=DEFAULT_DATETIME):\n        \"\"\" Specific fetch for gerrit 2.8 version.\n\n        Get open and closed reviews in different queries.\n        Take the newer review from both lists and iterate.\n        \"\"\"\n\n        # Convert date to Unix time\n        from_ut = datetime_to_utc(from_date)\n        from_ut = from_ut.timestamp()\n\n        filter_open = \"status:open\"\n        filter_closed = \"status:closed\"\n\n        last_item_open = self.client.next_retrieve_group_item()\n        last_item_closed = self.client.next_retrieve_group_item()\n        reviews_open = self._get_reviews(last_item_open, filter_open)\n        reviews_closed = self._get_reviews(last_item_closed, filter_closed)\n        last_nreviews_open = len(reviews_open)\n        last_nreviews_closed = len(reviews_closed)\n\n        while reviews_open or reviews_closed:\n            if reviews_open and reviews_closed:\n                if reviews_open[0]['lastUpdated'] >= reviews_closed[0]['lastUpdated']:\n                    review_open = reviews_open.pop(0)\n                    review = review_open\n                else:\n                    review_closed = reviews_closed.pop(0)\n                    review = review_closed\n            elif reviews_closed:\n                review_closed = reviews_closed.pop(0)\n                review = review_closed\n            else:\n                review_open = reviews_open.pop(0)\n                review = review_open\n\n            updated = review['lastUpdated']\n            if updated <= from_ut:\n                logger.debug(\"No more updates for %s\" % (self.hostname))\n                break\n            else:\n                yield review\n\n            if not reviews_open and last_nreviews_open >= self.max_reviews:\n                last_item_open = self.client.next_retrieve_group_item(last_item_open, review_open)\n                reviews_open = self._get_reviews(last_item_open, filter_open)\n                last_nreviews_open = len(reviews_open)\n            if not reviews_closed and last_nreviews_closed >= self.max_reviews:\n                last_item_closed = self.client.next_retrieve_group_item(last_item_closed, review_closed)\n                reviews_closed = self._get_reviews(last_item_closed, filter_closed)\n                last_nreviews_closed = len(reviews_closed)", "language": "python", "code": "def _fetch_gerrit28(self, from_date=DEFAULT_DATETIME):\n        \"\"\" Specific fetch for gerrit 2.8 version.\n\n        Get open and closed reviews in different queries.\n        Take the newer review from both lists and iterate.\n        \"\"\"\n\n        # Convert date to Unix time\n        from_ut = datetime_to_utc(from_date)\n        from_ut = from_ut.timestamp()\n\n        filter_open = \"status:open\"\n        filter_closed = \"status:closed\"\n\n        last_item_open = self.client.next_retrieve_group_item()\n        last_item_closed = self.client.next_retrieve_group_item()\n        reviews_open = self._get_reviews(last_item_open, filter_open)\n        reviews_closed = self._get_reviews(last_item_closed, filter_closed)\n        last_nreviews_open = len(reviews_open)\n        last_nreviews_closed = len(reviews_closed)\n\n        while reviews_open or reviews_closed:\n            if reviews_open and reviews_closed:\n                if reviews_open[0]['lastUpdated'] >= reviews_closed[0]['lastUpdated']:\n                    review_open = reviews_open.pop(0)\n                    review = review_open\n                else:\n                    review_closed = reviews_closed.pop(0)\n                    review = review_closed\n            elif reviews_closed:\n                review_closed = reviews_closed.pop(0)\n                review = review_closed\n            else:\n                review_open = reviews_open.pop(0)\n                review = review_open\n\n            updated = review['lastUpdated']\n            if updated <= from_ut:\n                logger.debug(\"No more updates for %s\" % (self.hostname))\n                break\n            else:\n                yield review\n\n            if not reviews_open and last_nreviews_open >= self.max_reviews:\n                last_item_open = self.client.next_retrieve_group_item(last_item_open, review_open)\n                reviews_open = self._get_reviews(last_item_open, filter_open)\n                last_nreviews_open = len(reviews_open)\n            if not reviews_closed and last_nreviews_closed >= self.max_reviews:\n                last_item_closed = self.client.next_retrieve_group_item(last_item_closed, review_closed)\n                reviews_closed = self._get_reviews(last_item_closed, filter_closed)\n                last_nreviews_closed = len(reviews_closed)", "code_tokens": ["def", "_fetch_gerrit28", "(", "self", ",", "from_date", "=", "DEFAULT_DATETIME", ")", ":", "# Convert date to Unix time", "from_ut", "=", "datetime_to_utc", "(", "from_date", ")", "from_ut", "=", "from_ut", ".", "timestamp", "(", ")", "filter_open", "=", "\"status:open\"", "filter_closed", "=", "\"status:closed\"", "last_item_open", "=", "self", ".", "client", ".", "next_retrieve_group_item", "(", ")", "last_item_closed", "=", "self", ".", "client", ".", "next_retrieve_group_item", "(", ")", "reviews_open", "=", "self", ".", "_get_reviews", "(", "last_item_open", ",", "filter_open", ")", "reviews_closed", "=", "self", ".", "_get_reviews", "(", "last_item_closed", ",", "filter_closed", ")", "last_nreviews_open", "=", "len", "(", "reviews_open", ")", "last_nreviews_closed", "=", "len", "(", "reviews_closed", ")", "while", "reviews_open", "or", "reviews_closed", ":", "if", "reviews_open", "and", "reviews_closed", ":", "if", "reviews_open", "[", "0", "]", "[", "'lastUpdated'", "]", ">=", "reviews_closed", "[", "0", "]", "[", "'lastUpdated'", "]", ":", "review_open", "=", "reviews_open", ".", "pop", "(", "0", ")", "review", "=", "review_open", "else", ":", "review_closed", "=", "reviews_closed", ".", "pop", "(", "0", ")", "review", "=", "review_closed", "elif", "reviews_closed", ":", "review_closed", "=", "reviews_closed", ".", "pop", "(", "0", ")", "review", "=", "review_closed", "else", ":", "review_open", "=", "reviews_open", ".", "pop", "(", "0", ")", "review", "=", "review_open", "updated", "=", "review", "[", "'lastUpdated'", "]", "if", "updated", "<=", "from_ut", ":", "logger", ".", "debug", "(", "\"No more updates for %s\"", "%", "(", "self", ".", "hostname", ")", ")", "break", "else", ":", "yield", "review", "if", "not", "reviews_open", "and", "last_nreviews_open", ">=", "self", ".", "max_reviews", ":", "last_item_open", "=", "self", ".", "client", ".", "next_retrieve_group_item", "(", "last_item_open", ",", "review_open", ")", "reviews_open", "=", "self", ".", "_get_reviews", "(", "last_item_open", ",", "filter_open", ")", "last_nreviews_open", "=", "len", "(", "reviews_open", ")", "if", "not", "reviews_closed", "and", "last_nreviews_closed", ">=", "self", ".", "max_reviews", ":", "last_item_closed", "=", "self", ".", "client", ".", "next_retrieve_group_item", "(", "last_item_closed", ",", "review_closed", ")", "reviews_closed", "=", "self", ".", "_get_reviews", "(", "last_item_closed", ",", "filter_closed", ")", "last_nreviews_closed", "=", "len", "(", "reviews_closed", ")"], "docstring": "Specific fetch for gerrit 2.8 version.\n\n        Get open and closed reviews in different queries.\n        Take the newer review from both lists and iterate.", "docstring_tokens": ["Specific", "fetch", "for", "gerrit", "2", ".", "8", "version", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gerrit.py#L186-L236", "partition": "test", "index": 3222, "time": "2016-05-09 19:01:51"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/jenkins.py", "func_name": "JenkinsClient.get_jobs", "original_string": "def get_jobs(self):\n        \"\"\" Retrieve all jobs\"\"\"\n\n        url_jenkins = urijoin(self.base_url, \"api\", \"json\")\n\n        response = self.fetch(url_jenkins)\n        return response.text", "language": "python", "code": "def get_jobs(self):\n        \"\"\" Retrieve all jobs\"\"\"\n\n        url_jenkins = urijoin(self.base_url, \"api\", \"json\")\n\n        response = self.fetch(url_jenkins)\n        return response.text", "code_tokens": ["def", "get_jobs", "(", "self", ")", ":", "url_jenkins", "=", "urijoin", "(", "self", ".", "base_url", ",", "\"api\"", ",", "\"json\"", ")", "response", "=", "self", ".", "fetch", "(", "url_jenkins", ")", "return", "response", ".", "text"], "docstring": "Retrieve all jobs", "docstring_tokens": ["Retrieve", "all", "jobs"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/jenkins.py#L222-L228", "partition": "test", "index": 3353, "time": "2016-05-10 12:10:06"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/jenkins.py", "func_name": "Jenkins.fetch", "original_string": "def fetch(self, category=CATEGORY_BUILD):\n        \"\"\"Fetch the builds from the url.\n\n        The method retrieves, from a Jenkins url, the\n        builds updated since the given date.\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of builds\n        \"\"\"\n\n        kwargs = {}\n        items = super().fetch(category, **kwargs)\n\n        return items", "language": "python", "code": "def fetch(self, category=CATEGORY_BUILD):\n        \"\"\"Fetch the builds from the url.\n\n        The method retrieves, from a Jenkins url, the\n        builds updated since the given date.\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of builds\n        \"\"\"\n\n        kwargs = {}\n        items = super().fetch(category, **kwargs)\n\n        return items", "code_tokens": ["def", "fetch", "(", "self", ",", "category", "=", "CATEGORY_BUILD", ")", ":", "kwargs", "=", "{", "}", "items", "=", "super", "(", ")", ".", "fetch", "(", "category", ",", "*", "*", "kwargs", ")", "return", "items"], "docstring": "Fetch the builds from the url.\n\n        The method retrieves, from a Jenkins url, the\n        builds updated since the given date.\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of builds", "docstring_tokens": ["Fetch", "the", "builds", "from", "the", "url", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/jenkins.py#L74-L88", "partition": "test", "index": 3352, "time": "2016-05-10 12:10:06"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/jenkins.py", "func_name": "JenkinsClient.get_builds", "original_string": "def get_builds(self, job_name):\n        \"\"\" Retrieve all builds from a job\"\"\"\n\n        if self.blacklist_jobs and job_name in self.blacklist_jobs:\n            logger.warning(\"Not getting blacklisted job: %s\", job_name)\n            return\n\n        payload = {'depth': self.detail_depth}\n        url_build = urijoin(self.base_url, \"job\", job_name, \"api\", \"json\")\n\n        response = self.fetch(url_build, payload=payload)\n        return response.text", "language": "python", "code": "def get_builds(self, job_name):\n        \"\"\" Retrieve all builds from a job\"\"\"\n\n        if self.blacklist_jobs and job_name in self.blacklist_jobs:\n            logger.warning(\"Not getting blacklisted job: %s\", job_name)\n            return\n\n        payload = {'depth': self.detail_depth}\n        url_build = urijoin(self.base_url, \"job\", job_name, \"api\", \"json\")\n\n        response = self.fetch(url_build, payload=payload)\n        return response.text", "code_tokens": ["def", "get_builds", "(", "self", ",", "job_name", ")", ":", "if", "self", ".", "blacklist_jobs", "and", "job_name", "in", "self", ".", "blacklist_jobs", ":", "logger", ".", "warning", "(", "\"Not getting blacklisted job: %s\"", ",", "job_name", ")", "return", "payload", "=", "{", "'depth'", ":", "self", ".", "detail_depth", "}", "url_build", "=", "urijoin", "(", "self", ".", "base_url", ",", "\"job\"", ",", "job_name", ",", "\"api\"", ",", "\"json\"", ")", "response", "=", "self", ".", "fetch", "(", "url_build", ",", "payload", "=", "payload", ")", "return", "response", ".", "text"], "docstring": "Retrieve all builds from a job", "docstring_tokens": ["Retrieve", "all", "builds", "from", "a", "job"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/jenkins.py#L230-L241", "partition": "test", "index": 3354, "time": "2016-05-10 12:10:06"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mediawiki.py", "func_name": "MediaWikiClient.get_recent_pages", "original_string": "def get_recent_pages(self, namespaces, rccontinue=''):\n        \"\"\"Retrieve recent pages from all namespaces starting from rccontinue.\"\"\"\n\n        namespaces.sort()\n        params = {\n            \"action\": \"query\",\n            \"list\": \"recentchanges\",\n            \"rclimit\": self.limit,\n            \"rcnamespace\": \"|\".join(namespaces),\n            \"rcprop\": \"title|timestamp|ids\",\n            \"format\": \"json\"\n        }\n        if rccontinue:\n            params['rccontinue'] = rccontinue\n\n        return self.call(params)", "language": "python", "code": "def get_recent_pages(self, namespaces, rccontinue=''):\n        \"\"\"Retrieve recent pages from all namespaces starting from rccontinue.\"\"\"\n\n        namespaces.sort()\n        params = {\n            \"action\": \"query\",\n            \"list\": \"recentchanges\",\n            \"rclimit\": self.limit,\n            \"rcnamespace\": \"|\".join(namespaces),\n            \"rcprop\": \"title|timestamp|ids\",\n            \"format\": \"json\"\n        }\n        if rccontinue:\n            params['rccontinue'] = rccontinue\n\n        return self.call(params)", "code_tokens": ["def", "get_recent_pages", "(", "self", ",", "namespaces", ",", "rccontinue", "=", "''", ")", ":", "namespaces", ".", "sort", "(", ")", "params", "=", "{", "\"action\"", ":", "\"query\"", ",", "\"list\"", ":", "\"recentchanges\"", ",", "\"rclimit\"", ":", "self", ".", "limit", ",", "\"rcnamespace\"", ":", "\"|\"", ".", "join", "(", "namespaces", ")", ",", "\"rcprop\"", ":", "\"title|timestamp|ids\"", ",", "\"format\"", ":", "\"json\"", "}", "if", "rccontinue", ":", "params", "[", "'rccontinue'", "]", "=", "rccontinue", "return", "self", ".", "call", "(", "params", ")"], "docstring": "Retrieve recent pages from all namespaces starting from rccontinue.", "docstring_tokens": ["Retrieve", "recent", "pages", "from", "all", "namespaces", "starting", "from", "rccontinue", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mediawiki.py#L462-L477", "partition": "test", "index": 3362, "time": "2016-05-26 19:05:44"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mediawiki.py", "func_name": "MediaWikiClient.get_pages", "original_string": "def get_pages(self, namespace, apcontinue=''):\n        \"\"\"Retrieve all pages from a namespace starting from apcontinue.\"\"\"\n        params = {\n            \"action\": \"query\",\n            \"list\": \"allpages\",\n            \"aplimit\": self.limit,\n            \"apnamespace\": namespace,\n            \"format\": \"json\"\n        }\n        if apcontinue:\n            params['apcontinue'] = apcontinue\n\n        return self.call(params)", "language": "python", "code": "def get_pages(self, namespace, apcontinue=''):\n        \"\"\"Retrieve all pages from a namespace starting from apcontinue.\"\"\"\n        params = {\n            \"action\": \"query\",\n            \"list\": \"allpages\",\n            \"aplimit\": self.limit,\n            \"apnamespace\": namespace,\n            \"format\": \"json\"\n        }\n        if apcontinue:\n            params['apcontinue'] = apcontinue\n\n        return self.call(params)", "code_tokens": ["def", "get_pages", "(", "self", ",", "namespace", ",", "apcontinue", "=", "''", ")", ":", "params", "=", "{", "\"action\"", ":", "\"query\"", ",", "\"list\"", ":", "\"allpages\"", ",", "\"aplimit\"", ":", "self", ".", "limit", ",", "\"apnamespace\"", ":", "namespace", ",", "\"format\"", ":", "\"json\"", "}", "if", "apcontinue", ":", "params", "[", "'apcontinue'", "]", "=", "apcontinue", "return", "self", ".", "call", "(", "params", ")"], "docstring": "Retrieve all pages from a namespace starting from apcontinue.", "docstring_tokens": ["Retrieve", "all", "pages", "from", "a", "namespace", "starting", "from", "apcontinue", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mediawiki.py#L448-L460", "partition": "test", "index": 3361, "time": "2016-05-26 19:05:44"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mediawiki.py", "func_name": "MediaWiki.__fetch_1_27", "original_string": "def __fetch_1_27(self, from_date=None):\n        \"\"\"Fetch the pages from the backend url for MediaWiki >=1.27\n\n        The method retrieves, from a MediaWiki url, the\n        wiki pages.\n\n        :returns: a generator of pages\n        \"\"\"\n\n        logger.info(\"Looking for pages at url '%s'\", self.url)\n\n        npages = 0  # number of pages processed\n        tpages = 0  # number of total pages\n        pages_done = []  # pages already retrieved in reviews API\n\n        namespaces_contents = self.__get_namespaces_contents()\n\n        arvcontinue = ''  # pagination for getting revisions and their pages\n        while arvcontinue is not None:\n            raw_pages = self.client.get_pages_from_allrevisions(namespaces_contents, from_date, arvcontinue)\n            data_json = json.loads(raw_pages)\n            arvcontinue = data_json['continue']['arvcontinue'] if 'continue' in data_json else None\n            pages_json = data_json['query']['allrevisions']\n            for page in pages_json:\n\n                if page['pageid'] in pages_done:\n                    logger.debug(\"Page %s already processed; skipped\", page['pageid'])\n                    continue\n\n                tpages += 1\n                pages_done.append(page['pageid'])\n                page_reviews = self.__get_page_reviews(page)\n\n                if not page_reviews:\n                    logger.warning(\"Revisions not found in %s [page id: %s], page skipped\",\n                                   page['title'], page['pageid'])\n                    continue\n\n                yield page_reviews\n                npages += 1\n\n        logger.info(\"Total number of pages: %i, skipped %i\", tpages, tpages - npages)", "language": "python", "code": "def __fetch_1_27(self, from_date=None):\n        \"\"\"Fetch the pages from the backend url for MediaWiki >=1.27\n\n        The method retrieves, from a MediaWiki url, the\n        wiki pages.\n\n        :returns: a generator of pages\n        \"\"\"\n\n        logger.info(\"Looking for pages at url '%s'\", self.url)\n\n        npages = 0  # number of pages processed\n        tpages = 0  # number of total pages\n        pages_done = []  # pages already retrieved in reviews API\n\n        namespaces_contents = self.__get_namespaces_contents()\n\n        arvcontinue = ''  # pagination for getting revisions and their pages\n        while arvcontinue is not None:\n            raw_pages = self.client.get_pages_from_allrevisions(namespaces_contents, from_date, arvcontinue)\n            data_json = json.loads(raw_pages)\n            arvcontinue = data_json['continue']['arvcontinue'] if 'continue' in data_json else None\n            pages_json = data_json['query']['allrevisions']\n            for page in pages_json:\n\n                if page['pageid'] in pages_done:\n                    logger.debug(\"Page %s already processed; skipped\", page['pageid'])\n                    continue\n\n                tpages += 1\n                pages_done.append(page['pageid'])\n                page_reviews = self.__get_page_reviews(page)\n\n                if not page_reviews:\n                    logger.warning(\"Revisions not found in %s [page id: %s], page skipped\",\n                                   page['title'], page['pageid'])\n                    continue\n\n                yield page_reviews\n                npages += 1\n\n        logger.info(\"Total number of pages: %i, skipped %i\", tpages, tpages - npages)", "code_tokens": ["def", "__fetch_1_27", "(", "self", ",", "from_date", "=", "None", ")", ":", "logger", ".", "info", "(", "\"Looking for pages at url '%s'\"", ",", "self", ".", "url", ")", "npages", "=", "0", "# number of pages processed", "tpages", "=", "0", "# number of total pages", "pages_done", "=", "[", "]", "# pages already retrieved in reviews API", "namespaces_contents", "=", "self", ".", "__get_namespaces_contents", "(", ")", "arvcontinue", "=", "''", "# pagination for getting revisions and their pages", "while", "arvcontinue", "is", "not", "None", ":", "raw_pages", "=", "self", ".", "client", ".", "get_pages_from_allrevisions", "(", "namespaces_contents", ",", "from_date", ",", "arvcontinue", ")", "data_json", "=", "json", ".", "loads", "(", "raw_pages", ")", "arvcontinue", "=", "data_json", "[", "'continue'", "]", "[", "'arvcontinue'", "]", "if", "'continue'", "in", "data_json", "else", "None", "pages_json", "=", "data_json", "[", "'query'", "]", "[", "'allrevisions'", "]", "for", "page", "in", "pages_json", ":", "if", "page", "[", "'pageid'", "]", "in", "pages_done", ":", "logger", ".", "debug", "(", "\"Page %s already processed; skipped\"", ",", "page", "[", "'pageid'", "]", ")", "continue", "tpages", "+=", "1", "pages_done", ".", "append", "(", "page", "[", "'pageid'", "]", ")", "page_reviews", "=", "self", ".", "__get_page_reviews", "(", "page", ")", "if", "not", "page_reviews", ":", "logger", ".", "warning", "(", "\"Revisions not found in %s [page id: %s], page skipped\"", ",", "page", "[", "'title'", "]", ",", "page", "[", "'pageid'", "]", ")", "continue", "yield", "page_reviews", "npages", "+=", "1", "logger", ".", "info", "(", "\"Total number of pages: %i, skipped %i\"", ",", "tpages", ",", "tpages", "-", "npages", ")"], "docstring": "Fetch the pages from the backend url for MediaWiki >=1.27\n\n        The method retrieves, from a MediaWiki url, the\n        wiki pages.\n\n        :returns: a generator of pages", "docstring_tokens": ["Fetch", "the", "pages", "from", "the", "backend", "url", "for", "MediaWiki", ">", "=", "1", ".", "27"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mediawiki.py#L202-L243", "partition": "test", "index": 3360, "time": "2016-05-26 19:05:44"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mediawiki.py", "func_name": "MediaWiki.__get_max_date", "original_string": "def __get_max_date(self, reviews):\n        \"\"\"\"Get the max date in unixtime format from reviews.\"\"\"\n        max_ts = 0\n        for review in reviews:\n            ts = str_to_datetime(review['timestamp'])\n            ts = datetime_to_utc(ts)\n            if ts.timestamp() > max_ts:\n                max_ts = ts.timestamp()\n        return max_ts", "language": "python", "code": "def __get_max_date(self, reviews):\n        \"\"\"\"Get the max date in unixtime format from reviews.\"\"\"\n        max_ts = 0\n        for review in reviews:\n            ts = str_to_datetime(review['timestamp'])\n            ts = datetime_to_utc(ts)\n            if ts.timestamp() > max_ts:\n                max_ts = ts.timestamp()\n        return max_ts", "code_tokens": ["def", "__get_max_date", "(", "self", ",", "reviews", ")", ":", "max_ts", "=", "0", "for", "review", "in", "reviews", ":", "ts", "=", "str_to_datetime", "(", "review", "[", "'timestamp'", "]", ")", "ts", "=", "datetime_to_utc", "(", "ts", ")", "if", "ts", ".", "timestamp", "(", ")", ">", "max_ts", ":", "max_ts", "=", "ts", ".", "timestamp", "(", ")", "return", "max_ts"], "docstring": "Get the max date in unixtime format from reviews.", "docstring_tokens": ["Get", "the", "max", "date", "in", "unixtime", "format", "from", "reviews", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mediawiki.py#L183-L191", "partition": "test", "index": 3359, "time": "2016-05-26 19:05:44"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mediawiki.py", "func_name": "MediaWiki.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the pages\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        from_date = kwargs['from_date']\n        reviews_api = kwargs['reviews_api']\n\n        mediawiki_version = self.client.get_version()\n        logger.info(\"MediaWiki version: %s\", mediawiki_version)\n\n        if reviews_api:\n            if ((mediawiki_version[0] == 1 and mediawiki_version[1] >= 27) or mediawiki_version[0] > 1):\n                fetcher = self.__fetch_1_27(from_date)\n            else:\n                logger.warning(\"Reviews API only available in MediaWiki >= 1.27\")\n                logger.warning(\"Using the Pages API instead\")\n                fetcher = self.__fetch_pre1_27(from_date)\n        else:\n            fetcher = self.__fetch_pre1_27(from_date)\n\n        for page_reviews in fetcher:\n            yield page_reviews", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the pages\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        from_date = kwargs['from_date']\n        reviews_api = kwargs['reviews_api']\n\n        mediawiki_version = self.client.get_version()\n        logger.info(\"MediaWiki version: %s\", mediawiki_version)\n\n        if reviews_api:\n            if ((mediawiki_version[0] == 1 and mediawiki_version[1] >= 27) or mediawiki_version[0] > 1):\n                fetcher = self.__fetch_1_27(from_date)\n            else:\n                logger.warning(\"Reviews API only available in MediaWiki >= 1.27\")\n                logger.warning(\"Using the Pages API instead\")\n                fetcher = self.__fetch_pre1_27(from_date)\n        else:\n            fetcher = self.__fetch_pre1_27(from_date)\n\n        for page_reviews in fetcher:\n            yield page_reviews", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "from_date", "=", "kwargs", "[", "'from_date'", "]", "reviews_api", "=", "kwargs", "[", "'reviews_api'", "]", "mediawiki_version", "=", "self", ".", "client", ".", "get_version", "(", ")", "logger", ".", "info", "(", "\"MediaWiki version: %s\"", ",", "mediawiki_version", ")", "if", "reviews_api", ":", "if", "(", "(", "mediawiki_version", "[", "0", "]", "==", "1", "and", "mediawiki_version", "[", "1", "]", ">=", "27", ")", "or", "mediawiki_version", "[", "0", "]", ">", "1", ")", ":", "fetcher", "=", "self", ".", "__fetch_1_27", "(", "from_date", ")", "else", ":", "logger", ".", "warning", "(", "\"Reviews API only available in MediaWiki >= 1.27\"", ")", "logger", ".", "warning", "(", "\"Using the Pages API instead\"", ")", "fetcher", "=", "self", ".", "__fetch_pre1_27", "(", "from_date", ")", "else", ":", "fetcher", "=", "self", ".", "__fetch_pre1_27", "(", "from_date", ")", "for", "page_reviews", "in", "fetcher", ":", "yield", "page_reviews"], "docstring": "Fetch the pages\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "the", "pages"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mediawiki.py#L107-L132", "partition": "test", "index": 3358, "time": "2016-05-26 19:05:44"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/discourse.py", "func_name": "DiscourseClient.post", "original_string": "def post(self, post_id):\n        \"\"\"Retrieve the post whit `post_id` identifier.\n\n        :param post_id: identifier of the post to retrieve\n        \"\"\"\n        params = {\n            self.PKEY: self.api_key\n        }\n\n        # http://example.com/posts/10.json\n        response = self._call(self.POSTS, post_id,\n                              params=params)\n\n        return response", "language": "python", "code": "def post(self, post_id):\n        \"\"\"Retrieve the post whit `post_id` identifier.\n\n        :param post_id: identifier of the post to retrieve\n        \"\"\"\n        params = {\n            self.PKEY: self.api_key\n        }\n\n        # http://example.com/posts/10.json\n        response = self._call(self.POSTS, post_id,\n                              params=params)\n\n        return response", "code_tokens": ["def", "post", "(", "self", ",", "post_id", ")", ":", "params", "=", "{", "self", ".", "PKEY", ":", "self", ".", "api_key", "}", "# http://example.com/posts/10.json", "response", "=", "self", ".", "_call", "(", "self", ".", "POSTS", ",", "post_id", ",", "params", "=", "params", ")", "return", "response"], "docstring": "Retrieve the post whit `post_id` identifier.\n\n        :param post_id: identifier of the post to retrieve", "docstring_tokens": ["Retrieve", "the", "post", "whit", "post_id", "identifier", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/discourse.py#L345-L358", "partition": "test", "index": 3387, "time": "2016-06-02 13:02:18"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/discourse.py", "func_name": "Discourse.__parse_topics_page", "original_string": "def __parse_topics_page(self, raw_json):\n        \"\"\"Parse a topics page stream.\n\n        The result of parsing process is a generator of tuples. Each\n        tuple contains de identifier of the topic, the last date\n        when it was updated and whether is pinned or not.\n\n        :param raw_json: JSON stream to parse\n\n        :returns: a generator of parsed bugs\n        \"\"\"\n        topics_page = json.loads(raw_json)\n\n        topics_ids = []\n\n        for topic in topics_page['topic_list']['topics']:\n            topic_id = topic['id']\n            if topic['last_posted_at'] is None:\n                logger.warning(\"Topic %s with last_posted_at null. Ignoring it.\", topic['title'])\n                continue\n            updated_at = str_to_datetime(topic['last_posted_at'])\n            pinned = topic['pinned']\n            topics_ids.append((topic_id, updated_at, pinned))\n\n        return topics_ids", "language": "python", "code": "def __parse_topics_page(self, raw_json):\n        \"\"\"Parse a topics page stream.\n\n        The result of parsing process is a generator of tuples. Each\n        tuple contains de identifier of the topic, the last date\n        when it was updated and whether is pinned or not.\n\n        :param raw_json: JSON stream to parse\n\n        :returns: a generator of parsed bugs\n        \"\"\"\n        topics_page = json.loads(raw_json)\n\n        topics_ids = []\n\n        for topic in topics_page['topic_list']['topics']:\n            topic_id = topic['id']\n            if topic['last_posted_at'] is None:\n                logger.warning(\"Topic %s with last_posted_at null. Ignoring it.\", topic['title'])\n                continue\n            updated_at = str_to_datetime(topic['last_posted_at'])\n            pinned = topic['pinned']\n            topics_ids.append((topic_id, updated_at, pinned))\n\n        return topics_ids", "code_tokens": ["def", "__parse_topics_page", "(", "self", ",", "raw_json", ")", ":", "topics_page", "=", "json", ".", "loads", "(", "raw_json", ")", "topics_ids", "=", "[", "]", "for", "topic", "in", "topics_page", "[", "'topic_list'", "]", "[", "'topics'", "]", ":", "topic_id", "=", "topic", "[", "'id'", "]", "if", "topic", "[", "'last_posted_at'", "]", "is", "None", ":", "logger", ".", "warning", "(", "\"Topic %s with last_posted_at null. Ignoring it.\"", ",", "topic", "[", "'title'", "]", ")", "continue", "updated_at", "=", "str_to_datetime", "(", "topic", "[", "'last_posted_at'", "]", ")", "pinned", "=", "topic", "[", "'pinned'", "]", "topics_ids", ".", "append", "(", "(", "topic_id", ",", "updated_at", ",", "pinned", ")", ")", "return", "topics_ids"], "docstring": "Parse a topics page stream.\n\n        The result of parsing process is a generator of tuples. Each\n        tuple contains de identifier of the topic, the last date\n        when it was updated and whether is pinned or not.\n\n        :param raw_json: JSON stream to parse\n\n        :returns: a generator of parsed bugs", "docstring_tokens": ["Parse", "a", "topics", "page", "stream", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/discourse.py#L248-L272", "partition": "test", "index": 3385, "time": "2016-06-03 18:22:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/bugzillarest.py", "func_name": "BugzillaRESTClient.bugs", "original_string": "def bugs(self, from_date=DEFAULT_DATETIME, offset=None, max_bugs=MAX_BUGS):\n        \"\"\"Get the information of a list of bugs.\n\n        :param from_date: retrieve bugs that where updated from that date;\n            dates are converted to UTC\n        :param offset: starting position for the search; i.e to return 11th\n            element, set this value to 10.\n        :param max_bugs: maximum number of bugs to reteurn per query\n        \"\"\"\n        date = datetime_to_utc(from_date)\n        date = date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n\n        params = {\n            self.PLAST_CHANGE_TIME: date,\n            self.PLIMIT: max_bugs,\n            self.PORDER: self.VCHANGE_DATE_ORDER,\n            self.PINCLUDE_FIELDS: self.VINCLUDE_ALL\n        }\n\n        if offset:\n            params[self.POFFSET] = offset\n\n        response = self.call(self.RBUG, params)\n\n        return response", "language": "python", "code": "def bugs(self, from_date=DEFAULT_DATETIME, offset=None, max_bugs=MAX_BUGS):\n        \"\"\"Get the information of a list of bugs.\n\n        :param from_date: retrieve bugs that where updated from that date;\n            dates are converted to UTC\n        :param offset: starting position for the search; i.e to return 11th\n            element, set this value to 10.\n        :param max_bugs: maximum number of bugs to reteurn per query\n        \"\"\"\n        date = datetime_to_utc(from_date)\n        date = date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n\n        params = {\n            self.PLAST_CHANGE_TIME: date,\n            self.PLIMIT: max_bugs,\n            self.PORDER: self.VCHANGE_DATE_ORDER,\n            self.PINCLUDE_FIELDS: self.VINCLUDE_ALL\n        }\n\n        if offset:\n            params[self.POFFSET] = offset\n\n        response = self.call(self.RBUG, params)\n\n        return response", "code_tokens": ["def", "bugs", "(", "self", ",", "from_date", "=", "DEFAULT_DATETIME", ",", "offset", "=", "None", ",", "max_bugs", "=", "MAX_BUGS", ")", ":", "date", "=", "datetime_to_utc", "(", "from_date", ")", "date", "=", "date", ".", "strftime", "(", "\"%Y-%m-%dT%H:%M:%SZ\"", ")", "params", "=", "{", "self", ".", "PLAST_CHANGE_TIME", ":", "date", ",", "self", ".", "PLIMIT", ":", "max_bugs", ",", "self", ".", "PORDER", ":", "self", ".", "VCHANGE_DATE_ORDER", ",", "self", ".", "PINCLUDE_FIELDS", ":", "self", ".", "VINCLUDE_ALL", "}", "if", "offset", ":", "params", "[", "self", ".", "POFFSET", "]", "=", "offset", "response", "=", "self", ".", "call", "(", "self", ".", "RBUG", ",", "params", ")", "return", "response"], "docstring": "Get the information of a list of bugs.\n\n        :param from_date: retrieve bugs that where updated from that date;\n            dates are converted to UTC\n        :param offset: starting position for the search; i.e to return 11th\n            element, set this value to 10.\n        :param max_bugs: maximum number of bugs to reteurn per query", "docstring_tokens": ["Get", "the", "information", "of", "a", "list", "of", "bugs", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/bugzillarest.py#L326-L350", "partition": "test", "index": 3171, "time": "2016-06-07 18:14:04"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/bugzillarest.py", "func_name": "BugzillaRESTClient.comments", "original_string": "def comments(self, *bug_ids):\n        \"\"\"Get the comments of the given bugs.\n\n        :param bug_ids: list of bug identifiers\n        \"\"\"\n        # Hack. The first value must be a valid bug id\n        resource = urijoin(self.RBUG, bug_ids[0], self.RCOMMENT)\n\n        params = {\n            self.PIDS: bug_ids\n        }\n\n        response = self.call(resource, params)\n\n        return response", "language": "python", "code": "def comments(self, *bug_ids):\n        \"\"\"Get the comments of the given bugs.\n\n        :param bug_ids: list of bug identifiers\n        \"\"\"\n        # Hack. The first value must be a valid bug id\n        resource = urijoin(self.RBUG, bug_ids[0], self.RCOMMENT)\n\n        params = {\n            self.PIDS: bug_ids\n        }\n\n        response = self.call(resource, params)\n\n        return response", "code_tokens": ["def", "comments", "(", "self", ",", "*", "bug_ids", ")", ":", "# Hack. The first value must be a valid bug id", "resource", "=", "urijoin", "(", "self", ".", "RBUG", ",", "bug_ids", "[", "0", "]", ",", "self", ".", "RCOMMENT", ")", "params", "=", "{", "self", ".", "PIDS", ":", "bug_ids", "}", "response", "=", "self", ".", "call", "(", "resource", ",", "params", ")", "return", "response"], "docstring": "Get the comments of the given bugs.\n\n        :param bug_ids: list of bug identifiers", "docstring_tokens": ["Get", "the", "comments", "of", "the", "given", "bugs", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/bugzillarest.py#L352-L366", "partition": "test", "index": 3172, "time": "2016-06-07 18:14:04"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/bugzillarest.py", "func_name": "BugzillaRESTClient.history", "original_string": "def history(self, *bug_ids):\n        \"\"\"Get the history of the given bugs.\n\n        :param bug_ids: list of bug identifiers\n        \"\"\"\n        resource = urijoin(self.RBUG, bug_ids[0], self.RHISTORY)\n\n        params = {\n            self.PIDS: bug_ids\n        }\n\n        response = self.call(resource, params)\n\n        return response", "language": "python", "code": "def history(self, *bug_ids):\n        \"\"\"Get the history of the given bugs.\n\n        :param bug_ids: list of bug identifiers\n        \"\"\"\n        resource = urijoin(self.RBUG, bug_ids[0], self.RHISTORY)\n\n        params = {\n            self.PIDS: bug_ids\n        }\n\n        response = self.call(resource, params)\n\n        return response", "code_tokens": ["def", "history", "(", "self", ",", "*", "bug_ids", ")", ":", "resource", "=", "urijoin", "(", "self", ".", "RBUG", ",", "bug_ids", "[", "0", "]", ",", "self", ".", "RHISTORY", ")", "params", "=", "{", "self", ".", "PIDS", ":", "bug_ids", "}", "response", "=", "self", ".", "call", "(", "resource", ",", "params", ")", "return", "response"], "docstring": "Get the history of the given bugs.\n\n        :param bug_ids: list of bug identifiers", "docstring_tokens": ["Get", "the", "history", "of", "the", "given", "bugs", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/bugzillarest.py#L368-L381", "partition": "test", "index": 3173, "time": "2016-06-07 18:14:04"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/bugzillarest.py", "func_name": "BugzillaRESTClient.attachments", "original_string": "def attachments(self, *bug_ids):\n        \"\"\"Get the attachments of the given bugs.\n\n        :param bug_id: list of bug identifiers\n        \"\"\"\n        resource = urijoin(self.RBUG, bug_ids[0], self.RATTACHMENT)\n\n        params = {\n            self.PIDS: bug_ids,\n            self.PEXCLUDE_FIELDS: self.VEXCLUDE_ATTCH_DATA\n        }\n\n        response = self.call(resource, params)\n\n        return response", "language": "python", "code": "def attachments(self, *bug_ids):\n        \"\"\"Get the attachments of the given bugs.\n\n        :param bug_id: list of bug identifiers\n        \"\"\"\n        resource = urijoin(self.RBUG, bug_ids[0], self.RATTACHMENT)\n\n        params = {\n            self.PIDS: bug_ids,\n            self.PEXCLUDE_FIELDS: self.VEXCLUDE_ATTCH_DATA\n        }\n\n        response = self.call(resource, params)\n\n        return response", "code_tokens": ["def", "attachments", "(", "self", ",", "*", "bug_ids", ")", ":", "resource", "=", "urijoin", "(", "self", ".", "RBUG", ",", "bug_ids", "[", "0", "]", ",", "self", ".", "RATTACHMENT", ")", "params", "=", "{", "self", ".", "PIDS", ":", "bug_ids", ",", "self", ".", "PEXCLUDE_FIELDS", ":", "self", ".", "VEXCLUDE_ATTCH_DATA", "}", "response", "=", "self", ".", "call", "(", "resource", ",", "params", ")", "return", "response"], "docstring": "Get the attachments of the given bugs.\n\n        :param bug_id: list of bug identifiers", "docstring_tokens": ["Get", "the", "attachments", "of", "the", "given", "bugs", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/bugzillarest.py#L383-L397", "partition": "test", "index": 3174, "time": "2016-06-07 18:14:04"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/bugzillarest.py", "func_name": "BugzillaREST.fetch", "original_string": "def fetch(self, category=CATEGORY_BUG, from_date=DEFAULT_DATETIME):\n        \"\"\"Fetch the bugs from the repository.\n\n        The method retrieves, from a Bugzilla repository, the bugs\n        updated since the given date.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain bugs updated since this date\n\n        :returns: a generator of bugs\n        \"\"\"\n        if not from_date:\n            from_date = DEFAULT_DATETIME\n\n        kwargs = {'from_date': from_date}\n        items = super().fetch(category, **kwargs)\n\n        return items", "language": "python", "code": "def fetch(self, category=CATEGORY_BUG, from_date=DEFAULT_DATETIME):\n        \"\"\"Fetch the bugs from the repository.\n\n        The method retrieves, from a Bugzilla repository, the bugs\n        updated since the given date.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain bugs updated since this date\n\n        :returns: a generator of bugs\n        \"\"\"\n        if not from_date:\n            from_date = DEFAULT_DATETIME\n\n        kwargs = {'from_date': from_date}\n        items = super().fetch(category, **kwargs)\n\n        return items", "code_tokens": ["def", "fetch", "(", "self", ",", "category", "=", "CATEGORY_BUG", ",", "from_date", "=", "DEFAULT_DATETIME", ")", ":", "if", "not", "from_date", ":", "from_date", "=", "DEFAULT_DATETIME", "kwargs", "=", "{", "'from_date'", ":", "from_date", "}", "items", "=", "super", "(", ")", ".", "fetch", "(", "category", ",", "*", "*", "kwargs", ")", "return", "items"], "docstring": "Fetch the bugs from the repository.\n\n        The method retrieves, from a Bugzilla repository, the bugs\n        updated since the given date.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain bugs updated since this date\n\n        :returns: a generator of bugs", "docstring_tokens": ["Fetch", "the", "bugs", "from", "the", "repository", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/bugzillarest.py#L79-L96", "partition": "test", "index": 3170, "time": "2016-06-08 13:47:29"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/supybot.py", "func_name": "SupybotParser._parse_supybot_msg", "original_string": "def _parse_supybot_msg(self, line):\n        \"\"\"Parse message section\"\"\"\n\n        patterns = [(self.SUPYBOT_COMMENT_REGEX, self.TCOMMENT),\n                    (self.SUPYBOT_COMMENT_ACTION_REGEX, self.TCOMMENT),\n                    (self.SUPYBOT_SERVER_REGEX, self.TSERVER),\n                    (self.SUPYBOT_BOT_REGEX, self.TCOMMENT)]\n\n        for p in patterns:\n            m = p[0].match(line)\n            if not m:\n                continue\n            return p[1], m.group('nick'), m.group('body').strip()\n\n        msg = \"invalid message on line %s\" % (str(self.nline))\n        raise ParseError(cause=msg)", "language": "python", "code": "def _parse_supybot_msg(self, line):\n        \"\"\"Parse message section\"\"\"\n\n        patterns = [(self.SUPYBOT_COMMENT_REGEX, self.TCOMMENT),\n                    (self.SUPYBOT_COMMENT_ACTION_REGEX, self.TCOMMENT),\n                    (self.SUPYBOT_SERVER_REGEX, self.TSERVER),\n                    (self.SUPYBOT_BOT_REGEX, self.TCOMMENT)]\n\n        for p in patterns:\n            m = p[0].match(line)\n            if not m:\n                continue\n            return p[1], m.group('nick'), m.group('body').strip()\n\n        msg = \"invalid message on line %s\" % (str(self.nline))\n        raise ParseError(cause=msg)", "code_tokens": ["def", "_parse_supybot_msg", "(", "self", ",", "line", ")", ":", "patterns", "=", "[", "(", "self", ".", "SUPYBOT_COMMENT_REGEX", ",", "self", ".", "TCOMMENT", ")", ",", "(", "self", ".", "SUPYBOT_COMMENT_ACTION_REGEX", ",", "self", ".", "TCOMMENT", ")", ",", "(", "self", ".", "SUPYBOT_SERVER_REGEX", ",", "self", ".", "TSERVER", ")", ",", "(", "self", ".", "SUPYBOT_BOT_REGEX", ",", "self", ".", "TCOMMENT", ")", "]", "for", "p", "in", "patterns", ":", "m", "=", "p", "[", "0", "]", ".", "match", "(", "line", ")", "if", "not", "m", ":", "continue", "return", "p", "[", "1", "]", ",", "m", ".", "group", "(", "'nick'", ")", ",", "m", ".", "group", "(", "'body'", ")", ".", "strip", "(", ")", "msg", "=", "\"invalid message on line %s\"", "%", "(", "str", "(", "self", ".", "nline", ")", ")", "raise", "ParseError", "(", "cause", "=", "msg", ")"], "docstring": "Parse message section", "docstring_tokens": ["Parse", "message", "section"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/supybot.py#L391-L406", "partition": "test", "index": 3383, "time": "2016-06-28 18:35:58"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/supybot.py", "func_name": "SupybotParser.parse", "original_string": "def parse(self):\n        \"\"\"Parse a Supybot IRC stream.\n\n        Returns an iterator of dicts. Each dicts contains information\n        about the date, type, nick and body of a single log entry.\n\n        :returns: iterator of parsed lines\n\n        :raises ParseError: when an invalid line is found parsing the given\n            stream\n        \"\"\"\n        for line in self.stream:\n            line = line.rstrip('\\n')\n            self.nline += 1\n\n            if self.SUPYBOT_EMPTY_REGEX.match(line):\n                continue\n\n            ts, msg = self._parse_supybot_timestamp(line)\n\n            if self.SUPYBOT_EMPTY_COMMENT_REGEX.match(msg):\n                continue\n            elif self.SUPYBOT_EMPTY_COMMENT_ACTION_REGEX.match(msg):\n                continue\n            elif self.SUPYBOT_EMPTY_BOT_REGEX.match(msg):\n                continue\n\n            itype, nick, body = self._parse_supybot_msg(msg)\n            item = self._build_item(ts, itype, nick, body)\n\n            yield item", "language": "python", "code": "def parse(self):\n        \"\"\"Parse a Supybot IRC stream.\n\n        Returns an iterator of dicts. Each dicts contains information\n        about the date, type, nick and body of a single log entry.\n\n        :returns: iterator of parsed lines\n\n        :raises ParseError: when an invalid line is found parsing the given\n            stream\n        \"\"\"\n        for line in self.stream:\n            line = line.rstrip('\\n')\n            self.nline += 1\n\n            if self.SUPYBOT_EMPTY_REGEX.match(line):\n                continue\n\n            ts, msg = self._parse_supybot_timestamp(line)\n\n            if self.SUPYBOT_EMPTY_COMMENT_REGEX.match(msg):\n                continue\n            elif self.SUPYBOT_EMPTY_COMMENT_ACTION_REGEX.match(msg):\n                continue\n            elif self.SUPYBOT_EMPTY_BOT_REGEX.match(msg):\n                continue\n\n            itype, nick, body = self._parse_supybot_msg(msg)\n            item = self._build_item(ts, itype, nick, body)\n\n            yield item", "code_tokens": ["def", "parse", "(", "self", ")", ":", "for", "line", "in", "self", ".", "stream", ":", "line", "=", "line", ".", "rstrip", "(", "'\\n'", ")", "self", ".", "nline", "+=", "1", "if", "self", ".", "SUPYBOT_EMPTY_REGEX", ".", "match", "(", "line", ")", ":", "continue", "ts", ",", "msg", "=", "self", ".", "_parse_supybot_timestamp", "(", "line", ")", "if", "self", ".", "SUPYBOT_EMPTY_COMMENT_REGEX", ".", "match", "(", "msg", ")", ":", "continue", "elif", "self", ".", "SUPYBOT_EMPTY_COMMENT_ACTION_REGEX", ".", "match", "(", "msg", ")", ":", "continue", "elif", "self", ".", "SUPYBOT_EMPTY_BOT_REGEX", ".", "match", "(", "msg", ")", ":", "continue", "itype", ",", "nick", ",", "body", "=", "self", ".", "_parse_supybot_msg", "(", "msg", ")", "item", "=", "self", ".", "_build_item", "(", "ts", ",", "itype", ",", "nick", ",", "body", ")", "yield", "item"], "docstring": "Parse a Supybot IRC stream.\n\n        Returns an iterator of dicts. Each dicts contains information\n        about the date, type, nick and body of a single log entry.\n\n        :returns: iterator of parsed lines\n\n        :raises ParseError: when an invalid line is found parsing the given\n            stream", "docstring_tokens": ["Parse", "a", "Supybot", "IRC", "stream", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/supybot.py#L345-L375", "partition": "test", "index": 3381, "time": "2016-06-28 18:35:58"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/supybot.py", "func_name": "SupybotParser._parse_supybot_timestamp", "original_string": "def _parse_supybot_timestamp(self, line):\n        \"\"\"Parse timestamp section\"\"\"\n\n        m = self.SUPYBOT_TIMESTAMP_REGEX.match(line)\n\n        if not m:\n            msg = \"date expected on line %s\" % (str(self.nline))\n            raise ParseError(cause=msg)\n\n        ts = m.group('ts')\n        msg = m.group('msg')\n\n        return ts, msg", "language": "python", "code": "def _parse_supybot_timestamp(self, line):\n        \"\"\"Parse timestamp section\"\"\"\n\n        m = self.SUPYBOT_TIMESTAMP_REGEX.match(line)\n\n        if not m:\n            msg = \"date expected on line %s\" % (str(self.nline))\n            raise ParseError(cause=msg)\n\n        ts = m.group('ts')\n        msg = m.group('msg')\n\n        return ts, msg", "code_tokens": ["def", "_parse_supybot_timestamp", "(", "self", ",", "line", ")", ":", "m", "=", "self", ".", "SUPYBOT_TIMESTAMP_REGEX", ".", "match", "(", "line", ")", "if", "not", "m", ":", "msg", "=", "\"date expected on line %s\"", "%", "(", "str", "(", "self", ".", "nline", ")", ")", "raise", "ParseError", "(", "cause", "=", "msg", ")", "ts", "=", "m", ".", "group", "(", "'ts'", ")", "msg", "=", "m", ".", "group", "(", "'msg'", ")", "return", "ts", ",", "msg"], "docstring": "Parse timestamp section", "docstring_tokens": ["Parse", "timestamp", "section"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/supybot.py#L377-L389", "partition": "test", "index": 3382, "time": "2016-06-28 18:35:58"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/supybot.py", "func_name": "Supybot.parse_supybot_log", "original_string": "def parse_supybot_log(filepath):\n        \"\"\"Parse a Supybot IRC log file.\n\n        The method parses the Supybot IRC log file and returns an iterator of\n        dictionaries. Each one of this, contains a message from the file.\n\n        :param filepath: path to the IRC log file\n\n        :returns: a generator of parsed messages\n\n        :raises ParseError: raised when the format of the Supybot log file\n            is invalid\n        :raises OSError: raised when an error occurs reading the\n            given file\n        \"\"\"\n        with open(filepath, 'r', errors='surrogateescape',\n                  newline=os.linesep) as f:\n            parser = SupybotParser(f)\n\n            try:\n                for message in parser.parse():\n                    yield message\n            except ParseError as e:\n                cause = \"file: %s; reason: %s\" % (filepath, str(e))\n                raise ParseError(cause=cause)", "language": "python", "code": "def parse_supybot_log(filepath):\n        \"\"\"Parse a Supybot IRC log file.\n\n        The method parses the Supybot IRC log file and returns an iterator of\n        dictionaries. Each one of this, contains a message from the file.\n\n        :param filepath: path to the IRC log file\n\n        :returns: a generator of parsed messages\n\n        :raises ParseError: raised when the format of the Supybot log file\n            is invalid\n        :raises OSError: raised when an error occurs reading the\n            given file\n        \"\"\"\n        with open(filepath, 'r', errors='surrogateescape',\n                  newline=os.linesep) as f:\n            parser = SupybotParser(f)\n\n            try:\n                for message in parser.parse():\n                    yield message\n            except ParseError as e:\n                cause = \"file: %s; reason: %s\" % (filepath, str(e))\n                raise ParseError(cause=cause)", "code_tokens": ["def", "parse_supybot_log", "(", "filepath", ")", ":", "with", "open", "(", "filepath", ",", "'r'", ",", "errors", "=", "'surrogateescape'", ",", "newline", "=", "os", ".", "linesep", ")", "as", "f", ":", "parser", "=", "SupybotParser", "(", "f", ")", "try", ":", "for", "message", "in", "parser", ".", "parse", "(", ")", ":", "yield", "message", "except", "ParseError", "as", "e", ":", "cause", "=", "\"file: %s; reason: %s\"", "%", "(", "filepath", ",", "str", "(", "e", ")", ")", "raise", "ParseError", "(", "cause", "=", "cause", ")"], "docstring": "Parse a Supybot IRC log file.\n\n        The method parses the Supybot IRC log file and returns an iterator of\n        dictionaries. Each one of this, contains a message from the file.\n\n        :param filepath: path to the IRC log file\n\n        :returns: a generator of parsed messages\n\n        :raises ParseError: raised when the format of the Supybot log file\n            is invalid\n        :raises OSError: raised when an error occurs reading the\n            given file", "docstring_tokens": ["Parse", "a", "Supybot", "IRC", "log", "file", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/supybot.py#L184-L208", "partition": "test", "index": 3378, "time": "2016-06-29 17:55:57"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/telegram.py", "func_name": "TelegramBotClient.updates", "original_string": "def updates(self, offset=None):\n        \"\"\"Fetch the messages that a bot can read.\n\n        When the `offset` is given it will retrieve all the messages\n        that are greater or equal to that offset. Take into account\n        that, due to how the API works, all previous messages will\n        be removed from the server.\n\n        :param offset: fetch the messages starting on this offset\n        \"\"\"\n        params = {}\n\n        if offset:\n            params[self.OFFSET] = offset\n\n        response = self._call(self.UPDATES_METHOD, params)\n\n        return response", "language": "python", "code": "def updates(self, offset=None):\n        \"\"\"Fetch the messages that a bot can read.\n\n        When the `offset` is given it will retrieve all the messages\n        that are greater or equal to that offset. Take into account\n        that, due to how the API works, all previous messages will\n        be removed from the server.\n\n        :param offset: fetch the messages starting on this offset\n        \"\"\"\n        params = {}\n\n        if offset:\n            params[self.OFFSET] = offset\n\n        response = self._call(self.UPDATES_METHOD, params)\n\n        return response", "code_tokens": ["def", "updates", "(", "self", ",", "offset", "=", "None", ")", ":", "params", "=", "{", "}", "if", "offset", ":", "params", "[", "self", ".", "OFFSET", "]", "=", "offset", "response", "=", "self", ".", "_call", "(", "self", ".", "UPDATES_METHOD", ",", "params", ")", "return", "response"], "docstring": "Fetch the messages that a bot can read.\n\n        When the `offset` is given it will retrieve all the messages\n        that are greater or equal to that offset. Take into account\n        that, due to how the API works, all previous messages will\n        be removed from the server.\n\n        :param offset: fetch the messages starting on this offset", "docstring_tokens": ["Fetch", "the", "messages", "that", "a", "bot", "can", "read", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/telegram.py#L312-L329", "partition": "test", "index": 3366, "time": "2016-07-01 17:48:15"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/telegram.py", "func_name": "Telegram.parse_messages", "original_string": "def parse_messages(raw_json):\n        \"\"\"Parse a Telegram JSON messages list.\n\n        The method parses the JSON stream and returns an iterator of\n        dictionaries. Each one of this, contains a Telegram message.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed messages\n        \"\"\"\n        result = json.loads(raw_json)\n\n        messages = result['result']\n        for msg in messages:\n            yield msg", "language": "python", "code": "def parse_messages(raw_json):\n        \"\"\"Parse a Telegram JSON messages list.\n\n        The method parses the JSON stream and returns an iterator of\n        dictionaries. Each one of this, contains a Telegram message.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed messages\n        \"\"\"\n        result = json.loads(raw_json)\n\n        messages = result['result']\n        for msg in messages:\n            yield msg", "code_tokens": ["def", "parse_messages", "(", "raw_json", ")", ":", "result", "=", "json", ".", "loads", "(", "raw_json", ")", "messages", "=", "result", "[", "'result'", "]", "for", "msg", "in", "messages", ":", "yield", "msg"], "docstring": "Parse a Telegram JSON messages list.\n\n        The method parses the JSON stream and returns an iterator of\n        dictionaries. Each one of this, contains a Telegram message.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed messages", "docstring_tokens": ["Parse", "a", "Telegram", "JSON", "messages", "list", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/telegram.py#L216-L230", "partition": "test", "index": 3364, "time": "2016-07-04 13:05:07"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/telegram.py", "func_name": "Telegram.fetch", "original_string": "def fetch(self, category=CATEGORY_MESSAGE, offset=DEFAULT_OFFSET, chats=None):\n        \"\"\"Fetch the messages the bot can read from the server.\n\n        The method retrieves, from the Telegram server, the messages\n        sent with an offset equal or greater than the given.\n\n        A list of chats, groups and channels identifiers can be set\n        using the parameter `chats`. When it is set, only those\n        messages sent to any of these will be returned. An empty list\n        will return no messages.\n\n        :param category: the category of items to fetch\n        :param offset: obtain messages from this offset\n        :param chats: list of chat names used to filter messages\n\n        :returns: a generator of messages\n\n        :raises ValueError: when `chats` is an empty list\n        \"\"\"\n        if not offset:\n            offset = DEFAULT_OFFSET\n\n        kwargs = {\"offset\": offset, \"chats\": chats}\n        items = super().fetch(category, **kwargs)\n\n        return items", "language": "python", "code": "def fetch(self, category=CATEGORY_MESSAGE, offset=DEFAULT_OFFSET, chats=None):\n        \"\"\"Fetch the messages the bot can read from the server.\n\n        The method retrieves, from the Telegram server, the messages\n        sent with an offset equal or greater than the given.\n\n        A list of chats, groups and channels identifiers can be set\n        using the parameter `chats`. When it is set, only those\n        messages sent to any of these will be returned. An empty list\n        will return no messages.\n\n        :param category: the category of items to fetch\n        :param offset: obtain messages from this offset\n        :param chats: list of chat names used to filter messages\n\n        :returns: a generator of messages\n\n        :raises ValueError: when `chats` is an empty list\n        \"\"\"\n        if not offset:\n            offset = DEFAULT_OFFSET\n\n        kwargs = {\"offset\": offset, \"chats\": chats}\n        items = super().fetch(category, **kwargs)\n\n        return items", "code_tokens": ["def", "fetch", "(", "self", ",", "category", "=", "CATEGORY_MESSAGE", ",", "offset", "=", "DEFAULT_OFFSET", ",", "chats", "=", "None", ")", ":", "if", "not", "offset", ":", "offset", "=", "DEFAULT_OFFSET", "kwargs", "=", "{", "\"offset\"", ":", "offset", ",", "\"chats\"", ":", "chats", "}", "items", "=", "super", "(", ")", ".", "fetch", "(", "category", ",", "*", "*", "kwargs", ")", "return", "items"], "docstring": "Fetch the messages the bot can read from the server.\n\n        The method retrieves, from the Telegram server, the messages\n        sent with an offset equal or greater than the given.\n\n        A list of chats, groups and channels identifiers can be set\n        using the parameter `chats`. When it is set, only those\n        messages sent to any of these will be returned. An empty list\n        will return no messages.\n\n        :param category: the category of items to fetch\n        :param offset: obtain messages from this offset\n        :param chats: list of chat names used to filter messages\n\n        :returns: a generator of messages\n\n        :raises ValueError: when `chats` is an empty list", "docstring_tokens": ["Fetch", "the", "messages", "the", "bot", "can", "read", "from", "the", "server", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/telegram.py#L78-L103", "partition": "test", "index": 3363, "time": "2016-07-04 13:05:07"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/confluence.py", "func_name": "ConfluenceClient.contents", "original_string": "def contents(self, from_date=DEFAULT_DATETIME,\n                 offset=None, max_contents=MAX_CONTENTS):\n        \"\"\"Get the contents of a repository.\n\n        This method returns an iterator that manages the pagination\n        over contents. Take into account that the seconds of `from_date`\n        parameter will be ignored because the API only works with\n        hours and minutes.\n\n        :param from_date: fetch the contents updated since this date\n        :param offset: fetch the contents starting from this offset\n        :param limit: maximum number of contents to fetch per request\n        \"\"\"\n        resource = self.RCONTENTS + '/' + self.MSEARCH\n\n        # Set confluence query parameter (cql)\n        date = from_date.strftime(\"%Y-%m-%d %H:%M\")\n        cql = self.VCQL % {'date': date}\n\n        # Set parameters\n        params = {\n            self.PCQL: cql,\n            self.PLIMIT: max_contents,\n            self.PEXPAND: self.PANCESTORS\n        }\n\n        if offset:\n            params[self.PSTART] = offset\n\n        for response in self._call(resource, params):\n            yield response", "language": "python", "code": "def contents(self, from_date=DEFAULT_DATETIME,\n                 offset=None, max_contents=MAX_CONTENTS):\n        \"\"\"Get the contents of a repository.\n\n        This method returns an iterator that manages the pagination\n        over contents. Take into account that the seconds of `from_date`\n        parameter will be ignored because the API only works with\n        hours and minutes.\n\n        :param from_date: fetch the contents updated since this date\n        :param offset: fetch the contents starting from this offset\n        :param limit: maximum number of contents to fetch per request\n        \"\"\"\n        resource = self.RCONTENTS + '/' + self.MSEARCH\n\n        # Set confluence query parameter (cql)\n        date = from_date.strftime(\"%Y-%m-%d %H:%M\")\n        cql = self.VCQL % {'date': date}\n\n        # Set parameters\n        params = {\n            self.PCQL: cql,\n            self.PLIMIT: max_contents,\n            self.PEXPAND: self.PANCESTORS\n        }\n\n        if offset:\n            params[self.PSTART] = offset\n\n        for response in self._call(resource, params):\n            yield response", "code_tokens": ["def", "contents", "(", "self", ",", "from_date", "=", "DEFAULT_DATETIME", ",", "offset", "=", "None", ",", "max_contents", "=", "MAX_CONTENTS", ")", ":", "resource", "=", "self", ".", "RCONTENTS", "+", "'/'", "+", "self", ".", "MSEARCH", "# Set confluence query parameter (cql)", "date", "=", "from_date", ".", "strftime", "(", "\"%Y-%m-%d %H:%M\"", ")", "cql", "=", "self", ".", "VCQL", "%", "{", "'date'", ":", "date", "}", "# Set parameters", "params", "=", "{", "self", ".", "PCQL", ":", "cql", ",", "self", ".", "PLIMIT", ":", "max_contents", ",", "self", ".", "PEXPAND", ":", "self", ".", "PANCESTORS", "}", "if", "offset", ":", "params", "[", "self", ".", "PSTART", "]", "=", "offset", "for", "response", "in", "self", ".", "_call", "(", "resource", ",", "params", ")", ":", "yield", "response"], "docstring": "Get the contents of a repository.\n\n        This method returns an iterator that manages the pagination\n        over contents. Take into account that the seconds of `from_date`\n        parameter will be ignored because the API only works with\n        hours and minutes.\n\n        :param from_date: fetch the contents updated since this date\n        :param offset: fetch the contents starting from this offset\n        :param limit: maximum number of contents to fetch per request", "docstring_tokens": ["Get", "the", "contents", "of", "a", "repository", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/confluence.py#L337-L367", "partition": "test", "index": 3398, "time": "2016-07-07 14:31:23"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/confluence.py", "func_name": "ConfluenceClient.historical_content", "original_string": "def historical_content(self, content_id, version):\n        \"\"\"Get the snapshot of a content for the given version.\n\n        :param content_id: fetch the snapshot of this content\n        :param version: snapshot version of the content\n        \"\"\"\n        resource = self.RCONTENTS + '/' + str(content_id)\n\n        params = {\n            self.PVERSION: version,\n            self.PSTATUS: self.VHISTORICAL,\n            self.PEXPAND: ','.join(self.VEXPAND)\n        }\n\n        # Only one item is returned\n        response = [response for response in self._call(resource, params)]\n        return response[0]", "language": "python", "code": "def historical_content(self, content_id, version):\n        \"\"\"Get the snapshot of a content for the given version.\n\n        :param content_id: fetch the snapshot of this content\n        :param version: snapshot version of the content\n        \"\"\"\n        resource = self.RCONTENTS + '/' + str(content_id)\n\n        params = {\n            self.PVERSION: version,\n            self.PSTATUS: self.VHISTORICAL,\n            self.PEXPAND: ','.join(self.VEXPAND)\n        }\n\n        # Only one item is returned\n        response = [response for response in self._call(resource, params)]\n        return response[0]", "code_tokens": ["def", "historical_content", "(", "self", ",", "content_id", ",", "version", ")", ":", "resource", "=", "self", ".", "RCONTENTS", "+", "'/'", "+", "str", "(", "content_id", ")", "params", "=", "{", "self", ".", "PVERSION", ":", "version", ",", "self", ".", "PSTATUS", ":", "self", ".", "VHISTORICAL", ",", "self", ".", "PEXPAND", ":", "','", ".", "join", "(", "self", ".", "VEXPAND", ")", "}", "# Only one item is returned", "response", "=", "[", "response", "for", "response", "in", "self", ".", "_call", "(", "resource", ",", "params", ")", "]", "return", "response", "[", "0", "]"], "docstring": "Get the snapshot of a content for the given version.\n\n        :param content_id: fetch the snapshot of this content\n        :param version: snapshot version of the content", "docstring_tokens": ["Get", "the", "snapshot", "of", "a", "content", "for", "the", "given", "version", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/confluence.py#L369-L385", "partition": "test", "index": 3399, "time": "2016-07-07 14:31:23"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/confluence.py", "func_name": "Confluence.parse_contents_summary", "original_string": "def parse_contents_summary(raw_json):\n        \"\"\"Parse a Confluence summary JSON list.\n\n        The method parses a JSON stream and returns an iterator\n        of diccionaries. Each dictionary is a content summary.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed content summaries.\n        \"\"\"\n        summary = json.loads(raw_json)\n\n        contents = summary['results']\n        for c in contents:\n            yield c", "language": "python", "code": "def parse_contents_summary(raw_json):\n        \"\"\"Parse a Confluence summary JSON list.\n\n        The method parses a JSON stream and returns an iterator\n        of diccionaries. Each dictionary is a content summary.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed content summaries.\n        \"\"\"\n        summary = json.loads(raw_json)\n\n        contents = summary['results']\n        for c in contents:\n            yield c", "code_tokens": ["def", "parse_contents_summary", "(", "raw_json", ")", ":", "summary", "=", "json", ".", "loads", "(", "raw_json", ")", "contents", "=", "summary", "[", "'results'", "]", "for", "c", "in", "contents", ":", "yield", "c"], "docstring": "Parse a Confluence summary JSON list.\n\n        The method parses a JSON stream and returns an iterator\n        of diccionaries. Each dictionary is a content summary.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed content summaries.", "docstring_tokens": ["Parse", "a", "Confluence", "summary", "JSON", "list", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/confluence.py#L191-L205", "partition": "test", "index": 3397, "time": "2016-07-08 13:24:16"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/confluence.py", "func_name": "Confluence.metadata_id", "original_string": "def metadata_id(item):\n        \"\"\"Extracts the identifier from a Confluence item.\n\n        This identifier will be the mix of two fields because a\n        historical content does not have any unique identifier.\n        In this case, 'id' and 'version' values are combined because\n        it should not be possible to have two equal version numbers\n        for the same content. The value to return will follow the\n        pattern: <content>#v<version> (i.e 28979#v10).\n        \"\"\"\n        cid = item['id']\n        cversion = item['version']['number']\n\n        return str(cid) + '#v' + str(cversion)", "language": "python", "code": "def metadata_id(item):\n        \"\"\"Extracts the identifier from a Confluence item.\n\n        This identifier will be the mix of two fields because a\n        historical content does not have any unique identifier.\n        In this case, 'id' and 'version' values are combined because\n        it should not be possible to have two equal version numbers\n        for the same content. The value to return will follow the\n        pattern: <content>#v<version> (i.e 28979#v10).\n        \"\"\"\n        cid = item['id']\n        cversion = item['version']['number']\n\n        return str(cid) + '#v' + str(cversion)", "code_tokens": ["def", "metadata_id", "(", "item", ")", ":", "cid", "=", "item", "[", "'id'", "]", "cversion", "=", "item", "[", "'version'", "]", "[", "'number'", "]", "return", "str", "(", "cid", ")", "+", "'#v'", "+", "str", "(", "cversion", ")"], "docstring": "Extracts the identifier from a Confluence item.\n\n        This identifier will be the mix of two fields because a\n        historical content does not have any unique identifier.\n        In this case, 'id' and 'version' values are combined because\n        it should not be possible to have two equal version numbers\n        for the same content. The value to return will follow the\n        pattern: <content>#v<version> (i.e 28979#v10).", "docstring_tokens": ["Extracts", "the", "identifier", "from", "a", "Confluence", "item", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/confluence.py#L150-L163", "partition": "test", "index": 3396, "time": "2016-07-08 13:24:16"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/jira.py", "func_name": "map_custom_field", "original_string": "def map_custom_field(custom_fields, fields):\n    \"\"\"Add extra information for custom fields.\n\n    :param custom_fields: set of custom fields with the extra information\n    :param fields: fields of the issue where to add the extra information\n\n    :returns: an set of items with the extra information mapped\n    \"\"\"\n    def build_cf(cf, v):\n        return {'id': cf['id'], 'name': cf['name'], 'value': v}\n\n    return {\n        k: build_cf(custom_fields[k], v)\n        for k, v in fields.items()\n        if k in custom_fields\n    }", "language": "python", "code": "def map_custom_field(custom_fields, fields):\n    \"\"\"Add extra information for custom fields.\n\n    :param custom_fields: set of custom fields with the extra information\n    :param fields: fields of the issue where to add the extra information\n\n    :returns: an set of items with the extra information mapped\n    \"\"\"\n    def build_cf(cf, v):\n        return {'id': cf['id'], 'name': cf['name'], 'value': v}\n\n    return {\n        k: build_cf(custom_fields[k], v)\n        for k, v in fields.items()\n        if k in custom_fields\n    }", "code_tokens": ["def", "map_custom_field", "(", "custom_fields", ",", "fields", ")", ":", "def", "build_cf", "(", "cf", ",", "v", ")", ":", "return", "{", "'id'", ":", "cf", "[", "'id'", "]", ",", "'name'", ":", "cf", "[", "'name'", "]", ",", "'value'", ":", "v", "}", "return", "{", "k", ":", "build_cf", "(", "custom_fields", "[", "k", "]", ",", "v", ")", "for", "k", ",", "v", "in", "fields", ".", "items", "(", ")", "if", "k", "in", "custom_fields", "}"], "docstring": "Add extra information for custom fields.\n\n    :param custom_fields: set of custom fields with the extra information\n    :param fields: fields of the issue where to add the extra information\n\n    :returns: an set of items with the extra information mapped", "docstring_tokens": ["Add", "extra", "information", "for", "custom", "fields", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/jira.py#L47-L62", "partition": "test", "index": 3345, "time": "2016-07-15 13:26:14"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/jira.py", "func_name": "filter_custom_fields", "original_string": "def filter_custom_fields(fields):\n    \"\"\"Filter custom fields from a given set of fields.\n\n    :param fields: set of fields\n\n    :returns: an object with the filtered custom fields\n    \"\"\"\n\n    custom_fields = {}\n\n    sorted_fields = [field for field in fields if field['custom'] is True]\n\n    for custom_field in sorted_fields:\n        custom_fields[custom_field['id']] = custom_field\n\n    return custom_fields", "language": "python", "code": "def filter_custom_fields(fields):\n    \"\"\"Filter custom fields from a given set of fields.\n\n    :param fields: set of fields\n\n    :returns: an object with the filtered custom fields\n    \"\"\"\n\n    custom_fields = {}\n\n    sorted_fields = [field for field in fields if field['custom'] is True]\n\n    for custom_field in sorted_fields:\n        custom_fields[custom_field['id']] = custom_field\n\n    return custom_fields", "code_tokens": ["def", "filter_custom_fields", "(", "fields", ")", ":", "custom_fields", "=", "{", "}", "sorted_fields", "=", "[", "field", "for", "field", "in", "fields", "if", "field", "[", "'custom'", "]", "is", "True", "]", "for", "custom_field", "in", "sorted_fields", ":", "custom_fields", "[", "custom_field", "[", "'id'", "]", "]", "=", "custom_field", "return", "custom_fields"], "docstring": "Filter custom fields from a given set of fields.\n\n    :param fields: set of fields\n\n    :returns: an object with the filtered custom fields", "docstring_tokens": ["Filter", "custom", "fields", "from", "a", "given", "set", "of", "fields", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/jira.py#L65-L80", "partition": "test", "index": 3346, "time": "2016-07-15 13:26:14"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/phabricator.py", "func_name": "ConduitClient._call", "original_string": "def _call(self, method, params):\n        \"\"\"Call a method.\n\n        :param method: method to call\n        :param params: dict with the HTTP parameters needed to call\n            the given method\n\n        :raises ConduitError: when an error is returned by the server\n        \"\"\"\n        url = self.URL % {'base': self.base_url, 'method': method}\n\n        # Conduit and POST parameters\n        params['__conduit__'] = {'token': self.api_token}\n\n        data = {\n            'params': json.dumps(params, sort_keys=True),\n            'output': 'json',\n            '__conduit__': True\n        }\n\n        logger.debug(\"Phabricator Conduit client requests: %s params: %s\",\n                     method, str(data))\n\n        r = self.fetch(url, payload=data, method=HttpClient.POST, verify=False)\n\n        # Check for possible Conduit API errors\n        result = r.json()\n\n        if result['error_code']:\n            raise ConduitError(error=result['error_info'],\n                               code=result['error_code'])\n\n        return r.text", "language": "python", "code": "def _call(self, method, params):\n        \"\"\"Call a method.\n\n        :param method: method to call\n        :param params: dict with the HTTP parameters needed to call\n            the given method\n\n        :raises ConduitError: when an error is returned by the server\n        \"\"\"\n        url = self.URL % {'base': self.base_url, 'method': method}\n\n        # Conduit and POST parameters\n        params['__conduit__'] = {'token': self.api_token}\n\n        data = {\n            'params': json.dumps(params, sort_keys=True),\n            'output': 'json',\n            '__conduit__': True\n        }\n\n        logger.debug(\"Phabricator Conduit client requests: %s params: %s\",\n                     method, str(data))\n\n        r = self.fetch(url, payload=data, method=HttpClient.POST, verify=False)\n\n        # Check for possible Conduit API errors\n        result = r.json()\n\n        if result['error_code']:\n            raise ConduitError(error=result['error_info'],\n                               code=result['error_code'])\n\n        return r.text", "code_tokens": ["def", "_call", "(", "self", ",", "method", ",", "params", ")", ":", "url", "=", "self", ".", "URL", "%", "{", "'base'", ":", "self", ".", "base_url", ",", "'method'", ":", "method", "}", "# Conduit and POST parameters", "params", "[", "'__conduit__'", "]", "=", "{", "'token'", ":", "self", ".", "api_token", "}", "data", "=", "{", "'params'", ":", "json", ".", "dumps", "(", "params", ",", "sort_keys", "=", "True", ")", ",", "'output'", ":", "'json'", ",", "'__conduit__'", ":", "True", "}", "logger", ".", "debug", "(", "\"Phabricator Conduit client requests: %s params: %s\"", ",", "method", ",", "str", "(", "data", ")", ")", "r", "=", "self", ".", "fetch", "(", "url", ",", "payload", "=", "data", ",", "method", "=", "HttpClient", ".", "POST", ",", "verify", "=", "False", ")", "# Check for possible Conduit API errors", "result", "=", "r", ".", "json", "(", ")", "if", "result", "[", "'error_code'", "]", ":", "raise", "ConduitError", "(", "error", "=", "result", "[", "'error_info'", "]", ",", "code", "=", "result", "[", "'error_code'", "]", ")", "return", "r", ".", "text"], "docstring": "Call a method.\n\n        :param method: method to call\n        :param params: dict with the HTTP parameters needed to call\n            the given method\n\n        :raises ConduitError: when an error is returned by the server", "docstring_tokens": ["Call", "a", "method", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/phabricator.py#L575-L607", "partition": "test", "index": 3395, "time": "2016-07-27 12:21:40"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/phabricator.py", "func_name": "ConduitClient.tasks", "original_string": "def tasks(self, from_date=DEFAULT_DATETIME):\n        \"\"\"Retrieve tasks.\n\n        :param from_date: retrieve tasks that where updated from that date;\n            dates are converted epoch time.\n        \"\"\"\n        # Convert 'from_date' to epoch timestamp.\n        # Zero value (1970-01-01 00:00:00) is not allowed for\n        # 'modifiedStart' so it will be set to 1, by default.\n        ts = int(datetime_to_utc(from_date).timestamp()) or 1\n\n        consts = {\n            self.PMODIFIED_START: ts\n        }\n\n        attachments = {\n            self. PPROJECTS: True\n        }\n\n        params = {\n            self.PCONSTRAINTS: consts,\n            self.PATTACHMENTS: attachments,\n            self.PORDER: self.VOUTDATED,\n        }\n\n        while True:\n            r = self._call(self.MANIPHEST_TASKS, params)\n            yield r\n            j = json.loads(r)\n            after = j['result']['cursor']['after']\n            if not after:\n                break\n            params[self.PAFTER] = after", "language": "python", "code": "def tasks(self, from_date=DEFAULT_DATETIME):\n        \"\"\"Retrieve tasks.\n\n        :param from_date: retrieve tasks that where updated from that date;\n            dates are converted epoch time.\n        \"\"\"\n        # Convert 'from_date' to epoch timestamp.\n        # Zero value (1970-01-01 00:00:00) is not allowed for\n        # 'modifiedStart' so it will be set to 1, by default.\n        ts = int(datetime_to_utc(from_date).timestamp()) or 1\n\n        consts = {\n            self.PMODIFIED_START: ts\n        }\n\n        attachments = {\n            self. PPROJECTS: True\n        }\n\n        params = {\n            self.PCONSTRAINTS: consts,\n            self.PATTACHMENTS: attachments,\n            self.PORDER: self.VOUTDATED,\n        }\n\n        while True:\n            r = self._call(self.MANIPHEST_TASKS, params)\n            yield r\n            j = json.loads(r)\n            after = j['result']['cursor']['after']\n            if not after:\n                break\n            params[self.PAFTER] = after", "code_tokens": ["def", "tasks", "(", "self", ",", "from_date", "=", "DEFAULT_DATETIME", ")", ":", "# Convert 'from_date' to epoch timestamp.", "# Zero value (1970-01-01 00:00:00) is not allowed for", "# 'modifiedStart' so it will be set to 1, by default.", "ts", "=", "int", "(", "datetime_to_utc", "(", "from_date", ")", ".", "timestamp", "(", ")", ")", "or", "1", "consts", "=", "{", "self", ".", "PMODIFIED_START", ":", "ts", "}", "attachments", "=", "{", "self", ".", "PPROJECTS", ":", "True", "}", "params", "=", "{", "self", ".", "PCONSTRAINTS", ":", "consts", ",", "self", ".", "PATTACHMENTS", ":", "attachments", ",", "self", ".", "PORDER", ":", "self", ".", "VOUTDATED", ",", "}", "while", "True", ":", "r", "=", "self", ".", "_call", "(", "self", ".", "MANIPHEST_TASKS", ",", "params", ")", "yield", "r", "j", "=", "json", ".", "loads", "(", "r", ")", "after", "=", "j", "[", "'result'", "]", "[", "'cursor'", "]", "[", "'after'", "]", "if", "not", "after", ":", "break", "params", "[", "self", ".", "PAFTER", "]", "=", "after"], "docstring": "Retrieve tasks.\n\n        :param from_date: retrieve tasks that where updated from that date;\n            dates are converted epoch time.", "docstring_tokens": ["Retrieve", "tasks", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/phabricator.py#L484-L516", "partition": "test", "index": 3391, "time": "2016-07-27 12:21:40"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/phabricator.py", "func_name": "ConduitClient.transactions", "original_string": "def transactions(self, *phids):\n        \"\"\"Retrieve tasks transactions.\n\n        :param phids: list of tasks identifiers\n        \"\"\"\n        params = {\n            self.PIDS: phids\n        }\n\n        response = self._call(self.MANIPHEST_TRANSACTIONS, params)\n\n        return response", "language": "python", "code": "def transactions(self, *phids):\n        \"\"\"Retrieve tasks transactions.\n\n        :param phids: list of tasks identifiers\n        \"\"\"\n        params = {\n            self.PIDS: phids\n        }\n\n        response = self._call(self.MANIPHEST_TRANSACTIONS, params)\n\n        return response", "code_tokens": ["def", "transactions", "(", "self", ",", "*", "phids", ")", ":", "params", "=", "{", "self", ".", "PIDS", ":", "phids", "}", "response", "=", "self", ".", "_call", "(", "self", ".", "MANIPHEST_TRANSACTIONS", ",", "params", ")", "return", "response"], "docstring": "Retrieve tasks transactions.\n\n        :param phids: list of tasks identifiers", "docstring_tokens": ["Retrieve", "tasks", "transactions", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/phabricator.py#L518-L529", "partition": "test", "index": 3392, "time": "2016-07-27 12:21:40"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/phabricator.py", "func_name": "Phabricator.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the tasks\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        from_date = kwargs['from_date']\n\n        logger.info(\"Fetching tasks of '%s' from %s\", self.url, str(from_date))\n\n        ntasks = 0\n\n        for task in self.__fetch_tasks(from_date):\n            yield task\n            ntasks += 1\n\n        logger.info(\"Fetch process completed: %s tasks fetched\", ntasks)", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the tasks\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        from_date = kwargs['from_date']\n\n        logger.info(\"Fetching tasks of '%s' from %s\", self.url, str(from_date))\n\n        ntasks = 0\n\n        for task in self.__fetch_tasks(from_date):\n            yield task\n            ntasks += 1\n\n        logger.info(\"Fetch process completed: %s tasks fetched\", ntasks)", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "from_date", "=", "kwargs", "[", "'from_date'", "]", "logger", ".", "info", "(", "\"Fetching tasks of '%s' from %s\"", ",", "self", ".", "url", ",", "str", "(", "from_date", ")", ")", "ntasks", "=", "0", "for", "task", "in", "self", ".", "__fetch_tasks", "(", "from_date", ")", ":", "yield", "task", "ntasks", "+=", "1", "logger", ".", "info", "(", "\"Fetch process completed: %s tasks fetched\"", ",", "ntasks", ")"], "docstring": "Fetch the tasks\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "the", "tasks"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/phabricator.py#L99-L117", "partition": "test", "index": 3388, "time": "2016-07-27 18:31:01"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/phabricator.py", "func_name": "ConduitClient.users", "original_string": "def users(self, *phids):\n        \"\"\"Retrieve users.\n\n        :params phids: list of users identifiers\n        \"\"\"\n        params = {\n            self.PHIDS: phids\n        }\n\n        response = self._call(self.PHAB_USERS, params)\n\n        return response", "language": "python", "code": "def users(self, *phids):\n        \"\"\"Retrieve users.\n\n        :params phids: list of users identifiers\n        \"\"\"\n        params = {\n            self.PHIDS: phids\n        }\n\n        response = self._call(self.PHAB_USERS, params)\n\n        return response", "code_tokens": ["def", "users", "(", "self", ",", "*", "phids", ")", ":", "params", "=", "{", "self", ".", "PHIDS", ":", "phids", "}", "response", "=", "self", ".", "_call", "(", "self", ".", "PHAB_USERS", ",", "params", ")", "return", "response"], "docstring": "Retrieve users.\n\n        :params phids: list of users identifiers", "docstring_tokens": ["Retrieve", "users", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/phabricator.py#L531-L542", "partition": "test", "index": 3393, "time": "2016-07-28 11:05:29"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/redmine.py", "func_name": "RedmineClient.issue", "original_string": "def issue(self, issue_id):\n        \"\"\"Get the information of the given issue.\n\n        :param issue_id: issue identifier\n        \"\"\"\n        resource = urijoin(self.RISSUES, str(issue_id) + self.CJSON)\n\n        params = {\n            self.PINCLUDE: ','.join([self.CATTACHMENTS, self.CCHANGESETS,\n                                     self.CCHILDREN, self.CJOURNALS,\n                                     self.CRELATIONS, self.CWATCHERS])\n        }\n\n        response = self._call(resource, params)\n\n        return response", "language": "python", "code": "def issue(self, issue_id):\n        \"\"\"Get the information of the given issue.\n\n        :param issue_id: issue identifier\n        \"\"\"\n        resource = urijoin(self.RISSUES, str(issue_id) + self.CJSON)\n\n        params = {\n            self.PINCLUDE: ','.join([self.CATTACHMENTS, self.CCHANGESETS,\n                                     self.CCHILDREN, self.CJOURNALS,\n                                     self.CRELATIONS, self.CWATCHERS])\n        }\n\n        response = self._call(resource, params)\n\n        return response", "code_tokens": ["def", "issue", "(", "self", ",", "issue_id", ")", ":", "resource", "=", "urijoin", "(", "self", ".", "RISSUES", ",", "str", "(", "issue_id", ")", "+", "self", ".", "CJSON", ")", "params", "=", "{", "self", ".", "PINCLUDE", ":", "','", ".", "join", "(", "[", "self", ".", "CATTACHMENTS", ",", "self", ".", "CCHANGESETS", ",", "self", ".", "CCHILDREN", ",", "self", ".", "CJOURNALS", ",", "self", ".", "CRELATIONS", ",", "self", ".", "CWATCHERS", "]", ")", "}", "response", "=", "self", ".", "_call", "(", "resource", ",", "params", ")", "return", "response"], "docstring": "Get the information of the given issue.\n\n        :param issue_id: issue identifier", "docstring_tokens": ["Get", "the", "information", "of", "the", "given", "issue", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/redmine.py#L380-L395", "partition": "test", "index": 3339, "time": "2016-08-01 10:43:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/redmine.py", "func_name": "RedmineClient.issues", "original_string": "def issues(self, from_date=DEFAULT_DATETIME,\n               offset=None, max_issues=MAX_ISSUES):\n        \"\"\"Get the information of a list of issues.\n\n        :param from_date: retrieve issues that where updated from that date;\n            dates are converted to UTC\n        :param offset: starting position for the search\n        :param max_issues: maximum number of issues to reteurn per query\n        \"\"\"\n        resource = self.RISSUES + self.CJSON\n\n        ts = datetime_to_utc(from_date)\n        ts = ts.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n\n        # By default, Redmine returns open issues only.\n        # Parameter 'status_id' is set to get all the statuses.\n        params = {\n            self.PSTATUS_ID: '*',\n            self.PSORT: self.PUPDATED_ON,\n            self.PUPDATED_ON: '>=' + ts,\n            self.PLIMIT: max_issues\n        }\n\n        if offset is not None:\n            params[self.POFFSET] = offset\n\n        response = self._call(resource, params)\n\n        return response", "language": "python", "code": "def issues(self, from_date=DEFAULT_DATETIME,\n               offset=None, max_issues=MAX_ISSUES):\n        \"\"\"Get the information of a list of issues.\n\n        :param from_date: retrieve issues that where updated from that date;\n            dates are converted to UTC\n        :param offset: starting position for the search\n        :param max_issues: maximum number of issues to reteurn per query\n        \"\"\"\n        resource = self.RISSUES + self.CJSON\n\n        ts = datetime_to_utc(from_date)\n        ts = ts.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n\n        # By default, Redmine returns open issues only.\n        # Parameter 'status_id' is set to get all the statuses.\n        params = {\n            self.PSTATUS_ID: '*',\n            self.PSORT: self.PUPDATED_ON,\n            self.PUPDATED_ON: '>=' + ts,\n            self.PLIMIT: max_issues\n        }\n\n        if offset is not None:\n            params[self.POFFSET] = offset\n\n        response = self._call(resource, params)\n\n        return response", "code_tokens": ["def", "issues", "(", "self", ",", "from_date", "=", "DEFAULT_DATETIME", ",", "offset", "=", "None", ",", "max_issues", "=", "MAX_ISSUES", ")", ":", "resource", "=", "self", ".", "RISSUES", "+", "self", ".", "CJSON", "ts", "=", "datetime_to_utc", "(", "from_date", ")", "ts", "=", "ts", ".", "strftime", "(", "\"%Y-%m-%dT%H:%M:%SZ\"", ")", "# By default, Redmine returns open issues only.", "# Parameter 'status_id' is set to get all the statuses.", "params", "=", "{", "self", ".", "PSTATUS_ID", ":", "'*'", ",", "self", ".", "PSORT", ":", "self", ".", "PUPDATED_ON", ",", "self", ".", "PUPDATED_ON", ":", "'>='", "+", "ts", ",", "self", ".", "PLIMIT", ":", "max_issues", "}", "if", "offset", "is", "not", "None", ":", "params", "[", "self", ".", "POFFSET", "]", "=", "offset", "response", "=", "self", ".", "_call", "(", "resource", ",", "params", ")", "return", "response"], "docstring": "Get the information of a list of issues.\n\n        :param from_date: retrieve issues that where updated from that date;\n            dates are converted to UTC\n        :param offset: starting position for the search\n        :param max_issues: maximum number of issues to reteurn per query", "docstring_tokens": ["Get", "the", "information", "of", "a", "list", "of", "issues", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/redmine.py#L350-L378", "partition": "test", "index": 3338, "time": "2016-08-01 10:43:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/redmine.py", "func_name": "RedmineClient._call", "original_string": "def _call(self, resource, params):\n        \"\"\"Call to get a resource.\n\n        :param method: resource to get\n        :param params: dict with the HTTP parameters needed to get\n            the given resource\n        \"\"\"\n        url = self.URL % {'base': self.base_url, 'resource': resource}\n\n        if self.api_token:\n            params[self.PKEY] = self.api_token\n\n        logger.debug(\"Redmine client requests: %s params: %s\",\n                     resource, str(params))\n\n        r = self.fetch(url, payload=params, verify=False)\n\n        return r.text", "language": "python", "code": "def _call(self, resource, params):\n        \"\"\"Call to get a resource.\n\n        :param method: resource to get\n        :param params: dict with the HTTP parameters needed to get\n            the given resource\n        \"\"\"\n        url = self.URL % {'base': self.base_url, 'resource': resource}\n\n        if self.api_token:\n            params[self.PKEY] = self.api_token\n\n        logger.debug(\"Redmine client requests: %s params: %s\",\n                     resource, str(params))\n\n        r = self.fetch(url, payload=params, verify=False)\n\n        return r.text", "code_tokens": ["def", "_call", "(", "self", ",", "resource", ",", "params", ")", ":", "url", "=", "self", ".", "URL", "%", "{", "'base'", ":", "self", ".", "base_url", ",", "'resource'", ":", "resource", "}", "if", "self", ".", "api_token", ":", "params", "[", "self", ".", "PKEY", "]", "=", "self", ".", "api_token", "logger", ".", "debug", "(", "\"Redmine client requests: %s params: %s\"", ",", "resource", ",", "str", "(", "params", ")", ")", "r", "=", "self", ".", "fetch", "(", "url", ",", "payload", "=", "params", ",", "verify", "=", "False", ")", "return", "r", ".", "text"], "docstring": "Call to get a resource.\n\n        :param method: resource to get\n        :param params: dict with the HTTP parameters needed to get\n            the given resource", "docstring_tokens": ["Call", "to", "get", "a", "resource", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/redmine.py#L426-L443", "partition": "test", "index": 3341, "time": "2016-08-01 10:43:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/redmine.py", "func_name": "Redmine.parse_issues", "original_string": "def parse_issues(raw_json):\n        \"\"\"Parse a Redmine issues JSON stream.\n\n        The method parses a JSON stream and returns a list iterator.\n        Each item is a dictionary that contains the issue parsed data.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed issues\n        \"\"\"\n        results = json.loads(raw_json)\n\n        issues = results['issues']\n        for issue in issues:\n            yield issue", "language": "python", "code": "def parse_issues(raw_json):\n        \"\"\"Parse a Redmine issues JSON stream.\n\n        The method parses a JSON stream and returns a list iterator.\n        Each item is a dictionary that contains the issue parsed data.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed issues\n        \"\"\"\n        results = json.loads(raw_json)\n\n        issues = results['issues']\n        for issue in issues:\n            yield issue", "code_tokens": ["def", "parse_issues", "(", "raw_json", ")", ":", "results", "=", "json", ".", "loads", "(", "raw_json", ")", "issues", "=", "results", "[", "'issues'", "]", "for", "issue", "in", "issues", ":", "yield", "issue"], "docstring": "Parse a Redmine issues JSON stream.\n\n        The method parses a JSON stream and returns a list iterator.\n        Each item is a dictionary that contains the issue parsed data.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed issues", "docstring_tokens": ["Parse", "a", "Redmine", "issues", "JSON", "stream", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/redmine.py#L182-L196", "partition": "test", "index": 3337, "time": "2016-08-01 19:27:26"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/phabricator.py", "func_name": "ConduitClient.phids", "original_string": "def phids(self, *phids):\n        \"\"\"Retrieve data about PHIDs.\n\n        :params phids: list of PHIDs\n        \"\"\"\n        params = {\n            self.PHIDS: phids\n        }\n\n        response = self._call(self.PHAB_PHIDS, params)\n\n        return response", "language": "python", "code": "def phids(self, *phids):\n        \"\"\"Retrieve data about PHIDs.\n\n        :params phids: list of PHIDs\n        \"\"\"\n        params = {\n            self.PHIDS: phids\n        }\n\n        response = self._call(self.PHAB_PHIDS, params)\n\n        return response", "code_tokens": ["def", "phids", "(", "self", ",", "*", "phids", ")", ":", "params", "=", "{", "self", ".", "PHIDS", ":", "phids", "}", "response", "=", "self", ".", "_call", "(", "self", ".", "PHAB_PHIDS", ",", "params", ")", "return", "response"], "docstring": "Retrieve data about PHIDs.\n\n        :params phids: list of PHIDs", "docstring_tokens": ["Retrieve", "data", "about", "PHIDs", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/phabricator.py#L544-L555", "partition": "test", "index": 3394, "time": "2016-09-22 11:45:56"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/redmine.py", "func_name": "RedmineClient.user", "original_string": "def user(self, user_id):\n        \"\"\"Get the information of the given user.\n\n        :param user_id: user identifier\n        \"\"\"\n        resource = urijoin(self.RUSERS, str(user_id) + self.CJSON)\n\n        params = {}\n\n        response = self._call(resource, params)\n\n        return response", "language": "python", "code": "def user(self, user_id):\n        \"\"\"Get the information of the given user.\n\n        :param user_id: user identifier\n        \"\"\"\n        resource = urijoin(self.RUSERS, str(user_id) + self.CJSON)\n\n        params = {}\n\n        response = self._call(resource, params)\n\n        return response", "code_tokens": ["def", "user", "(", "self", ",", "user_id", ")", ":", "resource", "=", "urijoin", "(", "self", ".", "RUSERS", ",", "str", "(", "user_id", ")", "+", "self", ".", "CJSON", ")", "params", "=", "{", "}", "response", "=", "self", ".", "_call", "(", "resource", ",", "params", ")", "return", "response"], "docstring": "Get the information of the given user.\n\n        :param user_id: user identifier", "docstring_tokens": ["Get", "the", "information", "of", "the", "given", "user", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/redmine.py#L397-L408", "partition": "test", "index": 3340, "time": "2016-11-02 13:44:24"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/meetup.py", "func_name": "MeetupClient.rsvps", "original_string": "def rsvps(self, group, event_id):\n        \"\"\"Fetch the rsvps of a given event.\"\"\"\n\n        resource = urijoin(group, self.REVENTS, event_id, self.RRSVPS)\n\n        # Same hack that in 'events' method\n        fixed_params = '?' + self.PFIELDS + '=' + ','.join(self.VRSVP_FIELDS)\n        fixed_params += '&' + self.PRESPONSE + '=' + ','.join(self.VRESPONSE)\n        resource += fixed_params\n\n        params = {\n            self.PPAGE: self.max_items\n        }\n\n        for page in self._fetch(resource, params):\n            yield page", "language": "python", "code": "def rsvps(self, group, event_id):\n        \"\"\"Fetch the rsvps of a given event.\"\"\"\n\n        resource = urijoin(group, self.REVENTS, event_id, self.RRSVPS)\n\n        # Same hack that in 'events' method\n        fixed_params = '?' + self.PFIELDS + '=' + ','.join(self.VRSVP_FIELDS)\n        fixed_params += '&' + self.PRESPONSE + '=' + ','.join(self.VRESPONSE)\n        resource += fixed_params\n\n        params = {\n            self.PPAGE: self.max_items\n        }\n\n        for page in self._fetch(resource, params):\n            yield page", "code_tokens": ["def", "rsvps", "(", "self", ",", "group", ",", "event_id", ")", ":", "resource", "=", "urijoin", "(", "group", ",", "self", ".", "REVENTS", ",", "event_id", ",", "self", ".", "RRSVPS", ")", "# Same hack that in 'events' method", "fixed_params", "=", "'?'", "+", "self", ".", "PFIELDS", "+", "'='", "+", "','", ".", "join", "(", "self", ".", "VRSVP_FIELDS", ")", "fixed_params", "+=", "'&'", "+", "self", ".", "PRESPONSE", "+", "'='", "+", "','", ".", "join", "(", "self", ".", "VRESPONSE", ")", "resource", "+=", "fixed_params", "params", "=", "{", "self", ".", "PPAGE", ":", "self", ".", "max_items", "}", "for", "page", "in", "self", ".", "_fetch", "(", "resource", ",", "params", ")", ":", "yield", "page"], "docstring": "Fetch the rsvps of a given event.", "docstring_tokens": ["Fetch", "the", "rsvps", "of", "a", "given", "event", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/meetup.py#L407-L422", "partition": "test", "index": 3209, "time": "2016-11-11 09:58:59"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/meetup.py", "func_name": "MeetupClient.comments", "original_string": "def comments(self, group, event_id):\n        \"\"\"Fetch the comments of a given event.\"\"\"\n\n        resource = urijoin(group, self.REVENTS, event_id, self.RCOMMENTS)\n\n        params = {\n            self.PPAGE: self.max_items\n        }\n\n        for page in self._fetch(resource, params):\n            yield page", "language": "python", "code": "def comments(self, group, event_id):\n        \"\"\"Fetch the comments of a given event.\"\"\"\n\n        resource = urijoin(group, self.REVENTS, event_id, self.RCOMMENTS)\n\n        params = {\n            self.PPAGE: self.max_items\n        }\n\n        for page in self._fetch(resource, params):\n            yield page", "code_tokens": ["def", "comments", "(", "self", ",", "group", ",", "event_id", ")", ":", "resource", "=", "urijoin", "(", "group", ",", "self", ".", "REVENTS", ",", "event_id", ",", "self", ".", "RCOMMENTS", ")", "params", "=", "{", "self", ".", "PPAGE", ":", "self", ".", "max_items", "}", "for", "page", "in", "self", ".", "_fetch", "(", "resource", ",", "params", ")", ":", "yield", "page"], "docstring": "Fetch the comments of a given event.", "docstring_tokens": ["Fetch", "the", "comments", "of", "a", "given", "event", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/meetup.py#L395-L405", "partition": "test", "index": 3208, "time": "2016-11-11 09:58:59"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/meetup.py", "func_name": "MeetupClient.events", "original_string": "def events(self, group, from_date=DEFAULT_DATETIME):\n        \"\"\"Fetch the events pages of a given group.\"\"\"\n\n        date = datetime_to_utc(from_date)\n        date = date.strftime(\"since:%Y-%m-%dT%H:%M:%S.000Z\")\n\n        resource = urijoin(group, self.REVENTS)\n\n        # Hack required due to Metup API does not support list\n        # values with the format `?param=value1&param=value2`.\n        # It only works with `?param=value1,value2`.\n        # Morever, urrlib3 encodes comma characters when values\n        # are given using params dict, which it doesn't work\n        # with Meetup, either.\n        fixed_params = '?' + self.PFIELDS + '=' + ','.join(self.VEVENT_FIELDS)\n        fixed_params += '&' + self.PSTATUS + '=' + ','.join(self.VSTATUS)\n        resource += fixed_params\n\n        params = {\n            self.PORDER: self.VUPDATED,\n            self.PSCROLL: date,\n            self.PPAGE: self.max_items\n        }\n\n        try:\n            for page in self._fetch(resource, params):\n                yield page\n        except requests.exceptions.HTTPError as error:\n            if error.response.status_code == 410:\n                msg = \"Group is no longer accessible: {}\".format(error)\n                raise RepositoryError(cause=msg)\n            else:\n                raise error", "language": "python", "code": "def events(self, group, from_date=DEFAULT_DATETIME):\n        \"\"\"Fetch the events pages of a given group.\"\"\"\n\n        date = datetime_to_utc(from_date)\n        date = date.strftime(\"since:%Y-%m-%dT%H:%M:%S.000Z\")\n\n        resource = urijoin(group, self.REVENTS)\n\n        # Hack required due to Metup API does not support list\n        # values with the format `?param=value1&param=value2`.\n        # It only works with `?param=value1,value2`.\n        # Morever, urrlib3 encodes comma characters when values\n        # are given using params dict, which it doesn't work\n        # with Meetup, either.\n        fixed_params = '?' + self.PFIELDS + '=' + ','.join(self.VEVENT_FIELDS)\n        fixed_params += '&' + self.PSTATUS + '=' + ','.join(self.VSTATUS)\n        resource += fixed_params\n\n        params = {\n            self.PORDER: self.VUPDATED,\n            self.PSCROLL: date,\n            self.PPAGE: self.max_items\n        }\n\n        try:\n            for page in self._fetch(resource, params):\n                yield page\n        except requests.exceptions.HTTPError as error:\n            if error.response.status_code == 410:\n                msg = \"Group is no longer accessible: {}\".format(error)\n                raise RepositoryError(cause=msg)\n            else:\n                raise error", "code_tokens": ["def", "events", "(", "self", ",", "group", ",", "from_date", "=", "DEFAULT_DATETIME", ")", ":", "date", "=", "datetime_to_utc", "(", "from_date", ")", "date", "=", "date", ".", "strftime", "(", "\"since:%Y-%m-%dT%H:%M:%S.000Z\"", ")", "resource", "=", "urijoin", "(", "group", ",", "self", ".", "REVENTS", ")", "# Hack required due to Metup API does not support list", "# values with the format `?param=value1&param=value2`.", "# It only works with `?param=value1,value2`.", "# Morever, urrlib3 encodes comma characters when values", "# are given using params dict, which it doesn't work", "# with Meetup, either.", "fixed_params", "=", "'?'", "+", "self", ".", "PFIELDS", "+", "'='", "+", "','", ".", "join", "(", "self", ".", "VEVENT_FIELDS", ")", "fixed_params", "+=", "'&'", "+", "self", ".", "PSTATUS", "+", "'='", "+", "','", ".", "join", "(", "self", ".", "VSTATUS", ")", "resource", "+=", "fixed_params", "params", "=", "{", "self", ".", "PORDER", ":", "self", ".", "VUPDATED", ",", "self", ".", "PSCROLL", ":", "date", ",", "self", ".", "PPAGE", ":", "self", ".", "max_items", "}", "try", ":", "for", "page", "in", "self", ".", "_fetch", "(", "resource", ",", "params", ")", ":", "yield", "page", "except", "requests", ".", "exceptions", ".", "HTTPError", "as", "error", ":", "if", "error", ".", "response", ".", "status_code", "==", "410", ":", "msg", "=", "\"Group is no longer accessible: {}\"", ".", "format", "(", "error", ")", "raise", "RepositoryError", "(", "cause", "=", "msg", ")", "else", ":", "raise", "error"], "docstring": "Fetch the events pages of a given group.", "docstring_tokens": ["Fetch", "the", "events", "pages", "of", "a", "given", "group", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/meetup.py#L361-L393", "partition": "test", "index": 3207, "time": "2016-11-11 09:58:59"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/meetup.py", "func_name": "Meetup.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the events\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        from_date = kwargs['from_date']\n        to_date = kwargs['to_date']\n\n        logger.info(\"Fetching events of '%s' group from %s to %s\",\n                    self.group, str(from_date),\n                    str(to_date) if to_date else '--')\n\n        to_date_ts = datetime_to_utc(to_date).timestamp() if to_date else None\n\n        nevents = 0\n        stop_fetching = False\n\n        ev_pages = self.client.events(self.group, from_date=from_date)\n\n        for evp in ev_pages:\n            events = [event for event in self.parse_json(evp)]\n\n            for event in events:\n                event_id = event['id']\n\n                event['comments'] = self.__fetch_and_parse_comments(event_id)\n                event['rsvps'] = self.__fetch_and_parse_rsvps(event_id)\n\n                # Check events updated before 'to_date'\n                event_ts = self.metadata_updated_on(event)\n\n                if to_date_ts and event_ts >= to_date_ts:\n                    stop_fetching = True\n                    continue\n\n                yield event\n                nevents += 1\n\n            if stop_fetching:\n                break\n\n        logger.info(\"Fetch process completed: %s events fetched\", nevents)", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the events\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        from_date = kwargs['from_date']\n        to_date = kwargs['to_date']\n\n        logger.info(\"Fetching events of '%s' group from %s to %s\",\n                    self.group, str(from_date),\n                    str(to_date) if to_date else '--')\n\n        to_date_ts = datetime_to_utc(to_date).timestamp() if to_date else None\n\n        nevents = 0\n        stop_fetching = False\n\n        ev_pages = self.client.events(self.group, from_date=from_date)\n\n        for evp in ev_pages:\n            events = [event for event in self.parse_json(evp)]\n\n            for event in events:\n                event_id = event['id']\n\n                event['comments'] = self.__fetch_and_parse_comments(event_id)\n                event['rsvps'] = self.__fetch_and_parse_rsvps(event_id)\n\n                # Check events updated before 'to_date'\n                event_ts = self.metadata_updated_on(event)\n\n                if to_date_ts and event_ts >= to_date_ts:\n                    stop_fetching = True\n                    continue\n\n                yield event\n                nevents += 1\n\n            if stop_fetching:\n                break\n\n        logger.info(\"Fetch process completed: %s events fetched\", nevents)", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "from_date", "=", "kwargs", "[", "'from_date'", "]", "to_date", "=", "kwargs", "[", "'to_date'", "]", "logger", ".", "info", "(", "\"Fetching events of '%s' group from %s to %s\"", ",", "self", ".", "group", ",", "str", "(", "from_date", ")", ",", "str", "(", "to_date", ")", "if", "to_date", "else", "'--'", ")", "to_date_ts", "=", "datetime_to_utc", "(", "to_date", ")", ".", "timestamp", "(", ")", "if", "to_date", "else", "None", "nevents", "=", "0", "stop_fetching", "=", "False", "ev_pages", "=", "self", ".", "client", ".", "events", "(", "self", ".", "group", ",", "from_date", "=", "from_date", ")", "for", "evp", "in", "ev_pages", ":", "events", "=", "[", "event", "for", "event", "in", "self", ".", "parse_json", "(", "evp", ")", "]", "for", "event", "in", "events", ":", "event_id", "=", "event", "[", "'id'", "]", "event", "[", "'comments'", "]", "=", "self", ".", "__fetch_and_parse_comments", "(", "event_id", ")", "event", "[", "'rsvps'", "]", "=", "self", ".", "__fetch_and_parse_rsvps", "(", "event_id", ")", "# Check events updated before 'to_date'", "event_ts", "=", "self", ".", "metadata_updated_on", "(", "event", ")", "if", "to_date_ts", "and", "event_ts", ">=", "to_date_ts", ":", "stop_fetching", "=", "True", "continue", "yield", "event", "nevents", "+=", "1", "if", "stop_fetching", ":", "break", "logger", ".", "info", "(", "\"Fetch process completed: %s events fetched\"", ",", "nevents", ")"], "docstring": "Fetch the events\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "the", "events"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/meetup.py#L124-L168", "partition": "test", "index": 3206, "time": "2016-11-11 17:57:15"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/meetup.py", "func_name": "Meetup.fetch", "original_string": "def fetch(self, category=CATEGORY_EVENT, from_date=DEFAULT_DATETIME, to_date=None,\n              filter_classified=False):\n        \"\"\"Fetch the events from the server.\n\n        This method fetches those events of a group stored on the server\n        that were updated since the given date. Data comments and rsvps\n        are included within each event.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain events updated since this date\n        :param to_date: obtain events updated before this date\n        :param filter_classified: remove classified fields from the resulting items\n\n        :returns: a generator of events\n        \"\"\"\n        if not from_date:\n            from_date = DEFAULT_DATETIME\n\n        from_date = datetime_to_utc(from_date)\n\n        kwargs = {\"from_date\": from_date, \"to_date\": to_date}\n        items = super().fetch(category,\n                              filter_classified=filter_classified,\n                              **kwargs)\n\n        return items", "language": "python", "code": "def fetch(self, category=CATEGORY_EVENT, from_date=DEFAULT_DATETIME, to_date=None,\n              filter_classified=False):\n        \"\"\"Fetch the events from the server.\n\n        This method fetches those events of a group stored on the server\n        that were updated since the given date. Data comments and rsvps\n        are included within each event.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain events updated since this date\n        :param to_date: obtain events updated before this date\n        :param filter_classified: remove classified fields from the resulting items\n\n        :returns: a generator of events\n        \"\"\"\n        if not from_date:\n            from_date = DEFAULT_DATETIME\n\n        from_date = datetime_to_utc(from_date)\n\n        kwargs = {\"from_date\": from_date, \"to_date\": to_date}\n        items = super().fetch(category,\n                              filter_classified=filter_classified,\n                              **kwargs)\n\n        return items", "code_tokens": ["def", "fetch", "(", "self", ",", "category", "=", "CATEGORY_EVENT", ",", "from_date", "=", "DEFAULT_DATETIME", ",", "to_date", "=", "None", ",", "filter_classified", "=", "False", ")", ":", "if", "not", "from_date", ":", "from_date", "=", "DEFAULT_DATETIME", "from_date", "=", "datetime_to_utc", "(", "from_date", ")", "kwargs", "=", "{", "\"from_date\"", ":", "from_date", ",", "\"to_date\"", ":", "to_date", "}", "items", "=", "super", "(", ")", ".", "fetch", "(", "category", ",", "filter_classified", "=", "filter_classified", ",", "*", "*", "kwargs", ")", "return", "items"], "docstring": "Fetch the events from the server.\n\n        This method fetches those events of a group stored on the server\n        that were updated since the given date. Data comments and rsvps\n        are included within each event.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain events updated since this date\n        :param to_date: obtain events updated before this date\n        :param filter_classified: remove classified fields from the resulting items\n\n        :returns: a generator of events", "docstring_tokens": ["Fetch", "the", "events", "from", "the", "server", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/meetup.py#L97-L122", "partition": "test", "index": 3205, "time": "2016-11-11 17:57:15"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/askbot.py", "func_name": "AskbotParser.parse_user_info", "original_string": "def parse_user_info(update_info):\n        \"\"\"Parse the user information of a given HTML container.\n\n        The method parses all the available user information in the container.\n        If the class \"user-info\" exists, the method will get all the available\n        information in the container. If not, if a class \"tip\" exists, it will be\n        a wiki post with no user associated. Else, it can be an empty container.\n\n        :param update_info: beautiful soup answer container element\n\n        :returns: an object with the parsed information\n        \"\"\"\n        user_info = {}\n        if update_info.select(\"div.user-info\"):\n            # Get all the <a> elements in the container. First <a> contains the user\n            # information, second one (if exists), the website of the user.\n            elements = update_info.select(\"div.user-info\")[0].find_all(\"a\")\n            href = elements[0].attrs[\"href\"]\n            user_info['id'] = re.search(r'\\d+', href).group(0)\n            user_info['username'] = elements[0].text\n            user_info['reputation'] = update_info.select('span.reputation-score')[0].text\n            user_info['badges'] = update_info.select(\"span.badges\")[0].attrs[\"title\"]\n            try:\n                elements[1]\n            except IndexError:\n                pass\n            else:\n                user_info['website'] = elements[1].attrs[\"href\"]\n            if update_info.select(\"img.flag\"):\n                flag = update_info.select(\"img.flag\")[0].attrs[\"alt\"]\n                user_info['country'] = re.sub(\"flag of \", \"\", flag)\n\n        return user_info", "language": "python", "code": "def parse_user_info(update_info):\n        \"\"\"Parse the user information of a given HTML container.\n\n        The method parses all the available user information in the container.\n        If the class \"user-info\" exists, the method will get all the available\n        information in the container. If not, if a class \"tip\" exists, it will be\n        a wiki post with no user associated. Else, it can be an empty container.\n\n        :param update_info: beautiful soup answer container element\n\n        :returns: an object with the parsed information\n        \"\"\"\n        user_info = {}\n        if update_info.select(\"div.user-info\"):\n            # Get all the <a> elements in the container. First <a> contains the user\n            # information, second one (if exists), the website of the user.\n            elements = update_info.select(\"div.user-info\")[0].find_all(\"a\")\n            href = elements[0].attrs[\"href\"]\n            user_info['id'] = re.search(r'\\d+', href).group(0)\n            user_info['username'] = elements[0].text\n            user_info['reputation'] = update_info.select('span.reputation-score')[0].text\n            user_info['badges'] = update_info.select(\"span.badges\")[0].attrs[\"title\"]\n            try:\n                elements[1]\n            except IndexError:\n                pass\n            else:\n                user_info['website'] = elements[1].attrs[\"href\"]\n            if update_info.select(\"img.flag\"):\n                flag = update_info.select(\"img.flag\")[0].attrs[\"alt\"]\n                user_info['country'] = re.sub(\"flag of \", \"\", flag)\n\n        return user_info", "code_tokens": ["def", "parse_user_info", "(", "update_info", ")", ":", "user_info", "=", "{", "}", "if", "update_info", ".", "select", "(", "\"div.user-info\"", ")", ":", "# Get all the <a> elements in the container. First <a> contains the user", "# information, second one (if exists), the website of the user.", "elements", "=", "update_info", ".", "select", "(", "\"div.user-info\"", ")", "[", "0", "]", ".", "find_all", "(", "\"a\"", ")", "href", "=", "elements", "[", "0", "]", ".", "attrs", "[", "\"href\"", "]", "user_info", "[", "'id'", "]", "=", "re", ".", "search", "(", "r'\\d+'", ",", "href", ")", ".", "group", "(", "0", ")", "user_info", "[", "'username'", "]", "=", "elements", "[", "0", "]", ".", "text", "user_info", "[", "'reputation'", "]", "=", "update_info", ".", "select", "(", "'span.reputation-score'", ")", "[", "0", "]", ".", "text", "user_info", "[", "'badges'", "]", "=", "update_info", ".", "select", "(", "\"span.badges\"", ")", "[", "0", "]", ".", "attrs", "[", "\"title\"", "]", "try", ":", "elements", "[", "1", "]", "except", "IndexError", ":", "pass", "else", ":", "user_info", "[", "'website'", "]", "=", "elements", "[", "1", "]", ".", "attrs", "[", "\"href\"", "]", "if", "update_info", ".", "select", "(", "\"img.flag\"", ")", ":", "flag", "=", "update_info", ".", "select", "(", "\"img.flag\"", ")", "[", "0", "]", ".", "attrs", "[", "\"alt\"", "]", "user_info", "[", "'country'", "]", "=", "re", ".", "sub", "(", "\"flag of \"", ",", "\"\"", ",", "flag", ")", "return", "user_info"], "docstring": "Parse the user information of a given HTML container.\n\n        The method parses all the available user information in the container.\n        If the class \"user-info\" exists, the method will get all the available\n        information in the container. If not, if a class \"tip\" exists, it will be\n        a wiki post with no user associated. Else, it can be an empty container.\n\n        :param update_info: beautiful soup answer container element\n\n        :returns: an object with the parsed information", "docstring_tokens": ["Parse", "the", "user", "information", "of", "a", "given", "HTML", "container", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/askbot.py#L481-L513", "partition": "test", "index": 3219, "time": "2016-11-14 16:39:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/askbot.py", "func_name": "AskbotParser.parse_number_of_html_pages", "original_string": "def parse_number_of_html_pages(html_question):\n        \"\"\"Parse number of answer pages to paginate over them.\n\n        :param html_question: raw HTML question element\n\n        :returns: an integer with the number of pages\n        \"\"\"\n        bs_question = bs4.BeautifulSoup(html_question, \"html.parser\")\n        try:\n            bs_question.select('div.paginator')[0]\n        except IndexError:\n            return 1\n        else:\n            return int(bs_question.select('div.paginator')[0].attrs['data-num-pages'])", "language": "python", "code": "def parse_number_of_html_pages(html_question):\n        \"\"\"Parse number of answer pages to paginate over them.\n\n        :param html_question: raw HTML question element\n\n        :returns: an integer with the number of pages\n        \"\"\"\n        bs_question = bs4.BeautifulSoup(html_question, \"html.parser\")\n        try:\n            bs_question.select('div.paginator')[0]\n        except IndexError:\n            return 1\n        else:\n            return int(bs_question.select('div.paginator')[0].attrs['data-num-pages'])", "code_tokens": ["def", "parse_number_of_html_pages", "(", "html_question", ")", ":", "bs_question", "=", "bs4", ".", "BeautifulSoup", "(", "html_question", ",", "\"html.parser\"", ")", "try", ":", "bs_question", ".", "select", "(", "'div.paginator'", ")", "[", "0", "]", "except", "IndexError", ":", "return", "1", "else", ":", "return", "int", "(", "bs_question", ".", "select", "(", "'div.paginator'", ")", "[", "0", "]", ".", "attrs", "[", "'data-num-pages'", "]", ")"], "docstring": "Parse number of answer pages to paginate over them.\n\n        :param html_question: raw HTML question element\n\n        :returns: an integer with the number of pages", "docstring_tokens": ["Parse", "number", "of", "answer", "pages", "to", "paginate", "over", "them", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/askbot.py#L465-L478", "partition": "test", "index": 3218, "time": "2016-11-14 16:39:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/askbot.py", "func_name": "AskbotParser.parse_answers", "original_string": "def parse_answers(html_question):\n        \"\"\"Parse the answers of a given HTML question.\n\n        The method parses the answers related with a given HTML question,\n        as well as all the comments related to the answer.\n\n        :param html_question: raw HTML question element\n\n        :returns: a list with the answers\n        \"\"\"\n\n        def parse_answer_container(update_info):\n            \"\"\"Parse the answer info container of a given HTML question.\n\n            The method parses the information available in the answer information\n            container. The container can have up to 2 elements: the first one\n            contains the information related with the user who generated the question\n            and the date (if any). The second one contains the date of the updated,\n            and the user who updated it (if not the same who generated the question).\n\n            :param update_info: beautiful soup update_info container element\n\n            :returns: an object with the parsed information\n            \"\"\"\n            container_info = {}\n            created = update_info[0]\n            answered_at = created.abbr.attrs[\"title\"]\n            # Convert date to UNIX timestamp\n            container_info['added_at'] = str(str_to_datetime(answered_at).timestamp())\n            container_info['answered_by'] = AskbotParser.parse_user_info(created)\n            try:\n                update_info[1]\n            except IndexError:\n                pass\n            else:\n                updated = update_info[1]\n                updated_at = updated.abbr.attrs[\"title\"]\n                # Convert date to UNIX timestamp\n                container_info['updated_at'] = str(str_to_datetime(updated_at).timestamp())\n                if AskbotParser.parse_user_info(updated):\n                    container_info['updated_by'] = AskbotParser.parse_user_info(updated)\n            return container_info\n\n        answer_list = []\n        # Select all the answers\n        bs_question = bs4.BeautifulSoup(html_question, \"html.parser\")\n        bs_answers = bs_question.select(\"div.answer\")\n        for bs_answer in bs_answers:\n            answer_id = bs_answer.attrs[\"data-post-id\"]\n            votes_element = bs_answer.select(\"div.vote-number\")[0].text\n            accepted_answer = bs_answer.select(\"div.answer-img-accept\")[0].get('title').endswith(\"correct\")\n            # Select the body of the answer\n            body = bs_answer.select(\"div.post-body\")\n            # Get the user information container and parse it\n            update_info = body[0].select(\"div.post-update-info\")\n            answer_container = parse_answer_container(update_info)\n            # Remove the update-info-container div to be able to get the body\n            body[0].div.extract().select(\"div.post-update-info-container\")\n            # Override the body with a clean one\n            body = body[0].get_text(strip=True)\n            # Generate the answer object\n            answer = {'id': answer_id,\n                      'score': votes_element,\n                      'summary': body,\n                      'accepted': accepted_answer\n                      }\n            # Update the object with the information in the answer container\n            answer.update(answer_container)\n            answer_list.append(answer)\n        return answer_list", "language": "python", "code": "def parse_answers(html_question):\n        \"\"\"Parse the answers of a given HTML question.\n\n        The method parses the answers related with a given HTML question,\n        as well as all the comments related to the answer.\n\n        :param html_question: raw HTML question element\n\n        :returns: a list with the answers\n        \"\"\"\n\n        def parse_answer_container(update_info):\n            \"\"\"Parse the answer info container of a given HTML question.\n\n            The method parses the information available in the answer information\n            container. The container can have up to 2 elements: the first one\n            contains the information related with the user who generated the question\n            and the date (if any). The second one contains the date of the updated,\n            and the user who updated it (if not the same who generated the question).\n\n            :param update_info: beautiful soup update_info container element\n\n            :returns: an object with the parsed information\n            \"\"\"\n            container_info = {}\n            created = update_info[0]\n            answered_at = created.abbr.attrs[\"title\"]\n            # Convert date to UNIX timestamp\n            container_info['added_at'] = str(str_to_datetime(answered_at).timestamp())\n            container_info['answered_by'] = AskbotParser.parse_user_info(created)\n            try:\n                update_info[1]\n            except IndexError:\n                pass\n            else:\n                updated = update_info[1]\n                updated_at = updated.abbr.attrs[\"title\"]\n                # Convert date to UNIX timestamp\n                container_info['updated_at'] = str(str_to_datetime(updated_at).timestamp())\n                if AskbotParser.parse_user_info(updated):\n                    container_info['updated_by'] = AskbotParser.parse_user_info(updated)\n            return container_info\n\n        answer_list = []\n        # Select all the answers\n        bs_question = bs4.BeautifulSoup(html_question, \"html.parser\")\n        bs_answers = bs_question.select(\"div.answer\")\n        for bs_answer in bs_answers:\n            answer_id = bs_answer.attrs[\"data-post-id\"]\n            votes_element = bs_answer.select(\"div.vote-number\")[0].text\n            accepted_answer = bs_answer.select(\"div.answer-img-accept\")[0].get('title').endswith(\"correct\")\n            # Select the body of the answer\n            body = bs_answer.select(\"div.post-body\")\n            # Get the user information container and parse it\n            update_info = body[0].select(\"div.post-update-info\")\n            answer_container = parse_answer_container(update_info)\n            # Remove the update-info-container div to be able to get the body\n            body[0].div.extract().select(\"div.post-update-info-container\")\n            # Override the body with a clean one\n            body = body[0].get_text(strip=True)\n            # Generate the answer object\n            answer = {'id': answer_id,\n                      'score': votes_element,\n                      'summary': body,\n                      'accepted': accepted_answer\n                      }\n            # Update the object with the information in the answer container\n            answer.update(answer_container)\n            answer_list.append(answer)\n        return answer_list", "code_tokens": ["def", "parse_answers", "(", "html_question", ")", ":", "def", "parse_answer_container", "(", "update_info", ")", ":", "\"\"\"Parse the answer info container of a given HTML question.\n\n            The method parses the information available in the answer information\n            container. The container can have up to 2 elements: the first one\n            contains the information related with the user who generated the question\n            and the date (if any). The second one contains the date of the updated,\n            and the user who updated it (if not the same who generated the question).\n\n            :param update_info: beautiful soup update_info container element\n\n            :returns: an object with the parsed information\n            \"\"\"", "container_info", "=", "{", "}", "created", "=", "update_info", "[", "0", "]", "answered_at", "=", "created", ".", "abbr", ".", "attrs", "[", "\"title\"", "]", "# Convert date to UNIX timestamp", "container_info", "[", "'added_at'", "]", "=", "str", "(", "str_to_datetime", "(", "answered_at", ")", ".", "timestamp", "(", ")", ")", "container_info", "[", "'answered_by'", "]", "=", "AskbotParser", ".", "parse_user_info", "(", "created", ")", "try", ":", "update_info", "[", "1", "]", "except", "IndexError", ":", "pass", "else", ":", "updated", "=", "update_info", "[", "1", "]", "updated_at", "=", "updated", ".", "abbr", ".", "attrs", "[", "\"title\"", "]", "# Convert date to UNIX timestamp", "container_info", "[", "'updated_at'", "]", "=", "str", "(", "str_to_datetime", "(", "updated_at", ")", ".", "timestamp", "(", ")", ")", "if", "AskbotParser", ".", "parse_user_info", "(", "updated", ")", ":", "container_info", "[", "'updated_by'", "]", "=", "AskbotParser", ".", "parse_user_info", "(", "updated", ")", "return", "container_info", "answer_list", "=", "[", "]", "# Select all the answers", "bs_question", "=", "bs4", ".", "BeautifulSoup", "(", "html_question", ",", "\"html.parser\"", ")", "bs_answers", "=", "bs_question", ".", "select", "(", "\"div.answer\"", ")", "for", "bs_answer", "in", "bs_answers", ":", "answer_id", "=", "bs_answer", ".", "attrs", "[", "\"data-post-id\"", "]", "votes_element", "=", "bs_answer", ".", "select", "(", "\"div.vote-number\"", ")", "[", "0", "]", ".", "text", "accepted_answer", "=", "bs_answer", ".", "select", "(", "\"div.answer-img-accept\"", ")", "[", "0", "]", ".", "get", "(", "'title'", ")", ".", "endswith", "(", "\"correct\"", ")", "# Select the body of the answer", "body", "=", "bs_answer", ".", "select", "(", "\"div.post-body\"", ")", "# Get the user information container and parse it", "update_info", "=", "body", "[", "0", "]", ".", "select", "(", "\"div.post-update-info\"", ")", "answer_container", "=", "parse_answer_container", "(", "update_info", ")", "# Remove the update-info-container div to be able to get the body", "body", "[", "0", "]", ".", "div", ".", "extract", "(", ")", ".", "select", "(", "\"div.post-update-info-container\"", ")", "# Override the body with a clean one", "body", "=", "body", "[", "0", "]", ".", "get_text", "(", "strip", "=", "True", ")", "# Generate the answer object", "answer", "=", "{", "'id'", ":", "answer_id", ",", "'score'", ":", "votes_element", ",", "'summary'", ":", "body", ",", "'accepted'", ":", "accepted_answer", "}", "# Update the object with the information in the answer container", "answer", ".", "update", "(", "answer_container", ")", "answer_list", ".", "append", "(", "answer", ")", "return", "answer_list"], "docstring": "Parse the answers of a given HTML question.\n\n        The method parses the answers related with a given HTML question,\n        as well as all the comments related to the answer.\n\n        :param html_question: raw HTML question element\n\n        :returns: a list with the answers", "docstring_tokens": ["Parse", "the", "answers", "of", "a", "given", "HTML", "question", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/askbot.py#L393-L462", "partition": "test", "index": 3217, "time": "2016-11-14 16:39:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/askbot.py", "func_name": "AskbotParser.parse_question_container", "original_string": "def parse_question_container(html_question):\n        \"\"\"Parse the question info container of a given HTML question.\n\n        The method parses the information available in the question information\n        container. The container can have up to 2 elements: the first one\n        contains the information related with the user who generated the question\n        and the date (if any). The second one contains the date of the updated,\n        and the user who updated it (if not the same who generated the question).\n\n        :param html_question: raw HTML question element\n\n        :returns: an object with the parsed information\n        \"\"\"\n        container_info = {}\n        bs_question = bs4.BeautifulSoup(html_question, \"html.parser\")\n        question = AskbotParser._find_question_container(bs_question)\n        container = question.select(\"div.post-update-info\")\n        created = container[0]\n        container_info['author'] = AskbotParser.parse_user_info(created)\n        try:\n            container[1]\n        except IndexError:\n            pass\n        else:\n            updated = container[1]\n            if AskbotParser.parse_user_info(updated):\n                container_info['updated_by'] = AskbotParser.parse_user_info(updated)\n\n        return container_info", "language": "python", "code": "def parse_question_container(html_question):\n        \"\"\"Parse the question info container of a given HTML question.\n\n        The method parses the information available in the question information\n        container. The container can have up to 2 elements: the first one\n        contains the information related with the user who generated the question\n        and the date (if any). The second one contains the date of the updated,\n        and the user who updated it (if not the same who generated the question).\n\n        :param html_question: raw HTML question element\n\n        :returns: an object with the parsed information\n        \"\"\"\n        container_info = {}\n        bs_question = bs4.BeautifulSoup(html_question, \"html.parser\")\n        question = AskbotParser._find_question_container(bs_question)\n        container = question.select(\"div.post-update-info\")\n        created = container[0]\n        container_info['author'] = AskbotParser.parse_user_info(created)\n        try:\n            container[1]\n        except IndexError:\n            pass\n        else:\n            updated = container[1]\n            if AskbotParser.parse_user_info(updated):\n                container_info['updated_by'] = AskbotParser.parse_user_info(updated)\n\n        return container_info", "code_tokens": ["def", "parse_question_container", "(", "html_question", ")", ":", "container_info", "=", "{", "}", "bs_question", "=", "bs4", ".", "BeautifulSoup", "(", "html_question", ",", "\"html.parser\"", ")", "question", "=", "AskbotParser", ".", "_find_question_container", "(", "bs_question", ")", "container", "=", "question", ".", "select", "(", "\"div.post-update-info\"", ")", "created", "=", "container", "[", "0", "]", "container_info", "[", "'author'", "]", "=", "AskbotParser", ".", "parse_user_info", "(", "created", ")", "try", ":", "container", "[", "1", "]", "except", "IndexError", ":", "pass", "else", ":", "updated", "=", "container", "[", "1", "]", "if", "AskbotParser", ".", "parse_user_info", "(", "updated", ")", ":", "container_info", "[", "'updated_by'", "]", "=", "AskbotParser", ".", "parse_user_info", "(", "updated", ")", "return", "container_info"], "docstring": "Parse the question info container of a given HTML question.\n\n        The method parses the information available in the question information\n        container. The container can have up to 2 elements: the first one\n        contains the information related with the user who generated the question\n        and the date (if any). The second one contains the date of the updated,\n        and the user who updated it (if not the same who generated the question).\n\n        :param html_question: raw HTML question element\n\n        :returns: an object with the parsed information", "docstring_tokens": ["Parse", "the", "question", "info", "container", "of", "a", "given", "HTML", "question", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/askbot.py#L362-L390", "partition": "test", "index": 3216, "time": "2016-11-14 16:39:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "find_backends", "original_string": "def find_backends(top_package):\n    \"\"\"Find available backends.\n\n    Look for the Perceval backends and commands under `top_package`\n    and its sub-packages. When `top_package` defines a namespace,\n    backends under that same namespace will be found too.\n\n    :param top_package: package storing backends\n\n    :returns: a tuple with two dicts: one with `Backend` classes and one\n        with `BackendCommand` classes\n    \"\"\"\n    candidates = pkgutil.walk_packages(top_package.__path__,\n                                       prefix=top_package.__name__ + '.')\n\n    modules = [name for _, name, is_pkg in candidates if not is_pkg]\n\n    return _import_backends(modules)", "language": "python", "code": "def find_backends(top_package):\n    \"\"\"Find available backends.\n\n    Look for the Perceval backends and commands under `top_package`\n    and its sub-packages. When `top_package` defines a namespace,\n    backends under that same namespace will be found too.\n\n    :param top_package: package storing backends\n\n    :returns: a tuple with two dicts: one with `Backend` classes and one\n        with `BackendCommand` classes\n    \"\"\"\n    candidates = pkgutil.walk_packages(top_package.__path__,\n                                       prefix=top_package.__name__ + '.')\n\n    modules = [name for _, name, is_pkg in candidates if not is_pkg]\n\n    return _import_backends(modules)", "code_tokens": ["def", "find_backends", "(", "top_package", ")", ":", "candidates", "=", "pkgutil", ".", "walk_packages", "(", "top_package", ".", "__path__", ",", "prefix", "=", "top_package", ".", "__name__", "+", "'.'", ")", "modules", "=", "[", "name", "for", "_", ",", "name", ",", "is_pkg", "in", "candidates", "if", "not", "is_pkg", "]", "return", "_import_backends", "(", "modules", ")"], "docstring": "Find available backends.\n\n    Look for the Perceval backends and commands under `top_package`\n    and its sub-packages. When `top_package` defines a namespace,\n    backends under that same namespace will be found too.\n\n    :param top_package: package storing backends\n\n    :returns: a tuple with two dicts: one with `Backend` classes and one\n        with `BackendCommand` classes", "docstring_tokens": ["Find", "available", "backends", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L631-L648", "partition": "test", "index": 3247, "time": "2016-11-22 14:09:39"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/askbot.py", "func_name": "AskbotClient.get_api_questions", "original_string": "def get_api_questions(self, path):\n        \"\"\"Retrieve a question page using the API.\n\n        :param page: page to retrieve\n        \"\"\"\n        npages = 1\n        next_request = True\n\n        path = urijoin(self.base_url, path)\n        while next_request:\n\n            try:\n                params = {\n                    'page': npages,\n                    'sort': self.ORDER_API\n                }\n\n                response = self.fetch(path, payload=params)\n\n                whole_page = response.text\n\n                raw_questions = json.loads(whole_page)\n                tpages = raw_questions['pages']\n\n                logger.debug(\"Fetching questions from '%s': page %s/%s\",\n                             self.base_url, npages, tpages)\n\n                if npages == tpages:\n                    next_request = False\n\n                npages = npages + 1\n                yield raw_questions\n\n            except requests.exceptions.TooManyRedirects as e:\n                logger.warning(\"%s, data not retrieved for resource %s\", e, path)\n                next_request = False", "language": "python", "code": "def get_api_questions(self, path):\n        \"\"\"Retrieve a question page using the API.\n\n        :param page: page to retrieve\n        \"\"\"\n        npages = 1\n        next_request = True\n\n        path = urijoin(self.base_url, path)\n        while next_request:\n\n            try:\n                params = {\n                    'page': npages,\n                    'sort': self.ORDER_API\n                }\n\n                response = self.fetch(path, payload=params)\n\n                whole_page = response.text\n\n                raw_questions = json.loads(whole_page)\n                tpages = raw_questions['pages']\n\n                logger.debug(\"Fetching questions from '%s': page %s/%s\",\n                             self.base_url, npages, tpages)\n\n                if npages == tpages:\n                    next_request = False\n\n                npages = npages + 1\n                yield raw_questions\n\n            except requests.exceptions.TooManyRedirects as e:\n                logger.warning(\"%s, data not retrieved for resource %s\", e, path)\n                next_request = False", "code_tokens": ["def", "get_api_questions", "(", "self", ",", "path", ")", ":", "npages", "=", "1", "next_request", "=", "True", "path", "=", "urijoin", "(", "self", ".", "base_url", ",", "path", ")", "while", "next_request", ":", "try", ":", "params", "=", "{", "'page'", ":", "npages", ",", "'sort'", ":", "self", ".", "ORDER_API", "}", "response", "=", "self", ".", "fetch", "(", "path", ",", "payload", "=", "params", ")", "whole_page", "=", "response", ".", "text", "raw_questions", "=", "json", ".", "loads", "(", "whole_page", ")", "tpages", "=", "raw_questions", "[", "'pages'", "]", "logger", ".", "debug", "(", "\"Fetching questions from '%s': page %s/%s\"", ",", "self", ".", "base_url", ",", "npages", ",", "tpages", ")", "if", "npages", "==", "tpages", ":", "next_request", "=", "False", "npages", "=", "npages", "+", "1", "yield", "raw_questions", "except", "requests", ".", "exceptions", ".", "TooManyRedirects", "as", "e", ":", "logger", ".", "warning", "(", "\"%s, data not retrieved for resource %s\"", ",", "e", ",", "path", ")", "next_request", "=", "False"], "docstring": "Retrieve a question page using the API.\n\n        :param page: page to retrieve", "docstring_tokens": ["Retrieve", "a", "question", "page", "using", "the", "API", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/askbot.py#L270-L305", "partition": "test", "index": 3213, "time": "2016-11-23 11:48:07"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/askbot.py", "func_name": "Askbot.__fetch_question", "original_string": "def __fetch_question(self, question):\n        \"\"\"Fetch an Askbot HTML question body.\n\n        The method fetchs the HTML question retrieving the\n        question body of the item question received\n\n        :param question: item with the question itself\n\n        :returns: a list of HTML page/s for the question\n        \"\"\"\n        html_question_items = []\n\n        npages = 1\n        next_request = True\n\n        while next_request:\n            try:\n                html_question = self.client.get_html_question(question['id'], npages)\n                html_question_items.append(html_question)\n                tpages = self.ab_parser.parse_number_of_html_pages(html_question)\n\n                if npages == tpages:\n                    next_request = False\n\n                npages = npages + 1\n            except requests.exceptions.TooManyRedirects as e:\n                logger.warning(\"%s, data not retrieved for question %s\", e, question['id'])\n                next_request = False\n\n        return html_question_items", "language": "python", "code": "def __fetch_question(self, question):\n        \"\"\"Fetch an Askbot HTML question body.\n\n        The method fetchs the HTML question retrieving the\n        question body of the item question received\n\n        :param question: item with the question itself\n\n        :returns: a list of HTML page/s for the question\n        \"\"\"\n        html_question_items = []\n\n        npages = 1\n        next_request = True\n\n        while next_request:\n            try:\n                html_question = self.client.get_html_question(question['id'], npages)\n                html_question_items.append(html_question)\n                tpages = self.ab_parser.parse_number_of_html_pages(html_question)\n\n                if npages == tpages:\n                    next_request = False\n\n                npages = npages + 1\n            except requests.exceptions.TooManyRedirects as e:\n                logger.warning(\"%s, data not retrieved for question %s\", e, question['id'])\n                next_request = False\n\n        return html_question_items", "code_tokens": ["def", "__fetch_question", "(", "self", ",", "question", ")", ":", "html_question_items", "=", "[", "]", "npages", "=", "1", "next_request", "=", "True", "while", "next_request", ":", "try", ":", "html_question", "=", "self", ".", "client", ".", "get_html_question", "(", "question", "[", "'id'", "]", ",", "npages", ")", "html_question_items", ".", "append", "(", "html_question", ")", "tpages", "=", "self", ".", "ab_parser", ".", "parse_number_of_html_pages", "(", "html_question", ")", "if", "npages", "==", "tpages", ":", "next_request", "=", "False", "npages", "=", "npages", "+", "1", "except", "requests", ".", "exceptions", ".", "TooManyRedirects", "as", "e", ":", "logger", ".", "warning", "(", "\"%s, data not retrieved for question %s\"", ",", "e", ",", "question", "[", "'id'", "]", ")", "next_request", "=", "False", "return", "html_question_items"], "docstring": "Fetch an Askbot HTML question body.\n\n        The method fetchs the HTML question retrieving the\n        question body of the item question received\n\n        :param question: item with the question itself\n\n        :returns: a list of HTML page/s for the question", "docstring_tokens": ["Fetch", "an", "Askbot", "HTML", "question", "body", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/askbot.py#L164-L193", "partition": "test", "index": 3210, "time": "2016-11-23 11:48:07"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/askbot.py", "func_name": "Askbot.__build_question", "original_string": "def __build_question(html_question, question, comments):\n        \"\"\"Build an Askbot HTML response.\n\n        The method puts together all the information regarding a question\n\n        :param html_question: array of HTML raw pages\n        :param question: question object from the API\n        :param comments: list of comments to add\n\n        :returns: a dict item with the parsed question information\n        \"\"\"\n        question_object = {}\n        # Parse the user info from the soup container\n        question_container = AskbotParser.parse_question_container(html_question[0])\n        # Add the info to the question object\n        question_object.update(question_container)\n        # Add the comments of the question (if any)\n        if comments[int(question['id'])]:\n            question_object['comments'] = comments[int(question['id'])]\n\n        answers = []\n\n        for page in html_question:\n            answers.extend(AskbotParser.parse_answers(page))\n\n        if len(answers) != 0:\n            question_object['answers'] = answers\n            for answer in question_object['answers']:\n                if comments[int(answer['id'])]:\n                    answer['comments'] = comments[int(answer['id'])]\n\n        return question_object", "language": "python", "code": "def __build_question(html_question, question, comments):\n        \"\"\"Build an Askbot HTML response.\n\n        The method puts together all the information regarding a question\n\n        :param html_question: array of HTML raw pages\n        :param question: question object from the API\n        :param comments: list of comments to add\n\n        :returns: a dict item with the parsed question information\n        \"\"\"\n        question_object = {}\n        # Parse the user info from the soup container\n        question_container = AskbotParser.parse_question_container(html_question[0])\n        # Add the info to the question object\n        question_object.update(question_container)\n        # Add the comments of the question (if any)\n        if comments[int(question['id'])]:\n            question_object['comments'] = comments[int(question['id'])]\n\n        answers = []\n\n        for page in html_question:\n            answers.extend(AskbotParser.parse_answers(page))\n\n        if len(answers) != 0:\n            question_object['answers'] = answers\n            for answer in question_object['answers']:\n                if comments[int(answer['id'])]:\n                    answer['comments'] = comments[int(answer['id'])]\n\n        return question_object", "code_tokens": ["def", "__build_question", "(", "html_question", ",", "question", ",", "comments", ")", ":", "question_object", "=", "{", "}", "# Parse the user info from the soup container", "question_container", "=", "AskbotParser", ".", "parse_question_container", "(", "html_question", "[", "0", "]", ")", "# Add the info to the question object", "question_object", ".", "update", "(", "question_container", ")", "# Add the comments of the question (if any)", "if", "comments", "[", "int", "(", "question", "[", "'id'", "]", ")", "]", ":", "question_object", "[", "'comments'", "]", "=", "comments", "[", "int", "(", "question", "[", "'id'", "]", ")", "]", "answers", "=", "[", "]", "for", "page", "in", "html_question", ":", "answers", ".", "extend", "(", "AskbotParser", ".", "parse_answers", "(", "page", ")", ")", "if", "len", "(", "answers", ")", "!=", "0", ":", "question_object", "[", "'answers'", "]", "=", "answers", "for", "answer", "in", "question_object", "[", "'answers'", "]", ":", "if", "comments", "[", "int", "(", "answer", "[", "'id'", "]", ")", "]", ":", "answer", "[", "'comments'", "]", "=", "comments", "[", "int", "(", "answer", "[", "'id'", "]", ")", "]", "return", "question_object"], "docstring": "Build an Askbot HTML response.\n\n        The method puts together all the information regarding a question\n\n        :param html_question: array of HTML raw pages\n        :param question: question object from the API\n        :param comments: list of comments to add\n\n        :returns: a dict item with the parsed question information", "docstring_tokens": ["Build", "an", "Askbot", "HTML", "response", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/askbot.py#L212-L243", "partition": "test", "index": 3212, "time": "2016-11-23 11:48:07"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/askbot.py", "func_name": "AskbotClient.get_html_question", "original_string": "def get_html_question(self, question_id, page=1):\n        \"\"\"Retrieve a raw HTML question and all it's information.\n\n        :param question_id: question identifier\n        :param page: page to retrieve\n        \"\"\"\n        path = urijoin(self.base_url, self.HTML_QUESTION, question_id)\n        params = {\n            'page': page,\n            'sort': self.ORDER_HTML\n        }\n\n        response = self.fetch(path, payload=params)\n        return response.text", "language": "python", "code": "def get_html_question(self, question_id, page=1):\n        \"\"\"Retrieve a raw HTML question and all it's information.\n\n        :param question_id: question identifier\n        :param page: page to retrieve\n        \"\"\"\n        path = urijoin(self.base_url, self.HTML_QUESTION, question_id)\n        params = {\n            'page': page,\n            'sort': self.ORDER_HTML\n        }\n\n        response = self.fetch(path, payload=params)\n        return response.text", "code_tokens": ["def", "get_html_question", "(", "self", ",", "question_id", ",", "page", "=", "1", ")", ":", "path", "=", "urijoin", "(", "self", ".", "base_url", ",", "self", ".", "HTML_QUESTION", ",", "question_id", ")", "params", "=", "{", "'page'", ":", "page", ",", "'sort'", ":", "self", ".", "ORDER_HTML", "}", "response", "=", "self", ".", "fetch", "(", "path", ",", "payload", "=", "params", ")", "return", "response", ".", "text"], "docstring": "Retrieve a raw HTML question and all it's information.\n\n        :param question_id: question identifier\n        :param page: page to retrieve", "docstring_tokens": ["Retrieve", "a", "raw", "HTML", "question", "and", "all", "it", "s", "information", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/askbot.py#L307-L320", "partition": "test", "index": 3214, "time": "2016-11-23 11:48:07"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/rss.py", "func_name": "RSS.fetch", "original_string": "def fetch(self, category=CATEGORY_ENTRY):\n        \"\"\"Fetch the entries from the url.\n\n        The method retrieves all entries from a RSS url\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of entries\n        \"\"\"\n        kwargs = {}\n        items = super().fetch(category, **kwargs)\n\n        return items", "language": "python", "code": "def fetch(self, category=CATEGORY_ENTRY):\n        \"\"\"Fetch the entries from the url.\n\n        The method retrieves all entries from a RSS url\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of entries\n        \"\"\"\n        kwargs = {}\n        items = super().fetch(category, **kwargs)\n\n        return items", "code_tokens": ["def", "fetch", "(", "self", ",", "category", "=", "CATEGORY_ENTRY", ")", ":", "kwargs", "=", "{", "}", "items", "=", "super", "(", ")", ".", "fetch", "(", "category", ",", "*", "*", "kwargs", ")", "return", "items"], "docstring": "Fetch the entries from the url.\n\n        The method retrieves all entries from a RSS url\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of entries", "docstring_tokens": ["Fetch", "the", "entries", "from", "the", "url", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/rss.py#L61-L73", "partition": "test", "index": 3167, "time": "2016-12-08 05:47:40"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/rss.py", "func_name": "RSS.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the entries\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        logger.info(\"Looking for rss entries at feed '%s'\", self.url)\n\n        nentries = 0  # number of entries\n\n        raw_entries = self.client.get_entries()\n        entries = self.parse_feed(raw_entries)['entries']\n        for item in entries:\n            yield item\n            nentries += 1\n\n        logger.info(\"Total number of entries: %i\", nentries)", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the entries\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        logger.info(\"Looking for rss entries at feed '%s'\", self.url)\n\n        nentries = 0  # number of entries\n\n        raw_entries = self.client.get_entries()\n        entries = self.parse_feed(raw_entries)['entries']\n        for item in entries:\n            yield item\n            nentries += 1\n\n        logger.info(\"Total number of entries: %i\", nentries)", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "logger", ".", "info", "(", "\"Looking for rss entries at feed '%s'\"", ",", "self", ".", "url", ")", "nentries", "=", "0", "# number of entries", "raw_entries", "=", "self", ".", "client", ".", "get_entries", "(", ")", "entries", "=", "self", ".", "parse_feed", "(", "raw_entries", ")", "[", "'entries'", "]", "for", "item", "in", "entries", ":", "yield", "item", "nentries", "+=", "1", "logger", ".", "info", "(", "\"Total number of entries: %i\"", ",", "nentries", ")"], "docstring": "Fetch the entries\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "the", "entries"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/rss.py#L75-L93", "partition": "test", "index": 3168, "time": "2016-12-08 05:47:40"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/rss.py", "func_name": "RSSCommand.setup_cmd_parser", "original_string": "def setup_cmd_parser(cls):\n        \"\"\"Returns the RSS argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              archive=True)\n\n        # Required arguments\n        parser.parser.add_argument('url',\n                                   help=\"URL of the RSS feed\")\n\n        return parser", "language": "python", "code": "def setup_cmd_parser(cls):\n        \"\"\"Returns the RSS argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              archive=True)\n\n        # Required arguments\n        parser.parser.add_argument('url',\n                                   help=\"URL of the RSS feed\")\n\n        return parser", "code_tokens": ["def", "setup_cmd_parser", "(", "cls", ")", ":", "parser", "=", "BackendCommandArgumentParser", "(", "cls", ".", "BACKEND", ".", "CATEGORIES", ",", "archive", "=", "True", ")", "# Required arguments", "parser", ".", "parser", ".", "add_argument", "(", "'url'", ",", "help", "=", "\"URL of the RSS feed\"", ")", "return", "parser"], "docstring": "Returns the RSS argument parser.", "docstring_tokens": ["Returns", "the", "RSS", "argument", "parser", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/rss.py#L180-L190", "partition": "test", "index": 3169, "time": "2016-12-08 05:47:40"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/askbot.py", "func_name": "Askbot.__fetch_comments", "original_string": "def __fetch_comments(self, question):\n        \"\"\"Fetch all the comments of an Askbot question and answers.\n\n        The method fetchs the list of every comment existing in a question and\n        its answers.\n\n        :param question: item with the question itself\n\n        :returns: a list of comments with the ids as hashes\n        \"\"\"\n        comments = {}\n        comments[question['id']] = json.loads(self.client.get_comments(question['id']))\n        for object_id in question['answer_ids']:\n            comments[object_id] = json.loads(self.client.get_comments(object_id))\n        return comments", "language": "python", "code": "def __fetch_comments(self, question):\n        \"\"\"Fetch all the comments of an Askbot question and answers.\n\n        The method fetchs the list of every comment existing in a question and\n        its answers.\n\n        :param question: item with the question itself\n\n        :returns: a list of comments with the ids as hashes\n        \"\"\"\n        comments = {}\n        comments[question['id']] = json.loads(self.client.get_comments(question['id']))\n        for object_id in question['answer_ids']:\n            comments[object_id] = json.loads(self.client.get_comments(object_id))\n        return comments", "code_tokens": ["def", "__fetch_comments", "(", "self", ",", "question", ")", ":", "comments", "=", "{", "}", "comments", "[", "question", "[", "'id'", "]", "]", "=", "json", ".", "loads", "(", "self", ".", "client", ".", "get_comments", "(", "question", "[", "'id'", "]", ")", ")", "for", "object_id", "in", "question", "[", "'answer_ids'", "]", ":", "comments", "[", "object_id", "]", "=", "json", ".", "loads", "(", "self", ".", "client", ".", "get_comments", "(", "object_id", ")", ")", "return", "comments"], "docstring": "Fetch all the comments of an Askbot question and answers.\n\n        The method fetchs the list of every comment existing in a question and\n        its answers.\n\n        :param question: item with the question itself\n\n        :returns: a list of comments with the ids as hashes", "docstring_tokens": ["Fetch", "all", "the", "comments", "of", "an", "Askbot", "question", "and", "answers", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/askbot.py#L195-L209", "partition": "test", "index": 3211, "time": "2016-12-14 14:26:05"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/askbot.py", "func_name": "AskbotClient.get_comments", "original_string": "def get_comments(self, post_id):\n        \"\"\"Retrieve a list of comments by a given id.\n\n        :param object_id: object identifiere\n        \"\"\"\n        path = urijoin(self.base_url, self.COMMENTS if self._use_new_urls else self.COMMENTS_OLD)\n        params = {\n            'post_id': post_id,\n            'post_type': 'answer',\n            'avatar_size': 0\n        }\n        headers = {'X-Requested-With': 'XMLHttpRequest'}\n\n        try:\n            response = self.fetch(path, payload=params, headers=headers)\n            raw = response.text\n        except requests.exceptions.HTTPError as ex:\n            if ex.response.status_code == 404:\n                logger.debug(\"Comments URL did not work. Using old URL schema.\")\n                self._use_new_urls = False\n                path = urijoin(self.base_url, self.COMMENTS_OLD)\n                response = self.fetch(path, payload=params, headers=headers)\n                raw = response.text\n            elif ex.response.status_code == 500:\n                logger.warning(\"Comments not retrieved due to %s\", ex)\n                raw = '[]'\n            else:\n                raise ex\n\n        return raw", "language": "python", "code": "def get_comments(self, post_id):\n        \"\"\"Retrieve a list of comments by a given id.\n\n        :param object_id: object identifiere\n        \"\"\"\n        path = urijoin(self.base_url, self.COMMENTS if self._use_new_urls else self.COMMENTS_OLD)\n        params = {\n            'post_id': post_id,\n            'post_type': 'answer',\n            'avatar_size': 0\n        }\n        headers = {'X-Requested-With': 'XMLHttpRequest'}\n\n        try:\n            response = self.fetch(path, payload=params, headers=headers)\n            raw = response.text\n        except requests.exceptions.HTTPError as ex:\n            if ex.response.status_code == 404:\n                logger.debug(\"Comments URL did not work. Using old URL schema.\")\n                self._use_new_urls = False\n                path = urijoin(self.base_url, self.COMMENTS_OLD)\n                response = self.fetch(path, payload=params, headers=headers)\n                raw = response.text\n            elif ex.response.status_code == 500:\n                logger.warning(\"Comments not retrieved due to %s\", ex)\n                raw = '[]'\n            else:\n                raise ex\n\n        return raw", "code_tokens": ["def", "get_comments", "(", "self", ",", "post_id", ")", ":", "path", "=", "urijoin", "(", "self", ".", "base_url", ",", "self", ".", "COMMENTS", "if", "self", ".", "_use_new_urls", "else", "self", ".", "COMMENTS_OLD", ")", "params", "=", "{", "'post_id'", ":", "post_id", ",", "'post_type'", ":", "'answer'", ",", "'avatar_size'", ":", "0", "}", "headers", "=", "{", "'X-Requested-With'", ":", "'XMLHttpRequest'", "}", "try", ":", "response", "=", "self", ".", "fetch", "(", "path", ",", "payload", "=", "params", ",", "headers", "=", "headers", ")", "raw", "=", "response", ".", "text", "except", "requests", ".", "exceptions", ".", "HTTPError", "as", "ex", ":", "if", "ex", ".", "response", ".", "status_code", "==", "404", ":", "logger", ".", "debug", "(", "\"Comments URL did not work. Using old URL schema.\"", ")", "self", ".", "_use_new_urls", "=", "False", "path", "=", "urijoin", "(", "self", ".", "base_url", ",", "self", ".", "COMMENTS_OLD", ")", "response", "=", "self", ".", "fetch", "(", "path", ",", "payload", "=", "params", ",", "headers", "=", "headers", ")", "raw", "=", "response", ".", "text", "elif", "ex", ".", "response", ".", "status_code", "==", "500", ":", "logger", ".", "warning", "(", "\"Comments not retrieved due to %s\"", ",", "ex", ")", "raw", "=", "'[]'", "else", ":", "raise", "ex", "return", "raw"], "docstring": "Retrieve a list of comments by a given id.\n\n        :param object_id: object identifiere", "docstring_tokens": ["Retrieve", "a", "list", "of", "comments", "by", "a", "given", "id", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/askbot.py#L322-L351", "partition": "test", "index": 3215, "time": "2016-12-14 14:26:05"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "BackendCommandArgumentParser.parse", "original_string": "def parse(self, *args):\n        \"\"\"Parse a list of arguments.\n\n        Parse argument strings needed to run a backend command. The result\n        will be a `argparse.Namespace` object populated with the values\n        obtained after the validation of the parameters.\n\n        :param args: argument strings\n\n        :result: an object with the parsed values\n        \"\"\"\n        parsed_args = self.parser.parse_args(args)\n\n        # Category was not set, remove it\n        if parsed_args.category is None:\n            delattr(parsed_args, 'category')\n\n        if self._from_date:\n            parsed_args.from_date = str_to_datetime(parsed_args.from_date)\n        if self._to_date and parsed_args.to_date:\n            parsed_args.to_date = str_to_datetime(parsed_args.to_date)\n        if self._archive and parsed_args.archived_since:\n            parsed_args.archived_since = str_to_datetime(parsed_args.archived_since)\n\n        if self._archive and parsed_args.fetch_archive and parsed_args.no_archive:\n            raise AttributeError(\"fetch-archive and no-archive arguments are not compatible\")\n        if self._archive and parsed_args.fetch_archive and not parsed_args.category:\n            raise AttributeError(\"fetch-archive needs a category to work with\")\n\n        # Set aliases\n        for alias, arg in self.aliases.items():\n            if (alias not in parsed_args) and (arg in parsed_args):\n                value = getattr(parsed_args, arg, None)\n                setattr(parsed_args, alias, value)\n\n        return parsed_args", "language": "python", "code": "def parse(self, *args):\n        \"\"\"Parse a list of arguments.\n\n        Parse argument strings needed to run a backend command. The result\n        will be a `argparse.Namespace` object populated with the values\n        obtained after the validation of the parameters.\n\n        :param args: argument strings\n\n        :result: an object with the parsed values\n        \"\"\"\n        parsed_args = self.parser.parse_args(args)\n\n        # Category was not set, remove it\n        if parsed_args.category is None:\n            delattr(parsed_args, 'category')\n\n        if self._from_date:\n            parsed_args.from_date = str_to_datetime(parsed_args.from_date)\n        if self._to_date and parsed_args.to_date:\n            parsed_args.to_date = str_to_datetime(parsed_args.to_date)\n        if self._archive and parsed_args.archived_since:\n            parsed_args.archived_since = str_to_datetime(parsed_args.archived_since)\n\n        if self._archive and parsed_args.fetch_archive and parsed_args.no_archive:\n            raise AttributeError(\"fetch-archive and no-archive arguments are not compatible\")\n        if self._archive and parsed_args.fetch_archive and not parsed_args.category:\n            raise AttributeError(\"fetch-archive needs a category to work with\")\n\n        # Set aliases\n        for alias, arg in self.aliases.items():\n            if (alias not in parsed_args) and (arg in parsed_args):\n                value = getattr(parsed_args, arg, None)\n                setattr(parsed_args, alias, value)\n\n        return parsed_args", "code_tokens": ["def", "parse", "(", "self", ",", "*", "args", ")", ":", "parsed_args", "=", "self", ".", "parser", ".", "parse_args", "(", "args", ")", "# Category was not set, remove it", "if", "parsed_args", ".", "category", "is", "None", ":", "delattr", "(", "parsed_args", ",", "'category'", ")", "if", "self", ".", "_from_date", ":", "parsed_args", ".", "from_date", "=", "str_to_datetime", "(", "parsed_args", ".", "from_date", ")", "if", "self", ".", "_to_date", "and", "parsed_args", ".", "to_date", ":", "parsed_args", ".", "to_date", "=", "str_to_datetime", "(", "parsed_args", ".", "to_date", ")", "if", "self", ".", "_archive", "and", "parsed_args", ".", "archived_since", ":", "parsed_args", ".", "archived_since", "=", "str_to_datetime", "(", "parsed_args", ".", "archived_since", ")", "if", "self", ".", "_archive", "and", "parsed_args", ".", "fetch_archive", "and", "parsed_args", ".", "no_archive", ":", "raise", "AttributeError", "(", "\"fetch-archive and no-archive arguments are not compatible\"", ")", "if", "self", ".", "_archive", "and", "parsed_args", ".", "fetch_archive", "and", "not", "parsed_args", ".", "category", ":", "raise", "AttributeError", "(", "\"fetch-archive needs a category to work with\"", ")", "# Set aliases", "for", "alias", ",", "arg", "in", "self", ".", "aliases", ".", "items", "(", ")", ":", "if", "(", "alias", "not", "in", "parsed_args", ")", "and", "(", "arg", "in", "parsed_args", ")", ":", "value", "=", "getattr", "(", "parsed_args", ",", "arg", ",", "None", ")", "setattr", "(", "parsed_args", ",", "alias", ",", "value", ")", "return", "parsed_args"], "docstring": "Parse a list of arguments.\n\n        Parse argument strings needed to run a backend command. The result\n        will be a `argparse.Namespace` object populated with the values\n        obtained after the validation of the parameters.\n\n        :param args: argument strings\n\n        :result: an object with the parsed values", "docstring_tokens": ["Parse", "a", "list", "of", "arguments", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L340-L375", "partition": "test", "index": 3251, "time": "2016-12-20 20:23:16"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "BackendCommand.run", "original_string": "def run(self):\n        \"\"\"Fetch and write items.\n\n        This method runs the backend to fetch the items from the given\n        origin. Items are converted to JSON objects and written to the\n        defined output.\n\n        If `fetch-archive` parameter was given as an argument during\n        the inizialization of the instance, the items will be retrieved\n        using the archive manager.\n        \"\"\"\n        backend_args = vars(self.parsed_args)\n        category = backend_args.pop('category', None)\n        filter_classified = backend_args.pop('filter_classified', False)\n        archived_since = backend_args.pop('archived_since', None)\n\n        if self.archive_manager and self.parsed_args.fetch_archive:\n            items = fetch_from_archive(self.BACKEND, backend_args,\n                                       self.archive_manager,\n                                       category,\n                                       archived_since)\n        else:\n            items = fetch(self.BACKEND, backend_args, category,\n                          filter_classified=filter_classified,\n                          manager=self.archive_manager)\n\n        try:\n            for item in items:\n                if self.json_line:\n                    obj = json.dumps(item, separators=(',', ':'), sort_keys=True)\n                else:\n                    obj = json.dumps(item, indent=4, sort_keys=True)\n                self.outfile.write(obj)\n                self.outfile.write('\\n')\n        except IOError as e:\n            raise RuntimeError(str(e))\n        except Exception as e:\n            raise RuntimeError(str(e))", "language": "python", "code": "def run(self):\n        \"\"\"Fetch and write items.\n\n        This method runs the backend to fetch the items from the given\n        origin. Items are converted to JSON objects and written to the\n        defined output.\n\n        If `fetch-archive` parameter was given as an argument during\n        the inizialization of the instance, the items will be retrieved\n        using the archive manager.\n        \"\"\"\n        backend_args = vars(self.parsed_args)\n        category = backend_args.pop('category', None)\n        filter_classified = backend_args.pop('filter_classified', False)\n        archived_since = backend_args.pop('archived_since', None)\n\n        if self.archive_manager and self.parsed_args.fetch_archive:\n            items = fetch_from_archive(self.BACKEND, backend_args,\n                                       self.archive_manager,\n                                       category,\n                                       archived_since)\n        else:\n            items = fetch(self.BACKEND, backend_args, category,\n                          filter_classified=filter_classified,\n                          manager=self.archive_manager)\n\n        try:\n            for item in items:\n                if self.json_line:\n                    obj = json.dumps(item, separators=(',', ':'), sort_keys=True)\n                else:\n                    obj = json.dumps(item, indent=4, sort_keys=True)\n                self.outfile.write(obj)\n                self.outfile.write('\\n')\n        except IOError as e:\n            raise RuntimeError(str(e))\n        except Exception as e:\n            raise RuntimeError(str(e))", "code_tokens": ["def", "run", "(", "self", ")", ":", "backend_args", "=", "vars", "(", "self", ".", "parsed_args", ")", "category", "=", "backend_args", ".", "pop", "(", "'category'", ",", "None", ")", "filter_classified", "=", "backend_args", ".", "pop", "(", "'filter_classified'", ",", "False", ")", "archived_since", "=", "backend_args", ".", "pop", "(", "'archived_since'", ",", "None", ")", "if", "self", ".", "archive_manager", "and", "self", ".", "parsed_args", ".", "fetch_archive", ":", "items", "=", "fetch_from_archive", "(", "self", ".", "BACKEND", ",", "backend_args", ",", "self", ".", "archive_manager", ",", "category", ",", "archived_since", ")", "else", ":", "items", "=", "fetch", "(", "self", ".", "BACKEND", ",", "backend_args", ",", "category", ",", "filter_classified", "=", "filter_classified", ",", "manager", "=", "self", ".", "archive_manager", ")", "try", ":", "for", "item", "in", "items", ":", "if", "self", ".", "json_line", ":", "obj", "=", "json", ".", "dumps", "(", "item", ",", "separators", "=", "(", "','", ",", "':'", ")", ",", "sort_keys", "=", "True", ")", "else", ":", "obj", "=", "json", ".", "dumps", "(", "item", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "self", ".", "outfile", ".", "write", "(", "obj", ")", "self", ".", "outfile", ".", "write", "(", "'\\n'", ")", "except", "IOError", "as", "e", ":", "raise", "RuntimeError", "(", "str", "(", "e", ")", ")", "except", "Exception", "as", "e", ":", "raise", "RuntimeError", "(", "str", "(", "e", ")", ")"], "docstring": "Fetch and write items.\n\n        This method runs the backend to fetch the items from the given\n        origin. Items are converted to JSON objects and written to the\n        defined output.\n\n        If `fetch-archive` parameter was given as an argument during\n        the inizialization of the instance, the items will be retrieved\n        using the archive manager.", "docstring_tokens": ["Fetch", "and", "write", "items", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L445-L482", "partition": "test", "index": 3255, "time": "2016-12-20 20:23:16"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "BackendCommandArgumentParser._set_auth_arguments", "original_string": "def _set_auth_arguments(self, basic_auth=True, token_auth=False):\n        \"\"\"Activate authentication arguments parsing\"\"\"\n\n        group = self.parser.add_argument_group('authentication arguments')\n\n        if basic_auth:\n            group.add_argument('-u', '--backend-user', dest='user',\n                               help=\"backend user\")\n            group.add_argument('-p', '--backend-password', dest='password',\n                               help=\"backend password\")\n        if token_auth:\n            group.add_argument('-t', '--api-token', dest='api_token',\n                               help=\"backend authentication token / API key\")", "language": "python", "code": "def _set_auth_arguments(self, basic_auth=True, token_auth=False):\n        \"\"\"Activate authentication arguments parsing\"\"\"\n\n        group = self.parser.add_argument_group('authentication arguments')\n\n        if basic_auth:\n            group.add_argument('-u', '--backend-user', dest='user',\n                               help=\"backend user\")\n            group.add_argument('-p', '--backend-password', dest='password',\n                               help=\"backend password\")\n        if token_auth:\n            group.add_argument('-t', '--api-token', dest='api_token',\n                               help=\"backend authentication token / API key\")", "code_tokens": ["def", "_set_auth_arguments", "(", "self", ",", "basic_auth", "=", "True", ",", "token_auth", "=", "False", ")", ":", "group", "=", "self", ".", "parser", ".", "add_argument_group", "(", "'authentication arguments'", ")", "if", "basic_auth", ":", "group", ".", "add_argument", "(", "'-u'", ",", "'--backend-user'", ",", "dest", "=", "'user'", ",", "help", "=", "\"backend user\"", ")", "group", ".", "add_argument", "(", "'-p'", ",", "'--backend-password'", ",", "dest", "=", "'password'", ",", "help", "=", "\"backend password\"", ")", "if", "token_auth", ":", "group", ".", "add_argument", "(", "'-t'", ",", "'--api-token'", ",", "dest", "=", "'api_token'", ",", "help", "=", "\"backend authentication token / API key\"", ")"], "docstring": "Activate authentication arguments parsing", "docstring_tokens": ["Activate", "authentication", "arguments", "parsing"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L377-L389", "partition": "test", "index": 3252, "time": "2016-12-20 20:23:16"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "BackendCommand._initialize_archive", "original_string": "def _initialize_archive(self):\n        \"\"\"Initialize archive based on the parsed parameters\"\"\"\n\n        if 'archive_path' not in self.parsed_args:\n            manager = None\n        elif self.parsed_args.no_archive:\n            manager = None\n        else:\n            if not self.parsed_args.archive_path:\n                archive_path = os.path.expanduser(ARCHIVES_DEFAULT_PATH)\n            else:\n                archive_path = self.parsed_args.archive_path\n\n            manager = ArchiveManager(archive_path)\n\n        self.archive_manager = manager", "language": "python", "code": "def _initialize_archive(self):\n        \"\"\"Initialize archive based on the parsed parameters\"\"\"\n\n        if 'archive_path' not in self.parsed_args:\n            manager = None\n        elif self.parsed_args.no_archive:\n            manager = None\n        else:\n            if not self.parsed_args.archive_path:\n                archive_path = os.path.expanduser(ARCHIVES_DEFAULT_PATH)\n            else:\n                archive_path = self.parsed_args.archive_path\n\n            manager = ArchiveManager(archive_path)\n\n        self.archive_manager = manager", "code_tokens": ["def", "_initialize_archive", "(", "self", ")", ":", "if", "'archive_path'", "not", "in", "self", ".", "parsed_args", ":", "manager", "=", "None", "elif", "self", ".", "parsed_args", ".", "no_archive", ":", "manager", "=", "None", "else", ":", "if", "not", "self", ".", "parsed_args", ".", "archive_path", ":", "archive_path", "=", "os", ".", "path", ".", "expanduser", "(", "ARCHIVES_DEFAULT_PATH", ")", "else", ":", "archive_path", "=", "self", ".", "parsed_args", ".", "archive_path", "manager", "=", "ArchiveManager", "(", "archive_path", ")", "self", ".", "archive_manager", "=", "manager"], "docstring": "Initialize archive based on the parsed parameters", "docstring_tokens": ["Initialize", "archive", "based", "on", "the", "parsed", "parameters"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L492-L507", "partition": "test", "index": 3256, "time": "2016-12-24 17:44:25"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository.count_objects", "original_string": "def count_objects(self):\n        \"\"\"Count the objects of a repository.\n\n        The method returns the total number of objects (packed and unpacked)\n        available on the repository.\n\n        :raises RepositoryError: when an error occurs counting the objects\n            of a repository\n        \"\"\"\n        cmd_count = ['git', 'count-objects', '-v']\n\n        outs = self._exec(cmd_count, cwd=self.dirpath, env=self.gitenv)\n        outs = outs.decode('utf-8', errors='surrogateescape').rstrip()\n\n        try:\n            cobjs = {k: v for k, v in (x.split(': ') for x in outs.split('\\n'))}\n            nobjs = int(cobjs['count']) + int(cobjs['in-pack'])\n        except KeyError as e:\n            error = \"unable to parse 'count-objects' output; reason: '%s' entry not found\" \\\n                % e.args[0]\n            raise RepositoryError(cause=error)\n        except ValueError as e:\n            error = \"unable to parse 'count-objects' output; reason: %s\" % str(e)\n            raise RepositoryError(cause=error)\n\n        logger.debug(\"Git %s repository has %s objects\",\n                     self.uri, str(nobjs))\n\n        return nobjs", "language": "python", "code": "def count_objects(self):\n        \"\"\"Count the objects of a repository.\n\n        The method returns the total number of objects (packed and unpacked)\n        available on the repository.\n\n        :raises RepositoryError: when an error occurs counting the objects\n            of a repository\n        \"\"\"\n        cmd_count = ['git', 'count-objects', '-v']\n\n        outs = self._exec(cmd_count, cwd=self.dirpath, env=self.gitenv)\n        outs = outs.decode('utf-8', errors='surrogateescape').rstrip()\n\n        try:\n            cobjs = {k: v for k, v in (x.split(': ') for x in outs.split('\\n'))}\n            nobjs = int(cobjs['count']) + int(cobjs['in-pack'])\n        except KeyError as e:\n            error = \"unable to parse 'count-objects' output; reason: '%s' entry not found\" \\\n                % e.args[0]\n            raise RepositoryError(cause=error)\n        except ValueError as e:\n            error = \"unable to parse 'count-objects' output; reason: %s\" % str(e)\n            raise RepositoryError(cause=error)\n\n        logger.debug(\"Git %s repository has %s objects\",\n                     self.uri, str(nobjs))\n\n        return nobjs", "code_tokens": ["def", "count_objects", "(", "self", ")", ":", "cmd_count", "=", "[", "'git'", ",", "'count-objects'", ",", "'-v'", "]", "outs", "=", "self", ".", "_exec", "(", "cmd_count", ",", "cwd", "=", "self", ".", "dirpath", ",", "env", "=", "self", ".", "gitenv", ")", "outs", "=", "outs", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "'surrogateescape'", ")", ".", "rstrip", "(", ")", "try", ":", "cobjs", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "(", "x", ".", "split", "(", "': '", ")", "for", "x", "in", "outs", ".", "split", "(", "'\\n'", ")", ")", "}", "nobjs", "=", "int", "(", "cobjs", "[", "'count'", "]", ")", "+", "int", "(", "cobjs", "[", "'in-pack'", "]", ")", "except", "KeyError", "as", "e", ":", "error", "=", "\"unable to parse 'count-objects' output; reason: '%s' entry not found\"", "%", "e", ".", "args", "[", "0", "]", "raise", "RepositoryError", "(", "cause", "=", "error", ")", "except", "ValueError", "as", "e", ":", "error", "=", "\"unable to parse 'count-objects' output; reason: %s\"", "%", "str", "(", "e", ")", "raise", "RepositoryError", "(", "cause", "=", "error", ")", "logger", ".", "debug", "(", "\"Git %s repository has %s objects\"", ",", "self", ".", "uri", ",", "str", "(", "nobjs", ")", ")", "return", "nobjs"], "docstring": "Count the objects of a repository.\n\n        The method returns the total number of objects (packed and unpacked)\n        available on the repository.\n\n        :raises RepositoryError: when an error occurs counting the objects\n            of a repository", "docstring_tokens": ["Count", "the", "objects", "of", "a", "repository", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L831-L859", "partition": "test", "index": 3271, "time": "2017-01-11 13:37:04"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mbox.py", "func_name": "_MBox.get_message", "original_string": "def get_message(self, key):\n        \"\"\"Return a Message representation or raise a KeyError.\"\"\"\n\n        start, stop = self._lookup(key)\n        self._file.seek(start)\n        from_line = self._file.readline().replace(mailbox.linesep, b'')\n        string = self._file.read(stop - self._file.tell())\n        msg = self._message_factory(string.replace(mailbox.linesep, b'\\n'))\n\n        try:\n            msg.set_from(from_line[5:].decode('ascii'))\n            return msg\n        except UnicodeDecodeError:\n            pass\n\n        try:\n            msg.set_from(from_line[5:].decode('utf-8'))\n        except UnicodeDecodeError:\n            msg.set_from(from_line[5:].decode('iso-8859-1'))\n\n        return msg", "language": "python", "code": "def get_message(self, key):\n        \"\"\"Return a Message representation or raise a KeyError.\"\"\"\n\n        start, stop = self._lookup(key)\n        self._file.seek(start)\n        from_line = self._file.readline().replace(mailbox.linesep, b'')\n        string = self._file.read(stop - self._file.tell())\n        msg = self._message_factory(string.replace(mailbox.linesep, b'\\n'))\n\n        try:\n            msg.set_from(from_line[5:].decode('ascii'))\n            return msg\n        except UnicodeDecodeError:\n            pass\n\n        try:\n            msg.set_from(from_line[5:].decode('utf-8'))\n        except UnicodeDecodeError:\n            msg.set_from(from_line[5:].decode('iso-8859-1'))\n\n        return msg", "code_tokens": ["def", "get_message", "(", "self", ",", "key", ")", ":", "start", ",", "stop", "=", "self", ".", "_lookup", "(", "key", ")", "self", ".", "_file", ".", "seek", "(", "start", ")", "from_line", "=", "self", ".", "_file", ".", "readline", "(", ")", ".", "replace", "(", "mailbox", ".", "linesep", ",", "b''", ")", "string", "=", "self", ".", "_file", ".", "read", "(", "stop", "-", "self", ".", "_file", ".", "tell", "(", ")", ")", "msg", "=", "self", ".", "_message_factory", "(", "string", ".", "replace", "(", "mailbox", ".", "linesep", ",", "b'\\n'", ")", ")", "try", ":", "msg", ".", "set_from", "(", "from_line", "[", "5", ":", "]", ".", "decode", "(", "'ascii'", ")", ")", "return", "msg", "except", "UnicodeDecodeError", ":", "pass", "try", ":", "msg", ".", "set_from", "(", "from_line", "[", "5", ":", "]", ".", "decode", "(", "'utf-8'", ")", ")", "except", "UnicodeDecodeError", ":", "msg", ".", "set_from", "(", "from_line", "[", "5", ":", "]", ".", "decode", "(", "'iso-8859-1'", ")", ")", "return", "msg"], "docstring": "Return a Message representation or raise a KeyError.", "docstring_tokens": ["Return", "a", "Message", "representation", "or", "raise", "a", "KeyError", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mbox.py#L303-L323", "partition": "test", "index": 3263, "time": "2017-01-27 11:54:40"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/utils.py", "func_name": "months_range", "original_string": "def months_range(from_date, to_date):\n    \"\"\"Generate a months range.\n\n    Generator of months starting on `from_date` util `to_date`. Each\n    returned item is a tuple of two datatime objects like in (month, month+1).\n    Thus, the result will follow the sequence:\n        ((fd, fd+1), (fd+1, fd+2), ..., (td-2, td-1), (td-1, td))\n\n    :param from_date: generate dates starting on this month\n    :param to_date: generate dates until this month\n\n    :result: a generator of months range\n    \"\"\"\n    start = datetime.datetime(from_date.year, from_date.month, 1)\n    end = datetime.datetime(to_date.year, to_date.month, 1)\n\n    month_gen = dateutil.rrule.rrule(freq=dateutil.rrule.MONTHLY,\n                                     dtstart=start, until=end)\n    months = [d for d in month_gen]\n\n    pos = 0\n    for x in range(1, len(months)):\n        yield months[pos], months[x]\n        pos = x", "language": "python", "code": "def months_range(from_date, to_date):\n    \"\"\"Generate a months range.\n\n    Generator of months starting on `from_date` util `to_date`. Each\n    returned item is a tuple of two datatime objects like in (month, month+1).\n    Thus, the result will follow the sequence:\n        ((fd, fd+1), (fd+1, fd+2), ..., (td-2, td-1), (td-1, td))\n\n    :param from_date: generate dates starting on this month\n    :param to_date: generate dates until this month\n\n    :result: a generator of months range\n    \"\"\"\n    start = datetime.datetime(from_date.year, from_date.month, 1)\n    end = datetime.datetime(to_date.year, to_date.month, 1)\n\n    month_gen = dateutil.rrule.rrule(freq=dateutil.rrule.MONTHLY,\n                                     dtstart=start, until=end)\n    months = [d for d in month_gen]\n\n    pos = 0\n    for x in range(1, len(months)):\n        yield months[pos], months[x]\n        pos = x", "code_tokens": ["def", "months_range", "(", "from_date", ",", "to_date", ")", ":", "start", "=", "datetime", ".", "datetime", "(", "from_date", ".", "year", ",", "from_date", ".", "month", ",", "1", ")", "end", "=", "datetime", ".", "datetime", "(", "to_date", ".", "year", ",", "to_date", ".", "month", ",", "1", ")", "month_gen", "=", "dateutil", ".", "rrule", ".", "rrule", "(", "freq", "=", "dateutil", ".", "rrule", ".", "MONTHLY", ",", "dtstart", "=", "start", ",", "until", "=", "end", ")", "months", "=", "[", "d", "for", "d", "in", "month_gen", "]", "pos", "=", "0", "for", "x", "in", "range", "(", "1", ",", "len", "(", "months", ")", ")", ":", "yield", "months", "[", "pos", "]", ",", "months", "[", "x", "]", "pos", "=", "x"], "docstring": "Generate a months range.\n\n    Generator of months starting on `from_date` util `to_date`. Each\n    returned item is a tuple of two datatime objects like in (month, month+1).\n    Thus, the result will follow the sequence:\n        ((fd, fd+1), (fd+1, fd+2), ..., (td-2, td-1), (td-1, td))\n\n    :param from_date: generate dates starting on this month\n    :param to_date: generate dates until this month\n\n    :result: a generator of months range", "docstring_tokens": ["Generate", "a", "months", "range", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/utils.py#L79-L102", "partition": "test", "index": 3333, "time": "2017-01-31 12:08:26"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository.is_detached", "original_string": "def is_detached(self):\n        \"\"\"Check if the repo is in a detached state.\n\n        The repository is in a detached state when HEAD is not a symbolic\n        reference.\n\n        :returns: whether the repository is detached or not\n\n        :raises RepositoryError: when an error occurs checking the state\n            of the repository\n        \"\"\"\n        cmd_sym = ['git', 'symbolic-ref', 'HEAD']\n\n        try:\n            self._exec(cmd_sym, cwd=self.dirpath, env=self.gitenv)\n        except RepositoryError as e:\n            if e.msg.find(\"ref HEAD is not a symbolic ref\") == -1:\n                raise e\n            return True\n        else:\n            return False", "language": "python", "code": "def is_detached(self):\n        \"\"\"Check if the repo is in a detached state.\n\n        The repository is in a detached state when HEAD is not a symbolic\n        reference.\n\n        :returns: whether the repository is detached or not\n\n        :raises RepositoryError: when an error occurs checking the state\n            of the repository\n        \"\"\"\n        cmd_sym = ['git', 'symbolic-ref', 'HEAD']\n\n        try:\n            self._exec(cmd_sym, cwd=self.dirpath, env=self.gitenv)\n        except RepositoryError as e:\n            if e.msg.find(\"ref HEAD is not a symbolic ref\") == -1:\n                raise e\n            return True\n        else:\n            return False", "code_tokens": ["def", "is_detached", "(", "self", ")", ":", "cmd_sym", "=", "[", "'git'", ",", "'symbolic-ref'", ",", "'HEAD'", "]", "try", ":", "self", ".", "_exec", "(", "cmd_sym", ",", "cwd", "=", "self", ".", "dirpath", ",", "env", "=", "self", ".", "gitenv", ")", "except", "RepositoryError", "as", "e", ":", "if", "e", ".", "msg", ".", "find", "(", "\"ref HEAD is not a symbolic ref\"", ")", "==", "-", "1", ":", "raise", "e", "return", "True", "else", ":", "return", "False"], "docstring": "Check if the repo is in a detached state.\n\n        The repository is in a detached state when HEAD is not a symbolic\n        reference.\n\n        :returns: whether the repository is detached or not\n\n        :raises RepositoryError: when an error occurs checking the state\n            of the repository", "docstring_tokens": ["Check", "if", "the", "repo", "is", "in", "a", "detached", "state", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L861-L881", "partition": "test", "index": 3272, "time": "2017-02-02 11:34:02"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/utils.py", "func_name": "message_to_dict", "original_string": "def message_to_dict(msg):\n    \"\"\"Convert an email message into a dictionary.\n\n    This function transforms an `email.message.Message` object\n    into a dictionary. Headers are stored as key:value pairs\n    while the body of the message is stored inside `body` key.\n    Body may have two other keys inside, 'plain', for plain body\n    messages and 'html', for HTML encoded messages.\n\n    The returned dictionary has the type `requests.structures.CaseInsensitiveDict`\n    due to same headers with different case formats can appear in\n    the same message.\n\n    :param msg: email message of type `email.message.Message`\n\n    :returns : dictionary of type `requests.structures.CaseInsensitiveDict`\n\n    :raises ParseError: when an error occurs transforming the message\n        to a dictionary\n    \"\"\"\n    def parse_headers(msg):\n        headers = {}\n\n        for header, value in msg.items():\n            hv = []\n\n            for text, charset in email.header.decode_header(value):\n                if type(text) == bytes:\n                    charset = charset if charset else 'utf-8'\n                    try:\n                        text = text.decode(charset, errors='surrogateescape')\n                    except (UnicodeError, LookupError):\n                        # Try again with a 7bit encoding\n                        text = text.decode('ascii', errors='surrogateescape')\n                hv.append(text)\n\n            v = ' '.join(hv)\n            headers[header] = v if v else None\n\n        return headers\n\n    def parse_payload(msg):\n        body = {}\n\n        if not msg.is_multipart():\n            payload = decode_payload(msg)\n            subtype = msg.get_content_subtype()\n            body[subtype] = [payload]\n        else:\n            # Include all the attached texts if it is multipart\n            # Ignores binary parts by default\n            for part in email.iterators.typed_subpart_iterator(msg):\n                payload = decode_payload(part)\n                subtype = part.get_content_subtype()\n                body.setdefault(subtype, []).append(payload)\n\n        return {k: '\\n'.join(v) for k, v in body.items()}\n\n    def decode_payload(msg_or_part):\n        charset = msg_or_part.get_content_charset('utf-8')\n        payload = msg_or_part.get_payload(decode=True)\n\n        try:\n            payload = payload.decode(charset, errors='surrogateescape')\n        except (UnicodeError, LookupError):\n            # Try again with a 7bit encoding\n            payload = payload.decode('ascii', errors='surrogateescape')\n        return payload\n\n    # The function starts here\n    message = requests.structures.CaseInsensitiveDict()\n\n    if isinstance(msg, mailbox.mboxMessage):\n        message['unixfrom'] = msg.get_from()\n    else:\n        message['unixfrom'] = None\n\n    try:\n        for k, v in parse_headers(msg).items():\n            message[k] = v\n        message['body'] = parse_payload(msg)\n    except UnicodeError as e:\n        raise ParseError(cause=str(e))\n\n    return message", "language": "python", "code": "def message_to_dict(msg):\n    \"\"\"Convert an email message into a dictionary.\n\n    This function transforms an `email.message.Message` object\n    into a dictionary. Headers are stored as key:value pairs\n    while the body of the message is stored inside `body` key.\n    Body may have two other keys inside, 'plain', for plain body\n    messages and 'html', for HTML encoded messages.\n\n    The returned dictionary has the type `requests.structures.CaseInsensitiveDict`\n    due to same headers with different case formats can appear in\n    the same message.\n\n    :param msg: email message of type `email.message.Message`\n\n    :returns : dictionary of type `requests.structures.CaseInsensitiveDict`\n\n    :raises ParseError: when an error occurs transforming the message\n        to a dictionary\n    \"\"\"\n    def parse_headers(msg):\n        headers = {}\n\n        for header, value in msg.items():\n            hv = []\n\n            for text, charset in email.header.decode_header(value):\n                if type(text) == bytes:\n                    charset = charset if charset else 'utf-8'\n                    try:\n                        text = text.decode(charset, errors='surrogateescape')\n                    except (UnicodeError, LookupError):\n                        # Try again with a 7bit encoding\n                        text = text.decode('ascii', errors='surrogateescape')\n                hv.append(text)\n\n            v = ' '.join(hv)\n            headers[header] = v if v else None\n\n        return headers\n\n    def parse_payload(msg):\n        body = {}\n\n        if not msg.is_multipart():\n            payload = decode_payload(msg)\n            subtype = msg.get_content_subtype()\n            body[subtype] = [payload]\n        else:\n            # Include all the attached texts if it is multipart\n            # Ignores binary parts by default\n            for part in email.iterators.typed_subpart_iterator(msg):\n                payload = decode_payload(part)\n                subtype = part.get_content_subtype()\n                body.setdefault(subtype, []).append(payload)\n\n        return {k: '\\n'.join(v) for k, v in body.items()}\n\n    def decode_payload(msg_or_part):\n        charset = msg_or_part.get_content_charset('utf-8')\n        payload = msg_or_part.get_payload(decode=True)\n\n        try:\n            payload = payload.decode(charset, errors='surrogateescape')\n        except (UnicodeError, LookupError):\n            # Try again with a 7bit encoding\n            payload = payload.decode('ascii', errors='surrogateescape')\n        return payload\n\n    # The function starts here\n    message = requests.structures.CaseInsensitiveDict()\n\n    if isinstance(msg, mailbox.mboxMessage):\n        message['unixfrom'] = msg.get_from()\n    else:\n        message['unixfrom'] = None\n\n    try:\n        for k, v in parse_headers(msg).items():\n            message[k] = v\n        message['body'] = parse_payload(msg)\n    except UnicodeError as e:\n        raise ParseError(cause=str(e))\n\n    return message", "code_tokens": ["def", "message_to_dict", "(", "msg", ")", ":", "def", "parse_headers", "(", "msg", ")", ":", "headers", "=", "{", "}", "for", "header", ",", "value", "in", "msg", ".", "items", "(", ")", ":", "hv", "=", "[", "]", "for", "text", ",", "charset", "in", "email", ".", "header", ".", "decode_header", "(", "value", ")", ":", "if", "type", "(", "text", ")", "==", "bytes", ":", "charset", "=", "charset", "if", "charset", "else", "'utf-8'", "try", ":", "text", "=", "text", ".", "decode", "(", "charset", ",", "errors", "=", "'surrogateescape'", ")", "except", "(", "UnicodeError", ",", "LookupError", ")", ":", "# Try again with a 7bit encoding", "text", "=", "text", ".", "decode", "(", "'ascii'", ",", "errors", "=", "'surrogateescape'", ")", "hv", ".", "append", "(", "text", ")", "v", "=", "' '", ".", "join", "(", "hv", ")", "headers", "[", "header", "]", "=", "v", "if", "v", "else", "None", "return", "headers", "def", "parse_payload", "(", "msg", ")", ":", "body", "=", "{", "}", "if", "not", "msg", ".", "is_multipart", "(", ")", ":", "payload", "=", "decode_payload", "(", "msg", ")", "subtype", "=", "msg", ".", "get_content_subtype", "(", ")", "body", "[", "subtype", "]", "=", "[", "payload", "]", "else", ":", "# Include all the attached texts if it is multipart", "# Ignores binary parts by default", "for", "part", "in", "email", ".", "iterators", ".", "typed_subpart_iterator", "(", "msg", ")", ":", "payload", "=", "decode_payload", "(", "part", ")", "subtype", "=", "part", ".", "get_content_subtype", "(", ")", "body", ".", "setdefault", "(", "subtype", ",", "[", "]", ")", ".", "append", "(", "payload", ")", "return", "{", "k", ":", "'\\n'", ".", "join", "(", "v", ")", "for", "k", ",", "v", "in", "body", ".", "items", "(", ")", "}", "def", "decode_payload", "(", "msg_or_part", ")", ":", "charset", "=", "msg_or_part", ".", "get_content_charset", "(", "'utf-8'", ")", "payload", "=", "msg_or_part", ".", "get_payload", "(", "decode", "=", "True", ")", "try", ":", "payload", "=", "payload", ".", "decode", "(", "charset", ",", "errors", "=", "'surrogateescape'", ")", "except", "(", "UnicodeError", ",", "LookupError", ")", ":", "# Try again with a 7bit encoding", "payload", "=", "payload", ".", "decode", "(", "'ascii'", ",", "errors", "=", "'surrogateescape'", ")", "return", "payload", "# The function starts here", "message", "=", "requests", ".", "structures", ".", "CaseInsensitiveDict", "(", ")", "if", "isinstance", "(", "msg", ",", "mailbox", ".", "mboxMessage", ")", ":", "message", "[", "'unixfrom'", "]", "=", "msg", ".", "get_from", "(", ")", "else", ":", "message", "[", "'unixfrom'", "]", "=", "None", "try", ":", "for", "k", ",", "v", "in", "parse_headers", "(", "msg", ")", ".", "items", "(", ")", ":", "message", "[", "k", "]", "=", "v", "message", "[", "'body'", "]", "=", "parse_payload", "(", "msg", ")", "except", "UnicodeError", "as", "e", ":", "raise", "ParseError", "(", "cause", "=", "str", "(", "e", ")", ")", "return", "message"], "docstring": "Convert an email message into a dictionary.\n\n    This function transforms an `email.message.Message` object\n    into a dictionary. Headers are stored as key:value pairs\n    while the body of the message is stored inside `body` key.\n    Body may have two other keys inside, 'plain', for plain body\n    messages and 'html', for HTML encoded messages.\n\n    The returned dictionary has the type `requests.structures.CaseInsensitiveDict`\n    due to same headers with different case formats can appear in\n    the same message.\n\n    :param msg: email message of type `email.message.Message`\n\n    :returns : dictionary of type `requests.structures.CaseInsensitiveDict`\n\n    :raises ParseError: when an error occurs transforming the message\n        to a dictionary", "docstring_tokens": ["Convert", "an", "email", "message", "into", "a", "dictionary", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/utils.py#L105-L189", "partition": "test", "index": 3334, "time": "2017-02-16 10:12:05"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/nntp.py", "func_name": "NNTP.metadata", "original_string": "def metadata(self, item, filter_classified=False):\n        \"\"\"NNTP metadata.\n\n        This method takes items, overriding `metadata` decorator,\n        to add extra information related to NNTP.\n\n        :param item: an item fetched by a backend\n        :param filter_classified: sets if classified fields were filtered\n        \"\"\"\n        item = super().metadata(item, filter_classified=filter_classified)\n        item['offset'] = item['data']['offset']\n\n        return item", "language": "python", "code": "def metadata(self, item, filter_classified=False):\n        \"\"\"NNTP metadata.\n\n        This method takes items, overriding `metadata` decorator,\n        to add extra information related to NNTP.\n\n        :param item: an item fetched by a backend\n        :param filter_classified: sets if classified fields were filtered\n        \"\"\"\n        item = super().metadata(item, filter_classified=filter_classified)\n        item['offset'] = item['data']['offset']\n\n        return item", "code_tokens": ["def", "metadata", "(", "self", ",", "item", ",", "filter_classified", "=", "False", ")", ":", "item", "=", "super", "(", ")", ".", "metadata", "(", "item", ",", "filter_classified", "=", "filter_classified", ")", "item", "[", "'offset'", "]", "=", "item", "[", "'data'", "]", "[", "'offset'", "]", "return", "item"], "docstring": "NNTP metadata.\n\n        This method takes items, overriding `metadata` decorator,\n        to add extra information related to NNTP.\n\n        :param item: an item fetched by a backend\n        :param filter_classified: sets if classified fields were filtered", "docstring_tokens": ["NNTP", "metadata", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/nntp.py#L133-L145", "partition": "test", "index": 3368, "time": "2017-02-16 19:16:02"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/nntp.py", "func_name": "NNTP.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the articles\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        offset = kwargs['offset']\n\n        logger.info(\"Fetching articles of '%s' group on '%s' offset %s\",\n                    self.group, self.host, str(offset))\n\n        narts, iarts, tarts = (0, 0, 0)\n\n        _, _, first, last, _ = self.client.group(self.group)\n\n        if offset <= last:\n            first = max(first, offset)\n            _, overview = self.client.over((first, last))\n        else:\n            overview = []\n\n        tarts = len(overview)\n\n        logger.debug(\"Total number of articles to fetch: %s\", tarts)\n\n        for article_id, _ in overview:\n            try:\n                article_raw = self.client.article(article_id)\n                article = self.__parse_article(article_raw)\n            except ParseError:\n                logger.warning(\"Error parsing %s article; skipping\",\n                               article_id)\n                iarts += 1\n                continue\n            except nntplib.NNTPTemporaryError as e:\n                logger.warning(\"Error '%s' fetching article %s; skipping\",\n                               e.response, article_id)\n                iarts += 1\n                continue\n\n            yield article\n            narts += 1", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the articles\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        offset = kwargs['offset']\n\n        logger.info(\"Fetching articles of '%s' group on '%s' offset %s\",\n                    self.group, self.host, str(offset))\n\n        narts, iarts, tarts = (0, 0, 0)\n\n        _, _, first, last, _ = self.client.group(self.group)\n\n        if offset <= last:\n            first = max(first, offset)\n            _, overview = self.client.over((first, last))\n        else:\n            overview = []\n\n        tarts = len(overview)\n\n        logger.debug(\"Total number of articles to fetch: %s\", tarts)\n\n        for article_id, _ in overview:\n            try:\n                article_raw = self.client.article(article_id)\n                article = self.__parse_article(article_raw)\n            except ParseError:\n                logger.warning(\"Error parsing %s article; skipping\",\n                               article_id)\n                iarts += 1\n                continue\n            except nntplib.NNTPTemporaryError as e:\n                logger.warning(\"Error '%s' fetching article %s; skipping\",\n                               e.response, article_id)\n                iarts += 1\n                continue\n\n            yield article\n            narts += 1", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "offset", "=", "kwargs", "[", "'offset'", "]", "logger", ".", "info", "(", "\"Fetching articles of '%s' group on '%s' offset %s\"", ",", "self", ".", "group", ",", "self", ".", "host", ",", "str", "(", "offset", ")", ")", "narts", ",", "iarts", ",", "tarts", "=", "(", "0", ",", "0", ",", "0", ")", "_", ",", "_", ",", "first", ",", "last", ",", "_", "=", "self", ".", "client", ".", "group", "(", "self", ".", "group", ")", "if", "offset", "<=", "last", ":", "first", "=", "max", "(", "first", ",", "offset", ")", "_", ",", "overview", "=", "self", ".", "client", ".", "over", "(", "(", "first", ",", "last", ")", ")", "else", ":", "overview", "=", "[", "]", "tarts", "=", "len", "(", "overview", ")", "logger", ".", "debug", "(", "\"Total number of articles to fetch: %s\"", ",", "tarts", ")", "for", "article_id", ",", "_", "in", "overview", ":", "try", ":", "article_raw", "=", "self", ".", "client", ".", "article", "(", "article_id", ")", "article", "=", "self", ".", "__parse_article", "(", "article_raw", ")", "except", "ParseError", ":", "logger", ".", "warning", "(", "\"Error parsing %s article; skipping\"", ",", "article_id", ")", "iarts", "+=", "1", "continue", "except", "nntplib", ".", "NNTPTemporaryError", "as", "e", ":", "logger", ".", "warning", "(", "\"Error '%s' fetching article %s; skipping\"", ",", "e", ".", "response", ",", "article_id", ")", "iarts", "+=", "1", "continue", "yield", "article", "narts", "+=", "1"], "docstring": "Fetch the articles\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "the", "articles"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/nntp.py#L88-L131", "partition": "test", "index": 3367, "time": "2017-02-16 19:16:02"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/nntp.py", "func_name": "NNTP.parse_article", "original_string": "def parse_article(raw_article):\n        \"\"\"Parse a NNTP article.\n\n        This method parses a NNTP article stored in a string object\n        and returns an dictionary.\n\n        :param raw_article: NNTP article string\n\n        :returns: a dictionary of type `requests.structures.CaseInsensitiveDict`\n\n        :raises ParseError: when an error is found parsing the article\n        \"\"\"\n        try:\n            message = email.message_from_string(raw_article)\n            article = message_to_dict(message)\n        except UnicodeEncodeError as e:\n            raise ParseError(cause=str(e))\n        return article", "language": "python", "code": "def parse_article(raw_article):\n        \"\"\"Parse a NNTP article.\n\n        This method parses a NNTP article stored in a string object\n        and returns an dictionary.\n\n        :param raw_article: NNTP article string\n\n        :returns: a dictionary of type `requests.structures.CaseInsensitiveDict`\n\n        :raises ParseError: when an error is found parsing the article\n        \"\"\"\n        try:\n            message = email.message_from_string(raw_article)\n            article = message_to_dict(message)\n        except UnicodeEncodeError as e:\n            raise ParseError(cause=str(e))\n        return article", "code_tokens": ["def", "parse_article", "(", "raw_article", ")", ":", "try", ":", "message", "=", "email", ".", "message_from_string", "(", "raw_article", ")", "article", "=", "message_to_dict", "(", "message", ")", "except", "UnicodeEncodeError", "as", "e", ":", "raise", "ParseError", "(", "cause", "=", "str", "(", "e", ")", ")", "return", "article"], "docstring": "Parse a NNTP article.\n\n        This method parses a NNTP article stored in a string object\n        and returns an dictionary.\n\n        :param raw_article: NNTP article string\n\n        :returns: a dictionary of type `requests.structures.CaseInsensitiveDict`\n\n        :raises ParseError: when an error is found parsing the article", "docstring_tokens": ["Parse", "a", "NNTP", "article", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/nntp.py#L199-L216", "partition": "test", "index": 3369, "time": "2017-02-16 19:16:02"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/slack.py", "func_name": "SlackClient.user", "original_string": "def user(self, user_id):\n        \"\"\"Fetch user info.\"\"\"\n\n        resource = self.RUSER_INFO\n\n        params = {\n            self.PUSER: user_id\n        }\n\n        response = self._fetch(resource, params)\n\n        return response", "language": "python", "code": "def user(self, user_id):\n        \"\"\"Fetch user info.\"\"\"\n\n        resource = self.RUSER_INFO\n\n        params = {\n            self.PUSER: user_id\n        }\n\n        response = self._fetch(resource, params)\n\n        return response", "code_tokens": ["def", "user", "(", "self", ",", "user_id", ")", ":", "resource", "=", "self", ".", "RUSER_INFO", "params", "=", "{", "self", ".", "PUSER", ":", "user_id", "}", "response", "=", "self", ".", "_fetch", "(", "resource", ",", "params", ")", "return", "response"], "docstring": "Fetch user info.", "docstring_tokens": ["Fetch", "user", "info", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/slack.py#L376-L387", "partition": "test", "index": 3194, "time": "2017-02-20 19:55:24"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/slack.py", "func_name": "Slack.fetch", "original_string": "def fetch(self, category=CATEGORY_MESSAGE, from_date=DEFAULT_DATETIME):\n        \"\"\"Fetch the messages from the channel.\n\n        This method fetches the messages stored on the channel that were\n        sent since the given date.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain messages sent since this date\n\n        :returns: a generator of messages\n        \"\"\"\n        if not from_date:\n            from_date = DEFAULT_DATETIME\n\n        from_date = datetime_to_utc(from_date)\n        latest = datetime_utcnow().timestamp()\n\n        kwargs = {'from_date': from_date, 'latest': latest}\n        items = super().fetch(category, **kwargs)\n\n        return items", "language": "python", "code": "def fetch(self, category=CATEGORY_MESSAGE, from_date=DEFAULT_DATETIME):\n        \"\"\"Fetch the messages from the channel.\n\n        This method fetches the messages stored on the channel that were\n        sent since the given date.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain messages sent since this date\n\n        :returns: a generator of messages\n        \"\"\"\n        if not from_date:\n            from_date = DEFAULT_DATETIME\n\n        from_date = datetime_to_utc(from_date)\n        latest = datetime_utcnow().timestamp()\n\n        kwargs = {'from_date': from_date, 'latest': latest}\n        items = super().fetch(category, **kwargs)\n\n        return items", "code_tokens": ["def", "fetch", "(", "self", ",", "category", "=", "CATEGORY_MESSAGE", ",", "from_date", "=", "DEFAULT_DATETIME", ")", ":", "if", "not", "from_date", ":", "from_date", "=", "DEFAULT_DATETIME", "from_date", "=", "datetime_to_utc", "(", "from_date", ")", "latest", "=", "datetime_utcnow", "(", ")", ".", "timestamp", "(", ")", "kwargs", "=", "{", "'from_date'", ":", "from_date", ",", "'latest'", ":", "latest", "}", "items", "=", "super", "(", ")", ".", "fetch", "(", "category", ",", "*", "*", "kwargs", ")", "return", "items"], "docstring": "Fetch the messages from the channel.\n\n        This method fetches the messages stored on the channel that were\n        sent since the given date.\n\n        :param category: the category of items to fetch\n        :param from_date: obtain messages sent since this date\n\n        :returns: a generator of messages", "docstring_tokens": ["Fetch", "the", "messages", "from", "the", "channel", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/slack.py#L76-L96", "partition": "test", "index": 3190, "time": "2017-02-21 14:57:10"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/slack.py", "func_name": "Slack.metadata_id", "original_string": "def metadata_id(item):\n        \"\"\"Extracts the identifier from a Slack item.\n\n        This identifier will be the mix of two fields because Slack\n        messages does not have any unique identifier. In this case,\n        'ts' and 'user' values (or 'bot_id' when the message is sent by a bot)\n        are combined because there have been cases where two messages were sent\n        by different users at the same time.\n        \"\"\"\n        if 'user' in item:\n            nick = item['user']\n        elif 'comment' in item:\n            nick = item['comment']['user']\n        else:\n            nick = item['bot_id']\n\n        return item['ts'] + nick", "language": "python", "code": "def metadata_id(item):\n        \"\"\"Extracts the identifier from a Slack item.\n\n        This identifier will be the mix of two fields because Slack\n        messages does not have any unique identifier. In this case,\n        'ts' and 'user' values (or 'bot_id' when the message is sent by a bot)\n        are combined because there have been cases where two messages were sent\n        by different users at the same time.\n        \"\"\"\n        if 'user' in item:\n            nick = item['user']\n        elif 'comment' in item:\n            nick = item['comment']['user']\n        else:\n            nick = item['bot_id']\n\n        return item['ts'] + nick", "code_tokens": ["def", "metadata_id", "(", "item", ")", ":", "if", "'user'", "in", "item", ":", "nick", "=", "item", "[", "'user'", "]", "elif", "'comment'", "in", "item", ":", "nick", "=", "item", "[", "'comment'", "]", "[", "'user'", "]", "else", ":", "nick", "=", "item", "[", "'bot_id'", "]", "return", "item", "[", "'ts'", "]", "+", "nick"], "docstring": "Extracts the identifier from a Slack item.\n\n        This identifier will be the mix of two fields because Slack\n        messages does not have any unique identifier. In this case,\n        'ts' and 'user' values (or 'bot_id' when the message is sent by a bot)\n        are combined because there have been cases where two messages were sent\n        by different users at the same time.", "docstring_tokens": ["Extracts", "the", "identifier", "from", "a", "Slack", "item", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/slack.py#L177-L193", "partition": "test", "index": 3191, "time": "2017-02-21 14:57:10"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/slack.py", "func_name": "SlackCommand.setup_cmd_parser", "original_string": "def setup_cmd_parser(cls):\n        \"\"\"Returns the Slack argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              from_date=True,\n                                              token_auth=True,\n                                              archive=True)\n\n        # Backend token is required\n        action = parser.parser._option_string_actions['--api-token']\n        action.required = True\n\n        # Slack options\n        group = parser.parser.add_argument_group('Slack arguments')\n        group.add_argument('--max-items', dest='max_items',\n                           type=int, default=MAX_ITEMS,\n                           help=\"Maximum number of items requested on the same query\")\n\n        # Required arguments\n        parser.parser.add_argument('channel',\n                                   help=\"Slack channel identifier\")\n\n        return parser", "language": "python", "code": "def setup_cmd_parser(cls):\n        \"\"\"Returns the Slack argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              from_date=True,\n                                              token_auth=True,\n                                              archive=True)\n\n        # Backend token is required\n        action = parser.parser._option_string_actions['--api-token']\n        action.required = True\n\n        # Slack options\n        group = parser.parser.add_argument_group('Slack arguments')\n        group.add_argument('--max-items', dest='max_items',\n                           type=int, default=MAX_ITEMS,\n                           help=\"Maximum number of items requested on the same query\")\n\n        # Required arguments\n        parser.parser.add_argument('channel',\n                                   help=\"Slack channel identifier\")\n\n        return parser", "code_tokens": ["def", "setup_cmd_parser", "(", "cls", ")", ":", "parser", "=", "BackendCommandArgumentParser", "(", "cls", ".", "BACKEND", ".", "CATEGORIES", ",", "from_date", "=", "True", ",", "token_auth", "=", "True", ",", "archive", "=", "True", ")", "# Backend token is required", "action", "=", "parser", ".", "parser", ".", "_option_string_actions", "[", "'--api-token'", "]", "action", ".", "required", "=", "True", "# Slack options", "group", "=", "parser", ".", "parser", ".", "add_argument_group", "(", "'Slack arguments'", ")", "group", ".", "add_argument", "(", "'--max-items'", ",", "dest", "=", "'max_items'", ",", "type", "=", "int", ",", "default", "=", "MAX_ITEMS", ",", "help", "=", "\"Maximum number of items requested on the same query\"", ")", "# Required arguments", "parser", ".", "parser", ".", "add_argument", "(", "'channel'", ",", "help", "=", "\"Slack channel identifier\"", ")", "return", "parser"], "docstring": "Returns the Slack argument parser.", "docstring_tokens": ["Returns", "the", "Slack", "argument", "parser", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/slack.py#L435-L457", "partition": "test", "index": 3195, "time": "2017-02-21 18:03:56"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/slack.py", "func_name": "SlackClient.channel_info", "original_string": "def channel_info(self, channel):\n        \"\"\"Fetch information about a channel.\"\"\"\n\n        resource = self.RCHANNEL_INFO\n\n        params = {\n            self.PCHANNEL: channel,\n        }\n\n        response = self._fetch(resource, params)\n\n        return response", "language": "python", "code": "def channel_info(self, channel):\n        \"\"\"Fetch information about a channel.\"\"\"\n\n        resource = self.RCHANNEL_INFO\n\n        params = {\n            self.PCHANNEL: channel,\n        }\n\n        response = self._fetch(resource, params)\n\n        return response", "code_tokens": ["def", "channel_info", "(", "self", ",", "channel", ")", ":", "resource", "=", "self", ".", "RCHANNEL_INFO", "params", "=", "{", "self", ".", "PCHANNEL", ":", "channel", ",", "}", "response", "=", "self", ".", "_fetch", "(", "resource", ",", "params", ")", "return", "response"], "docstring": "Fetch information about a channel.", "docstring_tokens": ["Fetch", "information", "about", "a", "channel", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/slack.py#L344-L355", "partition": "test", "index": 3193, "time": "2017-03-17 18:27:55"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/dockerhub.py", "func_name": "DockerHubClient.repository", "original_string": "def repository(self, owner, repository):\n        \"\"\"Fetch information about a repository.\"\"\"\n\n        url = urijoin(self.base_url, self.RREPOSITORY, owner, repository)\n\n        logger.debug(\"DockerHub client requests: %s\", url)\n\n        response = self.fetch(url)\n\n        return response.text", "language": "python", "code": "def repository(self, owner, repository):\n        \"\"\"Fetch information about a repository.\"\"\"\n\n        url = urijoin(self.base_url, self.RREPOSITORY, owner, repository)\n\n        logger.debug(\"DockerHub client requests: %s\", url)\n\n        response = self.fetch(url)\n\n        return response.text", "code_tokens": ["def", "repository", "(", "self", ",", "owner", ",", "repository", ")", ":", "url", "=", "urijoin", "(", "self", ".", "base_url", ",", "self", ".", "RREPOSITORY", ",", "owner", ",", "repository", ")", "logger", ".", "debug", "(", "\"DockerHub client requests: %s\"", ",", "url", ")", "response", "=", "self", ".", "fetch", "(", "url", ")", "return", "response", ".", "text"], "docstring": "Fetch information about a repository.", "docstring_tokens": ["Fetch", "information", "about", "a", "repository", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/dockerhub.py#L191-L200", "partition": "test", "index": 3344, "time": "2017-05-25 14:16:20"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/dockerhub.py", "func_name": "DockerHub.fetch", "original_string": "def fetch(self, category=CATEGORY_DOCKERHUB_DATA):\n        \"\"\"Fetch data from a Docker Hub repository.\n\n        The method retrieves, from a repository stored in Docker Hub,\n        its data which includes number of pulls, stars, description,\n        among other data.\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of data\n        \"\"\"\n        kwargs = {}\n        items = super().fetch(category, **kwargs)\n\n        return items", "language": "python", "code": "def fetch(self, category=CATEGORY_DOCKERHUB_DATA):\n        \"\"\"Fetch data from a Docker Hub repository.\n\n        The method retrieves, from a repository stored in Docker Hub,\n        its data which includes number of pulls, stars, description,\n        among other data.\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of data\n        \"\"\"\n        kwargs = {}\n        items = super().fetch(category, **kwargs)\n\n        return items", "code_tokens": ["def", "fetch", "(", "self", ",", "category", "=", "CATEGORY_DOCKERHUB_DATA", ")", ":", "kwargs", "=", "{", "}", "items", "=", "super", "(", ")", ".", "fetch", "(", "category", ",", "*", "*", "kwargs", ")", "return", "items"], "docstring": "Fetch data from a Docker Hub repository.\n\n        The method retrieves, from a repository stored in Docker Hub,\n        its data which includes number of pulls, stars, description,\n        among other data.\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of data", "docstring_tokens": ["Fetch", "data", "from", "a", "Docker", "Hub", "repository", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/dockerhub.py#L76-L90", "partition": "test", "index": 3342, "time": "2017-05-25 19:48:39"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/dockerhub.py", "func_name": "DockerHub.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the Dockher Hub items\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        logger.info(\"Fetching data from '%s' repository of '%s' owner\",\n                    self.repository, self.owner)\n\n        raw_data = self.client.repository(self.owner, self.repository)\n        fetched_on = datetime_utcnow().timestamp()\n\n        data = self.parse_json(raw_data)\n        data['fetched_on'] = fetched_on\n        yield data\n\n        logger.info(\"Fetch process completed\")", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the Dockher Hub items\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        logger.info(\"Fetching data from '%s' repository of '%s' owner\",\n                    self.repository, self.owner)\n\n        raw_data = self.client.repository(self.owner, self.repository)\n        fetched_on = datetime_utcnow().timestamp()\n\n        data = self.parse_json(raw_data)\n        data['fetched_on'] = fetched_on\n        yield data\n\n        logger.info(\"Fetch process completed\")", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "logger", ".", "info", "(", "\"Fetching data from '%s' repository of '%s' owner\"", ",", "self", ".", "repository", ",", "self", ".", "owner", ")", "raw_data", "=", "self", ".", "client", ".", "repository", "(", "self", ".", "owner", ",", "self", ".", "repository", ")", "fetched_on", "=", "datetime_utcnow", "(", ")", ".", "timestamp", "(", ")", "data", "=", "self", ".", "parse_json", "(", "raw_data", ")", "data", "[", "'fetched_on'", "]", "=", "fetched_on", "yield", "data", "logger", ".", "info", "(", "\"Fetch process completed\"", ")"], "docstring": "Fetch the Dockher Hub items\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "the", "Dockher", "Hub", "items"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/dockerhub.py#L92-L110", "partition": "test", "index": 3343, "time": "2017-05-25 19:48:39"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository.show", "original_string": "def show(self, commits=None, encoding='utf-8'):\n        \"\"\"Show the data of a set of commits.\n\n        The method returns the output of Git show command for a\n        set of commits using the following options:\n\n            git show --raw --numstat --pretty=fuller --decorate=full\n                --parents -M -C -c [<commit>...<commit>]\n\n        When the list of commits is empty, the command will return\n        data about the last commit, like the default behaviour of\n        `git show`.\n\n        :param commits: list of commits to show data\n        :param encoding: encode the output using this format\n\n        :returns: a generator where each item is a line from the show output\n\n        :raises EmptyRepositoryError: when the repository is empty and\n            the action cannot be performed\n        :raises RepositoryError: when an error occurs fetching the show output\n        \"\"\"\n        if self.is_empty():\n            logger.warning(\"Git %s repository is empty; unable to run show\",\n                           self.uri)\n            raise EmptyRepositoryError(repository=self.uri)\n\n        if commits is None:\n            commits = []\n\n        cmd_show = ['git', 'show']\n        cmd_show.extend(self.GIT_PRETTY_OUTPUT_OPTS)\n        cmd_show.extend(commits)\n\n        for line in self._exec_nb(cmd_show, cwd=self.dirpath, env=self.gitenv):\n            yield line\n\n        logger.debug(\"Git show fetched from %s repository (%s)\",\n                     self.uri, self.dirpath)", "language": "python", "code": "def show(self, commits=None, encoding='utf-8'):\n        \"\"\"Show the data of a set of commits.\n\n        The method returns the output of Git show command for a\n        set of commits using the following options:\n\n            git show --raw --numstat --pretty=fuller --decorate=full\n                --parents -M -C -c [<commit>...<commit>]\n\n        When the list of commits is empty, the command will return\n        data about the last commit, like the default behaviour of\n        `git show`.\n\n        :param commits: list of commits to show data\n        :param encoding: encode the output using this format\n\n        :returns: a generator where each item is a line from the show output\n\n        :raises EmptyRepositoryError: when the repository is empty and\n            the action cannot be performed\n        :raises RepositoryError: when an error occurs fetching the show output\n        \"\"\"\n        if self.is_empty():\n            logger.warning(\"Git %s repository is empty; unable to run show\",\n                           self.uri)\n            raise EmptyRepositoryError(repository=self.uri)\n\n        if commits is None:\n            commits = []\n\n        cmd_show = ['git', 'show']\n        cmd_show.extend(self.GIT_PRETTY_OUTPUT_OPTS)\n        cmd_show.extend(commits)\n\n        for line in self._exec_nb(cmd_show, cwd=self.dirpath, env=self.gitenv):\n            yield line\n\n        logger.debug(\"Git show fetched from %s repository (%s)\",\n                     self.uri, self.dirpath)", "code_tokens": ["def", "show", "(", "self", ",", "commits", "=", "None", ",", "encoding", "=", "'utf-8'", ")", ":", "if", "self", ".", "is_empty", "(", ")", ":", "logger", ".", "warning", "(", "\"Git %s repository is empty; unable to run show\"", ",", "self", ".", "uri", ")", "raise", "EmptyRepositoryError", "(", "repository", "=", "self", ".", "uri", ")", "if", "commits", "is", "None", ":", "commits", "=", "[", "]", "cmd_show", "=", "[", "'git'", ",", "'show'", "]", "cmd_show", ".", "extend", "(", "self", ".", "GIT_PRETTY_OUTPUT_OPTS", ")", "cmd_show", ".", "extend", "(", "commits", ")", "for", "line", "in", "self", ".", "_exec_nb", "(", "cmd_show", ",", "cwd", "=", "self", ".", "dirpath", ",", "env", "=", "self", ".", "gitenv", ")", ":", "yield", "line", "logger", ".", "debug", "(", "\"Git show fetched from %s repository (%s)\"", ",", "self", ".", "uri", ",", "self", ".", "dirpath", ")"], "docstring": "Show the data of a set of commits.\n\n        The method returns the output of Git show command for a\n        set of commits using the following options:\n\n            git show --raw --numstat --pretty=fuller --decorate=full\n                --parents -M -C -c [<commit>...<commit>]\n\n        When the list of commits is empty, the command will return\n        data about the last commit, like the default behaviour of\n        `git show`.\n\n        :param commits: list of commits to show data\n        :param encoding: encode the output using this format\n\n        :returns: a generator where each item is a line from the show output\n\n        :raises EmptyRepositoryError: when the repository is empty and\n            the action cannot be performed\n        :raises RepositoryError: when an error occurs fetching the show output", "docstring_tokens": ["Show", "the", "data", "of", "a", "set", "of", "commits", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L1043-L1081", "partition": "test", "index": 3277, "time": "2017-06-12 18:56:45"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository._discover_refs", "original_string": "def _discover_refs(self, remote=False):\n        \"\"\"Get the current list of local or remote refs.\"\"\"\n\n        if remote:\n            cmd_refs = ['git', 'ls-remote', '-h', '-t', '--exit-code', 'origin']\n            sep = '\\t'\n            ignored_error_codes = [2]\n        else:\n            # Check first whether the local repo is empty;\n            # Running 'show-ref' in empty repos gives an error\n            if self.is_empty():\n                raise EmptyRepositoryError(repository=self.uri)\n\n            cmd_refs = ['git', 'show-ref', '--heads', '--tags']\n            sep = ' '\n            ignored_error_codes = [1]\n\n        # Error codes returned when no matching refs (i.e, no heads\n        # or tags) are found in a repository will be ignored. Otherwise,\n        # the full process would fail for those situations.\n        outs = self._exec(cmd_refs, cwd=self.dirpath,\n                          env=self.gitenv,\n                          ignored_error_codes=ignored_error_codes)\n        outs = outs.decode('utf-8', errors='surrogateescape').rstrip()\n        outs = outs.split('\\n') if outs else []\n\n        refs = []\n\n        for line in outs:\n            data = line.split(sep)\n            ref = GitRef(data[0], data[1])\n            refs.append(ref)\n\n        return refs", "language": "python", "code": "def _discover_refs(self, remote=False):\n        \"\"\"Get the current list of local or remote refs.\"\"\"\n\n        if remote:\n            cmd_refs = ['git', 'ls-remote', '-h', '-t', '--exit-code', 'origin']\n            sep = '\\t'\n            ignored_error_codes = [2]\n        else:\n            # Check first whether the local repo is empty;\n            # Running 'show-ref' in empty repos gives an error\n            if self.is_empty():\n                raise EmptyRepositoryError(repository=self.uri)\n\n            cmd_refs = ['git', 'show-ref', '--heads', '--tags']\n            sep = ' '\n            ignored_error_codes = [1]\n\n        # Error codes returned when no matching refs (i.e, no heads\n        # or tags) are found in a repository will be ignored. Otherwise,\n        # the full process would fail for those situations.\n        outs = self._exec(cmd_refs, cwd=self.dirpath,\n                          env=self.gitenv,\n                          ignored_error_codes=ignored_error_codes)\n        outs = outs.decode('utf-8', errors='surrogateescape').rstrip()\n        outs = outs.split('\\n') if outs else []\n\n        refs = []\n\n        for line in outs:\n            data = line.split(sep)\n            ref = GitRef(data[0], data[1])\n            refs.append(ref)\n\n        return refs", "code_tokens": ["def", "_discover_refs", "(", "self", ",", "remote", "=", "False", ")", ":", "if", "remote", ":", "cmd_refs", "=", "[", "'git'", ",", "'ls-remote'", ",", "'-h'", ",", "'-t'", ",", "'--exit-code'", ",", "'origin'", "]", "sep", "=", "'\\t'", "ignored_error_codes", "=", "[", "2", "]", "else", ":", "# Check first whether the local repo is empty;", "# Running 'show-ref' in empty repos gives an error", "if", "self", ".", "is_empty", "(", ")", ":", "raise", "EmptyRepositoryError", "(", "repository", "=", "self", ".", "uri", ")", "cmd_refs", "=", "[", "'git'", ",", "'show-ref'", ",", "'--heads'", ",", "'--tags'", "]", "sep", "=", "' '", "ignored_error_codes", "=", "[", "1", "]", "# Error codes returned when no matching refs (i.e, no heads", "# or tags) are found in a repository will be ignored. Otherwise,", "# the full process would fail for those situations.", "outs", "=", "self", ".", "_exec", "(", "cmd_refs", ",", "cwd", "=", "self", ".", "dirpath", ",", "env", "=", "self", ".", "gitenv", ",", "ignored_error_codes", "=", "ignored_error_codes", ")", "outs", "=", "outs", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "'surrogateescape'", ")", ".", "rstrip", "(", ")", "outs", "=", "outs", ".", "split", "(", "'\\n'", ")", "if", "outs", "else", "[", "]", "refs", "=", "[", "]", "for", "line", "in", "outs", ":", "data", "=", "line", ".", "split", "(", "sep", ")", "ref", "=", "GitRef", "(", "data", "[", "0", "]", ",", "data", "[", "1", "]", ")", "refs", ".", "append", "(", "ref", ")", "return", "refs"], "docstring": "Get the current list of local or remote refs.", "docstring_tokens": ["Get", "the", "current", "list", "of", "local", "or", "remote", "refs", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L1169-L1202", "partition": "test", "index": 3281, "time": "2017-06-14 16:21:14"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository._read_commits_from_pack", "original_string": "def _read_commits_from_pack(self, packet_name):\n        \"\"\"Read the commits of a pack.\"\"\"\n\n        filepath = 'objects/pack/pack-' + packet_name\n\n        cmd_verify_pack = ['git', 'verify-pack', '-v', filepath]\n\n        outs = self._exec(cmd_verify_pack, cwd=self.dirpath, env=self.gitenv)\n        outs = outs.decode('utf-8', errors='surrogateescape').rstrip()\n\n        lines = [line.split(' ') for line in outs.split('\\n')]\n\n        # Commits usually come in the pack ordered from newest to oldest\n        commits = [parts[0] for parts in lines if parts[1] == 'commit']\n        commits.reverse()\n\n        return commits", "language": "python", "code": "def _read_commits_from_pack(self, packet_name):\n        \"\"\"Read the commits of a pack.\"\"\"\n\n        filepath = 'objects/pack/pack-' + packet_name\n\n        cmd_verify_pack = ['git', 'verify-pack', '-v', filepath]\n\n        outs = self._exec(cmd_verify_pack, cwd=self.dirpath, env=self.gitenv)\n        outs = outs.decode('utf-8', errors='surrogateescape').rstrip()\n\n        lines = [line.split(' ') for line in outs.split('\\n')]\n\n        # Commits usually come in the pack ordered from newest to oldest\n        commits = [parts[0] for parts in lines if parts[1] == 'commit']\n        commits.reverse()\n\n        return commits", "code_tokens": ["def", "_read_commits_from_pack", "(", "self", ",", "packet_name", ")", ":", "filepath", "=", "'objects/pack/pack-'", "+", "packet_name", "cmd_verify_pack", "=", "[", "'git'", ",", "'verify-pack'", ",", "'-v'", ",", "filepath", "]", "outs", "=", "self", ".", "_exec", "(", "cmd_verify_pack", ",", "cwd", "=", "self", ".", "dirpath", ",", "env", "=", "self", ".", "gitenv", ")", "outs", "=", "outs", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "'surrogateescape'", ")", ".", "rstrip", "(", ")", "lines", "=", "[", "line", ".", "split", "(", "' '", ")", "for", "line", "in", "outs", ".", "split", "(", "'\\n'", ")", "]", "# Commits usually come in the pack ordered from newest to oldest", "commits", "=", "[", "parts", "[", "0", "]", "for", "parts", "in", "lines", "if", "parts", "[", "1", "]", "==", "'commit'", "]", "commits", ".", "reverse", "(", ")", "return", "commits"], "docstring": "Read the commits of a pack.", "docstring_tokens": ["Read", "the", "commits", "of", "a", "pack", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L1119-L1135", "partition": "test", "index": 3279, "time": "2017-06-14 16:21:14"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository._fetch_pack", "original_string": "def _fetch_pack(self):\n        \"\"\"Fetch changes and store them in a pack.\"\"\"\n\n        def prepare_refs(refs):\n            return [ref.hash.encode('utf-8') for ref in refs\n                    if not ref.refname.endswith('^{}')]\n\n        def determine_wants(refs):\n            remote_refs = prepare_refs(self._discover_refs(remote=True))\n            local_refs = prepare_refs(self._discover_refs())\n            wants = [ref for ref in remote_refs if ref not in local_refs]\n            return wants\n\n        client, repo_path = dulwich.client.get_transport_and_path(self.uri)\n        repo = dulwich.repo.Repo(self.dirpath)\n        fd = io.BytesIO()\n\n        local_refs = self._discover_refs()\n        graph_walker = _GraphWalker(local_refs)\n\n        result = client.fetch_pack(repo_path,\n                                   determine_wants,\n                                   graph_walker,\n                                   fd.write)\n        refs = [GitRef(ref_hash.decode('utf-8'), ref_name.decode('utf-8'))\n                for ref_name, ref_hash in result.refs.items()]\n\n        if len(fd.getvalue()) > 0:\n            fd.seek(0)\n            pack = repo.object_store.add_thin_pack(fd.read, None)\n            pack_name = pack.name().decode('utf-8')\n        else:\n            pack_name = None\n\n        return (pack_name, refs)", "language": "python", "code": "def _fetch_pack(self):\n        \"\"\"Fetch changes and store them in a pack.\"\"\"\n\n        def prepare_refs(refs):\n            return [ref.hash.encode('utf-8') for ref in refs\n                    if not ref.refname.endswith('^{}')]\n\n        def determine_wants(refs):\n            remote_refs = prepare_refs(self._discover_refs(remote=True))\n            local_refs = prepare_refs(self._discover_refs())\n            wants = [ref for ref in remote_refs if ref not in local_refs]\n            return wants\n\n        client, repo_path = dulwich.client.get_transport_and_path(self.uri)\n        repo = dulwich.repo.Repo(self.dirpath)\n        fd = io.BytesIO()\n\n        local_refs = self._discover_refs()\n        graph_walker = _GraphWalker(local_refs)\n\n        result = client.fetch_pack(repo_path,\n                                   determine_wants,\n                                   graph_walker,\n                                   fd.write)\n        refs = [GitRef(ref_hash.decode('utf-8'), ref_name.decode('utf-8'))\n                for ref_name, ref_hash in result.refs.items()]\n\n        if len(fd.getvalue()) > 0:\n            fd.seek(0)\n            pack = repo.object_store.add_thin_pack(fd.read, None)\n            pack_name = pack.name().decode('utf-8')\n        else:\n            pack_name = None\n\n        return (pack_name, refs)", "code_tokens": ["def", "_fetch_pack", "(", "self", ")", ":", "def", "prepare_refs", "(", "refs", ")", ":", "return", "[", "ref", ".", "hash", ".", "encode", "(", "'utf-8'", ")", "for", "ref", "in", "refs", "if", "not", "ref", ".", "refname", ".", "endswith", "(", "'^{}'", ")", "]", "def", "determine_wants", "(", "refs", ")", ":", "remote_refs", "=", "prepare_refs", "(", "self", ".", "_discover_refs", "(", "remote", "=", "True", ")", ")", "local_refs", "=", "prepare_refs", "(", "self", ".", "_discover_refs", "(", ")", ")", "wants", "=", "[", "ref", "for", "ref", "in", "remote_refs", "if", "ref", "not", "in", "local_refs", "]", "return", "wants", "client", ",", "repo_path", "=", "dulwich", ".", "client", ".", "get_transport_and_path", "(", "self", ".", "uri", ")", "repo", "=", "dulwich", ".", "repo", ".", "Repo", "(", "self", ".", "dirpath", ")", "fd", "=", "io", ".", "BytesIO", "(", ")", "local_refs", "=", "self", ".", "_discover_refs", "(", ")", "graph_walker", "=", "_GraphWalker", "(", "local_refs", ")", "result", "=", "client", ".", "fetch_pack", "(", "repo_path", ",", "determine_wants", ",", "graph_walker", ",", "fd", ".", "write", ")", "refs", "=", "[", "GitRef", "(", "ref_hash", ".", "decode", "(", "'utf-8'", ")", ",", "ref_name", ".", "decode", "(", "'utf-8'", ")", ")", "for", "ref_name", ",", "ref_hash", "in", "result", ".", "refs", ".", "items", "(", ")", "]", "if", "len", "(", "fd", ".", "getvalue", "(", ")", ")", ">", "0", ":", "fd", ".", "seek", "(", "0", ")", "pack", "=", "repo", ".", "object_store", ".", "add_thin_pack", "(", "fd", ".", "read", ",", "None", ")", "pack_name", "=", "pack", ".", "name", "(", ")", ".", "decode", "(", "'utf-8'", ")", "else", ":", "pack_name", "=", "None", "return", "(", "pack_name", ",", "refs", ")"], "docstring": "Fetch changes and store them in a pack.", "docstring_tokens": ["Fetch", "changes", "and", "store", "them", "in", "a", "pack", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L1083-L1117", "partition": "test", "index": 3278, "time": "2017-06-14 16:21:14"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository._update_ref", "original_string": "def _update_ref(self, ref, delete=False):\n        \"\"\"Update a reference.\"\"\"\n\n        cmd = ['git', 'update-ref']\n\n        if delete:\n            cmd.extend(['-d', ref.refname])\n            action = 'deleted'\n        else:\n            cmd.extend([ref.refname, ref.hash])\n            action = 'updated to %s' % ref.hash\n\n        try:\n            self._exec(cmd, cwd=self.dirpath, env=self.gitenv)\n        except RepositoryError as e:\n            logger.warning(\"Git %s ref could not be %s during sync process in %s (%s); skipped\",\n                           ref.refname, action, self.uri, self.dirpath)\n        else:\n            logger.debug(\"Git %s ref %s in %s (%s)\",\n                         ref.refname, action, self.uri, self.dirpath)", "language": "python", "code": "def _update_ref(self, ref, delete=False):\n        \"\"\"Update a reference.\"\"\"\n\n        cmd = ['git', 'update-ref']\n\n        if delete:\n            cmd.extend(['-d', ref.refname])\n            action = 'deleted'\n        else:\n            cmd.extend([ref.refname, ref.hash])\n            action = 'updated to %s' % ref.hash\n\n        try:\n            self._exec(cmd, cwd=self.dirpath, env=self.gitenv)\n        except RepositoryError as e:\n            logger.warning(\"Git %s ref could not be %s during sync process in %s (%s); skipped\",\n                           ref.refname, action, self.uri, self.dirpath)\n        else:\n            logger.debug(\"Git %s ref %s in %s (%s)\",\n                         ref.refname, action, self.uri, self.dirpath)", "code_tokens": ["def", "_update_ref", "(", "self", ",", "ref", ",", "delete", "=", "False", ")", ":", "cmd", "=", "[", "'git'", ",", "'update-ref'", "]", "if", "delete", ":", "cmd", ".", "extend", "(", "[", "'-d'", ",", "ref", ".", "refname", "]", ")", "action", "=", "'deleted'", "else", ":", "cmd", ".", "extend", "(", "[", "ref", ".", "refname", ",", "ref", ".", "hash", "]", ")", "action", "=", "'updated to %s'", "%", "ref", ".", "hash", "try", ":", "self", ".", "_exec", "(", "cmd", ",", "cwd", "=", "self", ".", "dirpath", ",", "env", "=", "self", ".", "gitenv", ")", "except", "RepositoryError", "as", "e", ":", "logger", ".", "warning", "(", "\"Git %s ref could not be %s during sync process in %s (%s); skipped\"", ",", "ref", ".", "refname", ",", "action", ",", "self", ".", "uri", ",", "self", ".", "dirpath", ")", "else", ":", "logger", ".", "debug", "(", "\"Git %s ref %s in %s (%s)\"", ",", "ref", ".", "refname", ",", "action", ",", "self", ".", "uri", ",", "self", ".", "dirpath", ")"], "docstring": "Update a reference.", "docstring_tokens": ["Update", "a", "reference", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L1204-L1223", "partition": "test", "index": 3282, "time": "2017-06-14 16:21:14"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository._update_references", "original_string": "def _update_references(self, refs):\n        \"\"\"Update references removing old ones.\"\"\"\n\n        new_refs = [ref.refname for ref in refs]\n\n        # Delete old references\n        for old_ref in self._discover_refs():\n            if not old_ref.refname.startswith('refs/heads/'):\n                continue\n            if old_ref.refname in new_refs:\n                continue\n            self._update_ref(old_ref, delete=True)\n\n        # Update new references\n        for new_ref in refs:\n            refname = new_ref.refname\n\n            if refname.endswith('^{}'):\n                logger.debug(\"Annotated tag %s ignored for updating in sync process\",\n                             refname)\n                continue\n            elif not refname.startswith('refs/heads/') and not refname.startswith('refs/tags/'):\n                logger.debug(\"Reference %s not needed; ignored for updating in sync process\",\n                             refname)\n                continue\n            else:\n                self._update_ref(new_ref)\n\n        # Prune repository to remove old branches\n        cmd = ['git', 'remote', 'prune', 'origin']\n        self._exec(cmd, cwd=self.dirpath, env=self.gitenv)", "language": "python", "code": "def _update_references(self, refs):\n        \"\"\"Update references removing old ones.\"\"\"\n\n        new_refs = [ref.refname for ref in refs]\n\n        # Delete old references\n        for old_ref in self._discover_refs():\n            if not old_ref.refname.startswith('refs/heads/'):\n                continue\n            if old_ref.refname in new_refs:\n                continue\n            self._update_ref(old_ref, delete=True)\n\n        # Update new references\n        for new_ref in refs:\n            refname = new_ref.refname\n\n            if refname.endswith('^{}'):\n                logger.debug(\"Annotated tag %s ignored for updating in sync process\",\n                             refname)\n                continue\n            elif not refname.startswith('refs/heads/') and not refname.startswith('refs/tags/'):\n                logger.debug(\"Reference %s not needed; ignored for updating in sync process\",\n                             refname)\n                continue\n            else:\n                self._update_ref(new_ref)\n\n        # Prune repository to remove old branches\n        cmd = ['git', 'remote', 'prune', 'origin']\n        self._exec(cmd, cwd=self.dirpath, env=self.gitenv)", "code_tokens": ["def", "_update_references", "(", "self", ",", "refs", ")", ":", "new_refs", "=", "[", "ref", ".", "refname", "for", "ref", "in", "refs", "]", "# Delete old references", "for", "old_ref", "in", "self", ".", "_discover_refs", "(", ")", ":", "if", "not", "old_ref", ".", "refname", ".", "startswith", "(", "'refs/heads/'", ")", ":", "continue", "if", "old_ref", ".", "refname", "in", "new_refs", ":", "continue", "self", ".", "_update_ref", "(", "old_ref", ",", "delete", "=", "True", ")", "# Update new references", "for", "new_ref", "in", "refs", ":", "refname", "=", "new_ref", ".", "refname", "if", "refname", ".", "endswith", "(", "'^{}'", ")", ":", "logger", ".", "debug", "(", "\"Annotated tag %s ignored for updating in sync process\"", ",", "refname", ")", "continue", "elif", "not", "refname", ".", "startswith", "(", "'refs/heads/'", ")", "and", "not", "refname", ".", "startswith", "(", "'refs/tags/'", ")", ":", "logger", ".", "debug", "(", "\"Reference %s not needed; ignored for updating in sync process\"", ",", "refname", ")", "continue", "else", ":", "self", ".", "_update_ref", "(", "new_ref", ")", "# Prune repository to remove old branches", "cmd", "=", "[", "'git'", ",", "'remote'", ",", "'prune'", ",", "'origin'", "]", "self", ".", "_exec", "(", "cmd", ",", "cwd", "=", "self", ".", "dirpath", ",", "env", "=", "self", ".", "gitenv", ")"], "docstring": "Update references removing old ones.", "docstring_tokens": ["Update", "references", "removing", "old", "ones", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L1137-L1167", "partition": "test", "index": 3280, "time": "2017-06-14 16:21:14"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository.sync", "original_string": "def sync(self):\n        \"\"\"Keep the repository in sync.\n\n        This method will synchronize the repository with its 'origin',\n        fetching newest objects and updating references. It uses low\n        level commands which allow to keep track of which things\n        have changed in the repository.\n\n        The method also returns a list of hashes related to the new\n        commits fetched during the process.\n\n        :returns: list of new commits\n\n        :raises RepositoryError: when an error occurs synchronizing\n            the repository\n        \"\"\"\n        pack_name, refs = self._fetch_pack()\n\n        if pack_name:\n            commits = self._read_commits_from_pack(pack_name)\n        else:\n            commits = []\n            logger.debug(\"Git repository %s (%s) does not have any new object\",\n                         self.uri, self.dirpath)\n\n        self._update_references(refs)\n\n        logger.debug(\"Git repository %s (%s) is synced\",\n                     self.uri, self.dirpath)\n\n        return commits", "language": "python", "code": "def sync(self):\n        \"\"\"Keep the repository in sync.\n\n        This method will synchronize the repository with its 'origin',\n        fetching newest objects and updating references. It uses low\n        level commands which allow to keep track of which things\n        have changed in the repository.\n\n        The method also returns a list of hashes related to the new\n        commits fetched during the process.\n\n        :returns: list of new commits\n\n        :raises RepositoryError: when an error occurs synchronizing\n            the repository\n        \"\"\"\n        pack_name, refs = self._fetch_pack()\n\n        if pack_name:\n            commits = self._read_commits_from_pack(pack_name)\n        else:\n            commits = []\n            logger.debug(\"Git repository %s (%s) does not have any new object\",\n                         self.uri, self.dirpath)\n\n        self._update_references(refs)\n\n        logger.debug(\"Git repository %s (%s) is synced\",\n                     self.uri, self.dirpath)\n\n        return commits", "code_tokens": ["def", "sync", "(", "self", ")", ":", "pack_name", ",", "refs", "=", "self", ".", "_fetch_pack", "(", ")", "if", "pack_name", ":", "commits", "=", "self", ".", "_read_commits_from_pack", "(", "pack_name", ")", "else", ":", "commits", "=", "[", "]", "logger", ".", "debug", "(", "\"Git repository %s (%s) does not have any new object\"", ",", "self", ".", "uri", ",", "self", ".", "dirpath", ")", "self", ".", "_update_references", "(", "refs", ")", "logger", ".", "debug", "(", "\"Git repository %s (%s) is synced\"", ",", "self", ".", "uri", ",", "self", ".", "dirpath", ")", "return", "commits"], "docstring": "Keep the repository in sync.\n\n        This method will synchronize the repository with its 'origin',\n        fetching newest objects and updating references. It uses low\n        level commands which allow to keep track of which things\n        have changed in the repository.\n\n        The method also returns a list of hashes related to the new\n        commits fetched during the process.\n\n        :returns: list of new commits\n\n        :raises RepositoryError: when an error occurs synchronizing\n            the repository", "docstring_tokens": ["Keep", "the", "repository", "in", "sync", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L912-L942", "partition": "test", "index": 3274, "time": "2017-06-14 16:21:14"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "Git.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the commits\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        from_date = kwargs['from_date']\n        to_date = kwargs['to_date']\n        branches = kwargs['branches']\n        latest_items = kwargs['latest_items']\n        no_update = kwargs['no_update']\n\n        ncommits = 0\n\n        try:\n            if os.path.isfile(self.gitpath):\n                commits = self.__fetch_from_log()\n            else:\n                commits = self.__fetch_from_repo(from_date, to_date, branches,\n                                                 latest_items, no_update)\n\n            for commit in commits:\n                yield commit\n                ncommits += 1\n        except EmptyRepositoryError:\n            pass\n\n        logger.info(\"Fetch process completed: %s commits fetched\",\n                    ncommits)", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the commits\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        from_date = kwargs['from_date']\n        to_date = kwargs['to_date']\n        branches = kwargs['branches']\n        latest_items = kwargs['latest_items']\n        no_update = kwargs['no_update']\n\n        ncommits = 0\n\n        try:\n            if os.path.isfile(self.gitpath):\n                commits = self.__fetch_from_log()\n            else:\n                commits = self.__fetch_from_repo(from_date, to_date, branches,\n                                                 latest_items, no_update)\n\n            for commit in commits:\n                yield commit\n                ncommits += 1\n        except EmptyRepositoryError:\n            pass\n\n        logger.info(\"Fetch process completed: %s commits fetched\",\n                    ncommits)", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "from_date", "=", "kwargs", "[", "'from_date'", "]", "to_date", "=", "kwargs", "[", "'to_date'", "]", "branches", "=", "kwargs", "[", "'branches'", "]", "latest_items", "=", "kwargs", "[", "'latest_items'", "]", "no_update", "=", "kwargs", "[", "'no_update'", "]", "ncommits", "=", "0", "try", ":", "if", "os", ".", "path", ".", "isfile", "(", "self", ".", "gitpath", ")", ":", "commits", "=", "self", ".", "__fetch_from_log", "(", ")", "else", ":", "commits", "=", "self", ".", "__fetch_from_repo", "(", "from_date", ",", "to_date", ",", "branches", ",", "latest_items", ",", "no_update", ")", "for", "commit", "in", "commits", ":", "yield", "commit", "ncommits", "+=", "1", "except", "EmptyRepositoryError", ":", "pass", "logger", ".", "info", "(", "\"Fetch process completed: %s commits fetched\"", ",", "ncommits", ")"], "docstring": "Fetch the commits\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "the", "commits"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L134-L164", "partition": "test", "index": 3265, "time": "2017-06-14 19:20:41"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient.user_orgs", "original_string": "def user_orgs(self, login):\n        \"\"\"Get the user public organizations\"\"\"\n        if login in self._users_orgs:\n            return self._users_orgs[login]\n\n        url = urijoin(self.base_url, 'users', login, 'orgs')\n        try:\n            r = self.fetch(url)\n            orgs = r.text\n        except requests.exceptions.HTTPError as error:\n            # 404 not found is wrongly received sometimes\n            if error.response.status_code == 404:\n                logger.error(\"Can't get github login orgs: %s\", error)\n                orgs = '[]'\n            else:\n                raise error\n\n        self._users_orgs[login] = orgs\n\n        return orgs", "language": "python", "code": "def user_orgs(self, login):\n        \"\"\"Get the user public organizations\"\"\"\n        if login in self._users_orgs:\n            return self._users_orgs[login]\n\n        url = urijoin(self.base_url, 'users', login, 'orgs')\n        try:\n            r = self.fetch(url)\n            orgs = r.text\n        except requests.exceptions.HTTPError as error:\n            # 404 not found is wrongly received sometimes\n            if error.response.status_code == 404:\n                logger.error(\"Can't get github login orgs: %s\", error)\n                orgs = '[]'\n            else:\n                raise error\n\n        self._users_orgs[login] = orgs\n\n        return orgs", "code_tokens": ["def", "user_orgs", "(", "self", ",", "login", ")", ":", "if", "login", "in", "self", ".", "_users_orgs", ":", "return", "self", ".", "_users_orgs", "[", "login", "]", "url", "=", "urijoin", "(", "self", ".", "base_url", ",", "'users'", ",", "login", ",", "'orgs'", ")", "try", ":", "r", "=", "self", ".", "fetch", "(", "url", ")", "orgs", "=", "r", ".", "text", "except", "requests", ".", "exceptions", ".", "HTTPError", "as", "error", ":", "# 404 not found is wrongly received sometimes", "if", "error", ".", "response", ".", "status_code", "==", "404", ":", "logger", ".", "error", "(", "\"Can't get github login orgs: %s\"", ",", "error", ")", "orgs", "=", "'[]'", "else", ":", "raise", "error", "self", ".", "_users_orgs", "[", "login", "]", "=", "orgs", "return", "orgs"], "docstring": "Get the user public organizations", "docstring_tokens": ["Get", "the", "user", "public", "organizations"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L694-L713", "partition": "test", "index": 3313, "time": "2017-09-12 11:33:54"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient.issues", "original_string": "def issues(self, from_date=None):\n        \"\"\"Fetch the issues from the repository.\n\n        The method retrieves, from a GitHub repository, the issues\n        updated since the given date.\n\n        :param from_date: obtain issues updated since this date\n\n        :returns: a generator of issues\n        \"\"\"\n        payload = {\n            'state': 'all',\n            'per_page': PER_PAGE,\n            'direction': 'asc',\n            'sort': 'updated'}\n\n        if from_date:\n            payload['since'] = from_date.isoformat()\n\n        path = urijoin(\"issues\")\n        return self.fetch_items(path, payload)", "language": "python", "code": "def issues(self, from_date=None):\n        \"\"\"Fetch the issues from the repository.\n\n        The method retrieves, from a GitHub repository, the issues\n        updated since the given date.\n\n        :param from_date: obtain issues updated since this date\n\n        :returns: a generator of issues\n        \"\"\"\n        payload = {\n            'state': 'all',\n            'per_page': PER_PAGE,\n            'direction': 'asc',\n            'sort': 'updated'}\n\n        if from_date:\n            payload['since'] = from_date.isoformat()\n\n        path = urijoin(\"issues\")\n        return self.fetch_items(path, payload)", "code_tokens": ["def", "issues", "(", "self", ",", "from_date", "=", "None", ")", ":", "payload", "=", "{", "'state'", ":", "'all'", ",", "'per_page'", ":", "PER_PAGE", ",", "'direction'", ":", "'asc'", ",", "'sort'", ":", "'updated'", "}", "if", "from_date", ":", "payload", "[", "'since'", "]", "=", "from_date", ".", "isoformat", "(", ")", "path", "=", "urijoin", "(", "\"issues\"", ")", "return", "self", ".", "fetch_items", "(", "path", ",", "payload", ")"], "docstring": "Fetch the issues from the repository.\n\n        The method retrieves, from a GitHub repository, the issues\n        updated since the given date.\n\n        :param from_date: obtain issues updated since this date\n\n        :returns: a generator of issues", "docstring_tokens": ["Fetch", "the", "issues", "from", "the", "repository", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L578-L598", "partition": "test", "index": 3306, "time": "2017-09-12 11:33:54"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient.user", "original_string": "def user(self, login):\n        \"\"\"Get the user information and update the user cache\"\"\"\n        user = None\n\n        if login in self._users:\n            return self._users[login]\n\n        url_user = urijoin(self.base_url, 'users', login)\n\n        logging.info(\"Getting info for %s\" % (url_user))\n\n        r = self.fetch(url_user)\n        user = r.text\n        self._users[login] = user\n\n        return user", "language": "python", "code": "def user(self, login):\n        \"\"\"Get the user information and update the user cache\"\"\"\n        user = None\n\n        if login in self._users:\n            return self._users[login]\n\n        url_user = urijoin(self.base_url, 'users', login)\n\n        logging.info(\"Getting info for %s\" % (url_user))\n\n        r = self.fetch(url_user)\n        user = r.text\n        self._users[login] = user\n\n        return user", "code_tokens": ["def", "user", "(", "self", ",", "login", ")", ":", "user", "=", "None", "if", "login", "in", "self", ".", "_users", ":", "return", "self", ".", "_users", "[", "login", "]", "url_user", "=", "urijoin", "(", "self", ".", "base_url", ",", "'users'", ",", "login", ")", "logging", ".", "info", "(", "\"Getting info for %s\"", "%", "(", "url_user", ")", ")", "r", "=", "self", ".", "fetch", "(", "url_user", ")", "user", "=", "r", ".", "text", "self", ".", "_users", "[", "login", "]", "=", "user", "return", "user"], "docstring": "Get the user information and update the user cache", "docstring_tokens": ["Get", "the", "user", "information", "and", "update", "the", "user", "cache"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L677-L692", "partition": "test", "index": 3312, "time": "2017-09-12 11:33:54"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.__get_issue_assignees", "original_string": "def __get_issue_assignees(self, raw_assignees):\n        \"\"\"Get issue assignees\"\"\"\n\n        assignees = []\n        for ra in raw_assignees:\n            assignees.append(self.__get_user(ra['login']))\n\n        return assignees", "language": "python", "code": "def __get_issue_assignees(self, raw_assignees):\n        \"\"\"Get issue assignees\"\"\"\n\n        assignees = []\n        for ra in raw_assignees:\n            assignees.append(self.__get_user(ra['login']))\n\n        return assignees", "code_tokens": ["def", "__get_issue_assignees", "(", "self", ",", "raw_assignees", ")", ":", "assignees", "=", "[", "]", "for", "ra", "in", "raw_assignees", ":", "assignees", ".", "append", "(", "self", ".", "__get_user", "(", "ra", "[", "'login'", "]", ")", ")", "return", "assignees"], "docstring": "Get issue assignees", "docstring_tokens": ["Get", "issue", "assignees"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L367-L374", "partition": "test", "index": 3300, "time": "2017-09-13 09:57:10"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.__get_issue_comment_reactions", "original_string": "def __get_issue_comment_reactions(self, comment_id, total_count):\n        \"\"\"Get reactions on issue comments\"\"\"\n\n        reactions = []\n\n        if total_count == 0:\n            return reactions\n\n        group_reactions = self.client.issue_comment_reactions(comment_id)\n\n        for raw_reactions in group_reactions:\n\n            for reaction in json.loads(raw_reactions):\n                reaction['user_data'] = self.__get_user(reaction['user']['login'])\n                reactions.append(reaction)\n\n        return reactions", "language": "python", "code": "def __get_issue_comment_reactions(self, comment_id, total_count):\n        \"\"\"Get reactions on issue comments\"\"\"\n\n        reactions = []\n\n        if total_count == 0:\n            return reactions\n\n        group_reactions = self.client.issue_comment_reactions(comment_id)\n\n        for raw_reactions in group_reactions:\n\n            for reaction in json.loads(raw_reactions):\n                reaction['user_data'] = self.__get_user(reaction['user']['login'])\n                reactions.append(reaction)\n\n        return reactions", "code_tokens": ["def", "__get_issue_comment_reactions", "(", "self", ",", "comment_id", ",", "total_count", ")", ":", "reactions", "=", "[", "]", "if", "total_count", "==", "0", ":", "return", "reactions", "group_reactions", "=", "self", ".", "client", ".", "issue_comment_reactions", "(", "comment_id", ")", "for", "raw_reactions", "in", "group_reactions", ":", "for", "reaction", "in", "json", ".", "loads", "(", "raw_reactions", ")", ":", "reaction", "[", "'user_data'", "]", "=", "self", ".", "__get_user", "(", "reaction", "[", "'user'", "]", "[", "'login'", "]", ")", "reactions", ".", "append", "(", "reaction", ")", "return", "reactions"], "docstring": "Get reactions on issue comments", "docstring_tokens": ["Get", "reactions", "on", "issue", "comments"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L342-L358", "partition": "test", "index": 3299, "time": "2017-09-14 12:14:04"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient.issue_reactions", "original_string": "def issue_reactions(self, issue_number):\n        \"\"\"Get reactions of an issue\"\"\"\n\n        payload = {\n            'per_page': PER_PAGE,\n            'direction': 'asc',\n            'sort': 'updated'\n        }\n\n        path = urijoin(\"issues\", str(issue_number), \"reactions\")\n        return self.fetch_items(path, payload)", "language": "python", "code": "def issue_reactions(self, issue_number):\n        \"\"\"Get reactions of an issue\"\"\"\n\n        payload = {\n            'per_page': PER_PAGE,\n            'direction': 'asc',\n            'sort': 'updated'\n        }\n\n        path = urijoin(\"issues\", str(issue_number), \"reactions\")\n        return self.fetch_items(path, payload)", "code_tokens": ["def", "issue_reactions", "(", "self", ",", "issue_number", ")", ":", "payload", "=", "{", "'per_page'", ":", "PER_PAGE", ",", "'direction'", ":", "'asc'", ",", "'sort'", ":", "'updated'", "}", "path", "=", "urijoin", "(", "\"issues\"", ",", "str", "(", "issue_number", ")", ",", "\"reactions\"", ")", "return", "self", ".", "fetch_items", "(", "path", ",", "payload", ")"], "docstring": "Get reactions of an issue", "docstring_tokens": ["Get", "reactions", "of", "an", "issue"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L542-L552", "partition": "test", "index": 3305, "time": "2017-09-14 14:41:02"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.__get_issue_reactions", "original_string": "def __get_issue_reactions(self, issue_number, total_count):\n        \"\"\"Get issue reactions\"\"\"\n\n        reactions = []\n\n        if total_count == 0:\n            return reactions\n\n        group_reactions = self.client.issue_reactions(issue_number)\n\n        for raw_reactions in group_reactions:\n\n            for reaction in json.loads(raw_reactions):\n                reaction['user_data'] = self.__get_user(reaction['user']['login'])\n                reactions.append(reaction)\n\n        return reactions", "language": "python", "code": "def __get_issue_reactions(self, issue_number, total_count):\n        \"\"\"Get issue reactions\"\"\"\n\n        reactions = []\n\n        if total_count == 0:\n            return reactions\n\n        group_reactions = self.client.issue_reactions(issue_number)\n\n        for raw_reactions in group_reactions:\n\n            for reaction in json.loads(raw_reactions):\n                reaction['user_data'] = self.__get_user(reaction['user']['login'])\n                reactions.append(reaction)\n\n        return reactions", "code_tokens": ["def", "__get_issue_reactions", "(", "self", ",", "issue_number", ",", "total_count", ")", ":", "reactions", "=", "[", "]", "if", "total_count", "==", "0", ":", "return", "reactions", "group_reactions", "=", "self", ".", "client", ".", "issue_reactions", "(", "issue_number", ")", "for", "raw_reactions", "in", "group_reactions", ":", "for", "reaction", "in", "json", ".", "loads", "(", "raw_reactions", ")", ":", "reaction", "[", "'user_data'", "]", "=", "self", ".", "__get_user", "(", "reaction", "[", "'user'", "]", "[", "'login'", "]", ")", "reactions", ".", "append", "(", "reaction", ")", "return", "reactions"], "docstring": "Get issue reactions", "docstring_tokens": ["Get", "issue", "reactions"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L307-L323", "partition": "test", "index": 3298, "time": "2017-09-14 14:41:02"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/launchpad.py", "func_name": "LaunchpadClient.issue", "original_string": "def issue(self, issue_id):\n        \"\"\"Get the issue data by its ID\"\"\"\n\n        path = urijoin(\"bugs\", str(issue_id))\n        url_issue = self.__get_url(path)\n        raw_text = self.__send_request(url_issue)\n\n        return raw_text", "language": "python", "code": "def issue(self, issue_id):\n        \"\"\"Get the issue data by its ID\"\"\"\n\n        path = urijoin(\"bugs\", str(issue_id))\n        url_issue = self.__get_url(path)\n        raw_text = self.__send_request(url_issue)\n\n        return raw_text", "code_tokens": ["def", "issue", "(", "self", ",", "issue_id", ")", ":", "path", "=", "urijoin", "(", "\"bugs\"", ",", "str", "(", "issue_id", ")", ")", "url_issue", "=", "self", ".", "__get_url", "(", "path", ")", "raw_text", "=", "self", ".", "__send_request", "(", "url_issue", ")", "return", "raw_text"], "docstring": "Get the issue data by its ID", "docstring_tokens": ["Get", "the", "issue", "data", "by", "its", "ID"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/launchpad.py#L338-L345", "partition": "test", "index": 3236, "time": "2017-09-26 13:00:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/launchpad.py", "func_name": "LaunchpadClient.issue_collection", "original_string": "def issue_collection(self, issue_id, collection_name):\n        \"\"\"Get a collection list of a given issue\"\"\"\n\n        path = urijoin(\"bugs\", str(issue_id), collection_name)\n        url_collection = self.__get_url(path)\n        payload = {'ws.size': self.items_per_page, 'ws.start': 0, 'order_by': 'date_last_updated'}\n\n        raw_items = self.__fetch_items(path=url_collection, payload=payload)\n\n        return raw_items", "language": "python", "code": "def issue_collection(self, issue_id, collection_name):\n        \"\"\"Get a collection list of a given issue\"\"\"\n\n        path = urijoin(\"bugs\", str(issue_id), collection_name)\n        url_collection = self.__get_url(path)\n        payload = {'ws.size': self.items_per_page, 'ws.start': 0, 'order_by': 'date_last_updated'}\n\n        raw_items = self.__fetch_items(path=url_collection, payload=payload)\n\n        return raw_items", "code_tokens": ["def", "issue_collection", "(", "self", ",", "issue_id", ",", "collection_name", ")", ":", "path", "=", "urijoin", "(", "\"bugs\"", ",", "str", "(", "issue_id", ")", ",", "collection_name", ")", "url_collection", "=", "self", ".", "__get_url", "(", "path", ")", "payload", "=", "{", "'ws.size'", ":", "self", ".", "items_per_page", ",", "'ws.start'", ":", "0", ",", "'order_by'", ":", "'date_last_updated'", "}", "raw_items", "=", "self", ".", "__fetch_items", "(", "path", "=", "url_collection", ",", "payload", "=", "payload", ")", "return", "raw_items"], "docstring": "Get a collection list of a given issue", "docstring_tokens": ["Get", "a", "collection", "list", "of", "a", "given", "issue"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/launchpad.py#L347-L356", "partition": "test", "index": 3237, "time": "2017-09-26 13:00:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/launchpad.py", "func_name": "Launchpad.__fetch_issue_activities", "original_string": "def __fetch_issue_activities(self, issue_id):\n        \"\"\"Get activities on an issue\"\"\"\n\n        for activities_raw in self.client.issue_collection(issue_id, \"activity\"):\n            activities = json.loads(activities_raw)\n\n            for act in activities['entries']:\n                act['person_data'] = self.__fetch_user_data('{PERSON}', act['person_link'])\n                yield act", "language": "python", "code": "def __fetch_issue_activities(self, issue_id):\n        \"\"\"Get activities on an issue\"\"\"\n\n        for activities_raw in self.client.issue_collection(issue_id, \"activity\"):\n            activities = json.loads(activities_raw)\n\n            for act in activities['entries']:\n                act['person_data'] = self.__fetch_user_data('{PERSON}', act['person_link'])\n                yield act", "code_tokens": ["def", "__fetch_issue_activities", "(", "self", ",", "issue_id", ")", ":", "for", "activities_raw", "in", "self", ".", "client", ".", "issue_collection", "(", "issue_id", ",", "\"activity\"", ")", ":", "activities", "=", "json", ".", "loads", "(", "activities_raw", ")", "for", "act", "in", "activities", "[", "'entries'", "]", ":", "act", "[", "'person_data'", "]", "=", "self", ".", "__fetch_user_data", "(", "'{PERSON}'", ",", "act", "[", "'person_link'", "]", ")", "yield", "act"], "docstring": "Get activities on an issue", "docstring_tokens": ["Get", "activities", "on", "an", "issue"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/launchpad.py#L248-L256", "partition": "test", "index": 3233, "time": "2017-09-26 13:00:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/launchpad.py", "func_name": "LaunchpadClient.__get_url_project", "original_string": "def __get_url_project(self):\n        \"\"\"Build URL project\"\"\"\n\n        if self.package:\n            url = self.__get_url_distribution_package()\n        else:\n            url = self.__get_url_distribution()\n\n        return url", "language": "python", "code": "def __get_url_project(self):\n        \"\"\"Build URL project\"\"\"\n\n        if self.package:\n            url = self.__get_url_distribution_package()\n        else:\n            url = self.__get_url_distribution()\n\n        return url", "code_tokens": ["def", "__get_url_project", "(", "self", ")", ":", "if", "self", ".", "package", ":", "url", "=", "self", ".", "__get_url_distribution_package", "(", ")", "else", ":", "url", "=", "self", ".", "__get_url_distribution", "(", ")", "return", "url"], "docstring": "Build URL project", "docstring_tokens": ["Build", "URL", "project"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/launchpad.py#L358-L366", "partition": "test", "index": 3238, "time": "2017-09-26 13:00:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/launchpad.py", "func_name": "LaunchpadClient.__fetch_items", "original_string": "def __fetch_items(self, path, payload):\n        \"\"\"Return the items from Launchpad API using pagination\"\"\"\n\n        page = 0  # current page\n        url_next = path\n        fetch_data = True\n\n        while fetch_data:\n            logger.debug(\"Fetching page: %i\", page)\n\n            try:\n                raw_content = self.__send_request(url_next, payload)\n                content = json.loads(raw_content)\n            except requests.exceptions.HTTPError as e:\n                if e.response.status_code in [410]:\n                    logger.warning(\"Data is not available - %s\", url_next)\n                    raw_content = '{\"total_size\": 0, \"start\": 0, \"entries\": []}'\n                    content = json.loads(raw_content)\n                else:\n                    raise e\n\n            if 'next_collection_link' in content:\n                url_next = content['next_collection_link']\n                payload = None\n            else:\n                fetch_data = False\n\n            yield raw_content\n            page += 1", "language": "python", "code": "def __fetch_items(self, path, payload):\n        \"\"\"Return the items from Launchpad API using pagination\"\"\"\n\n        page = 0  # current page\n        url_next = path\n        fetch_data = True\n\n        while fetch_data:\n            logger.debug(\"Fetching page: %i\", page)\n\n            try:\n                raw_content = self.__send_request(url_next, payload)\n                content = json.loads(raw_content)\n            except requests.exceptions.HTTPError as e:\n                if e.response.status_code in [410]:\n                    logger.warning(\"Data is not available - %s\", url_next)\n                    raw_content = '{\"total_size\": 0, \"start\": 0, \"entries\": []}'\n                    content = json.loads(raw_content)\n                else:\n                    raise e\n\n            if 'next_collection_link' in content:\n                url_next = content['next_collection_link']\n                payload = None\n            else:\n                fetch_data = False\n\n            yield raw_content\n            page += 1", "code_tokens": ["def", "__fetch_items", "(", "self", ",", "path", ",", "payload", ")", ":", "page", "=", "0", "# current page", "url_next", "=", "path", "fetch_data", "=", "True", "while", "fetch_data", ":", "logger", ".", "debug", "(", "\"Fetching page: %i\"", ",", "page", ")", "try", ":", "raw_content", "=", "self", ".", "__send_request", "(", "url_next", ",", "payload", ")", "content", "=", "json", ".", "loads", "(", "raw_content", ")", "except", "requests", ".", "exceptions", ".", "HTTPError", "as", "e", ":", "if", "e", ".", "response", ".", "status_code", "in", "[", "410", "]", ":", "logger", ".", "warning", "(", "\"Data is not available - %s\"", ",", "url_next", ")", "raw_content", "=", "'{\"total_size\": 0, \"start\": 0, \"entries\": []}'", "content", "=", "json", ".", "loads", "(", "raw_content", ")", "else", ":", "raise", "e", "if", "'next_collection_link'", "in", "content", ":", "url_next", "=", "content", "[", "'next_collection_link'", "]", "payload", "=", "None", "else", ":", "fetch_data", "=", "False", "yield", "raw_content", "page", "+=", "1"], "docstring": "Return the items from Launchpad API using pagination", "docstring_tokens": ["Return", "the", "items", "from", "Launchpad", "API", "using", "pagination"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/launchpad.py#L418-L446", "partition": "test", "index": 3239, "time": "2017-09-26 13:00:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/launchpad.py", "func_name": "Launchpad.__fetch_issue_attachments", "original_string": "def __fetch_issue_attachments(self, issue_id):\n        \"\"\"Get attachments of an issue\"\"\"\n\n        for attachments_raw in self.client.issue_collection(issue_id, \"attachments\"):\n            attachments = json.loads(attachments_raw)\n\n            for attachment in attachments['entries']:\n                yield attachment", "language": "python", "code": "def __fetch_issue_attachments(self, issue_id):\n        \"\"\"Get attachments of an issue\"\"\"\n\n        for attachments_raw in self.client.issue_collection(issue_id, \"attachments\"):\n            attachments = json.loads(attachments_raw)\n\n            for attachment in attachments['entries']:\n                yield attachment", "code_tokens": ["def", "__fetch_issue_attachments", "(", "self", ",", "issue_id", ")", ":", "for", "attachments_raw", "in", "self", ".", "client", ".", "issue_collection", "(", "issue_id", ",", "\"attachments\"", ")", ":", "attachments", "=", "json", ".", "loads", "(", "attachments_raw", ")", "for", "attachment", "in", "attachments", "[", "'entries'", "]", ":", "yield", "attachment"], "docstring": "Get attachments of an issue", "docstring_tokens": ["Get", "attachments", "of", "an", "issue"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/launchpad.py#L229-L236", "partition": "test", "index": 3231, "time": "2017-09-26 13:00:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/launchpad.py", "func_name": "Launchpad.__fetch_issue_data", "original_string": "def __fetch_issue_data(self, issue_id):\n        \"\"\"Get data associated to an issue\"\"\"\n\n        raw_issue = self.client.issue(issue_id)\n        issue = json.loads(raw_issue)\n\n        return issue", "language": "python", "code": "def __fetch_issue_data(self, issue_id):\n        \"\"\"Get data associated to an issue\"\"\"\n\n        raw_issue = self.client.issue(issue_id)\n        issue = json.loads(raw_issue)\n\n        return issue", "code_tokens": ["def", "__fetch_issue_data", "(", "self", ",", "issue_id", ")", ":", "raw_issue", "=", "self", ".", "client", ".", "issue", "(", "issue_id", ")", "issue", "=", "json", ".", "loads", "(", "raw_issue", ")", "return", "issue"], "docstring": "Get data associated to an issue", "docstring_tokens": ["Get", "data", "associated", "to", "an", "issue"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/launchpad.py#L221-L227", "partition": "test", "index": 3230, "time": "2017-09-26 13:00:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/launchpad.py", "func_name": "Launchpad.__fetch_user_data", "original_string": "def __fetch_user_data(self, tag_type, user_link):\n        \"\"\"Get data associated to an user\"\"\"\n\n        user_name = self.client.user_name(user_link)\n\n        user = {}\n\n        if not user_name:\n            return user\n\n        user_raw = self.client.user(user_name)\n        user = json.loads(user_raw)\n\n        return user", "language": "python", "code": "def __fetch_user_data(self, tag_type, user_link):\n        \"\"\"Get data associated to an user\"\"\"\n\n        user_name = self.client.user_name(user_link)\n\n        user = {}\n\n        if not user_name:\n            return user\n\n        user_raw = self.client.user(user_name)\n        user = json.loads(user_raw)\n\n        return user", "code_tokens": ["def", "__fetch_user_data", "(", "self", ",", "tag_type", ",", "user_link", ")", ":", "user_name", "=", "self", ".", "client", ".", "user_name", "(", "user_link", ")", "user", "=", "{", "}", "if", "not", "user_name", ":", "return", "user", "user_raw", "=", "self", ".", "client", ".", "user", "(", "user_name", ")", "user", "=", "json", ".", "loads", "(", "user_raw", ")", "return", "user"], "docstring": "Get data associated to an user", "docstring_tokens": ["Get", "data", "associated", "to", "an", "user"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/launchpad.py#L258-L271", "partition": "test", "index": 3234, "time": "2017-09-26 13:00:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/launchpad.py", "func_name": "LaunchpadClient.user", "original_string": "def user(self, user_name):\n        \"\"\"Get the user data by URL\"\"\"\n\n        user = None\n\n        if user_name in self._users:\n            return self._users[user_name]\n\n        url_user = self.__get_url(\"~\" + user_name)\n\n        logger.info(\"Getting info for %s\" % (url_user))\n\n        try:\n            raw_user = self.__send_request(url_user)\n            user = raw_user\n        except requests.exceptions.HTTPError as e:\n            if e.response.status_code in [404, 410]:\n                logger.warning(\"Data is not available - %s\", url_user)\n                user = '{}'\n            else:\n                raise e\n\n        self._users[user_name] = user\n\n        return user", "language": "python", "code": "def user(self, user_name):\n        \"\"\"Get the user data by URL\"\"\"\n\n        user = None\n\n        if user_name in self._users:\n            return self._users[user_name]\n\n        url_user = self.__get_url(\"~\" + user_name)\n\n        logger.info(\"Getting info for %s\" % (url_user))\n\n        try:\n            raw_user = self.__send_request(url_user)\n            user = raw_user\n        except requests.exceptions.HTTPError as e:\n            if e.response.status_code in [404, 410]:\n                logger.warning(\"Data is not available - %s\", url_user)\n                user = '{}'\n            else:\n                raise e\n\n        self._users[user_name] = user\n\n        return user", "code_tokens": ["def", "user", "(", "self", ",", "user_name", ")", ":", "user", "=", "None", "if", "user_name", "in", "self", ".", "_users", ":", "return", "self", ".", "_users", "[", "user_name", "]", "url_user", "=", "self", ".", "__get_url", "(", "\"~\"", "+", "user_name", ")", "logger", ".", "info", "(", "\"Getting info for %s\"", "%", "(", "url_user", ")", ")", "try", ":", "raw_user", "=", "self", ".", "__send_request", "(", "url_user", ")", "user", "=", "raw_user", "except", "requests", ".", "exceptions", ".", "HTTPError", "as", "e", ":", "if", "e", ".", "response", ".", "status_code", "in", "[", "404", ",", "410", "]", ":", "logger", ".", "warning", "(", "\"Data is not available - %s\"", ",", "url_user", ")", "user", "=", "'{}'", "else", ":", "raise", "e", "self", ".", "_users", "[", "user_name", "]", "=", "user", "return", "user"], "docstring": "Get the user data by URL", "docstring_tokens": ["Get", "the", "user", "data", "by", "URL"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/launchpad.py#L307-L331", "partition": "test", "index": 3235, "time": "2017-09-26 13:00:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/launchpad.py", "func_name": "Launchpad.__fetch_issue_messages", "original_string": "def __fetch_issue_messages(self, issue_id):\n        \"\"\"Get messages of an issue\"\"\"\n\n        for messages_raw in self.client.issue_collection(issue_id, \"messages\"):\n            messages = json.loads(messages_raw)\n\n            for msg in messages['entries']:\n                msg['owner_data'] = self.__fetch_user_data('{OWNER}', msg['owner_link'])\n                yield msg", "language": "python", "code": "def __fetch_issue_messages(self, issue_id):\n        \"\"\"Get messages of an issue\"\"\"\n\n        for messages_raw in self.client.issue_collection(issue_id, \"messages\"):\n            messages = json.loads(messages_raw)\n\n            for msg in messages['entries']:\n                msg['owner_data'] = self.__fetch_user_data('{OWNER}', msg['owner_link'])\n                yield msg", "code_tokens": ["def", "__fetch_issue_messages", "(", "self", ",", "issue_id", ")", ":", "for", "messages_raw", "in", "self", ".", "client", ".", "issue_collection", "(", "issue_id", ",", "\"messages\"", ")", ":", "messages", "=", "json", ".", "loads", "(", "messages_raw", ")", "for", "msg", "in", "messages", "[", "'entries'", "]", ":", "msg", "[", "'owner_data'", "]", "=", "self", ".", "__fetch_user_data", "(", "'{OWNER}'", ",", "msg", "[", "'owner_link'", "]", ")", "yield", "msg"], "docstring": "Get messages of an issue", "docstring_tokens": ["Get", "messages", "of", "an", "issue"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/launchpad.py#L238-L246", "partition": "test", "index": 3232, "time": "2017-09-26 13:00:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.metadata_category", "original_string": "def metadata_category(item):\n        \"\"\"Extracts the category from a GitHub item.\n\n        This backend generates two types of item which are\n        'issue' and 'pull_request'.\n        \"\"\"\n\n        if \"base\" in item:\n            category = CATEGORY_PULL_REQUEST\n        elif \"forks_count\" in item:\n            category = CATEGORY_REPO\n        else:\n            category = CATEGORY_ISSUE\n\n        return category", "language": "python", "code": "def metadata_category(item):\n        \"\"\"Extracts the category from a GitHub item.\n\n        This backend generates two types of item which are\n        'issue' and 'pull_request'.\n        \"\"\"\n\n        if \"base\" in item:\n            category = CATEGORY_PULL_REQUEST\n        elif \"forks_count\" in item:\n            category = CATEGORY_REPO\n        else:\n            category = CATEGORY_ISSUE\n\n        return category", "code_tokens": ["def", "metadata_category", "(", "item", ")", ":", "if", "\"base\"", "in", "item", ":", "category", "=", "CATEGORY_PULL_REQUEST", "elif", "\"forks_count\"", "in", "item", ":", "category", "=", "CATEGORY_REPO", "else", ":", "category", "=", "CATEGORY_ISSUE", "return", "category"], "docstring": "Extracts the category from a GitHub item.\n\n        This backend generates two types of item which are\n        'issue' and 'pull_request'.", "docstring_tokens": ["Extracts", "the", "category", "from", "a", "GitHub", "item", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L211-L225", "partition": "test", "index": 3295, "time": "2017-09-28 17:12:26"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.metadata_updated_on", "original_string": "def metadata_updated_on(item):\n        \"\"\"Extracts the update time from a GitHub item.\n\n        The timestamp used is extracted from 'updated_at' field.\n        This date is converted to UNIX timestamp format. As GitHub\n        dates are in UTC the conversion is straightforward.\n\n        :param item: item generated by the backend\n\n        :returns: a UNIX timestamp\n        \"\"\"\n        if \"forks_count\" in item:\n            return item['fetched_on']\n        else:\n            ts = item['updated_at']\n            ts = str_to_datetime(ts)\n\n            return ts.timestamp()", "language": "python", "code": "def metadata_updated_on(item):\n        \"\"\"Extracts the update time from a GitHub item.\n\n        The timestamp used is extracted from 'updated_at' field.\n        This date is converted to UNIX timestamp format. As GitHub\n        dates are in UTC the conversion is straightforward.\n\n        :param item: item generated by the backend\n\n        :returns: a UNIX timestamp\n        \"\"\"\n        if \"forks_count\" in item:\n            return item['fetched_on']\n        else:\n            ts = item['updated_at']\n            ts = str_to_datetime(ts)\n\n            return ts.timestamp()", "code_tokens": ["def", "metadata_updated_on", "(", "item", ")", ":", "if", "\"forks_count\"", "in", "item", ":", "return", "item", "[", "'fetched_on'", "]", "else", ":", "ts", "=", "item", "[", "'updated_at'", "]", "ts", "=", "str_to_datetime", "(", "ts", ")", "return", "ts", ".", "timestamp", "(", ")"], "docstring": "Extracts the update time from a GitHub item.\n\n        The timestamp used is extracted from 'updated_at' field.\n        This date is converted to UNIX timestamp format. As GitHub\n        dates are in UTC the conversion is straightforward.\n\n        :param item: item generated by the backend\n\n        :returns: a UNIX timestamp", "docstring_tokens": ["Extracts", "the", "update", "time", "from", "a", "GitHub", "item", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L191-L208", "partition": "test", "index": 3294, "time": "2017-09-28 17:12:26"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.__get_pull_review_comment_reactions", "original_string": "def __get_pull_review_comment_reactions(self, comment_id, total_count):\n        \"\"\"Get pull review comment reactions\"\"\"\n\n        reactions = []\n\n        if total_count == 0:\n            return reactions\n\n        group_reactions = self.client.pull_review_comment_reactions(comment_id)\n\n        for raw_reactions in group_reactions:\n\n            for reaction in json.loads(raw_reactions):\n                reaction['user_data'] = self.__get_user(reaction['user']['login'])\n                reactions.append(reaction)\n\n        return reactions", "language": "python", "code": "def __get_pull_review_comment_reactions(self, comment_id, total_count):\n        \"\"\"Get pull review comment reactions\"\"\"\n\n        reactions = []\n\n        if total_count == 0:\n            return reactions\n\n        group_reactions = self.client.pull_review_comment_reactions(comment_id)\n\n        for raw_reactions in group_reactions:\n\n            for reaction in json.loads(raw_reactions):\n                reaction['user_data'] = self.__get_user(reaction['user']['login'])\n                reactions.append(reaction)\n\n        return reactions", "code_tokens": ["def", "__get_pull_review_comment_reactions", "(", "self", ",", "comment_id", ",", "total_count", ")", ":", "reactions", "=", "[", "]", "if", "total_count", "==", "0", ":", "return", "reactions", "group_reactions", "=", "self", ".", "client", ".", "pull_review_comment_reactions", "(", "comment_id", ")", "for", "raw_reactions", "in", "group_reactions", ":", "for", "reaction", "in", "json", ".", "loads", "(", "raw_reactions", ")", ":", "reaction", "[", "'user_data'", "]", "=", "self", ".", "__get_user", "(", "reaction", "[", "'user'", "]", "[", "'login'", "]", ")", "reactions", ".", "append", "(", "reaction", ")", "return", "reactions"], "docstring": "Get pull review comment reactions", "docstring_tokens": ["Get", "pull", "review", "comment", "reactions"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L429-L445", "partition": "test", "index": 3303, "time": "2017-10-06 10:27:22"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient.pull_requested_reviewers", "original_string": "def pull_requested_reviewers(self, pr_number):\n        \"\"\"Get pull requested reviewers\"\"\"\n\n        requested_reviewers_url = urijoin(\"pulls\", str(pr_number), \"requested_reviewers\")\n        return self.fetch_items(requested_reviewers_url, {})", "language": "python", "code": "def pull_requested_reviewers(self, pr_number):\n        \"\"\"Get pull requested reviewers\"\"\"\n\n        requested_reviewers_url = urijoin(\"pulls\", str(pr_number), \"requested_reviewers\")\n        return self.fetch_items(requested_reviewers_url, {})", "code_tokens": ["def", "pull_requested_reviewers", "(", "self", ",", "pr_number", ")", ":", "requested_reviewers_url", "=", "urijoin", "(", "\"pulls\"", ",", "str", "(", "pr_number", ")", ",", "\"requested_reviewers\"", ")", "return", "self", ".", "fetch_items", "(", "requested_reviewers_url", ",", "{", "}", ")"], "docstring": "Get pull requested reviewers", "docstring_tokens": ["Get", "pull", "requested", "reviewers"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L637-L641", "partition": "test", "index": 3309, "time": "2017-10-06 10:27:22"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient.pulls", "original_string": "def pulls(self, from_date=None):\n        \"\"\"Fetch the pull requests from the repository.\n\n        The method retrieves, from a GitHub repository, the pull requests\n        updated since the given date.\n\n        :param from_date: obtain pull requests updated since this date\n\n        :returns: a generator of pull requests\n        \"\"\"\n        issues_groups = self.issues(from_date=from_date)\n\n        for raw_issues in issues_groups:\n            issues = json.loads(raw_issues)\n            for issue in issues:\n\n                if \"pull_request\" not in issue:\n                    continue\n\n                pull_number = issue[\"number\"]\n                path = urijoin(self.base_url, 'repos', self.owner, self.repository, \"pulls\", pull_number)\n\n                r = self.fetch(path)\n                pull = r.text\n\n                yield pull", "language": "python", "code": "def pulls(self, from_date=None):\n        \"\"\"Fetch the pull requests from the repository.\n\n        The method retrieves, from a GitHub repository, the pull requests\n        updated since the given date.\n\n        :param from_date: obtain pull requests updated since this date\n\n        :returns: a generator of pull requests\n        \"\"\"\n        issues_groups = self.issues(from_date=from_date)\n\n        for raw_issues in issues_groups:\n            issues = json.loads(raw_issues)\n            for issue in issues:\n\n                if \"pull_request\" not in issue:\n                    continue\n\n                pull_number = issue[\"number\"]\n                path = urijoin(self.base_url, 'repos', self.owner, self.repository, \"pulls\", pull_number)\n\n                r = self.fetch(path)\n                pull = r.text\n\n                yield pull", "code_tokens": ["def", "pulls", "(", "self", ",", "from_date", "=", "None", ")", ":", "issues_groups", "=", "self", ".", "issues", "(", "from_date", "=", "from_date", ")", "for", "raw_issues", "in", "issues_groups", ":", "issues", "=", "json", ".", "loads", "(", "raw_issues", ")", "for", "issue", "in", "issues", ":", "if", "\"pull_request\"", "not", "in", "issue", ":", "continue", "pull_number", "=", "issue", "[", "\"number\"", "]", "path", "=", "urijoin", "(", "self", ".", "base_url", ",", "'repos'", ",", "self", ".", "owner", ",", "self", ".", "repository", ",", "\"pulls\"", ",", "pull_number", ")", "r", "=", "self", ".", "fetch", "(", "path", ")", "pull", "=", "r", ".", "text", "yield", "pull"], "docstring": "Fetch the pull requests from the repository.\n\n        The method retrieves, from a GitHub repository, the pull requests\n        updated since the given date.\n\n        :param from_date: obtain pull requests updated since this date\n\n        :returns: a generator of pull requests", "docstring_tokens": ["Fetch", "the", "pull", "requests", "from", "the", "repository", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L600-L625", "partition": "test", "index": 3307, "time": "2017-10-06 10:27:22"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.__get_pull_requested_reviewers", "original_string": "def __get_pull_requested_reviewers(self, pr_number):\n        \"\"\"Get pull request requested reviewers\"\"\"\n\n        requested_reviewers = []\n        group_requested_reviewers = self.client.pull_requested_reviewers(pr_number)\n\n        for raw_requested_reviewers in group_requested_reviewers:\n            group_requested_reviewers = json.loads(raw_requested_reviewers)\n\n            for requested_reviewer in group_requested_reviewers['users']:\n                user_data = self.__get_user(requested_reviewer['login'])\n                requested_reviewers.append(user_data)\n\n        return requested_reviewers", "language": "python", "code": "def __get_pull_requested_reviewers(self, pr_number):\n        \"\"\"Get pull request requested reviewers\"\"\"\n\n        requested_reviewers = []\n        group_requested_reviewers = self.client.pull_requested_reviewers(pr_number)\n\n        for raw_requested_reviewers in group_requested_reviewers:\n            group_requested_reviewers = json.loads(raw_requested_reviewers)\n\n            for requested_reviewer in group_requested_reviewers['users']:\n                user_data = self.__get_user(requested_reviewer['login'])\n                requested_reviewers.append(user_data)\n\n        return requested_reviewers", "code_tokens": ["def", "__get_pull_requested_reviewers", "(", "self", ",", "pr_number", ")", ":", "requested_reviewers", "=", "[", "]", "group_requested_reviewers", "=", "self", ".", "client", ".", "pull_requested_reviewers", "(", "pr_number", ")", "for", "raw_requested_reviewers", "in", "group_requested_reviewers", ":", "group_requested_reviewers", "=", "json", ".", "loads", "(", "raw_requested_reviewers", ")", "for", "requested_reviewer", "in", "group_requested_reviewers", "[", "'users'", "]", ":", "user_data", "=", "self", ".", "__get_user", "(", "requested_reviewer", "[", "'login'", "]", ")", "requested_reviewers", ".", "append", "(", "user_data", ")", "return", "requested_reviewers"], "docstring": "Get pull request requested reviewers", "docstring_tokens": ["Get", "pull", "request", "requested", "reviewers"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L376-L389", "partition": "test", "index": 3301, "time": "2017-10-06 10:27:22"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.__fetch_pull_requests", "original_string": "def __fetch_pull_requests(self, from_date, to_date):\n        \"\"\"Fetch the pull requests\"\"\"\n\n        raw_pulls = self.client.pulls(from_date=from_date)\n        for raw_pull in raw_pulls:\n            pull = json.loads(raw_pull)\n\n            if str_to_datetime(pull['updated_at']) > to_date:\n                return\n\n            self.__init_extra_pull_fields(pull)\n            for field in TARGET_PULL_FIELDS:\n\n                if not pull[field]:\n                    continue\n\n                if field == 'user':\n                    pull[field + '_data'] = self.__get_user(pull[field]['login'])\n                elif field == 'merged_by':\n                    pull[field + '_data'] = self.__get_user(pull[field]['login'])\n                elif field == 'review_comments':\n                    pull[field + '_data'] = self.__get_pull_review_comments(pull['number'])\n                elif field == 'requested_reviewers':\n                    pull[field + '_data'] = self.__get_pull_requested_reviewers(pull['number'])\n                elif field == 'commits':\n                    pull[field + '_data'] = self.__get_pull_commits(pull['number'])\n\n            yield pull", "language": "python", "code": "def __fetch_pull_requests(self, from_date, to_date):\n        \"\"\"Fetch the pull requests\"\"\"\n\n        raw_pulls = self.client.pulls(from_date=from_date)\n        for raw_pull in raw_pulls:\n            pull = json.loads(raw_pull)\n\n            if str_to_datetime(pull['updated_at']) > to_date:\n                return\n\n            self.__init_extra_pull_fields(pull)\n            for field in TARGET_PULL_FIELDS:\n\n                if not pull[field]:\n                    continue\n\n                if field == 'user':\n                    pull[field + '_data'] = self.__get_user(pull[field]['login'])\n                elif field == 'merged_by':\n                    pull[field + '_data'] = self.__get_user(pull[field]['login'])\n                elif field == 'review_comments':\n                    pull[field + '_data'] = self.__get_pull_review_comments(pull['number'])\n                elif field == 'requested_reviewers':\n                    pull[field + '_data'] = self.__get_pull_requested_reviewers(pull['number'])\n                elif field == 'commits':\n                    pull[field + '_data'] = self.__get_pull_commits(pull['number'])\n\n            yield pull", "code_tokens": ["def", "__fetch_pull_requests", "(", "self", ",", "from_date", ",", "to_date", ")", ":", "raw_pulls", "=", "self", ".", "client", ".", "pulls", "(", "from_date", "=", "from_date", ")", "for", "raw_pull", "in", "raw_pulls", ":", "pull", "=", "json", ".", "loads", "(", "raw_pull", ")", "if", "str_to_datetime", "(", "pull", "[", "'updated_at'", "]", ")", ">", "to_date", ":", "return", "self", ".", "__init_extra_pull_fields", "(", "pull", ")", "for", "field", "in", "TARGET_PULL_FIELDS", ":", "if", "not", "pull", "[", "field", "]", ":", "continue", "if", "field", "==", "'user'", ":", "pull", "[", "field", "+", "'_data'", "]", "=", "self", ".", "__get_user", "(", "pull", "[", "field", "]", "[", "'login'", "]", ")", "elif", "field", "==", "'merged_by'", ":", "pull", "[", "field", "+", "'_data'", "]", "=", "self", ".", "__get_user", "(", "pull", "[", "field", "]", "[", "'login'", "]", ")", "elif", "field", "==", "'review_comments'", ":", "pull", "[", "field", "+", "'_data'", "]", "=", "self", ".", "__get_pull_review_comments", "(", "pull", "[", "'number'", "]", ")", "elif", "field", "==", "'requested_reviewers'", ":", "pull", "[", "field", "+", "'_data'", "]", "=", "self", ".", "__get_pull_requested_reviewers", "(", "pull", "[", "'number'", "]", ")", "elif", "field", "==", "'commits'", ":", "pull", "[", "field", "+", "'_data'", "]", "=", "self", ".", "__get_pull_commits", "(", "pull", "[", "'number'", "]", ")", "yield", "pull"], "docstring": "Fetch the pull requests", "docstring_tokens": ["Fetch", "the", "pull", "requests"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L267-L294", "partition": "test", "index": 3296, "time": "2017-10-06 10:27:22"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient.pull_review_comment_reactions", "original_string": "def pull_review_comment_reactions(self, comment_id):\n        \"\"\"Get reactions of a review comment\"\"\"\n\n        payload = {\n            'per_page': PER_PAGE,\n            'direction': 'asc',\n            'sort': 'updated'\n        }\n\n        path = urijoin(\"pulls\", \"comments\", str(comment_id), \"reactions\")\n        return self.fetch_items(path, payload)", "language": "python", "code": "def pull_review_comment_reactions(self, comment_id):\n        \"\"\"Get reactions of a review comment\"\"\"\n\n        payload = {\n            'per_page': PER_PAGE,\n            'direction': 'asc',\n            'sort': 'updated'\n        }\n\n        path = urijoin(\"pulls\", \"comments\", str(comment_id), \"reactions\")\n        return self.fetch_items(path, payload)", "code_tokens": ["def", "pull_review_comment_reactions", "(", "self", ",", "comment_id", ")", ":", "payload", "=", "{", "'per_page'", ":", "PER_PAGE", ",", "'direction'", ":", "'asc'", ",", "'sort'", ":", "'updated'", "}", "path", "=", "urijoin", "(", "\"pulls\"", ",", "\"comments\"", ",", "str", "(", "comment_id", ")", ",", "\"reactions\"", ")", "return", "self", ".", "fetch_items", "(", "path", ",", "payload", ")"], "docstring": "Get reactions of a review comment", "docstring_tokens": ["Get", "reactions", "of", "a", "review", "comment"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L665-L675", "partition": "test", "index": 3311, "time": "2017-10-06 10:27:22"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/client.py", "func_name": "RateLimitHandler.setup_rate_limit_handler", "original_string": "def setup_rate_limit_handler(self, sleep_for_rate=False, min_rate_to_sleep=MIN_RATE_LIMIT,\n                                 rate_limit_header=RATE_LIMIT_HEADER,\n                                 rate_limit_reset_header=RATE_LIMIT_RESET_HEADER):\n        \"\"\"Setup the rate limit handler.\n\n        :param sleep_for_rate: sleep until rate limit is reset\n        :param min_rate_to_sleep: minimun rate needed to make the fecthing process sleep\n        :param rate_limit_header: header from where extract the rate limit data\n        :param rate_limit_reset_header: header from where extract the rate limit reset data\n        \"\"\"\n        self.rate_limit = None\n        self.rate_limit_reset_ts = None\n        self.sleep_for_rate = sleep_for_rate\n        self.rate_limit_header = rate_limit_header\n        self.rate_limit_reset_header = rate_limit_reset_header\n\n        if min_rate_to_sleep > self.MAX_RATE_LIMIT:\n            msg = \"Minimum rate to sleep value exceeded (%d).\"\n            msg += \"High values might cause the client to sleep forever.\"\n            msg += \"Reset to %d.\"\n            self.min_rate_to_sleep = self.MAX_RATE_LIMIT\n            logger.warning(msg, min_rate_to_sleep, self.MAX_RATE_LIMIT)\n        else:\n            self.min_rate_to_sleep = min_rate_to_sleep", "language": "python", "code": "def setup_rate_limit_handler(self, sleep_for_rate=False, min_rate_to_sleep=MIN_RATE_LIMIT,\n                                 rate_limit_header=RATE_LIMIT_HEADER,\n                                 rate_limit_reset_header=RATE_LIMIT_RESET_HEADER):\n        \"\"\"Setup the rate limit handler.\n\n        :param sleep_for_rate: sleep until rate limit is reset\n        :param min_rate_to_sleep: minimun rate needed to make the fecthing process sleep\n        :param rate_limit_header: header from where extract the rate limit data\n        :param rate_limit_reset_header: header from where extract the rate limit reset data\n        \"\"\"\n        self.rate_limit = None\n        self.rate_limit_reset_ts = None\n        self.sleep_for_rate = sleep_for_rate\n        self.rate_limit_header = rate_limit_header\n        self.rate_limit_reset_header = rate_limit_reset_header\n\n        if min_rate_to_sleep > self.MAX_RATE_LIMIT:\n            msg = \"Minimum rate to sleep value exceeded (%d).\"\n            msg += \"High values might cause the client to sleep forever.\"\n            msg += \"Reset to %d.\"\n            self.min_rate_to_sleep = self.MAX_RATE_LIMIT\n            logger.warning(msg, min_rate_to_sleep, self.MAX_RATE_LIMIT)\n        else:\n            self.min_rate_to_sleep = min_rate_to_sleep", "code_tokens": ["def", "setup_rate_limit_handler", "(", "self", ",", "sleep_for_rate", "=", "False", ",", "min_rate_to_sleep", "=", "MIN_RATE_LIMIT", ",", "rate_limit_header", "=", "RATE_LIMIT_HEADER", ",", "rate_limit_reset_header", "=", "RATE_LIMIT_RESET_HEADER", ")", ":", "self", ".", "rate_limit", "=", "None", "self", ".", "rate_limit_reset_ts", "=", "None", "self", ".", "sleep_for_rate", "=", "sleep_for_rate", "self", ".", "rate_limit_header", "=", "rate_limit_header", "self", ".", "rate_limit_reset_header", "=", "rate_limit_reset_header", "if", "min_rate_to_sleep", ">", "self", ".", "MAX_RATE_LIMIT", ":", "msg", "=", "\"Minimum rate to sleep value exceeded (%d).\"", "msg", "+=", "\"High values might cause the client to sleep forever.\"", "msg", "+=", "\"Reset to %d.\"", "self", ".", "min_rate_to_sleep", "=", "self", ".", "MAX_RATE_LIMIT", "logger", ".", "warning", "(", "msg", ",", "min_rate_to_sleep", ",", "self", ".", "MAX_RATE_LIMIT", ")", "else", ":", "self", ".", "min_rate_to_sleep", "=", "min_rate_to_sleep"], "docstring": "Setup the rate limit handler.\n\n        :param sleep_for_rate: sleep until rate limit is reset\n        :param min_rate_to_sleep: minimun rate needed to make the fecthing process sleep\n        :param rate_limit_header: header from where extract the rate limit data\n        :param rate_limit_reset_header: header from where extract the rate limit reset data", "docstring_tokens": ["Setup", "the", "rate", "limit", "handler", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/client.py#L225-L248", "partition": "test", "index": 3375, "time": "2017-11-23 14:23:24"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/client.py", "func_name": "RateLimitHandler.update_rate_limit", "original_string": "def update_rate_limit(self, response):\n        \"\"\"Update the rate limit and the time to reset\n        from the response headers.\n\n        :param: response: the response object\n        \"\"\"\n        if self.rate_limit_header in response.headers:\n            self.rate_limit = int(response.headers[self.rate_limit_header])\n            logger.debug(\"Rate limit: %s\", self.rate_limit)\n        else:\n            self.rate_limit = None\n\n        if self.rate_limit_reset_header in response.headers:\n            self.rate_limit_reset_ts = int(response.headers[self.rate_limit_reset_header])\n            logger.debug(\"Rate limit reset: %s\", self.calculate_time_to_reset())\n        else:\n            self.rate_limit_reset_ts = None", "language": "python", "code": "def update_rate_limit(self, response):\n        \"\"\"Update the rate limit and the time to reset\n        from the response headers.\n\n        :param: response: the response object\n        \"\"\"\n        if self.rate_limit_header in response.headers:\n            self.rate_limit = int(response.headers[self.rate_limit_header])\n            logger.debug(\"Rate limit: %s\", self.rate_limit)\n        else:\n            self.rate_limit = None\n\n        if self.rate_limit_reset_header in response.headers:\n            self.rate_limit_reset_ts = int(response.headers[self.rate_limit_reset_header])\n            logger.debug(\"Rate limit reset: %s\", self.calculate_time_to_reset())\n        else:\n            self.rate_limit_reset_ts = None", "code_tokens": ["def", "update_rate_limit", "(", "self", ",", "response", ")", ":", "if", "self", ".", "rate_limit_header", "in", "response", ".", "headers", ":", "self", ".", "rate_limit", "=", "int", "(", "response", ".", "headers", "[", "self", ".", "rate_limit_header", "]", ")", "logger", ".", "debug", "(", "\"Rate limit: %s\"", ",", "self", ".", "rate_limit", ")", "else", ":", "self", ".", "rate_limit", "=", "None", "if", "self", ".", "rate_limit_reset_header", "in", "response", ".", "headers", ":", "self", ".", "rate_limit_reset_ts", "=", "int", "(", "response", ".", "headers", "[", "self", ".", "rate_limit_reset_header", "]", ")", "logger", ".", "debug", "(", "\"Rate limit reset: %s\"", ",", "self", ".", "calculate_time_to_reset", "(", ")", ")", "else", ":", "self", ".", "rate_limit_reset_ts", "=", "None"], "docstring": "Update the rate limit and the time to reset\n        from the response headers.\n\n        :param: response: the response object", "docstring_tokens": ["Update", "the", "rate", "limit", "and", "the", "time", "to", "reset", "from", "the", "response", "headers", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/client.py#L273-L289", "partition": "test", "index": 3377, "time": "2017-11-23 14:23:24"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/client.py", "func_name": "HttpClient._create_http_session", "original_string": "def _create_http_session(self):\n        \"\"\"Create a http session and initialize the retry object.\"\"\"\n\n        self.session = requests.Session()\n\n        if self.headers:\n            self.session.headers.update(self.headers)\n\n        retries = urllib3.util.Retry(total=self.max_retries,\n                                     connect=self.max_retries_on_connect,\n                                     read=self.max_retries_on_read,\n                                     redirect=self.max_retries_on_redirect,\n                                     status=self.max_retries_on_status,\n                                     method_whitelist=self.method_whitelist,\n                                     status_forcelist=self.status_forcelist,\n                                     backoff_factor=self.sleep_time,\n                                     raise_on_redirect=self.raise_on_redirect,\n                                     raise_on_status=self.raise_on_status,\n                                     respect_retry_after_header=self.respect_retry_after_header)\n\n        self.session.mount('http://', requests.adapters.HTTPAdapter(max_retries=retries))\n        self.session.mount('https://', requests.adapters.HTTPAdapter(max_retries=retries))", "language": "python", "code": "def _create_http_session(self):\n        \"\"\"Create a http session and initialize the retry object.\"\"\"\n\n        self.session = requests.Session()\n\n        if self.headers:\n            self.session.headers.update(self.headers)\n\n        retries = urllib3.util.Retry(total=self.max_retries,\n                                     connect=self.max_retries_on_connect,\n                                     read=self.max_retries_on_read,\n                                     redirect=self.max_retries_on_redirect,\n                                     status=self.max_retries_on_status,\n                                     method_whitelist=self.method_whitelist,\n                                     status_forcelist=self.status_forcelist,\n                                     backoff_factor=self.sleep_time,\n                                     raise_on_redirect=self.raise_on_redirect,\n                                     raise_on_status=self.raise_on_status,\n                                     respect_retry_after_header=self.respect_retry_after_header)\n\n        self.session.mount('http://', requests.adapters.HTTPAdapter(max_retries=retries))\n        self.session.mount('https://', requests.adapters.HTTPAdapter(max_retries=retries))", "code_tokens": ["def", "_create_http_session", "(", "self", ")", ":", "self", ".", "session", "=", "requests", ".", "Session", "(", ")", "if", "self", ".", "headers", ":", "self", ".", "session", ".", "headers", ".", "update", "(", "self", ".", "headers", ")", "retries", "=", "urllib3", ".", "util", ".", "Retry", "(", "total", "=", "self", ".", "max_retries", ",", "connect", "=", "self", ".", "max_retries_on_connect", ",", "read", "=", "self", ".", "max_retries_on_read", ",", "redirect", "=", "self", ".", "max_retries_on_redirect", ",", "status", "=", "self", ".", "max_retries_on_status", ",", "method_whitelist", "=", "self", ".", "method_whitelist", ",", "status_forcelist", "=", "self", ".", "status_forcelist", ",", "backoff_factor", "=", "self", ".", "sleep_time", ",", "raise_on_redirect", "=", "self", ".", "raise_on_redirect", ",", "raise_on_status", "=", "self", ".", "raise_on_status", ",", "respect_retry_after_header", "=", "self", ".", "respect_retry_after_header", ")", "self", ".", "session", ".", "mount", "(", "'http://'", ",", "requests", ".", "adapters", ".", "HTTPAdapter", "(", "max_retries", "=", "retries", ")", ")", "self", ".", "session", ".", "mount", "(", "'https://'", ",", "requests", ".", "adapters", ".", "HTTPAdapter", "(", "max_retries", "=", "retries", ")", ")"], "docstring": "Create a http session and initialize the retry object.", "docstring_tokens": ["Create", "a", "http", "session", "and", "initialize", "the", "retry", "object", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/client.py#L180-L201", "partition": "test", "index": 3374, "time": "2017-11-23 14:23:24"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/client.py", "func_name": "RateLimitHandler.sleep_for_rate_limit", "original_string": "def sleep_for_rate_limit(self):\n        \"\"\"The fetching process sleeps until the rate limit is restored or\n           raises a RateLimitError exception if sleep_for_rate flag is disabled.\n        \"\"\"\n        if self.rate_limit is not None and self.rate_limit <= self.min_rate_to_sleep:\n            seconds_to_reset = self.calculate_time_to_reset()\n\n            if seconds_to_reset < 0:\n                logger.warning(\"Value of sleep for rate limit is negative, reset it to 0\")\n                seconds_to_reset = 0\n\n            cause = \"Rate limit exhausted.\"\n            if self.sleep_for_rate:\n                logger.info(\"%s Waiting %i secs for rate limit reset.\", cause, seconds_to_reset)\n                time.sleep(seconds_to_reset)\n            else:\n                raise RateLimitError(cause=cause, seconds_to_reset=seconds_to_reset)", "language": "python", "code": "def sleep_for_rate_limit(self):\n        \"\"\"The fetching process sleeps until the rate limit is restored or\n           raises a RateLimitError exception if sleep_for_rate flag is disabled.\n        \"\"\"\n        if self.rate_limit is not None and self.rate_limit <= self.min_rate_to_sleep:\n            seconds_to_reset = self.calculate_time_to_reset()\n\n            if seconds_to_reset < 0:\n                logger.warning(\"Value of sleep for rate limit is negative, reset it to 0\")\n                seconds_to_reset = 0\n\n            cause = \"Rate limit exhausted.\"\n            if self.sleep_for_rate:\n                logger.info(\"%s Waiting %i secs for rate limit reset.\", cause, seconds_to_reset)\n                time.sleep(seconds_to_reset)\n            else:\n                raise RateLimitError(cause=cause, seconds_to_reset=seconds_to_reset)", "code_tokens": ["def", "sleep_for_rate_limit", "(", "self", ")", ":", "if", "self", ".", "rate_limit", "is", "not", "None", "and", "self", ".", "rate_limit", "<=", "self", ".", "min_rate_to_sleep", ":", "seconds_to_reset", "=", "self", ".", "calculate_time_to_reset", "(", ")", "if", "seconds_to_reset", "<", "0", ":", "logger", ".", "warning", "(", "\"Value of sleep for rate limit is negative, reset it to 0\"", ")", "seconds_to_reset", "=", "0", "cause", "=", "\"Rate limit exhausted.\"", "if", "self", ".", "sleep_for_rate", ":", "logger", ".", "info", "(", "\"%s Waiting %i secs for rate limit reset.\"", ",", "cause", ",", "seconds_to_reset", ")", "time", ".", "sleep", "(", "seconds_to_reset", ")", "else", ":", "raise", "RateLimitError", "(", "cause", "=", "cause", ",", "seconds_to_reset", "=", "seconds_to_reset", ")"], "docstring": "The fetching process sleeps until the rate limit is restored or\n           raises a RateLimitError exception if sleep_for_rate flag is disabled.", "docstring_tokens": ["The", "fetching", "process", "sleeps", "until", "the", "rate", "limit", "is", "restored", "or", "raises", "a", "RateLimitError", "exception", "if", "sleep_for_rate", "flag", "is", "disabled", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/client.py#L250-L266", "partition": "test", "index": 3376, "time": "2017-11-23 14:23:24"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabCommand.setup_cmd_parser", "original_string": "def setup_cmd_parser(cls):\n        \"\"\"Returns the GitLab argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              from_date=True,\n                                              token_auth=True,\n                                              archive=True)\n\n        # GitLab options\n        group = parser.parser.add_argument_group('GitLab arguments')\n        group.add_argument('--enterprise-url', dest='base_url',\n                           help=\"Base URL for GitLab Enterprise instance\")\n        group.add_argument('--sleep-for-rate', dest='sleep_for_rate',\n                           action='store_true',\n                           help=\"sleep for getting more rate\")\n        group.add_argument('--min-rate-to-sleep', dest='min_rate_to_sleep',\n                           default=MIN_RATE_LIMIT, type=int,\n                           help=\"sleep until reset when the rate limit \\\n                               reaches this value\")\n        group.add_argument('--blacklist-ids', dest='blacklist_ids',\n                           nargs='*', type=int,\n                           help=\"Ids of items that must not be retrieved.\")\n\n        # Generic client options\n        group.add_argument('--max-retries', dest='max_retries',\n                           default=MAX_RETRIES, type=int,\n                           help=\"number of API call retries\")\n        group.add_argument('--sleep-time', dest='sleep_time',\n                           default=DEFAULT_SLEEP_TIME, type=int,\n                           help=\"sleeping time between API call retries\")\n\n        # Positional arguments\n        parser.parser.add_argument('owner',\n                                   help=\"GitLab owner\")\n        parser.parser.add_argument('repository',\n                                   help=\"GitLab repository\")\n\n        return parser", "language": "python", "code": "def setup_cmd_parser(cls):\n        \"\"\"Returns the GitLab argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              from_date=True,\n                                              token_auth=True,\n                                              archive=True)\n\n        # GitLab options\n        group = parser.parser.add_argument_group('GitLab arguments')\n        group.add_argument('--enterprise-url', dest='base_url',\n                           help=\"Base URL for GitLab Enterprise instance\")\n        group.add_argument('--sleep-for-rate', dest='sleep_for_rate',\n                           action='store_true',\n                           help=\"sleep for getting more rate\")\n        group.add_argument('--min-rate-to-sleep', dest='min_rate_to_sleep',\n                           default=MIN_RATE_LIMIT, type=int,\n                           help=\"sleep until reset when the rate limit \\\n                               reaches this value\")\n        group.add_argument('--blacklist-ids', dest='blacklist_ids',\n                           nargs='*', type=int,\n                           help=\"Ids of items that must not be retrieved.\")\n\n        # Generic client options\n        group.add_argument('--max-retries', dest='max_retries',\n                           default=MAX_RETRIES, type=int,\n                           help=\"number of API call retries\")\n        group.add_argument('--sleep-time', dest='sleep_time',\n                           default=DEFAULT_SLEEP_TIME, type=int,\n                           help=\"sleeping time between API call retries\")\n\n        # Positional arguments\n        parser.parser.add_argument('owner',\n                                   help=\"GitLab owner\")\n        parser.parser.add_argument('repository',\n                                   help=\"GitLab repository\")\n\n        return parser", "code_tokens": ["def", "setup_cmd_parser", "(", "cls", ")", ":", "parser", "=", "BackendCommandArgumentParser", "(", "cls", ".", "BACKEND", ".", "CATEGORIES", ",", "from_date", "=", "True", ",", "token_auth", "=", "True", ",", "archive", "=", "True", ")", "# GitLab options", "group", "=", "parser", ".", "parser", ".", "add_argument_group", "(", "'GitLab arguments'", ")", "group", ".", "add_argument", "(", "'--enterprise-url'", ",", "dest", "=", "'base_url'", ",", "help", "=", "\"Base URL for GitLab Enterprise instance\"", ")", "group", ".", "add_argument", "(", "'--sleep-for-rate'", ",", "dest", "=", "'sleep_for_rate'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"sleep for getting more rate\"", ")", "group", ".", "add_argument", "(", "'--min-rate-to-sleep'", ",", "dest", "=", "'min_rate_to_sleep'", ",", "default", "=", "MIN_RATE_LIMIT", ",", "type", "=", "int", ",", "help", "=", "\"sleep until reset when the rate limit \\\n                               reaches this value\"", ")", "group", ".", "add_argument", "(", "'--blacklist-ids'", ",", "dest", "=", "'blacklist_ids'", ",", "nargs", "=", "'*'", ",", "type", "=", "int", ",", "help", "=", "\"Ids of items that must not be retrieved.\"", ")", "# Generic client options", "group", ".", "add_argument", "(", "'--max-retries'", ",", "dest", "=", "'max_retries'", ",", "default", "=", "MAX_RETRIES", ",", "type", "=", "int", ",", "help", "=", "\"number of API call retries\"", ")", "group", ".", "add_argument", "(", "'--sleep-time'", ",", "dest", "=", "'sleep_time'", ",", "default", "=", "DEFAULT_SLEEP_TIME", ",", "type", "=", "int", ",", "help", "=", "\"sleeping time between API call retries\"", ")", "# Positional arguments", "parser", ".", "parser", ".", "add_argument", "(", "'owner'", ",", "help", "=", "\"GitLab owner\"", ")", "parser", ".", "parser", ".", "add_argument", "(", "'repository'", ",", "help", "=", "\"GitLab repository\"", ")", "return", "parser"], "docstring": "Returns the GitLab argument parser.", "docstring_tokens": ["Returns", "the", "GitLab", "argument", "parser", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L632-L669", "partition": "test", "index": 3189, "time": "2017-12-12 15:52:28"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabClient.notes", "original_string": "def notes(self, item_type, item_id):\n        \"\"\"Get the notes from pagination\"\"\"\n\n        payload = {\n            'order_by': 'updated_at',\n            'sort': 'asc',\n            'per_page': PER_PAGE\n        }\n\n        path = urijoin(item_type, str(item_id), GitLabClient.NOTES)\n\n        return self.fetch_items(path, payload)", "language": "python", "code": "def notes(self, item_type, item_id):\n        \"\"\"Get the notes from pagination\"\"\"\n\n        payload = {\n            'order_by': 'updated_at',\n            'sort': 'asc',\n            'per_page': PER_PAGE\n        }\n\n        path = urijoin(item_type, str(item_id), GitLabClient.NOTES)\n\n        return self.fetch_items(path, payload)", "code_tokens": ["def", "notes", "(", "self", ",", "item_type", ",", "item_id", ")", ":", "payload", "=", "{", "'order_by'", ":", "'updated_at'", ",", "'sort'", ":", "'asc'", ",", "'per_page'", ":", "PER_PAGE", "}", "path", "=", "urijoin", "(", "item_type", ",", "str", "(", "item_id", ")", ",", "GitLabClient", ".", "NOTES", ")", "return", "self", ".", "fetch_items", "(", "path", ",", "payload", ")"], "docstring": "Get the notes from pagination", "docstring_tokens": ["Get", "the", "notes", "from", "pagination"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L481-L492", "partition": "test", "index": 3183, "time": "2017-12-12 15:52:28"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLab.__get_issue_notes", "original_string": "def __get_issue_notes(self, issue_id):\n        \"\"\"Get issue notes\"\"\"\n\n        notes = []\n\n        group_notes = self.client.notes(GitLabClient.ISSUES, issue_id)\n\n        for raw_notes in group_notes:\n\n            for note in json.loads(raw_notes):\n                note_id = note['id']\n                note['award_emoji_data'] = \\\n                    self.__get_note_award_emoji(GitLabClient.ISSUES, issue_id, note_id)\n                notes.append(note)\n\n        return notes", "language": "python", "code": "def __get_issue_notes(self, issue_id):\n        \"\"\"Get issue notes\"\"\"\n\n        notes = []\n\n        group_notes = self.client.notes(GitLabClient.ISSUES, issue_id)\n\n        for raw_notes in group_notes:\n\n            for note in json.loads(raw_notes):\n                note_id = note['id']\n                note['award_emoji_data'] = \\\n                    self.__get_note_award_emoji(GitLabClient.ISSUES, issue_id, note_id)\n                notes.append(note)\n\n        return notes", "code_tokens": ["def", "__get_issue_notes", "(", "self", ",", "issue_id", ")", ":", "notes", "=", "[", "]", "group_notes", "=", "self", ".", "client", ".", "notes", "(", "GitLabClient", ".", "ISSUES", ",", "issue_id", ")", "for", "raw_notes", "in", "group_notes", ":", "for", "note", "in", "json", ".", "loads", "(", "raw_notes", ")", ":", "note_id", "=", "note", "[", "'id'", "]", "note", "[", "'award_emoji_data'", "]", "=", "self", ".", "__get_note_award_emoji", "(", "GitLabClient", ".", "ISSUES", ",", "issue_id", ",", "note_id", ")", "notes", ".", "append", "(", "note", ")", "return", "notes"], "docstring": "Get issue notes", "docstring_tokens": ["Get", "issue", "notes"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L232-L247", "partition": "test", "index": 3175, "time": "2017-12-12 15:52:28"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLab.__get_merge_notes", "original_string": "def __get_merge_notes(self, merge_id):\n        \"\"\"Get merge notes\"\"\"\n\n        notes = []\n\n        group_notes = self.client.notes(GitLabClient.MERGES, merge_id)\n\n        for raw_notes in group_notes:\n            for note in json.loads(raw_notes):\n                note_id = note['id']\n                note['award_emoji_data'] = \\\n                    self.__get_note_award_emoji(GitLabClient.MERGES, merge_id, note_id)\n                notes.append(note)\n\n        return notes", "language": "python", "code": "def __get_merge_notes(self, merge_id):\n        \"\"\"Get merge notes\"\"\"\n\n        notes = []\n\n        group_notes = self.client.notes(GitLabClient.MERGES, merge_id)\n\n        for raw_notes in group_notes:\n            for note in json.loads(raw_notes):\n                note_id = note['id']\n                note['award_emoji_data'] = \\\n                    self.__get_note_award_emoji(GitLabClient.MERGES, merge_id, note_id)\n                notes.append(note)\n\n        return notes", "code_tokens": ["def", "__get_merge_notes", "(", "self", ",", "merge_id", ")", ":", "notes", "=", "[", "]", "group_notes", "=", "self", ".", "client", ".", "notes", "(", "GitLabClient", ".", "MERGES", ",", "merge_id", ")", "for", "raw_notes", "in", "group_notes", ":", "for", "note", "in", "json", ".", "loads", "(", "raw_notes", ")", ":", "note_id", "=", "note", "[", "'id'", "]", "note", "[", "'award_emoji_data'", "]", "=", "self", ".", "__get_note_award_emoji", "(", "GitLabClient", ".", "MERGES", ",", "merge_id", ",", "note_id", ")", "notes", ".", "append", "(", "note", ")", "return", "notes"], "docstring": "Get merge notes", "docstring_tokens": ["Get", "merge", "notes"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L277-L291", "partition": "test", "index": 3177, "time": "2017-12-12 15:52:28"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabClient.merges", "original_string": "def merges(self, from_date=None):\n        \"\"\"Get the merge requests from pagination\"\"\"\n\n        payload = {\n            'state': 'all',\n            'order_by': 'updated_at',\n            'sort': 'asc',\n            'view': 'simple',\n            'per_page': PER_PAGE\n        }\n\n        if from_date:\n            payload['updated_after'] = from_date.isoformat()\n\n        return self.fetch_items(GitLabClient.MERGES, payload)", "language": "python", "code": "def merges(self, from_date=None):\n        \"\"\"Get the merge requests from pagination\"\"\"\n\n        payload = {\n            'state': 'all',\n            'order_by': 'updated_at',\n            'sort': 'asc',\n            'view': 'simple',\n            'per_page': PER_PAGE\n        }\n\n        if from_date:\n            payload['updated_after'] = from_date.isoformat()\n\n        return self.fetch_items(GitLabClient.MERGES, payload)", "code_tokens": ["def", "merges", "(", "self", ",", "from_date", "=", "None", ")", ":", "payload", "=", "{", "'state'", ":", "'all'", ",", "'order_by'", ":", "'updated_at'", ",", "'sort'", ":", "'asc'", ",", "'view'", ":", "'simple'", ",", "'per_page'", ":", "PER_PAGE", "}", "if", "from_date", ":", "payload", "[", "'updated_after'", "]", "=", "from_date", ".", "isoformat", "(", ")", "return", "self", ".", "fetch_items", "(", "GitLabClient", ".", "MERGES", ",", "payload", ")"], "docstring": "Get the merge requests from pagination", "docstring_tokens": ["Get", "the", "merge", "requests", "from", "pagination"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L431-L445", "partition": "test", "index": 3179, "time": "2017-12-12 15:52:28"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabClient.merge", "original_string": "def merge(self, merge_id):\n        \"\"\"Get the merge full data\"\"\"\n\n        path = urijoin(self.base_url,\n                       GitLabClient.PROJECTS, self.owner + '%2F' + self.repository,\n                       GitLabClient.MERGES, merge_id)\n\n        response = self.fetch(path)\n\n        return response.text", "language": "python", "code": "def merge(self, merge_id):\n        \"\"\"Get the merge full data\"\"\"\n\n        path = urijoin(self.base_url,\n                       GitLabClient.PROJECTS, self.owner + '%2F' + self.repository,\n                       GitLabClient.MERGES, merge_id)\n\n        response = self.fetch(path)\n\n        return response.text", "code_tokens": ["def", "merge", "(", "self", ",", "merge_id", ")", ":", "path", "=", "urijoin", "(", "self", ".", "base_url", ",", "GitLabClient", ".", "PROJECTS", ",", "self", ".", "owner", "+", "'%2F'", "+", "self", ".", "repository", ",", "GitLabClient", ".", "MERGES", ",", "merge_id", ")", "response", "=", "self", ".", "fetch", "(", "path", ")", "return", "response", ".", "text"], "docstring": "Get the merge full data", "docstring_tokens": ["Get", "the", "merge", "full", "data"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L447-L456", "partition": "test", "index": 3180, "time": "2017-12-12 15:52:28"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabClient.merge_versions", "original_string": "def merge_versions(self, merge_id):\n        \"\"\"Get the merge versions from pagination\"\"\"\n\n        payload = {\n            'order_by': 'updated_at',\n            'sort': 'asc',\n            'per_page': PER_PAGE\n        }\n\n        path = urijoin(GitLabClient.MERGES, str(merge_id), GitLabClient.VERSIONS)\n        return self.fetch_items(path, payload)", "language": "python", "code": "def merge_versions(self, merge_id):\n        \"\"\"Get the merge versions from pagination\"\"\"\n\n        payload = {\n            'order_by': 'updated_at',\n            'sort': 'asc',\n            'per_page': PER_PAGE\n        }\n\n        path = urijoin(GitLabClient.MERGES, str(merge_id), GitLabClient.VERSIONS)\n        return self.fetch_items(path, payload)", "code_tokens": ["def", "merge_versions", "(", "self", ",", "merge_id", ")", ":", "payload", "=", "{", "'order_by'", ":", "'updated_at'", ",", "'sort'", ":", "'asc'", ",", "'per_page'", ":", "PER_PAGE", "}", "path", "=", "urijoin", "(", "GitLabClient", ".", "MERGES", ",", "str", "(", "merge_id", ")", ",", "GitLabClient", ".", "VERSIONS", ")", "return", "self", ".", "fetch_items", "(", "path", ",", "payload", ")"], "docstring": "Get the merge versions from pagination", "docstring_tokens": ["Get", "the", "merge", "versions", "from", "pagination"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L458-L468", "partition": "test", "index": 3181, "time": "2017-12-12 15:52:28"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabClient.note_emojis", "original_string": "def note_emojis(self, item_type, item_id, note_id):\n        \"\"\"Get emojis of a note\"\"\"\n\n        payload = {\n            'order_by': 'updated_at',\n            'sort': 'asc',\n            'per_page': PER_PAGE\n        }\n\n        path = urijoin(item_type, str(item_id), GitLabClient.NOTES,\n                       str(note_id), GitLabClient.EMOJI)\n\n        return self.fetch_items(path, payload)", "language": "python", "code": "def note_emojis(self, item_type, item_id, note_id):\n        \"\"\"Get emojis of a note\"\"\"\n\n        payload = {\n            'order_by': 'updated_at',\n            'sort': 'asc',\n            'per_page': PER_PAGE\n        }\n\n        path = urijoin(item_type, str(item_id), GitLabClient.NOTES,\n                       str(note_id), GitLabClient.EMOJI)\n\n        return self.fetch_items(path, payload)", "code_tokens": ["def", "note_emojis", "(", "self", ",", "item_type", ",", "item_id", ",", "note_id", ")", ":", "payload", "=", "{", "'order_by'", ":", "'updated_at'", ",", "'sort'", ":", "'asc'", ",", "'per_page'", ":", "PER_PAGE", "}", "path", "=", "urijoin", "(", "item_type", ",", "str", "(", "item_id", ")", ",", "GitLabClient", ".", "NOTES", ",", "str", "(", "note_id", ")", ",", "GitLabClient", ".", "EMOJI", ")", "return", "self", ".", "fetch_items", "(", "path", ",", "payload", ")"], "docstring": "Get emojis of a note", "docstring_tokens": ["Get", "emojis", "of", "a", "note"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L507-L519", "partition": "test", "index": 3185, "time": "2017-12-12 15:52:28"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabClient.fetch_items", "original_string": "def fetch_items(self, path, payload):\n        \"\"\"Return the items from GitLab API using links pagination\"\"\"\n\n        page = 0  # current page\n        last_page = None  # last page\n        url_next = urijoin(self.base_url, GitLabClient.PROJECTS, self.owner + '%2F' + self.repository, path)\n\n        logger.debug(\"Get GitLab paginated items from \" + url_next)\n\n        response = self.fetch(url_next, payload=payload)\n\n        items = response.text\n        page += 1\n\n        if 'last' in response.links:\n            last_url = response.links['last']['url']\n            last_page = last_url.split('&page=')[1].split('&')[0]\n            last_page = int(last_page)\n            logger.debug(\"Page: %i/%i\" % (page, last_page))\n\n        while items:\n            yield items\n\n            items = None\n\n            if 'next' in response.links:\n                url_next = response.links['next']['url']  # Loving requests :)\n                response = self.fetch(url_next, payload=payload)\n                page += 1\n\n                items = response.text\n                logger.debug(\"Page: %i/%i\" % (page, last_page))", "language": "python", "code": "def fetch_items(self, path, payload):\n        \"\"\"Return the items from GitLab API using links pagination\"\"\"\n\n        page = 0  # current page\n        last_page = None  # last page\n        url_next = urijoin(self.base_url, GitLabClient.PROJECTS, self.owner + '%2F' + self.repository, path)\n\n        logger.debug(\"Get GitLab paginated items from \" + url_next)\n\n        response = self.fetch(url_next, payload=payload)\n\n        items = response.text\n        page += 1\n\n        if 'last' in response.links:\n            last_url = response.links['last']['url']\n            last_page = last_url.split('&page=')[1].split('&')[0]\n            last_page = int(last_page)\n            logger.debug(\"Page: %i/%i\" % (page, last_page))\n\n        while items:\n            yield items\n\n            items = None\n\n            if 'next' in response.links:\n                url_next = response.links['next']['url']  # Loving requests :)\n                response = self.fetch(url_next, payload=payload)\n                page += 1\n\n                items = response.text\n                logger.debug(\"Page: %i/%i\" % (page, last_page))", "code_tokens": ["def", "fetch_items", "(", "self", ",", "path", ",", "payload", ")", ":", "page", "=", "0", "# current page", "last_page", "=", "None", "# last page", "url_next", "=", "urijoin", "(", "self", ".", "base_url", ",", "GitLabClient", ".", "PROJECTS", ",", "self", ".", "owner", "+", "'%2F'", "+", "self", ".", "repository", ",", "path", ")", "logger", ".", "debug", "(", "\"Get GitLab paginated items from \"", "+", "url_next", ")", "response", "=", "self", ".", "fetch", "(", "url_next", ",", "payload", "=", "payload", ")", "items", "=", "response", ".", "text", "page", "+=", "1", "if", "'last'", "in", "response", ".", "links", ":", "last_url", "=", "response", ".", "links", "[", "'last'", "]", "[", "'url'", "]", "last_page", "=", "last_url", ".", "split", "(", "'&page='", ")", "[", "1", "]", ".", "split", "(", "'&'", ")", "[", "0", "]", "last_page", "=", "int", "(", "last_page", ")", "logger", ".", "debug", "(", "\"Page: %i/%i\"", "%", "(", "page", ",", "last_page", ")", ")", "while", "items", ":", "yield", "items", "items", "=", "None", "if", "'next'", "in", "response", ".", "links", ":", "url_next", "=", "response", ".", "links", "[", "'next'", "]", "[", "'url'", "]", "# Loving requests :)", "response", "=", "self", ".", "fetch", "(", "url_next", ",", "payload", "=", "payload", ")", "page", "+=", "1", "items", "=", "response", ".", "text", "logger", ".", "debug", "(", "\"Page: %i/%i\"", "%", "(", "page", ",", "last_page", ")", ")"], "docstring": "Return the items from GitLab API using links pagination", "docstring_tokens": ["Return", "the", "items", "from", "GitLab", "API", "using", "links", "pagination"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L554-L585", "partition": "test", "index": 3187, "time": "2017-12-12 15:52:28"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabClient.calculate_time_to_reset", "original_string": "def calculate_time_to_reset(self):\n        \"\"\"Calculate the seconds to reset the token requests, by obtaining the different\n        between the current date and the next date when the token is fully regenerated.\n        \"\"\"\n\n        time_to_reset = self.rate_limit_reset_ts - (datetime_utcnow().replace(microsecond=0).timestamp() + 1)\n\n        if time_to_reset < 0:\n            time_to_reset = 0\n\n        return time_to_reset", "language": "python", "code": "def calculate_time_to_reset(self):\n        \"\"\"Calculate the seconds to reset the token requests, by obtaining the different\n        between the current date and the next date when the token is fully regenerated.\n        \"\"\"\n\n        time_to_reset = self.rate_limit_reset_ts - (datetime_utcnow().replace(microsecond=0).timestamp() + 1)\n\n        if time_to_reset < 0:\n            time_to_reset = 0\n\n        return time_to_reset", "code_tokens": ["def", "calculate_time_to_reset", "(", "self", ")", ":", "time_to_reset", "=", "self", ".", "rate_limit_reset_ts", "-", "(", "datetime_utcnow", "(", ")", ".", "replace", "(", "microsecond", "=", "0", ")", ".", "timestamp", "(", ")", "+", "1", ")", "if", "time_to_reset", "<", "0", ":", "time_to_reset", "=", "0", "return", "time_to_reset"], "docstring": "Calculate the seconds to reset the token requests, by obtaining the different\n        between the current date and the next date when the token is fully regenerated.", "docstring_tokens": ["Calculate", "the", "seconds", "to", "reset", "the", "token", "requests", "by", "obtaining", "the", "different", "between", "the", "current", "date", "and", "the", "next", "date", "when", "the", "token", "is", "fully", "regenerated", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L521-L531", "partition": "test", "index": 3186, "time": "2017-12-12 15:52:28"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "Archive.init_metadata", "original_string": "def init_metadata(self, origin, backend_name, backend_version,\n                      category, backend_params):\n        \"\"\"Init metadata information.\n\n        Metatada is composed by basic information needed to identify\n        where archived data came from and how it can be retrieved\n        and built into Perceval items.\n\n        :param: origin: identifier of the repository\n        :param: backend_name: name of the backend\n        :param: backend_version: version of the backend\n        :param: category: category of the items fetched\n        :param: backend_params: dict representation of the fetch parameters\n\n        raises ArchiveError: when an error occurs initializing the metadata\n        \"\"\"\n        created_on = datetime_to_utc(datetime_utcnow())\n        created_on_dumped = created_on.isoformat()\n        backend_params_dumped = pickle.dumps(backend_params, 0)\n\n        metadata = (origin, backend_name, backend_version, category,\n                    backend_params_dumped, created_on_dumped,)\n\n        try:\n            cursor = self._db.cursor()\n            insert_stmt = \"INSERT INTO \" + self.METADATA_TABLE + \" \"\\\n                          \"(origin, backend_name, backend_version, \" \\\n                          \"category, backend_params, created_on) \" \\\n                          \"VALUES (?, ?, ?, ?, ?, ?)\"\n            cursor.execute(insert_stmt, metadata)\n\n            self._db.commit()\n            cursor.close()\n        except sqlite3.DatabaseError as e:\n            msg = \"metadata initialization error; cause: %s\" % str(e)\n            raise ArchiveError(cause=msg)\n\n        self.origin = origin\n        self.backend_name = backend_name\n        self.backend_version = backend_version\n        self.category = category\n        self.backend_params = backend_params\n        self.created_on = created_on\n\n        logger.debug(\"Metadata of archive %s initialized to %s\",\n                     self.archive_path, metadata)", "language": "python", "code": "def init_metadata(self, origin, backend_name, backend_version,\n                      category, backend_params):\n        \"\"\"Init metadata information.\n\n        Metatada is composed by basic information needed to identify\n        where archived data came from and how it can be retrieved\n        and built into Perceval items.\n\n        :param: origin: identifier of the repository\n        :param: backend_name: name of the backend\n        :param: backend_version: version of the backend\n        :param: category: category of the items fetched\n        :param: backend_params: dict representation of the fetch parameters\n\n        raises ArchiveError: when an error occurs initializing the metadata\n        \"\"\"\n        created_on = datetime_to_utc(datetime_utcnow())\n        created_on_dumped = created_on.isoformat()\n        backend_params_dumped = pickle.dumps(backend_params, 0)\n\n        metadata = (origin, backend_name, backend_version, category,\n                    backend_params_dumped, created_on_dumped,)\n\n        try:\n            cursor = self._db.cursor()\n            insert_stmt = \"INSERT INTO \" + self.METADATA_TABLE + \" \"\\\n                          \"(origin, backend_name, backend_version, \" \\\n                          \"category, backend_params, created_on) \" \\\n                          \"VALUES (?, ?, ?, ?, ?, ?)\"\n            cursor.execute(insert_stmt, metadata)\n\n            self._db.commit()\n            cursor.close()\n        except sqlite3.DatabaseError as e:\n            msg = \"metadata initialization error; cause: %s\" % str(e)\n            raise ArchiveError(cause=msg)\n\n        self.origin = origin\n        self.backend_name = backend_name\n        self.backend_version = backend_version\n        self.category = category\n        self.backend_params = backend_params\n        self.created_on = created_on\n\n        logger.debug(\"Metadata of archive %s initialized to %s\",\n                     self.archive_path, metadata)", "code_tokens": ["def", "init_metadata", "(", "self", ",", "origin", ",", "backend_name", ",", "backend_version", ",", "category", ",", "backend_params", ")", ":", "created_on", "=", "datetime_to_utc", "(", "datetime_utcnow", "(", ")", ")", "created_on_dumped", "=", "created_on", ".", "isoformat", "(", ")", "backend_params_dumped", "=", "pickle", ".", "dumps", "(", "backend_params", ",", "0", ")", "metadata", "=", "(", "origin", ",", "backend_name", ",", "backend_version", ",", "category", ",", "backend_params_dumped", ",", "created_on_dumped", ",", ")", "try", ":", "cursor", "=", "self", ".", "_db", ".", "cursor", "(", ")", "insert_stmt", "=", "\"INSERT INTO \"", "+", "self", ".", "METADATA_TABLE", "+", "\" \"", "\"(origin, backend_name, backend_version, \"", "\"category, backend_params, created_on) \"", "\"VALUES (?, ?, ?, ?, ?, ?)\"", "cursor", ".", "execute", "(", "insert_stmt", ",", "metadata", ")", "self", ".", "_db", ".", "commit", "(", ")", "cursor", ".", "close", "(", ")", "except", "sqlite3", ".", "DatabaseError", "as", "e", ":", "msg", "=", "\"metadata initialization error; cause: %s\"", "%", "str", "(", "e", ")", "raise", "ArchiveError", "(", "cause", "=", "msg", ")", "self", ".", "origin", "=", "origin", "self", ".", "backend_name", "=", "backend_name", "self", ".", "backend_version", "=", "backend_version", "self", ".", "category", "=", "category", "self", ".", "backend_params", "=", "backend_params", "self", ".", "created_on", "=", "created_on", "logger", ".", "debug", "(", "\"Metadata of archive %s initialized to %s\"", ",", "self", ".", "archive_path", ",", "metadata", ")"], "docstring": "Init metadata information.\n\n        Metatada is composed by basic information needed to identify\n        where archived data came from and how it can be retrieved\n        and built into Perceval items.\n\n        :param: origin: identifier of the repository\n        :param: backend_name: name of the backend\n        :param: backend_version: version of the backend\n        :param: category: category of the items fetched\n        :param: backend_params: dict representation of the fetch parameters\n\n        raises ArchiveError: when an error occurs initializing the metadata", "docstring_tokens": ["Init", "metadata", "information", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L106-L151", "partition": "test", "index": 3319, "time": "2018-01-16 11:15:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "Archive.retrieve", "original_string": "def retrieve(self, uri, payload, headers):\n        \"\"\"Retrieve a raw item from the archive.\n\n        The method will return the `data` content corresponding to the\n        hascode derived from the given parameters.\n\n        :param uri: request URI\n        :param payload: request payload\n        :param headers: request headers\n\n        :returns: the archived data\n\n        :raises ArchiveError: when an error occurs retrieving data\n        \"\"\"\n        hashcode = self.make_hashcode(uri, payload, headers)\n\n        logger.debug(\"Retrieving entry %s with %s %s %s in %s\",\n                     hashcode, uri, payload, headers, self.archive_path)\n\n        self._db.row_factory = sqlite3.Row\n\n        try:\n            cursor = self._db.cursor()\n            select_stmt = \"SELECT data \" \\\n                          \"FROM \" + self.ARCHIVE_TABLE + \" \" \\\n                          \"WHERE hashcode = ?\"\n            cursor.execute(select_stmt, (hashcode,))\n            row = cursor.fetchone()\n            cursor.close()\n        except sqlite3.DatabaseError as e:\n            msg = \"data retrieval error; cause: %s\" % str(e)\n            raise ArchiveError(cause=msg)\n\n        if row:\n            found = pickle.loads(row['data'])\n        else:\n            msg = \"entry %s not found in archive %s\" % (hashcode, self.archive_path)\n            raise ArchiveError(cause=msg)\n\n        return found", "language": "python", "code": "def retrieve(self, uri, payload, headers):\n        \"\"\"Retrieve a raw item from the archive.\n\n        The method will return the `data` content corresponding to the\n        hascode derived from the given parameters.\n\n        :param uri: request URI\n        :param payload: request payload\n        :param headers: request headers\n\n        :returns: the archived data\n\n        :raises ArchiveError: when an error occurs retrieving data\n        \"\"\"\n        hashcode = self.make_hashcode(uri, payload, headers)\n\n        logger.debug(\"Retrieving entry %s with %s %s %s in %s\",\n                     hashcode, uri, payload, headers, self.archive_path)\n\n        self._db.row_factory = sqlite3.Row\n\n        try:\n            cursor = self._db.cursor()\n            select_stmt = \"SELECT data \" \\\n                          \"FROM \" + self.ARCHIVE_TABLE + \" \" \\\n                          \"WHERE hashcode = ?\"\n            cursor.execute(select_stmt, (hashcode,))\n            row = cursor.fetchone()\n            cursor.close()\n        except sqlite3.DatabaseError as e:\n            msg = \"data retrieval error; cause: %s\" % str(e)\n            raise ArchiveError(cause=msg)\n\n        if row:\n            found = pickle.loads(row['data'])\n        else:\n            msg = \"entry %s not found in archive %s\" % (hashcode, self.archive_path)\n            raise ArchiveError(cause=msg)\n\n        return found", "code_tokens": ["def", "retrieve", "(", "self", ",", "uri", ",", "payload", ",", "headers", ")", ":", "hashcode", "=", "self", ".", "make_hashcode", "(", "uri", ",", "payload", ",", "headers", ")", "logger", ".", "debug", "(", "\"Retrieving entry %s with %s %s %s in %s\"", ",", "hashcode", ",", "uri", ",", "payload", ",", "headers", ",", "self", ".", "archive_path", ")", "self", ".", "_db", ".", "row_factory", "=", "sqlite3", ".", "Row", "try", ":", "cursor", "=", "self", ".", "_db", ".", "cursor", "(", ")", "select_stmt", "=", "\"SELECT data \"", "\"FROM \"", "+", "self", ".", "ARCHIVE_TABLE", "+", "\" \"", "\"WHERE hashcode = ?\"", "cursor", ".", "execute", "(", "select_stmt", ",", "(", "hashcode", ",", ")", ")", "row", "=", "cursor", ".", "fetchone", "(", ")", "cursor", ".", "close", "(", ")", "except", "sqlite3", ".", "DatabaseError", "as", "e", ":", "msg", "=", "\"data retrieval error; cause: %s\"", "%", "str", "(", "e", ")", "raise", "ArchiveError", "(", "cause", "=", "msg", ")", "if", "row", ":", "found", "=", "pickle", ".", "loads", "(", "row", "[", "'data'", "]", ")", "else", ":", "msg", "=", "\"entry %s not found in archive %s\"", "%", "(", "hashcode", ",", "self", ".", "archive_path", ")", "raise", "ArchiveError", "(", "cause", "=", "msg", ")", "return", "found"], "docstring": "Retrieve a raw item from the archive.\n\n        The method will return the `data` content corresponding to the\n        hascode derived from the given parameters.\n\n        :param uri: request URI\n        :param payload: request payload\n        :param headers: request headers\n\n        :returns: the archived data\n\n        :raises ArchiveError: when an error occurs retrieving data", "docstring_tokens": ["Retrieve", "a", "raw", "item", "from", "the", "archive", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L193-L232", "partition": "test", "index": 3321, "time": "2018-01-16 11:15:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "Archive.store", "original_string": "def store(self, uri, payload, headers, data):\n        \"\"\"Store a raw item in this archive.\n\n        The method will store `data` content in this archive. The unique\n        identifier for that item will be generated using the rest of the\n        parameters.\n\n        :param uri: request URI\n        :param payload: request payload\n        :param headers: request headers\n        :param data: data to store in this archive\n\n        :raises ArchiveError: when an error occurs storing the given data\n        \"\"\"\n        hashcode = self.make_hashcode(uri, payload, headers)\n        payload_dump = pickle.dumps(payload, 0)\n        headers_dump = pickle.dumps(headers, 0)\n        data_dump = pickle.dumps(data, 0)\n\n        logger.debug(\"Archiving %s with %s %s %s in %s\",\n                     hashcode, uri, payload, headers, self.archive_path)\n\n        try:\n            cursor = self._db.cursor()\n            insert_stmt = \"INSERT INTO \" + self.ARCHIVE_TABLE + \" (\" \\\n                          \"id, hashcode, uri, payload, headers, data) \" \\\n                          \"VALUES(?,?,?,?,?,?)\"\n            cursor.execute(insert_stmt, (None, hashcode, uri,\n                                         payload_dump, headers_dump, data_dump))\n            self._db.commit()\n            cursor.close()\n        except sqlite3.IntegrityError as e:\n            msg = \"data storage error; cause: duplicated entry %s\" % hashcode\n            raise ArchiveError(cause=msg)\n        except sqlite3.DatabaseError as e:\n            msg = \"data storage error; cause: %s\" % str(e)\n            raise ArchiveError(cause=msg)\n\n        logger.debug(\"%s data archived in %s\", hashcode, self.archive_path)", "language": "python", "code": "def store(self, uri, payload, headers, data):\n        \"\"\"Store a raw item in this archive.\n\n        The method will store `data` content in this archive. The unique\n        identifier for that item will be generated using the rest of the\n        parameters.\n\n        :param uri: request URI\n        :param payload: request payload\n        :param headers: request headers\n        :param data: data to store in this archive\n\n        :raises ArchiveError: when an error occurs storing the given data\n        \"\"\"\n        hashcode = self.make_hashcode(uri, payload, headers)\n        payload_dump = pickle.dumps(payload, 0)\n        headers_dump = pickle.dumps(headers, 0)\n        data_dump = pickle.dumps(data, 0)\n\n        logger.debug(\"Archiving %s with %s %s %s in %s\",\n                     hashcode, uri, payload, headers, self.archive_path)\n\n        try:\n            cursor = self._db.cursor()\n            insert_stmt = \"INSERT INTO \" + self.ARCHIVE_TABLE + \" (\" \\\n                          \"id, hashcode, uri, payload, headers, data) \" \\\n                          \"VALUES(?,?,?,?,?,?)\"\n            cursor.execute(insert_stmt, (None, hashcode, uri,\n                                         payload_dump, headers_dump, data_dump))\n            self._db.commit()\n            cursor.close()\n        except sqlite3.IntegrityError as e:\n            msg = \"data storage error; cause: duplicated entry %s\" % hashcode\n            raise ArchiveError(cause=msg)\n        except sqlite3.DatabaseError as e:\n            msg = \"data storage error; cause: %s\" % str(e)\n            raise ArchiveError(cause=msg)\n\n        logger.debug(\"%s data archived in %s\", hashcode, self.archive_path)", "code_tokens": ["def", "store", "(", "self", ",", "uri", ",", "payload", ",", "headers", ",", "data", ")", ":", "hashcode", "=", "self", ".", "make_hashcode", "(", "uri", ",", "payload", ",", "headers", ")", "payload_dump", "=", "pickle", ".", "dumps", "(", "payload", ",", "0", ")", "headers_dump", "=", "pickle", ".", "dumps", "(", "headers", ",", "0", ")", "data_dump", "=", "pickle", ".", "dumps", "(", "data", ",", "0", ")", "logger", ".", "debug", "(", "\"Archiving %s with %s %s %s in %s\"", ",", "hashcode", ",", "uri", ",", "payload", ",", "headers", ",", "self", ".", "archive_path", ")", "try", ":", "cursor", "=", "self", ".", "_db", ".", "cursor", "(", ")", "insert_stmt", "=", "\"INSERT INTO \"", "+", "self", ".", "ARCHIVE_TABLE", "+", "\" (\"", "\"id, hashcode, uri, payload, headers, data) \"", "\"VALUES(?,?,?,?,?,?)\"", "cursor", ".", "execute", "(", "insert_stmt", ",", "(", "None", ",", "hashcode", ",", "uri", ",", "payload_dump", ",", "headers_dump", ",", "data_dump", ")", ")", "self", ".", "_db", ".", "commit", "(", ")", "cursor", ".", "close", "(", ")", "except", "sqlite3", ".", "IntegrityError", "as", "e", ":", "msg", "=", "\"data storage error; cause: duplicated entry %s\"", "%", "hashcode", "raise", "ArchiveError", "(", "cause", "=", "msg", ")", "except", "sqlite3", ".", "DatabaseError", "as", "e", ":", "msg", "=", "\"data storage error; cause: %s\"", "%", "str", "(", "e", ")", "raise", "ArchiveError", "(", "cause", "=", "msg", ")", "logger", ".", "debug", "(", "\"%s data archived in %s\"", ",", "hashcode", ",", "self", ".", "archive_path", ")"], "docstring": "Store a raw item in this archive.\n\n        The method will store `data` content in this archive. The unique\n        identifier for that item will be generated using the rest of the\n        parameters.\n\n        :param uri: request URI\n        :param payload: request payload\n        :param headers: request headers\n        :param data: data to store in this archive\n\n        :raises ArchiveError: when an error occurs storing the given data", "docstring_tokens": ["Store", "a", "raw", "item", "in", "this", "archive", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L153-L191", "partition": "test", "index": 3320, "time": "2018-01-16 11:15:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "Archive._count_table_rows", "original_string": "def _count_table_rows(self, table_name):\n        \"\"\"Fetch the number of rows in a table\"\"\"\n\n        cursor = self._db.cursor()\n        select_stmt = \"SELECT COUNT(*) FROM \" + table_name\n\n        try:\n            cursor.execute(select_stmt)\n            row = cursor.fetchone()\n        except sqlite3.DatabaseError as e:\n            msg = \"invalid archive file; cause: %s\" % str(e)\n            raise ArchiveError(cause=msg)\n        finally:\n            cursor.close()\n\n        return row[0]", "language": "python", "code": "def _count_table_rows(self, table_name):\n        \"\"\"Fetch the number of rows in a table\"\"\"\n\n        cursor = self._db.cursor()\n        select_stmt = \"SELECT COUNT(*) FROM \" + table_name\n\n        try:\n            cursor.execute(select_stmt)\n            row = cursor.fetchone()\n        except sqlite3.DatabaseError as e:\n            msg = \"invalid archive file; cause: %s\" % str(e)\n            raise ArchiveError(cause=msg)\n        finally:\n            cursor.close()\n\n        return row[0]", "code_tokens": ["def", "_count_table_rows", "(", "self", ",", "table_name", ")", ":", "cursor", "=", "self", ".", "_db", ".", "cursor", "(", ")", "select_stmt", "=", "\"SELECT COUNT(*) FROM \"", "+", "table_name", "try", ":", "cursor", ".", "execute", "(", "select_stmt", ")", "row", "=", "cursor", ".", "fetchone", "(", ")", "except", "sqlite3", ".", "DatabaseError", "as", "e", ":", "msg", "=", "\"invalid archive file; cause: %s\"", "%", "str", "(", "e", ")", "raise", "ArchiveError", "(", "cause", "=", "msg", ")", "finally", ":", "cursor", ".", "close", "(", ")", "return", "row", "[", "0", "]"], "docstring": "Fetch the number of rows in a table", "docstring_tokens": ["Fetch", "the", "number", "of", "rows", "in", "a", "table"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L330-L345", "partition": "test", "index": 3326, "time": "2018-01-16 11:15:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "Archive._load_metadata", "original_string": "def _load_metadata(self):\n        \"\"\"Load metadata from the archive file\"\"\"\n\n        logger.debug(\"Loading metadata infomation of archive %s\", self.archive_path)\n\n        cursor = self._db.cursor()\n        select_stmt = \"SELECT origin, backend_name, backend_version, \" \\\n                      \"category, backend_params, created_on \" \\\n                      \"FROM \" + self.METADATA_TABLE + \" \" \\\n                      \"LIMIT 1\"\n        cursor.execute(select_stmt)\n        row = cursor.fetchone()\n        cursor.close()\n\n        if row:\n            self.origin = row[0]\n            self.backend_name = row[1]\n            self.backend_version = row[2]\n            self.category = row[3]\n            self.backend_params = pickle.loads(row[4])\n            self.created_on = str_to_datetime(row[5])\n        else:\n            logger.debug(\"Metadata of archive %s was empty\", self.archive_path)\n\n        logger.debug(\"Metadata of archive %s loaded\", self.archive_path)", "language": "python", "code": "def _load_metadata(self):\n        \"\"\"Load metadata from the archive file\"\"\"\n\n        logger.debug(\"Loading metadata infomation of archive %s\", self.archive_path)\n\n        cursor = self._db.cursor()\n        select_stmt = \"SELECT origin, backend_name, backend_version, \" \\\n                      \"category, backend_params, created_on \" \\\n                      \"FROM \" + self.METADATA_TABLE + \" \" \\\n                      \"LIMIT 1\"\n        cursor.execute(select_stmt)\n        row = cursor.fetchone()\n        cursor.close()\n\n        if row:\n            self.origin = row[0]\n            self.backend_name = row[1]\n            self.backend_version = row[2]\n            self.category = row[3]\n            self.backend_params = pickle.loads(row[4])\n            self.created_on = str_to_datetime(row[5])\n        else:\n            logger.debug(\"Metadata of archive %s was empty\", self.archive_path)\n\n        logger.debug(\"Metadata of archive %s loaded\", self.archive_path)", "code_tokens": ["def", "_load_metadata", "(", "self", ")", ":", "logger", ".", "debug", "(", "\"Loading metadata infomation of archive %s\"", ",", "self", ".", "archive_path", ")", "cursor", "=", "self", ".", "_db", ".", "cursor", "(", ")", "select_stmt", "=", "\"SELECT origin, backend_name, backend_version, \"", "\"category, backend_params, created_on \"", "\"FROM \"", "+", "self", ".", "METADATA_TABLE", "+", "\" \"", "\"LIMIT 1\"", "cursor", ".", "execute", "(", "select_stmt", ")", "row", "=", "cursor", ".", "fetchone", "(", ")", "cursor", ".", "close", "(", ")", "if", "row", ":", "self", ".", "origin", "=", "row", "[", "0", "]", "self", ".", "backend_name", "=", "row", "[", "1", "]", "self", ".", "backend_version", "=", "row", "[", "2", "]", "self", ".", "category", "=", "row", "[", "3", "]", "self", ".", "backend_params", "=", "pickle", ".", "loads", "(", "row", "[", "4", "]", ")", "self", ".", "created_on", "=", "str_to_datetime", "(", "row", "[", "5", "]", ")", "else", ":", "logger", ".", "debug", "(", "\"Metadata of archive %s was empty\"", ",", "self", ".", "archive_path", ")", "logger", ".", "debug", "(", "\"Metadata of archive %s loaded\"", ",", "self", ".", "archive_path", ")"], "docstring": "Load metadata from the archive file", "docstring_tokens": ["Load", "metadata", "from", "the", "archive", "file"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L304-L328", "partition": "test", "index": 3325, "time": "2018-01-16 11:15:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "Archive._verify_archive", "original_string": "def _verify_archive(self):\n        \"\"\"Check whether the archive is valid or not.\n\n        This method will check if tables were created and if they\n        contain valid data.\n        \"\"\"\n        nentries = self._count_table_rows(self.ARCHIVE_TABLE)\n        nmetadata = self._count_table_rows(self.METADATA_TABLE)\n\n        if nmetadata > 1:\n            msg = \"archive %s metadata corrupted; multiple metadata entries\" % (self.archive_path)\n            raise ArchiveError(cause=msg)\n        if nmetadata == 0 and nentries > 0:\n            msg = \"archive %s metadata is empty but %s entries were achived\" % (self.archive_path)\n            raise ArchiveError(cause=msg)\n\n        logger.debug(\"Integrity of archive %s OK; entries: %s rows, metadata: %s rows\",\n                     self.archive_path, nentries, nmetadata)", "language": "python", "code": "def _verify_archive(self):\n        \"\"\"Check whether the archive is valid or not.\n\n        This method will check if tables were created and if they\n        contain valid data.\n        \"\"\"\n        nentries = self._count_table_rows(self.ARCHIVE_TABLE)\n        nmetadata = self._count_table_rows(self.METADATA_TABLE)\n\n        if nmetadata > 1:\n            msg = \"archive %s metadata corrupted; multiple metadata entries\" % (self.archive_path)\n            raise ArchiveError(cause=msg)\n        if nmetadata == 0 and nentries > 0:\n            msg = \"archive %s metadata is empty but %s entries were achived\" % (self.archive_path)\n            raise ArchiveError(cause=msg)\n\n        logger.debug(\"Integrity of archive %s OK; entries: %s rows, metadata: %s rows\",\n                     self.archive_path, nentries, nmetadata)", "code_tokens": ["def", "_verify_archive", "(", "self", ")", ":", "nentries", "=", "self", ".", "_count_table_rows", "(", "self", ".", "ARCHIVE_TABLE", ")", "nmetadata", "=", "self", ".", "_count_table_rows", "(", "self", ".", "METADATA_TABLE", ")", "if", "nmetadata", ">", "1", ":", "msg", "=", "\"archive %s metadata corrupted; multiple metadata entries\"", "%", "(", "self", ".", "archive_path", ")", "raise", "ArchiveError", "(", "cause", "=", "msg", ")", "if", "nmetadata", "==", "0", "and", "nentries", ">", "0", ":", "msg", "=", "\"archive %s metadata is empty but %s entries were achived\"", "%", "(", "self", ".", "archive_path", ")", "raise", "ArchiveError", "(", "cause", "=", "msg", ")", "logger", ".", "debug", "(", "\"Integrity of archive %s OK; entries: %s rows, metadata: %s rows\"", ",", "self", ".", "archive_path", ",", "nentries", ",", "nmetadata", ")"], "docstring": "Check whether the archive is valid or not.\n\n        This method will check if tables were created and if they\n        contain valid data.", "docstring_tokens": ["Check", "whether", "the", "archive", "is", "valid", "or", "not", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L285-L302", "partition": "test", "index": 3324, "time": "2018-01-16 11:15:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "Archive.make_hashcode", "original_string": "def make_hashcode(uri, payload, headers):\n        \"\"\"Generate a SHA1 based on the given arguments.\n\n        Hashcodes created by this method will used as unique identifiers\n        for the raw items or resources stored by this archive.\n\n        :param uri: URI to the resource\n        :param payload: payload of the request needed to fetch the resource\n        :param headers: headers of the request needed to fetch the resource\n\n        :returns: a SHA1 hash code\n        \"\"\"\n        def dict_to_json_str(data):\n            return json.dumps(data, sort_keys=True)\n\n        content = ':'.join([uri, dict_to_json_str(payload), dict_to_json_str(headers)])\n        hashcode = hashlib.sha1(content.encode('utf-8'))\n        return hashcode.hexdigest()", "language": "python", "code": "def make_hashcode(uri, payload, headers):\n        \"\"\"Generate a SHA1 based on the given arguments.\n\n        Hashcodes created by this method will used as unique identifiers\n        for the raw items or resources stored by this archive.\n\n        :param uri: URI to the resource\n        :param payload: payload of the request needed to fetch the resource\n        :param headers: headers of the request needed to fetch the resource\n\n        :returns: a SHA1 hash code\n        \"\"\"\n        def dict_to_json_str(data):\n            return json.dumps(data, sort_keys=True)\n\n        content = ':'.join([uri, dict_to_json_str(payload), dict_to_json_str(headers)])\n        hashcode = hashlib.sha1(content.encode('utf-8'))\n        return hashcode.hexdigest()", "code_tokens": ["def", "make_hashcode", "(", "uri", ",", "payload", ",", "headers", ")", ":", "def", "dict_to_json_str", "(", "data", ")", ":", "return", "json", ".", "dumps", "(", "data", ",", "sort_keys", "=", "True", ")", "content", "=", "':'", ".", "join", "(", "[", "uri", ",", "dict_to_json_str", "(", "payload", ")", ",", "dict_to_json_str", "(", "headers", ")", "]", ")", "hashcode", "=", "hashlib", ".", "sha1", "(", "content", ".", "encode", "(", "'utf-8'", ")", ")", "return", "hashcode", ".", "hexdigest", "(", ")"], "docstring": "Generate a SHA1 based on the given arguments.\n\n        Hashcodes created by this method will used as unique identifiers\n        for the raw items or resources stored by this archive.\n\n        :param uri: URI to the resource\n        :param payload: payload of the request needed to fetch the resource\n        :param headers: headers of the request needed to fetch the resource\n\n        :returns: a SHA1 hash code", "docstring_tokens": ["Generate", "a", "SHA1", "based", "on", "the", "given", "arguments", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L266-L283", "partition": "test", "index": 3323, "time": "2018-01-16 11:15:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "Archive.create", "original_string": "def create(cls, archive_path):\n        \"\"\"Create a brand new archive.\n\n         Call this method to create a new and empty archive. It will initialize\n         the storage file in the path defined by `archive_path`.\n\n        :param archive_path: absolute path where the archive file will be created\n\n        :raises ArchiveError: when the archive file already exists\n        \"\"\"\n        if os.path.exists(archive_path):\n            msg = \"archive %s already exists; remove it before creating a new one\"\n            raise ArchiveError(cause=msg % (archive_path))\n\n        conn = sqlite3.connect(archive_path)\n\n        cursor = conn.cursor()\n        cursor.execute(cls.METADATA_CREATE_STMT)\n        cursor.execute(cls.ARCHIVE_CREATE_STMT)\n        conn.commit()\n\n        cursor.close()\n        conn.close()\n\n        logger.debug(\"Creating archive %s\", archive_path)\n        archive = cls(archive_path)\n        logger.debug(\"Achive %s was created\", archive_path)\n\n        return archive", "language": "python", "code": "def create(cls, archive_path):\n        \"\"\"Create a brand new archive.\n\n         Call this method to create a new and empty archive. It will initialize\n         the storage file in the path defined by `archive_path`.\n\n        :param archive_path: absolute path where the archive file will be created\n\n        :raises ArchiveError: when the archive file already exists\n        \"\"\"\n        if os.path.exists(archive_path):\n            msg = \"archive %s already exists; remove it before creating a new one\"\n            raise ArchiveError(cause=msg % (archive_path))\n\n        conn = sqlite3.connect(archive_path)\n\n        cursor = conn.cursor()\n        cursor.execute(cls.METADATA_CREATE_STMT)\n        cursor.execute(cls.ARCHIVE_CREATE_STMT)\n        conn.commit()\n\n        cursor.close()\n        conn.close()\n\n        logger.debug(\"Creating archive %s\", archive_path)\n        archive = cls(archive_path)\n        logger.debug(\"Achive %s was created\", archive_path)\n\n        return archive", "code_tokens": ["def", "create", "(", "cls", ",", "archive_path", ")", ":", "if", "os", ".", "path", ".", "exists", "(", "archive_path", ")", ":", "msg", "=", "\"archive %s already exists; remove it before creating a new one\"", "raise", "ArchiveError", "(", "cause", "=", "msg", "%", "(", "archive_path", ")", ")", "conn", "=", "sqlite3", ".", "connect", "(", "archive_path", ")", "cursor", "=", "conn", ".", "cursor", "(", ")", "cursor", ".", "execute", "(", "cls", ".", "METADATA_CREATE_STMT", ")", "cursor", ".", "execute", "(", "cls", ".", "ARCHIVE_CREATE_STMT", ")", "conn", ".", "commit", "(", ")", "cursor", ".", "close", "(", ")", "conn", ".", "close", "(", ")", "logger", ".", "debug", "(", "\"Creating archive %s\"", ",", "archive_path", ")", "archive", "=", "cls", "(", "archive_path", ")", "logger", ".", "debug", "(", "\"Achive %s was created\"", ",", "archive_path", ")", "return", "archive"], "docstring": "Create a brand new archive.\n\n         Call this method to create a new and empty archive. It will initialize\n         the storage file in the path defined by `archive_path`.\n\n        :param archive_path: absolute path where the archive file will be created\n\n        :raises ArchiveError: when the archive file already exists", "docstring_tokens": ["Create", "a", "brand", "new", "archive", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L235-L263", "partition": "test", "index": 3322, "time": "2018-01-16 11:15:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient._get_token_rate_limit", "original_string": "def _get_token_rate_limit(self, token):\n        \"\"\"Return token's remaining API points\"\"\"\n\n        rate_url = urijoin(self.base_url, \"rate_limit\")\n        self.session.headers.update({'Authorization': 'token ' + token})\n        remaining = 0\n        try:\n            headers = super().fetch(rate_url).headers\n            if self.rate_limit_header in headers:\n                remaining = int(headers[self.rate_limit_header])\n        except requests.exceptions.HTTPError as error:\n            logger.warning(\"Rate limit not initialized: %s\", error)\n        return remaining", "language": "python", "code": "def _get_token_rate_limit(self, token):\n        \"\"\"Return token's remaining API points\"\"\"\n\n        rate_url = urijoin(self.base_url, \"rate_limit\")\n        self.session.headers.update({'Authorization': 'token ' + token})\n        remaining = 0\n        try:\n            headers = super().fetch(rate_url).headers\n            if self.rate_limit_header in headers:\n                remaining = int(headers[self.rate_limit_header])\n        except requests.exceptions.HTTPError as error:\n            logger.warning(\"Rate limit not initialized: %s\", error)\n        return remaining", "code_tokens": ["def", "_get_token_rate_limit", "(", "self", ",", "token", ")", ":", "rate_url", "=", "urijoin", "(", "self", ".", "base_url", ",", "\"rate_limit\"", ")", "self", ".", "session", ".", "headers", ".", "update", "(", "{", "'Authorization'", ":", "'token '", "+", "token", "}", ")", "remaining", "=", "0", "try", ":", "headers", "=", "super", "(", ")", ".", "fetch", "(", "rate_url", ")", ".", "headers", "if", "self", ".", "rate_limit_header", "in", "headers", ":", "remaining", "=", "int", "(", "headers", "[", "self", ".", "rate_limit_header", "]", ")", "except", "requests", ".", "exceptions", ".", "HTTPError", "as", "error", ":", "logger", ".", "warning", "(", "\"Rate limit not initialized: %s\"", ",", "error", ")", "return", "remaining"], "docstring": "Return token's remaining API points", "docstring_tokens": ["Return", "token", "s", "remaining", "API", "points"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L772-L784", "partition": "test", "index": 3314, "time": "2018-01-16 12:40:26"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient._update_current_rate_limit", "original_string": "def _update_current_rate_limit(self):\n        \"\"\"Update rate limits data for the current token\"\"\"\n\n        url = urijoin(self.base_url, \"rate_limit\")\n        try:\n            # Turn off archiving when checking rates, because that would cause\n            # archive key conflict (the same URLs giving different responses)\n            arch = self.archive\n            self.archive = None\n            response = super().fetch(url)\n            self.archive = arch\n            self.update_rate_limit(response)\n            self.last_rate_limit_checked = self.rate_limit\n        except requests.exceptions.HTTPError as error:\n            if error.response.status_code == 404:\n                logger.warning(\"Rate limit not initialized: %s\", error)\n            else:\n                raise error", "language": "python", "code": "def _update_current_rate_limit(self):\n        \"\"\"Update rate limits data for the current token\"\"\"\n\n        url = urijoin(self.base_url, \"rate_limit\")\n        try:\n            # Turn off archiving when checking rates, because that would cause\n            # archive key conflict (the same URLs giving different responses)\n            arch = self.archive\n            self.archive = None\n            response = super().fetch(url)\n            self.archive = arch\n            self.update_rate_limit(response)\n            self.last_rate_limit_checked = self.rate_limit\n        except requests.exceptions.HTTPError as error:\n            if error.response.status_code == 404:\n                logger.warning(\"Rate limit not initialized: %s\", error)\n            else:\n                raise error", "code_tokens": ["def", "_update_current_rate_limit", "(", "self", ")", ":", "url", "=", "urijoin", "(", "self", ".", "base_url", ",", "\"rate_limit\"", ")", "try", ":", "# Turn off archiving when checking rates, because that would cause", "# archive key conflict (the same URLs giving different responses)", "arch", "=", "self", ".", "archive", "self", ".", "archive", "=", "None", "response", "=", "super", "(", ")", ".", "fetch", "(", "url", ")", "self", ".", "archive", "=", "arch", "self", ".", "update_rate_limit", "(", "response", ")", "self", ".", "last_rate_limit_checked", "=", "self", ".", "rate_limit", "except", "requests", ".", "exceptions", ".", "HTTPError", "as", "error", ":", "if", "error", ".", "response", ".", "status_code", "==", "404", ":", "logger", ".", "warning", "(", "\"Rate limit not initialized: %s\"", ",", "error", ")", "else", ":", "raise", "error"], "docstring": "Update rate limits data for the current token", "docstring_tokens": ["Update", "rate", "limits", "data", "for", "the", "current", "token"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L848-L865", "partition": "test", "index": 3318, "time": "2018-01-16 12:40:26"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/jira.py", "func_name": "JiraClient.get_fields", "original_string": "def get_fields(self):\n        \"\"\"Retrieve all the fields available.\"\"\"\n\n        url = urijoin(self.base_url, self.RESOURCE, self.VERSION_API, 'field')\n        req = self.fetch(url)\n\n        return req.text", "language": "python", "code": "def get_fields(self):\n        \"\"\"Retrieve all the fields available.\"\"\"\n\n        url = urijoin(self.base_url, self.RESOURCE, self.VERSION_API, 'field')\n        req = self.fetch(url)\n\n        return req.text", "code_tokens": ["def", "get_fields", "(", "self", ")", ":", "url", "=", "urijoin", "(", "self", ".", "base_url", ",", "self", ".", "RESOURCE", ",", "self", ".", "VERSION_API", ",", "'field'", ")", "req", "=", "self", ".", "fetch", "(", "url", ")", "return", "req", ".", "text"], "docstring": "Retrieve all the fields available.", "docstring_tokens": ["Retrieve", "all", "the", "fields", "available", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/jira.py#L346-L352", "partition": "test", "index": 3351, "time": "2018-01-17 18:17:55"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/jira.py", "func_name": "JiraClient.get_items", "original_string": "def get_items(self, from_date, url, expand_fields=True):\n        \"\"\"Retrieve all the items from a given date.\n\n        :param url: endpoint API url\n        :param from_date: obtain items updated since this date\n        :param expand_fields: if True, it includes the expand fields in the payload\n        \"\"\"\n        start_at = 0\n\n        req = self.fetch(url, payload=self.__build_payload(start_at, from_date, expand_fields))\n        issues = req.text\n\n        data = req.json()\n        titems = data['total']\n        nitems = data['maxResults']\n\n        start_at += min(nitems, titems)\n        self.__log_status(start_at, titems, url)\n\n        while issues:\n            yield issues\n            issues = None\n\n            if data['startAt'] + nitems < titems:\n                req = self.fetch(url, payload=self.__build_payload(start_at, from_date, expand_fields))\n\n                data = req.json()\n                start_at += nitems\n                issues = req.text\n                self.__log_status(start_at, titems, url)", "language": "python", "code": "def get_items(self, from_date, url, expand_fields=True):\n        \"\"\"Retrieve all the items from a given date.\n\n        :param url: endpoint API url\n        :param from_date: obtain items updated since this date\n        :param expand_fields: if True, it includes the expand fields in the payload\n        \"\"\"\n        start_at = 0\n\n        req = self.fetch(url, payload=self.__build_payload(start_at, from_date, expand_fields))\n        issues = req.text\n\n        data = req.json()\n        titems = data['total']\n        nitems = data['maxResults']\n\n        start_at += min(nitems, titems)\n        self.__log_status(start_at, titems, url)\n\n        while issues:\n            yield issues\n            issues = None\n\n            if data['startAt'] + nitems < titems:\n                req = self.fetch(url, payload=self.__build_payload(start_at, from_date, expand_fields))\n\n                data = req.json()\n                start_at += nitems\n                issues = req.text\n                self.__log_status(start_at, titems, url)", "code_tokens": ["def", "get_items", "(", "self", ",", "from_date", ",", "url", ",", "expand_fields", "=", "True", ")", ":", "start_at", "=", "0", "req", "=", "self", ".", "fetch", "(", "url", ",", "payload", "=", "self", ".", "__build_payload", "(", "start_at", ",", "from_date", ",", "expand_fields", ")", ")", "issues", "=", "req", ".", "text", "data", "=", "req", ".", "json", "(", ")", "titems", "=", "data", "[", "'total'", "]", "nitems", "=", "data", "[", "'maxResults'", "]", "start_at", "+=", "min", "(", "nitems", ",", "titems", ")", "self", ".", "__log_status", "(", "start_at", ",", "titems", ",", "url", ")", "while", "issues", ":", "yield", "issues", "issues", "=", "None", "if", "data", "[", "'startAt'", "]", "+", "nitems", "<", "titems", ":", "req", "=", "self", ".", "fetch", "(", "url", ",", "payload", "=", "self", ".", "__build_payload", "(", "start_at", ",", "from_date", ",", "expand_fields", ")", ")", "data", "=", "req", ".", "json", "(", ")", "start_at", "+=", "nitems", "issues", "=", "req", ".", "text", "self", ".", "__log_status", "(", "start_at", ",", "titems", ",", "url", ")"], "docstring": "Retrieve all the items from a given date.\n\n        :param url: endpoint API url\n        :param from_date: obtain items updated since this date\n        :param expand_fields: if True, it includes the expand fields in the payload", "docstring_tokens": ["Retrieve", "all", "the", "items", "from", "a", "given", "date", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/jira.py#L295-L324", "partition": "test", "index": 3348, "time": "2018-01-17 18:17:55"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/phabricator.py", "func_name": "Phabricator.parse_tasks", "original_string": "def parse_tasks(raw_json):\n        \"\"\"Parse a Phabricator tasks JSON stream.\n\n        The method parses a JSON stream and returns a list iterator.\n        Each item is a dictionary that contains the task parsed data.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed tasks\n        \"\"\"\n        results = json.loads(raw_json)\n\n        tasks = results['result']['data']\n        for t in tasks:\n            yield t", "language": "python", "code": "def parse_tasks(raw_json):\n        \"\"\"Parse a Phabricator tasks JSON stream.\n\n        The method parses a JSON stream and returns a list iterator.\n        Each item is a dictionary that contains the task parsed data.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed tasks\n        \"\"\"\n        results = json.loads(raw_json)\n\n        tasks = results['result']['data']\n        for t in tasks:\n            yield t", "code_tokens": ["def", "parse_tasks", "(", "raw_json", ")", ":", "results", "=", "json", ".", "loads", "(", "raw_json", ")", "tasks", "=", "results", "[", "'result'", "]", "[", "'data'", "]", "for", "t", "in", "tasks", ":", "yield", "t"], "docstring": "Parse a Phabricator tasks JSON stream.\n\n        The method parses a JSON stream and returns a list iterator.\n        Each item is a dictionary that contains the task parsed data.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed tasks", "docstring_tokens": ["Parse", "a", "Phabricator", "tasks", "JSON", "stream", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/phabricator.py#L165-L179", "partition": "test", "index": 3389, "time": "2018-01-18 13:57:41"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/phabricator.py", "func_name": "Phabricator.parse_users", "original_string": "def parse_users(raw_json):\n        \"\"\"Parse a Phabricator users JSON stream.\n\n        The method parses a JSON stream and returns a list iterator.\n        Each item is a dictionary that contais the user parsed data.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed users\n        \"\"\"\n        results = json.loads(raw_json)\n\n        users = results['result']\n        for u in users:\n            yield u", "language": "python", "code": "def parse_users(raw_json):\n        \"\"\"Parse a Phabricator users JSON stream.\n\n        The method parses a JSON stream and returns a list iterator.\n        Each item is a dictionary that contais the user parsed data.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed users\n        \"\"\"\n        results = json.loads(raw_json)\n\n        users = results['result']\n        for u in users:\n            yield u", "code_tokens": ["def", "parse_users", "(", "raw_json", ")", ":", "results", "=", "json", ".", "loads", "(", "raw_json", ")", "users", "=", "results", "[", "'result'", "]", "for", "u", "in", "users", ":", "yield", "u"], "docstring": "Parse a Phabricator users JSON stream.\n\n        The method parses a JSON stream and returns a list iterator.\n        Each item is a dictionary that contais the user parsed data.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed users", "docstring_tokens": ["Parse", "a", "Phabricator", "users", "JSON", "stream", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/phabricator.py#L196-L210", "partition": "test", "index": 3390, "time": "2018-01-18 13:57:41"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/telegram.py", "func_name": "Telegram._filter_message_by_chats", "original_string": "def _filter_message_by_chats(self, message, chats):\n        \"\"\"Check if a message can be filtered based in a list of chats.\n\n        This method returns `True` when the message was sent to a chat\n        of the given list. It also returns `True` when chats is `None`.\n\n        :param message: Telegram message\n        :param chats: list of chat, groups and channels identifiers\n\n        :returns: `True` when the message can be filtered; otherwise,\n            it returns `False`\n        \"\"\"\n        if chats is None:\n            return True\n\n        chat_id = message['message']['chat']['id']\n\n        return chat_id in chats", "language": "python", "code": "def _filter_message_by_chats(self, message, chats):\n        \"\"\"Check if a message can be filtered based in a list of chats.\n\n        This method returns `True` when the message was sent to a chat\n        of the given list. It also returns `True` when chats is `None`.\n\n        :param message: Telegram message\n        :param chats: list of chat, groups and channels identifiers\n\n        :returns: `True` when the message can be filtered; otherwise,\n            it returns `False`\n        \"\"\"\n        if chats is None:\n            return True\n\n        chat_id = message['message']['chat']['id']\n\n        return chat_id in chats", "code_tokens": ["def", "_filter_message_by_chats", "(", "self", ",", "message", ",", "chats", ")", ":", "if", "chats", "is", "None", ":", "return", "True", "chat_id", "=", "message", "[", "'message'", "]", "[", "'chat'", "]", "[", "'id'", "]", "return", "chat_id", "in", "chats"], "docstring": "Check if a message can be filtered based in a list of chats.\n\n        This method returns `True` when the message was sent to a chat\n        of the given list. It also returns `True` when chats is `None`.\n\n        :param message: Telegram message\n        :param chats: list of chat, groups and channels identifiers\n\n        :returns: `True` when the message can be filtered; otherwise,\n            it returns `False`", "docstring_tokens": ["Check", "if", "a", "message", "can", "be", "filtered", "based", "in", "a", "list", "of", "chats", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/telegram.py#L237-L254", "partition": "test", "index": 3365, "time": "2018-01-18 15:38:40"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "Backend.fetch", "original_string": "def fetch(self, category, filter_classified=False, **kwargs):\n        \"\"\"Fetch items from the repository.\n\n        The method retrieves items from a repository.\n\n        To removed classified fields from the resulting items, set\n        the parameter `filter_classified`. Take into account this\n        parameter is incompatible with archiving items. Raw client\n        data are archived before any other process. Therefore,\n        classified data  are stored within the archive. To prevent\n        from possible data leaks or security issues when users do\n        not need these fields, archiving and filtering are not\n        compatible.\n\n        :param category: the category of the items fetched\n        :param filter_classified: remove classified fields from the resulting items\n        :param kwargs: a list of other parameters (e.g., from_date, offset, etc.\n        specific for each backend)\n\n        :returns: a generator of items\n\n        :raises BackendError: either when the category is not valid or\n            'filter_classified' and 'archive' are active at the same time.\n        \"\"\"\n        if category not in self.categories:\n            cause = \"%s category not valid for %s\" % (category, self.__class__.__name__)\n            raise BackendError(cause=cause)\n\n        if filter_classified and self.archive:\n            cause = \"classified fields filtering is not compatible with archiving items\"\n            raise BackendError(cause=cause)\n\n        if self.archive:\n            self.archive.init_metadata(self.origin, self.__class__.__name__, self.version, category,\n                                       kwargs)\n\n        self.client = self._init_client()\n\n        for item in self.fetch_items(category, **kwargs):\n            if filter_classified:\n                item = self.filter_classified_data(item)\n\n            yield self.metadata(item, filter_classified=filter_classified)", "language": "python", "code": "def fetch(self, category, filter_classified=False, **kwargs):\n        \"\"\"Fetch items from the repository.\n\n        The method retrieves items from a repository.\n\n        To removed classified fields from the resulting items, set\n        the parameter `filter_classified`. Take into account this\n        parameter is incompatible with archiving items. Raw client\n        data are archived before any other process. Therefore,\n        classified data  are stored within the archive. To prevent\n        from possible data leaks or security issues when users do\n        not need these fields, archiving and filtering are not\n        compatible.\n\n        :param category: the category of the items fetched\n        :param filter_classified: remove classified fields from the resulting items\n        :param kwargs: a list of other parameters (e.g., from_date, offset, etc.\n        specific for each backend)\n\n        :returns: a generator of items\n\n        :raises BackendError: either when the category is not valid or\n            'filter_classified' and 'archive' are active at the same time.\n        \"\"\"\n        if category not in self.categories:\n            cause = \"%s category not valid for %s\" % (category, self.__class__.__name__)\n            raise BackendError(cause=cause)\n\n        if filter_classified and self.archive:\n            cause = \"classified fields filtering is not compatible with archiving items\"\n            raise BackendError(cause=cause)\n\n        if self.archive:\n            self.archive.init_metadata(self.origin, self.__class__.__name__, self.version, category,\n                                       kwargs)\n\n        self.client = self._init_client()\n\n        for item in self.fetch_items(category, **kwargs):\n            if filter_classified:\n                item = self.filter_classified_data(item)\n\n            yield self.metadata(item, filter_classified=filter_classified)", "code_tokens": ["def", "fetch", "(", "self", ",", "category", ",", "filter_classified", "=", "False", ",", "*", "*", "kwargs", ")", ":", "if", "category", "not", "in", "self", ".", "categories", ":", "cause", "=", "\"%s category not valid for %s\"", "%", "(", "category", ",", "self", ".", "__class__", ".", "__name__", ")", "raise", "BackendError", "(", "cause", "=", "cause", ")", "if", "filter_classified", "and", "self", ".", "archive", ":", "cause", "=", "\"classified fields filtering is not compatible with archiving items\"", "raise", "BackendError", "(", "cause", "=", "cause", ")", "if", "self", ".", "archive", ":", "self", ".", "archive", ".", "init_metadata", "(", "self", ".", "origin", ",", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "version", ",", "category", ",", "kwargs", ")", "self", ".", "client", "=", "self", ".", "_init_client", "(", ")", "for", "item", "in", "self", ".", "fetch_items", "(", "category", ",", "*", "*", "kwargs", ")", ":", "if", "filter_classified", ":", "item", "=", "self", ".", "filter_classified_data", "(", "item", ")", "yield", "self", ".", "metadata", "(", "item", ",", "filter_classified", "=", "filter_classified", ")"], "docstring": "Fetch items from the repository.\n\n        The method retrieves items from a repository.\n\n        To removed classified fields from the resulting items, set\n        the parameter `filter_classified`. Take into account this\n        parameter is incompatible with archiving items. Raw client\n        data are archived before any other process. Therefore,\n        classified data  are stored within the archive. To prevent\n        from possible data leaks or security issues when users do\n        not need these fields, archiving and filtering are not\n        compatible.\n\n        :param category: the category of the items fetched\n        :param filter_classified: remove classified fields from the resulting items\n        :param kwargs: a list of other parameters (e.g., from_date, offset, etc.\n        specific for each backend)\n\n        :returns: a generator of items\n\n        :raises BackendError: either when the category is not valid or\n            'filter_classified' and 'archive' are active at the same time.", "docstring_tokens": ["Fetch", "items", "from", "the", "repository", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L124-L166", "partition": "test", "index": 3248, "time": "2018-01-22 18:58:58"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "Backend.fetch_from_archive", "original_string": "def fetch_from_archive(self):\n        \"\"\"Fetch the questions from an archive.\n\n        It returns the items stored within an archive. If this method is called but\n        no archive was provided, the method will raise a `ArchiveError` exception.\n\n        :returns: a generator of items\n\n        :raises ArchiveError: raised when an error occurs accessing an archive\n        \"\"\"\n        if not self.archive:\n            raise ArchiveError(cause=\"archive instance was not provided\")\n\n        self.client = self._init_client(from_archive=True)\n\n        for item in self.fetch_items(self.archive.category, **self.archive.backend_params):\n            yield self.metadata(item)", "language": "python", "code": "def fetch_from_archive(self):\n        \"\"\"Fetch the questions from an archive.\n\n        It returns the items stored within an archive. If this method is called but\n        no archive was provided, the method will raise a `ArchiveError` exception.\n\n        :returns: a generator of items\n\n        :raises ArchiveError: raised when an error occurs accessing an archive\n        \"\"\"\n        if not self.archive:\n            raise ArchiveError(cause=\"archive instance was not provided\")\n\n        self.client = self._init_client(from_archive=True)\n\n        for item in self.fetch_items(self.archive.category, **self.archive.backend_params):\n            yield self.metadata(item)", "code_tokens": ["def", "fetch_from_archive", "(", "self", ")", ":", "if", "not", "self", ".", "archive", ":", "raise", "ArchiveError", "(", "cause", "=", "\"archive instance was not provided\"", ")", "self", ".", "client", "=", "self", ".", "_init_client", "(", "from_archive", "=", "True", ")", "for", "item", "in", "self", ".", "fetch_items", "(", "self", ".", "archive", ".", "category", ",", "*", "*", "self", ".", "archive", ".", "backend_params", ")", ":", "yield", "self", ".", "metadata", "(", "item", ")"], "docstring": "Fetch the questions from an archive.\n\n        It returns the items stored within an archive. If this method is called but\n        no archive was provided, the method will raise a `ArchiveError` exception.\n\n        :returns: a generator of items\n\n        :raises ArchiveError: raised when an error occurs accessing an archive", "docstring_tokens": ["Fetch", "the", "questions", "from", "an", "archive", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L168-L184", "partition": "test", "index": 3249, "time": "2018-01-22 18:58:58"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/nntp.py", "func_name": "NNTTPClient._fetch_from_archive", "original_string": "def _fetch_from_archive(self, method, args):\n        \"\"\"Fetch data from the archive\n\n        :param method: the name of the command to execute\n        :param args: the arguments required by the command\n        \"\"\"\n        if not self.archive:\n            raise ArchiveError(cause=\"Archive not provided\")\n\n        data = self.archive.retrieve(method, args, None)\n\n        if isinstance(data, nntplib.NNTPTemporaryError):\n            raise data\n\n        return data", "language": "python", "code": "def _fetch_from_archive(self, method, args):\n        \"\"\"Fetch data from the archive\n\n        :param method: the name of the command to execute\n        :param args: the arguments required by the command\n        \"\"\"\n        if not self.archive:\n            raise ArchiveError(cause=\"Archive not provided\")\n\n        data = self.archive.retrieve(method, args, None)\n\n        if isinstance(data, nntplib.NNTPTemporaryError):\n            raise data\n\n        return data", "code_tokens": ["def", "_fetch_from_archive", "(", "self", ",", "method", ",", "args", ")", ":", "if", "not", "self", ".", "archive", ":", "raise", "ArchiveError", "(", "cause", "=", "\"Archive not provided\"", ")", "data", "=", "self", ".", "archive", ".", "retrieve", "(", "method", ",", "args", ",", "None", ")", "if", "isinstance", "(", "data", ",", "nntplib", ".", "NNTPTemporaryError", ")", ":", "raise", "data", "return", "data"], "docstring": "Fetch data from the archive\n\n        :param method: the name of the command to execute\n        :param args: the arguments required by the command", "docstring_tokens": ["Fetch", "data", "from", "the", "archive"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/nntp.py#L339-L353", "partition": "test", "index": 3373, "time": "2018-01-25 16:28:47"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/nntp.py", "func_name": "NNTTPClient._fetch_from_remote", "original_string": "def _fetch_from_remote(self, method, args):\n        \"\"\"Fetch data from NNTP\n\n        :param method: the name of the command to execute\n        :param args: the arguments required by the command\n        \"\"\"\n        try:\n            if method == NNTTPClient.GROUP:\n                data = self.handler.group(args)\n            elif method == NNTTPClient.OVER:\n                data = self.handler.over(args)\n            elif method == NNTTPClient.ARTICLE:\n                data = self._fetch_article(args)\n        except nntplib.NNTPTemporaryError as e:\n            data = e\n            raise e\n        finally:\n            if self.archive:\n                self.archive.store(method, args, None, data)\n\n        return data", "language": "python", "code": "def _fetch_from_remote(self, method, args):\n        \"\"\"Fetch data from NNTP\n\n        :param method: the name of the command to execute\n        :param args: the arguments required by the command\n        \"\"\"\n        try:\n            if method == NNTTPClient.GROUP:\n                data = self.handler.group(args)\n            elif method == NNTTPClient.OVER:\n                data = self.handler.over(args)\n            elif method == NNTTPClient.ARTICLE:\n                data = self._fetch_article(args)\n        except nntplib.NNTPTemporaryError as e:\n            data = e\n            raise e\n        finally:\n            if self.archive:\n                self.archive.store(method, args, None, data)\n\n        return data", "code_tokens": ["def", "_fetch_from_remote", "(", "self", ",", "method", ",", "args", ")", ":", "try", ":", "if", "method", "==", "NNTTPClient", ".", "GROUP", ":", "data", "=", "self", ".", "handler", ".", "group", "(", "args", ")", "elif", "method", "==", "NNTTPClient", ".", "OVER", ":", "data", "=", "self", ".", "handler", ".", "over", "(", "args", ")", "elif", "method", "==", "NNTTPClient", ".", "ARTICLE", ":", "data", "=", "self", ".", "_fetch_article", "(", "args", ")", "except", "nntplib", ".", "NNTPTemporaryError", "as", "e", ":", "data", "=", "e", "raise", "e", "finally", ":", "if", "self", ".", "archive", ":", "self", ".", "archive", ".", "store", "(", "method", ",", "args", ",", "None", ",", "data", ")", "return", "data"], "docstring": "Fetch data from NNTP\n\n        :param method: the name of the command to execute\n        :param args: the arguments required by the command", "docstring_tokens": ["Fetch", "data", "from", "NNTP"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/nntp.py#L317-L337", "partition": "test", "index": 3372, "time": "2018-01-25 16:28:47"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/nntp.py", "func_name": "NNTTPClient._fetch_article", "original_string": "def _fetch_article(self, article_id):\n        \"\"\"Fetch article data\n\n        :param article_id: id of the article to fetch\n        \"\"\"\n        fetched_data = self.handler.article(article_id)\n        data = {\n            'number': fetched_data[1].number,\n            'message_id': fetched_data[1].message_id,\n            'lines': fetched_data[1].lines\n        }\n\n        return data", "language": "python", "code": "def _fetch_article(self, article_id):\n        \"\"\"Fetch article data\n\n        :param article_id: id of the article to fetch\n        \"\"\"\n        fetched_data = self.handler.article(article_id)\n        data = {\n            'number': fetched_data[1].number,\n            'message_id': fetched_data[1].message_id,\n            'lines': fetched_data[1].lines\n        }\n\n        return data", "code_tokens": ["def", "_fetch_article", "(", "self", ",", "article_id", ")", ":", "fetched_data", "=", "self", ".", "handler", ".", "article", "(", "article_id", ")", "data", "=", "{", "'number'", ":", "fetched_data", "[", "1", "]", ".", "number", ",", "'message_id'", ":", "fetched_data", "[", "1", "]", ".", "message_id", ",", "'lines'", ":", "fetched_data", "[", "1", "]", ".", "lines", "}", "return", "data"], "docstring": "Fetch article data\n\n        :param article_id: id of the article to fetch", "docstring_tokens": ["Fetch", "article", "data"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/nntp.py#L303-L315", "partition": "test", "index": 3371, "time": "2018-01-25 16:28:47"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/nntp.py", "func_name": "NNTTPClient._fetch", "original_string": "def _fetch(self, method, args):\n        \"\"\"Fetch NNTP data from the server or from the archive\n\n        :param method: the name of the command to execute\n        :param args: the arguments required by the command\n        \"\"\"\n        if self.from_archive:\n            data = self._fetch_from_archive(method, args)\n        else:\n            data = self._fetch_from_remote(method, args)\n\n        return data", "language": "python", "code": "def _fetch(self, method, args):\n        \"\"\"Fetch NNTP data from the server or from the archive\n\n        :param method: the name of the command to execute\n        :param args: the arguments required by the command\n        \"\"\"\n        if self.from_archive:\n            data = self._fetch_from_archive(method, args)\n        else:\n            data = self._fetch_from_remote(method, args)\n\n        return data", "code_tokens": ["def", "_fetch", "(", "self", ",", "method", ",", "args", ")", ":", "if", "self", ".", "from_archive", ":", "data", "=", "self", ".", "_fetch_from_archive", "(", "method", ",", "args", ")", "else", ":", "data", "=", "self", ".", "_fetch_from_remote", "(", "method", ",", "args", ")", "return", "data"], "docstring": "Fetch NNTP data from the server or from the archive\n\n        :param method: the name of the command to execute\n        :param args: the arguments required by the command", "docstring_tokens": ["Fetch", "NNTP", "data", "from", "the", "server", "or", "from", "the", "archive"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/nntp.py#L290-L301", "partition": "test", "index": 3370, "time": "2018-01-25 16:28:47"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gerrit.py", "func_name": "Gerrit.parse_reviews", "original_string": "def parse_reviews(raw_data):\n        \"\"\"Parse a Gerrit reviews list.\"\"\"\n\n        # Join isolated reviews in JSON in array for parsing\n        items_raw = \"[\" + raw_data.replace(\"\\n\", \",\") + \"]\"\n        items_raw = items_raw.replace(\",]\", \"]\")\n        items = json.loads(items_raw)\n        reviews = []\n\n        for item in items:\n            if 'project' in item.keys():\n                reviews.append(item)\n\n        return reviews", "language": "python", "code": "def parse_reviews(raw_data):\n        \"\"\"Parse a Gerrit reviews list.\"\"\"\n\n        # Join isolated reviews in JSON in array for parsing\n        items_raw = \"[\" + raw_data.replace(\"\\n\", \",\") + \"]\"\n        items_raw = items_raw.replace(\",]\", \"]\")\n        items = json.loads(items_raw)\n        reviews = []\n\n        for item in items:\n            if 'project' in item.keys():\n                reviews.append(item)\n\n        return reviews", "code_tokens": ["def", "parse_reviews", "(", "raw_data", ")", ":", "# Join isolated reviews in JSON in array for parsing", "items_raw", "=", "\"[\"", "+", "raw_data", ".", "replace", "(", "\"\\n\"", ",", "\",\"", ")", "+", "\"]\"", "items_raw", "=", "items_raw", ".", "replace", "(", "\",]\"", ",", "\"]\"", ")", "items", "=", "json", ".", "loads", "(", "items_raw", ")", "reviews", "=", "[", "]", "for", "item", "in", "items", ":", "if", "'project'", "in", "item", ".", "keys", "(", ")", ":", "reviews", ".", "append", "(", "item", ")", "return", "reviews"], "docstring": "Parse a Gerrit reviews list.", "docstring_tokens": ["Parse", "a", "Gerrit", "reviews", "list", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gerrit.py#L165-L178", "partition": "test", "index": 3221, "time": "2018-01-26 09:39:16"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mbox.py", "func_name": "MBox.metadata_updated_on", "original_string": "def metadata_updated_on(item):\n        \"\"\"Extracts the update time from a MBox item.\n\n        The timestamp used is extracted from 'Date' field in its\n        several forms. This date is converted to UNIX timestamp\n        format.\n\n        :param item: item generated by the backend\n\n        :returns: a UNIX timestamp\n        \"\"\"\n        ts = item[MBox.DATE_FIELD]\n        ts = str_to_datetime(ts)\n\n        return ts.timestamp()", "language": "python", "code": "def metadata_updated_on(item):\n        \"\"\"Extracts the update time from a MBox item.\n\n        The timestamp used is extracted from 'Date' field in its\n        several forms. This date is converted to UNIX timestamp\n        format.\n\n        :param item: item generated by the backend\n\n        :returns: a UNIX timestamp\n        \"\"\"\n        ts = item[MBox.DATE_FIELD]\n        ts = str_to_datetime(ts)\n\n        return ts.timestamp()", "code_tokens": ["def", "metadata_updated_on", "(", "item", ")", ":", "ts", "=", "item", "[", "MBox", ".", "DATE_FIELD", "]", "ts", "=", "str_to_datetime", "(", "ts", ")", "return", "ts", ".", "timestamp", "(", ")"], "docstring": "Extracts the update time from a MBox item.\n\n        The timestamp used is extracted from 'Date' field in its\n        several forms. This date is converted to UNIX timestamp\n        format.\n\n        :param item: item generated by the backend\n\n        :returns: a UNIX timestamp", "docstring_tokens": ["Extracts", "the", "update", "time", "from", "a", "MBox", "item", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mbox.py#L143-L157", "partition": "test", "index": 3257, "time": "2018-01-26 10:45:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mbox.py", "func_name": "MBox.parse_mbox", "original_string": "def parse_mbox(filepath):\n        \"\"\"Parse a mbox file.\n\n        This method parses a mbox file and returns an iterator of dictionaries.\n        Each one of this contains an email message.\n\n        :param filepath: path of the mbox to parse\n\n        :returns : generator of messages; each message is stored in a\n            dictionary of type `requests.structures.CaseInsensitiveDict`\n        \"\"\"\n        mbox = _MBox(filepath, create=False)\n\n        for msg in mbox:\n            message = message_to_dict(msg)\n            yield message", "language": "python", "code": "def parse_mbox(filepath):\n        \"\"\"Parse a mbox file.\n\n        This method parses a mbox file and returns an iterator of dictionaries.\n        Each one of this contains an email message.\n\n        :param filepath: path of the mbox to parse\n\n        :returns : generator of messages; each message is stored in a\n            dictionary of type `requests.structures.CaseInsensitiveDict`\n        \"\"\"\n        mbox = _MBox(filepath, create=False)\n\n        for msg in mbox:\n            message = message_to_dict(msg)\n            yield message", "code_tokens": ["def", "parse_mbox", "(", "filepath", ")", ":", "mbox", "=", "_MBox", "(", "filepath", ",", "create", "=", "False", ")", "for", "msg", "in", "mbox", ":", "message", "=", "message_to_dict", "(", "msg", ")", "yield", "message"], "docstring": "Parse a mbox file.\n\n        This method parses a mbox file and returns an iterator of dictionaries.\n        Each one of this contains an email message.\n\n        :param filepath: path of the mbox to parse\n\n        :returns : generator of messages; each message is stored in a\n            dictionary of type `requests.structures.CaseInsensitiveDict`", "docstring_tokens": ["Parse", "a", "mbox", "file", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mbox.py#L169-L184", "partition": "test", "index": 3258, "time": "2018-01-26 10:45:36"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/supybot.py", "func_name": "Supybot.__retrieve_archives", "original_string": "def __retrieve_archives(self, from_date):\n        \"\"\"Retrieve the Supybot archives after the given date\"\"\"\n\n        archives = []\n\n        candidates = self.__list_supybot_archives()\n\n        for candidate in candidates:\n            dt = self.__parse_date_from_filepath(candidate)\n\n            if dt.date() >= from_date.date():\n                archives.append((dt, candidate))\n            else:\n                logger.debug(\"Archive %s stored before %s; skipped\",\n                             candidate, str(from_date))\n\n        archives.sort(key=lambda x: x[0])\n\n        return [archive[1] for archive in archives]", "language": "python", "code": "def __retrieve_archives(self, from_date):\n        \"\"\"Retrieve the Supybot archives after the given date\"\"\"\n\n        archives = []\n\n        candidates = self.__list_supybot_archives()\n\n        for candidate in candidates:\n            dt = self.__parse_date_from_filepath(candidate)\n\n            if dt.date() >= from_date.date():\n                archives.append((dt, candidate))\n            else:\n                logger.debug(\"Archive %s stored before %s; skipped\",\n                             candidate, str(from_date))\n\n        archives.sort(key=lambda x: x[0])\n\n        return [archive[1] for archive in archives]", "code_tokens": ["def", "__retrieve_archives", "(", "self", ",", "from_date", ")", ":", "archives", "=", "[", "]", "candidates", "=", "self", ".", "__list_supybot_archives", "(", ")", "for", "candidate", "in", "candidates", ":", "dt", "=", "self", ".", "__parse_date_from_filepath", "(", "candidate", ")", "if", "dt", ".", "date", "(", ")", ">=", "from_date", ".", "date", "(", ")", ":", "archives", ".", "append", "(", "(", "dt", ",", "candidate", ")", ")", "else", ":", "logger", ".", "debug", "(", "\"Archive %s stored before %s; skipped\"", ",", "candidate", ",", "str", "(", "from_date", ")", ")", "archives", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "return", "[", "archive", "[", "1", "]", "for", "archive", "in", "archives", "]"], "docstring": "Retrieve the Supybot archives after the given date", "docstring_tokens": ["Retrieve", "the", "Supybot", "archives", "after", "the", "given", "date"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/supybot.py#L213-L231", "partition": "test", "index": 3379, "time": "2018-01-29 09:28:08"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/supybot.py", "func_name": "Supybot.__list_supybot_archives", "original_string": "def __list_supybot_archives(self):\n        \"\"\"List the filepath of the archives stored in dirpath\"\"\"\n\n        archives = []\n\n        for root, _, files in os.walk(self.dirpath):\n            for filename in files:\n                location = os.path.join(root, filename)\n                archives.append(location)\n\n        return archives", "language": "python", "code": "def __list_supybot_archives(self):\n        \"\"\"List the filepath of the archives stored in dirpath\"\"\"\n\n        archives = []\n\n        for root, _, files in os.walk(self.dirpath):\n            for filename in files:\n                location = os.path.join(root, filename)\n                archives.append(location)\n\n        return archives", "code_tokens": ["def", "__list_supybot_archives", "(", "self", ")", ":", "archives", "=", "[", "]", "for", "root", ",", "_", ",", "files", "in", "os", ".", "walk", "(", "self", ".", "dirpath", ")", ":", "for", "filename", "in", "files", ":", "location", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", "archives", ".", "append", "(", "location", ")", "return", "archives"], "docstring": "List the filepath of the archives stored in dirpath", "docstring_tokens": ["List", "the", "filepath", "of", "the", "archives", "stored", "in", "dirpath"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/supybot.py#L233-L243", "partition": "test", "index": 3380, "time": "2018-01-29 09:28:08"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "ArchiveManager.search", "original_string": "def search(self, origin, backend_name, category, archived_after):\n        \"\"\"Search archives.\n\n        Get the archives which store data based on the given parameters.\n        These parameters define which the origin was (`origin`), how data\n        was fetched (`backend_name`) and data type ('category').\n        Only those archives created on or after `archived_after` will be\n        returned.\n\n        The method returns a list with the file paths to those archives.\n        The list is sorted by the date of creation of each archive.\n\n        :param origin: data origin\n        :param backend_name: backed used to fetch data\n        :param category: type of the items fetched by the backend\n        :param archived_after: get archives created on or after this date\n\n        :returns: a list with archive names which match the search criteria\n        \"\"\"\n        archives = self._search_archives(origin, backend_name,\n                                         category, archived_after)\n        archives = [(fp, date) for fp, date in archives]\n        archives = [fp for fp, _ in sorted(archives, key=lambda x: x[1])]\n\n        return archives", "language": "python", "code": "def search(self, origin, backend_name, category, archived_after):\n        \"\"\"Search archives.\n\n        Get the archives which store data based on the given parameters.\n        These parameters define which the origin was (`origin`), how data\n        was fetched (`backend_name`) and data type ('category').\n        Only those archives created on or after `archived_after` will be\n        returned.\n\n        The method returns a list with the file paths to those archives.\n        The list is sorted by the date of creation of each archive.\n\n        :param origin: data origin\n        :param backend_name: backed used to fetch data\n        :param category: type of the items fetched by the backend\n        :param archived_after: get archives created on or after this date\n\n        :returns: a list with archive names which match the search criteria\n        \"\"\"\n        archives = self._search_archives(origin, backend_name,\n                                         category, archived_after)\n        archives = [(fp, date) for fp, date in archives]\n        archives = [fp for fp, _ in sorted(archives, key=lambda x: x[1])]\n\n        return archives", "code_tokens": ["def", "search", "(", "self", ",", "origin", ",", "backend_name", ",", "category", ",", "archived_after", ")", ":", "archives", "=", "self", ".", "_search_archives", "(", "origin", ",", "backend_name", ",", "category", ",", "archived_after", ")", "archives", "=", "[", "(", "fp", ",", "date", ")", "for", "fp", ",", "date", "in", "archives", "]", "archives", "=", "[", "fp", "for", "fp", ",", "_", "in", "sorted", "(", "archives", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "]", "return", "archives"], "docstring": "Search archives.\n\n        Get the archives which store data based on the given parameters.\n        These parameters define which the origin was (`origin`), how data\n        was fetched (`backend_name`) and data type ('category').\n        Only those archives created on or after `archived_after` will be\n        returned.\n\n        The method returns a list with the file paths to those archives.\n        The list is sorted by the date of creation of each archive.\n\n        :param origin: data origin\n        :param backend_name: backed used to fetch data\n        :param category: type of the items fetched by the backend\n        :param archived_after: get archives created on or after this date\n\n        :returns: a list with archive names which match the search criteria", "docstring_tokens": ["Search", "archives", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L414-L438", "partition": "test", "index": 3329, "time": "2018-01-31 18:13:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "ArchiveManager.remove_archive", "original_string": "def remove_archive(self, archive_path):\n        \"\"\"Remove an archive.\n\n        This method deletes from the filesystem the archive stored\n        in `archive_path`.\n\n        :param archive_path: path to the archive\n\n        :raises ArchiveManangerError: when an error occurs removing the\n            archive\n        \"\"\"\n        try:\n            Archive(archive_path)\n        except ArchiveError as e:\n            raise ArchiveManagerError(cause=str(e))\n\n        os.remove(archive_path)", "language": "python", "code": "def remove_archive(self, archive_path):\n        \"\"\"Remove an archive.\n\n        This method deletes from the filesystem the archive stored\n        in `archive_path`.\n\n        :param archive_path: path to the archive\n\n        :raises ArchiveManangerError: when an error occurs removing the\n            archive\n        \"\"\"\n        try:\n            Archive(archive_path)\n        except ArchiveError as e:\n            raise ArchiveManagerError(cause=str(e))\n\n        os.remove(archive_path)", "code_tokens": ["def", "remove_archive", "(", "self", ",", "archive_path", ")", ":", "try", ":", "Archive", "(", "archive_path", ")", "except", "ArchiveError", "as", "e", ":", "raise", "ArchiveManagerError", "(", "cause", "=", "str", "(", "e", ")", ")", "os", ".", "remove", "(", "archive_path", ")"], "docstring": "Remove an archive.\n\n        This method deletes from the filesystem the archive stored\n        in `archive_path`.\n\n        :param archive_path: path to the archive\n\n        :raises ArchiveManangerError: when an error occurs removing the\n            archive", "docstring_tokens": ["Remove", "an", "archive", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L396-L412", "partition": "test", "index": 3328, "time": "2018-01-31 18:13:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "ArchiveManager.create_archive", "original_string": "def create_archive(self):\n        \"\"\"Create a new archive.\n\n        The method creates in the filesystem a brand new archive with\n        a random SHA1 as its name. The first byte of the hashcode will\n        be the name of the subdirectory; the remaining bytes, the\n        archive name.\n\n        :returns: a new `Archive` object\n\n        :raises ArchiveManagerError: when an error occurs creating the\n            new archive\n        \"\"\"\n        hashcode = uuid.uuid4().hex\n        archive_dir = os.path.join(self.dirpath, hashcode[0:2])\n        archive_name = hashcode[2:] + self.STORAGE_EXT\n        archive_path = os.path.join(archive_dir, archive_name)\n\n        if not os.path.exists(archive_dir):\n            os.makedirs(archive_dir)\n\n        try:\n            archive = Archive.create(archive_path)\n        except ArchiveError as e:\n            raise ArchiveManagerError(cause=str(e))\n\n        return archive", "language": "python", "code": "def create_archive(self):\n        \"\"\"Create a new archive.\n\n        The method creates in the filesystem a brand new archive with\n        a random SHA1 as its name. The first byte of the hashcode will\n        be the name of the subdirectory; the remaining bytes, the\n        archive name.\n\n        :returns: a new `Archive` object\n\n        :raises ArchiveManagerError: when an error occurs creating the\n            new archive\n        \"\"\"\n        hashcode = uuid.uuid4().hex\n        archive_dir = os.path.join(self.dirpath, hashcode[0:2])\n        archive_name = hashcode[2:] + self.STORAGE_EXT\n        archive_path = os.path.join(archive_dir, archive_name)\n\n        if not os.path.exists(archive_dir):\n            os.makedirs(archive_dir)\n\n        try:\n            archive = Archive.create(archive_path)\n        except ArchiveError as e:\n            raise ArchiveManagerError(cause=str(e))\n\n        return archive", "code_tokens": ["def", "create_archive", "(", "self", ")", ":", "hashcode", "=", "uuid", ".", "uuid4", "(", ")", ".", "hex", "archive_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dirpath", ",", "hashcode", "[", "0", ":", "2", "]", ")", "archive_name", "=", "hashcode", "[", "2", ":", "]", "+", "self", ".", "STORAGE_EXT", "archive_path", "=", "os", ".", "path", ".", "join", "(", "archive_dir", ",", "archive_name", ")", "if", "not", "os", ".", "path", ".", "exists", "(", "archive_dir", ")", ":", "os", ".", "makedirs", "(", "archive_dir", ")", "try", ":", "archive", "=", "Archive", ".", "create", "(", "archive_path", ")", "except", "ArchiveError", "as", "e", ":", "raise", "ArchiveManagerError", "(", "cause", "=", "str", "(", "e", ")", ")", "return", "archive"], "docstring": "Create a new archive.\n\n        The method creates in the filesystem a brand new archive with\n        a random SHA1 as its name. The first byte of the hashcode will\n        be the name of the subdirectory; the remaining bytes, the\n        archive name.\n\n        :returns: a new `Archive` object\n\n        :raises ArchiveManagerError: when an error occurs creating the\n            new archive", "docstring_tokens": ["Create", "a", "new", "archive", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L368-L394", "partition": "test", "index": 3327, "time": "2018-01-31 18:13:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "ArchiveManager._search_archives", "original_string": "def _search_archives(self, origin, backend_name, category, archived_after):\n        \"\"\"Search archives using filters.\"\"\"\n\n        for archive_path in self._search_files():\n            try:\n                archive = Archive(archive_path)\n            except ArchiveError:\n                continue\n\n            match = archive.origin == origin and \\\n                archive.backend_name == backend_name and \\\n                archive.category == category and \\\n                archive.created_on >= archived_after\n\n            if not match:\n                continue\n\n            yield archive_path, archive.created_on", "language": "python", "code": "def _search_archives(self, origin, backend_name, category, archived_after):\n        \"\"\"Search archives using filters.\"\"\"\n\n        for archive_path in self._search_files():\n            try:\n                archive = Archive(archive_path)\n            except ArchiveError:\n                continue\n\n            match = archive.origin == origin and \\\n                archive.backend_name == backend_name and \\\n                archive.category == category and \\\n                archive.created_on >= archived_after\n\n            if not match:\n                continue\n\n            yield archive_path, archive.created_on", "code_tokens": ["def", "_search_archives", "(", "self", ",", "origin", ",", "backend_name", ",", "category", ",", "archived_after", ")", ":", "for", "archive_path", "in", "self", ".", "_search_files", "(", ")", ":", "try", ":", "archive", "=", "Archive", "(", "archive_path", ")", "except", "ArchiveError", ":", "continue", "match", "=", "archive", ".", "origin", "==", "origin", "and", "archive", ".", "backend_name", "==", "backend_name", "and", "archive", ".", "category", "==", "category", "and", "archive", ".", "created_on", ">=", "archived_after", "if", "not", "match", ":", "continue", "yield", "archive_path", ",", "archive", ".", "created_on"], "docstring": "Search archives using filters.", "docstring_tokens": ["Search", "archives", "using", "filters", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L440-L457", "partition": "test", "index": 3330, "time": "2018-01-31 18:13:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/archive.py", "func_name": "ArchiveManager._search_files", "original_string": "def _search_files(self):\n        \"\"\"Retrieve the file paths stored under the base path.\"\"\"\n\n        for root, _, files in os.walk(self.dirpath):\n            for filename in files:\n                location = os.path.join(root, filename)\n                yield location", "language": "python", "code": "def _search_files(self):\n        \"\"\"Retrieve the file paths stored under the base path.\"\"\"\n\n        for root, _, files in os.walk(self.dirpath):\n            for filename in files:\n                location = os.path.join(root, filename)\n                yield location", "code_tokens": ["def", "_search_files", "(", "self", ")", ":", "for", "root", ",", "_", ",", "files", "in", "os", ".", "walk", "(", "self", ".", "dirpath", ")", ":", "for", "filename", "in", "files", ":", "location", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", "yield", "location"], "docstring": "Retrieve the file paths stored under the base path.", "docstring_tokens": ["Retrieve", "the", "file", "paths", "stored", "under", "the", "base", "path", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/archive.py#L459-L465", "partition": "test", "index": 3331, "time": "2018-01-31 18:13:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "BackendCommandArgumentParser._set_archive_arguments", "original_string": "def _set_archive_arguments(self):\n        \"\"\"Activate archive arguments parsing\"\"\"\n\n        group = self.parser.add_argument_group('archive arguments')\n        group.add_argument('--archive-path', dest='archive_path', default=None,\n                           help=\"directory path to the archives\")\n        group.add_argument('--no-archive', dest='no_archive', action='store_true',\n                           help=\"do not archive data\")\n        group.add_argument('--fetch-archive', dest='fetch_archive', action='store_true',\n                           help=\"fetch data from the archives\")\n        group.add_argument('--archived-since', dest='archived_since', default='1970-01-01',\n                           help=\"retrieve items archived since the given date\")", "language": "python", "code": "def _set_archive_arguments(self):\n        \"\"\"Activate archive arguments parsing\"\"\"\n\n        group = self.parser.add_argument_group('archive arguments')\n        group.add_argument('--archive-path', dest='archive_path', default=None,\n                           help=\"directory path to the archives\")\n        group.add_argument('--no-archive', dest='no_archive', action='store_true',\n                           help=\"do not archive data\")\n        group.add_argument('--fetch-archive', dest='fetch_archive', action='store_true',\n                           help=\"fetch data from the archives\")\n        group.add_argument('--archived-since', dest='archived_since', default='1970-01-01',\n                           help=\"retrieve items archived since the given date\")", "code_tokens": ["def", "_set_archive_arguments", "(", "self", ")", ":", "group", "=", "self", ".", "parser", ".", "add_argument_group", "(", "'archive arguments'", ")", "group", ".", "add_argument", "(", "'--archive-path'", ",", "dest", "=", "'archive_path'", ",", "default", "=", "None", ",", "help", "=", "\"directory path to the archives\"", ")", "group", ".", "add_argument", "(", "'--no-archive'", ",", "dest", "=", "'no_archive'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"do not archive data\"", ")", "group", ".", "add_argument", "(", "'--fetch-archive'", ",", "dest", "=", "'fetch_archive'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"fetch data from the archives\"", ")", "group", ".", "add_argument", "(", "'--archived-since'", ",", "dest", "=", "'archived_since'", ",", "default", "=", "'1970-01-01'", ",", "help", "=", "\"retrieve items archived since the given date\"", ")"], "docstring": "Activate archive arguments parsing", "docstring_tokens": ["Activate", "archive", "arguments", "parsing"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L391-L402", "partition": "test", "index": 3253, "time": "2018-02-06 12:12:46"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "fetch", "original_string": "def fetch(backend_class, backend_args, category, filter_classified=False,\n          manager=None):\n    \"\"\"Fetch items using the given backend.\n\n    Generator to get items using the given backend class. When\n    an archive manager is given, this function will store\n    the fetched items in an `Archive`. If an exception is raised,\n    this archive will be removed to avoid corrupted archives.\n\n    The parameters needed to initialize the `backend` class and\n    get the items are given using `backend_args` dict parameter.\n\n    :param backend_class: backend class to fetch items\n    :param backend_args: dict of arguments needed to fetch the items\n    :param category: category of the items to retrieve.\n       If None, it will use the default backend category\n    :param filter_classified: remove classified fields from the resulting items\n    :param manager: archive manager needed to store the items\n\n    :returns: a generator of items\n    \"\"\"\n    init_args = find_signature_parameters(backend_class.__init__,\n                                          backend_args)\n    archive = manager.create_archive() if manager else None\n    init_args['archive'] = archive\n\n    backend = backend_class(**init_args)\n\n    if category:\n        backend_args['category'] = category\n    if filter_classified:\n        backend_args['filter_classified'] = filter_classified\n\n    fetch_args = find_signature_parameters(backend.fetch,\n                                           backend_args)\n    items = backend.fetch(**fetch_args)\n\n    try:\n        for item in items:\n            yield item\n    except Exception as e:\n        if manager:\n            archive_path = archive.archive_path\n            manager.remove_archive(archive_path)\n        raise e", "language": "python", "code": "def fetch(backend_class, backend_args, category, filter_classified=False,\n          manager=None):\n    \"\"\"Fetch items using the given backend.\n\n    Generator to get items using the given backend class. When\n    an archive manager is given, this function will store\n    the fetched items in an `Archive`. If an exception is raised,\n    this archive will be removed to avoid corrupted archives.\n\n    The parameters needed to initialize the `backend` class and\n    get the items are given using `backend_args` dict parameter.\n\n    :param backend_class: backend class to fetch items\n    :param backend_args: dict of arguments needed to fetch the items\n    :param category: category of the items to retrieve.\n       If None, it will use the default backend category\n    :param filter_classified: remove classified fields from the resulting items\n    :param manager: archive manager needed to store the items\n\n    :returns: a generator of items\n    \"\"\"\n    init_args = find_signature_parameters(backend_class.__init__,\n                                          backend_args)\n    archive = manager.create_archive() if manager else None\n    init_args['archive'] = archive\n\n    backend = backend_class(**init_args)\n\n    if category:\n        backend_args['category'] = category\n    if filter_classified:\n        backend_args['filter_classified'] = filter_classified\n\n    fetch_args = find_signature_parameters(backend.fetch,\n                                           backend_args)\n    items = backend.fetch(**fetch_args)\n\n    try:\n        for item in items:\n            yield item\n    except Exception as e:\n        if manager:\n            archive_path = archive.archive_path\n            manager.remove_archive(archive_path)\n        raise e", "code_tokens": ["def", "fetch", "(", "backend_class", ",", "backend_args", ",", "category", ",", "filter_classified", "=", "False", ",", "manager", "=", "None", ")", ":", "init_args", "=", "find_signature_parameters", "(", "backend_class", ".", "__init__", ",", "backend_args", ")", "archive", "=", "manager", ".", "create_archive", "(", ")", "if", "manager", "else", "None", "init_args", "[", "'archive'", "]", "=", "archive", "backend", "=", "backend_class", "(", "*", "*", "init_args", ")", "if", "category", ":", "backend_args", "[", "'category'", "]", "=", "category", "if", "filter_classified", ":", "backend_args", "[", "'filter_classified'", "]", "=", "filter_classified", "fetch_args", "=", "find_signature_parameters", "(", "backend", ".", "fetch", ",", "backend_args", ")", "items", "=", "backend", ".", "fetch", "(", "*", "*", "fetch_args", ")", "try", ":", "for", "item", "in", "items", ":", "yield", "item", "except", "Exception", "as", "e", ":", "if", "manager", ":", "archive_path", "=", "archive", ".", "archive_path", "manager", ".", "remove_archive", "(", "archive_path", ")", "raise", "e"], "docstring": "Fetch items using the given backend.\n\n    Generator to get items using the given backend class. When\n    an archive manager is given, this function will store\n    the fetched items in an `Archive`. If an exception is raised,\n    this archive will be removed to avoid corrupted archives.\n\n    The parameters needed to initialize the `backend` class and\n    get the items are given using `backend_args` dict parameter.\n\n    :param backend_class: backend class to fetch items\n    :param backend_args: dict of arguments needed to fetch the items\n    :param category: category of the items to retrieve.\n       If None, it will use the default backend category\n    :param filter_classified: remove classified fields from the resulting items\n    :param manager: archive manager needed to store the items\n\n    :returns: a generator of items", "docstring_tokens": ["Fetch", "items", "using", "the", "given", "backend", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L545-L589", "partition": "test", "index": 3245, "time": "2018-02-09 01:25:26"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "fetch_from_archive", "original_string": "def fetch_from_archive(backend_class, backend_args, manager,\n                       category, archived_after):\n    \"\"\"Fetch items from an archive manager.\n\n    Generator to get the items of a category (previously fetched\n    by the given backend class) from an archive manager. Only those\n    items archived after the given date will be returned.\n\n    The parameters needed to initialize `backend` and get the\n    items are given using `backend_args` dict parameter.\n\n    :param backend_class: backend class to retrive items\n    :param backend_args: dict of arguments needed to retrieve the items\n    :param manager: archive manager where the items will be retrieved\n    :param category: category of the items to retrieve\n    :param archived_after: return items archived after this date\n\n    :returns: a generator of archived items\n    \"\"\"\n    init_args = find_signature_parameters(backend_class.__init__,\n                                          backend_args)\n    backend = backend_class(**init_args)\n\n    filepaths = manager.search(backend.origin,\n                               backend.__class__.__name__,\n                               category,\n                               archived_after)\n\n    for filepath in filepaths:\n        backend.archive = Archive(filepath)\n        items = backend.fetch_from_archive()\n\n        try:\n            for item in items:\n                yield item\n        except ArchiveError as e:\n            logger.warning(\"Ignoring %s archive due to: %s\", filepath, str(e))", "language": "python", "code": "def fetch_from_archive(backend_class, backend_args, manager,\n                       category, archived_after):\n    \"\"\"Fetch items from an archive manager.\n\n    Generator to get the items of a category (previously fetched\n    by the given backend class) from an archive manager. Only those\n    items archived after the given date will be returned.\n\n    The parameters needed to initialize `backend` and get the\n    items are given using `backend_args` dict parameter.\n\n    :param backend_class: backend class to retrive items\n    :param backend_args: dict of arguments needed to retrieve the items\n    :param manager: archive manager where the items will be retrieved\n    :param category: category of the items to retrieve\n    :param archived_after: return items archived after this date\n\n    :returns: a generator of archived items\n    \"\"\"\n    init_args = find_signature_parameters(backend_class.__init__,\n                                          backend_args)\n    backend = backend_class(**init_args)\n\n    filepaths = manager.search(backend.origin,\n                               backend.__class__.__name__,\n                               category,\n                               archived_after)\n\n    for filepath in filepaths:\n        backend.archive = Archive(filepath)\n        items = backend.fetch_from_archive()\n\n        try:\n            for item in items:\n                yield item\n        except ArchiveError as e:\n            logger.warning(\"Ignoring %s archive due to: %s\", filepath, str(e))", "code_tokens": ["def", "fetch_from_archive", "(", "backend_class", ",", "backend_args", ",", "manager", ",", "category", ",", "archived_after", ")", ":", "init_args", "=", "find_signature_parameters", "(", "backend_class", ".", "__init__", ",", "backend_args", ")", "backend", "=", "backend_class", "(", "*", "*", "init_args", ")", "filepaths", "=", "manager", ".", "search", "(", "backend", ".", "origin", ",", "backend", ".", "__class__", ".", "__name__", ",", "category", ",", "archived_after", ")", "for", "filepath", "in", "filepaths", ":", "backend", ".", "archive", "=", "Archive", "(", "filepath", ")", "items", "=", "backend", ".", "fetch_from_archive", "(", ")", "try", ":", "for", "item", "in", "items", ":", "yield", "item", "except", "ArchiveError", "as", "e", ":", "logger", ".", "warning", "(", "\"Ignoring %s archive due to: %s\"", ",", "filepath", ",", "str", "(", "e", ")", ")"], "docstring": "Fetch items from an archive manager.\n\n    Generator to get the items of a category (previously fetched\n    by the given backend class) from an archive manager. Only those\n    items archived after the given date will be returned.\n\n    The parameters needed to initialize `backend` and get the\n    items are given using `backend_args` dict parameter.\n\n    :param backend_class: backend class to retrive items\n    :param backend_args: dict of arguments needed to retrieve the items\n    :param manager: archive manager where the items will be retrieved\n    :param category: category of the items to retrieve\n    :param archived_after: return items archived after this date\n\n    :returns: a generator of archived items", "docstring_tokens": ["Fetch", "items", "from", "an", "archive", "manager", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L592-L628", "partition": "test", "index": 3246, "time": "2018-02-09 01:25:26"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gerrit.py", "func_name": "GerritClient.__execute_from_remote", "original_string": "def __execute_from_remote(self, cmd):\n        \"\"\"Execute gerrit command with retry if it fails\"\"\"\n\n        result = None  # data result from the cmd execution\n        retries = 0\n\n        while retries < self.MAX_RETRIES:\n            try:\n                result = subprocess.check_output(cmd, shell=True)\n                break\n            except subprocess.CalledProcessError as ex:\n                logger.error(\"gerrit cmd %s failed: %s\", cmd, ex)\n                time.sleep(self.RETRY_WAIT * retries)\n                retries += 1\n\n        if result is None:\n            result = RuntimeError(cmd + \" failed \" + str(self.MAX_RETRIES) + \" times. Giving up!\")\n\n        if self.archive:\n            cmd = self.sanitize_for_archive(cmd)\n            self.archive.store(cmd, None, None, result)\n\n        if isinstance(result, RuntimeError):\n            raise result\n\n        return result", "language": "python", "code": "def __execute_from_remote(self, cmd):\n        \"\"\"Execute gerrit command with retry if it fails\"\"\"\n\n        result = None  # data result from the cmd execution\n        retries = 0\n\n        while retries < self.MAX_RETRIES:\n            try:\n                result = subprocess.check_output(cmd, shell=True)\n                break\n            except subprocess.CalledProcessError as ex:\n                logger.error(\"gerrit cmd %s failed: %s\", cmd, ex)\n                time.sleep(self.RETRY_WAIT * retries)\n                retries += 1\n\n        if result is None:\n            result = RuntimeError(cmd + \" failed \" + str(self.MAX_RETRIES) + \" times. Giving up!\")\n\n        if self.archive:\n            cmd = self.sanitize_for_archive(cmd)\n            self.archive.store(cmd, None, None, result)\n\n        if isinstance(result, RuntimeError):\n            raise result\n\n        return result", "code_tokens": ["def", "__execute_from_remote", "(", "self", ",", "cmd", ")", ":", "result", "=", "None", "# data result from the cmd execution", "retries", "=", "0", "while", "retries", "<", "self", ".", "MAX_RETRIES", ":", "try", ":", "result", "=", "subprocess", ".", "check_output", "(", "cmd", ",", "shell", "=", "True", ")", "break", "except", "subprocess", ".", "CalledProcessError", "as", "ex", ":", "logger", ".", "error", "(", "\"gerrit cmd %s failed: %s\"", ",", "cmd", ",", "ex", ")", "time", ".", "sleep", "(", "self", ".", "RETRY_WAIT", "*", "retries", ")", "retries", "+=", "1", "if", "result", "is", "None", ":", "result", "=", "RuntimeError", "(", "cmd", "+", "\" failed \"", "+", "str", "(", "self", ".", "MAX_RETRIES", ")", "+", "\" times. Giving up!\"", ")", "if", "self", ".", "archive", ":", "cmd", "=", "self", ".", "sanitize_for_archive", "(", "cmd", ")", "self", ".", "archive", ".", "store", "(", "cmd", ",", "None", ",", "None", ",", "result", ")", "if", "isinstance", "(", "result", ",", "RuntimeError", ")", ":", "raise", "result", "return", "result"], "docstring": "Execute gerrit command with retry if it fails", "docstring_tokens": ["Execute", "gerrit", "command", "with", "retry", "if", "it", "fails"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gerrit.py#L424-L449", "partition": "test", "index": 3228, "time": "2018-03-06 11:44:01"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gerrit.py", "func_name": "GerritClient.__execute_from_archive", "original_string": "def __execute_from_archive(self, cmd):\n        \"\"\"Execute gerrit command against the archive\"\"\"\n\n        cmd = self.sanitize_for_archive(cmd)\n        response = self.archive.retrieve(cmd, None, None)\n\n        if isinstance(response, RuntimeError):\n            raise response\n\n        return response", "language": "python", "code": "def __execute_from_archive(self, cmd):\n        \"\"\"Execute gerrit command against the archive\"\"\"\n\n        cmd = self.sanitize_for_archive(cmd)\n        response = self.archive.retrieve(cmd, None, None)\n\n        if isinstance(response, RuntimeError):\n            raise response\n\n        return response", "code_tokens": ["def", "__execute_from_archive", "(", "self", ",", "cmd", ")", ":", "cmd", "=", "self", ".", "sanitize_for_archive", "(", "cmd", ")", "response", "=", "self", ".", "archive", ".", "retrieve", "(", "cmd", ",", "None", ",", "None", ")", "if", "isinstance", "(", "response", ",", "RuntimeError", ")", ":", "raise", "response", "return", "response"], "docstring": "Execute gerrit command against the archive", "docstring_tokens": ["Execute", "gerrit", "command", "against", "the", "archive"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gerrit.py#L413-L422", "partition": "test", "index": 3227, "time": "2018-03-06 11:44:01"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gerrit.py", "func_name": "GerritClient.__execute", "original_string": "def __execute(self, cmd):\n        \"\"\"Execute gerrit command\"\"\"\n\n        if self.from_archive:\n            response = self.__execute_from_archive(cmd)\n        else:\n            response = self.__execute_from_remote(cmd)\n\n        return response", "language": "python", "code": "def __execute(self, cmd):\n        \"\"\"Execute gerrit command\"\"\"\n\n        if self.from_archive:\n            response = self.__execute_from_archive(cmd)\n        else:\n            response = self.__execute_from_remote(cmd)\n\n        return response", "code_tokens": ["def", "__execute", "(", "self", ",", "cmd", ")", ":", "if", "self", ".", "from_archive", ":", "response", "=", "self", ".", "__execute_from_archive", "(", "cmd", ")", "else", ":", "response", "=", "self", ".", "__execute_from_remote", "(", "cmd", ")", "return", "response"], "docstring": "Execute gerrit command", "docstring_tokens": ["Execute", "gerrit", "command"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gerrit.py#L403-L411", "partition": "test", "index": 3226, "time": "2018-03-06 11:44:01"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mattermost.py", "func_name": "MattermostClient.user", "original_string": "def user(self, user):\n        \"\"\"Fetch user data.\"\"\"\n\n        entrypoint = self.RUSERS + '/' + user\n        response = self._fetch(entrypoint, None)\n\n        return response", "language": "python", "code": "def user(self, user):\n        \"\"\"Fetch user data.\"\"\"\n\n        entrypoint = self.RUSERS + '/' + user\n        response = self._fetch(entrypoint, None)\n\n        return response", "code_tokens": ["def", "user", "(", "self", ",", "user", ")", ":", "entrypoint", "=", "self", ".", "RUSERS", "+", "'/'", "+", "user", "response", "=", "self", ".", "_fetch", "(", "entrypoint", ",", "None", ")", "return", "response"], "docstring": "Fetch user data.", "docstring_tokens": ["Fetch", "user", "data", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mattermost.py#L313-L319", "partition": "test", "index": 3166, "time": "2018-04-26 10:58:51"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mattermost.py", "func_name": "Mattermost._parse_posts", "original_string": "def _parse_posts(self, raw_posts):\n        \"\"\"Parse posts and returns in order.\"\"\"\n\n        parsed_posts = self.parse_json(raw_posts)\n\n        # Posts are not sorted. The order is provided by\n        # 'order' key.\n        for post_id in parsed_posts['order']:\n            yield parsed_posts['posts'][post_id]", "language": "python", "code": "def _parse_posts(self, raw_posts):\n        \"\"\"Parse posts and returns in order.\"\"\"\n\n        parsed_posts = self.parse_json(raw_posts)\n\n        # Posts are not sorted. The order is provided by\n        # 'order' key.\n        for post_id in parsed_posts['order']:\n            yield parsed_posts['posts'][post_id]", "code_tokens": ["def", "_parse_posts", "(", "self", ",", "raw_posts", ")", ":", "parsed_posts", "=", "self", ".", "parse_json", "(", "raw_posts", ")", "# Posts are not sorted. The order is provided by", "# 'order' key.", "for", "post_id", "in", "parsed_posts", "[", "'order'", "]", ":", "yield", "parsed_posts", "[", "'posts'", "]", "[", "post_id", "]"], "docstring": "Parse posts and returns in order.", "docstring_tokens": ["Parse", "posts", "and", "returns", "in", "order", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mattermost.py#L234-L242", "partition": "test", "index": 3165, "time": "2018-04-26 10:58:51"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/mattermost.py", "func_name": "Mattermost.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the messages.\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        from_date = kwargs['from_date']\n\n        logger.info(\"Fetching messages of '%s' - '%s' channel from %s\",\n                    self.url, self.channel, str(from_date))\n\n        fetching = True\n        page = 0\n        nposts = 0\n\n        # Convert timestamp to integer for comparing\n        since = int(from_date.timestamp() * 1000)\n\n        while fetching:\n            raw_posts = self.client.posts(self.channel, page=page)\n\n            posts_before = nposts\n\n            for post in self._parse_posts(raw_posts):\n                if post['update_at'] < since:\n                    fetching = False\n                    break\n\n                # Fetch user data\n                user_id = post['user_id']\n                user = self._get_or_fetch_user(user_id)\n                post['user_data'] = user\n\n                yield post\n                nposts += 1\n\n            if fetching:\n                # If no new posts were fetched; stop the process\n                if posts_before == nposts:\n                    fetching = False\n                else:\n                    page += 1\n\n        logger.info(\"Fetch process completed: %s posts fetched\", nposts)", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the messages.\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        from_date = kwargs['from_date']\n\n        logger.info(\"Fetching messages of '%s' - '%s' channel from %s\",\n                    self.url, self.channel, str(from_date))\n\n        fetching = True\n        page = 0\n        nposts = 0\n\n        # Convert timestamp to integer for comparing\n        since = int(from_date.timestamp() * 1000)\n\n        while fetching:\n            raw_posts = self.client.posts(self.channel, page=page)\n\n            posts_before = nposts\n\n            for post in self._parse_posts(raw_posts):\n                if post['update_at'] < since:\n                    fetching = False\n                    break\n\n                # Fetch user data\n                user_id = post['user_id']\n                user = self._get_or_fetch_user(user_id)\n                post['user_data'] = user\n\n                yield post\n                nposts += 1\n\n            if fetching:\n                # If no new posts were fetched; stop the process\n                if posts_before == nposts:\n                    fetching = False\n                else:\n                    page += 1\n\n        logger.info(\"Fetch process completed: %s posts fetched\", nposts)", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "from_date", "=", "kwargs", "[", "'from_date'", "]", "logger", ".", "info", "(", "\"Fetching messages of '%s' - '%s' channel from %s\"", ",", "self", ".", "url", ",", "self", ".", "channel", ",", "str", "(", "from_date", ")", ")", "fetching", "=", "True", "page", "=", "0", "nposts", "=", "0", "# Convert timestamp to integer for comparing", "since", "=", "int", "(", "from_date", ".", "timestamp", "(", ")", "*", "1000", ")", "while", "fetching", ":", "raw_posts", "=", "self", ".", "client", ".", "posts", "(", "self", ".", "channel", ",", "page", "=", "page", ")", "posts_before", "=", "nposts", "for", "post", "in", "self", ".", "_parse_posts", "(", "raw_posts", ")", ":", "if", "post", "[", "'update_at'", "]", "<", "since", ":", "fetching", "=", "False", "break", "# Fetch user data", "user_id", "=", "post", "[", "'user_id'", "]", "user", "=", "self", ".", "_get_or_fetch_user", "(", "user_id", ")", "post", "[", "'user_data'", "]", "=", "user", "yield", "post", "nposts", "+=", "1", "if", "fetching", ":", "# If no new posts were fetched; stop the process", "if", "posts_before", "==", "nposts", ":", "fetching", "=", "False", "else", ":", "page", "+=", "1", "logger", ".", "info", "(", "\"Fetch process completed: %s posts fetched\"", ",", "nposts", ")"], "docstring": "Fetch the messages.\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "the", "messages", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/mattermost.py#L116-L161", "partition": "test", "index": 3164, "time": "2018-04-26 10:58:51"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.__get_pull_commits", "original_string": "def __get_pull_commits(self, pr_number):\n        \"\"\"Get pull request commit hashes\"\"\"\n\n        hashes = []\n        group_pull_commits = self.client.pull_commits(pr_number)\n\n        for raw_pull_commits in group_pull_commits:\n\n            for commit in json.loads(raw_pull_commits):\n                commit_hash = commit['sha']\n                hashes.append(commit_hash)\n\n        return hashes", "language": "python", "code": "def __get_pull_commits(self, pr_number):\n        \"\"\"Get pull request commit hashes\"\"\"\n\n        hashes = []\n        group_pull_commits = self.client.pull_commits(pr_number)\n\n        for raw_pull_commits in group_pull_commits:\n\n            for commit in json.loads(raw_pull_commits):\n                commit_hash = commit['sha']\n                hashes.append(commit_hash)\n\n        return hashes", "code_tokens": ["def", "__get_pull_commits", "(", "self", ",", "pr_number", ")", ":", "hashes", "=", "[", "]", "group_pull_commits", "=", "self", ".", "client", ".", "pull_commits", "(", "pr_number", ")", "for", "raw_pull_commits", "in", "group_pull_commits", ":", "for", "commit", "in", "json", ".", "loads", "(", "raw_pull_commits", ")", ":", "commit_hash", "=", "commit", "[", "'sha'", "]", "hashes", ".", "append", "(", "commit_hash", ")", "return", "hashes"], "docstring": "Get pull request commit hashes", "docstring_tokens": ["Get", "pull", "request", "commit", "hashes"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L391-L403", "partition": "test", "index": 3302, "time": "2018-06-04 10:44:44"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient.pull_commits", "original_string": "def pull_commits(self, pr_number):\n        \"\"\"Get pull request commits\"\"\"\n\n        payload = {\n            'per_page': PER_PAGE,\n        }\n\n        commit_url = urijoin(\"pulls\", str(pr_number), \"commits\")\n        return self.fetch_items(commit_url, payload)", "language": "python", "code": "def pull_commits(self, pr_number):\n        \"\"\"Get pull request commits\"\"\"\n\n        payload = {\n            'per_page': PER_PAGE,\n        }\n\n        commit_url = urijoin(\"pulls\", str(pr_number), \"commits\")\n        return self.fetch_items(commit_url, payload)", "code_tokens": ["def", "pull_commits", "(", "self", ",", "pr_number", ")", ":", "payload", "=", "{", "'per_page'", ":", "PER_PAGE", ",", "}", "commit_url", "=", "urijoin", "(", "\"pulls\"", ",", "str", "(", "pr_number", ")", ",", "\"commits\"", ")", "return", "self", ".", "fetch_items", "(", "commit_url", ",", "payload", ")"], "docstring": "Get pull request commits", "docstring_tokens": ["Get", "pull", "request", "commits"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L643-L651", "partition": "test", "index": 3310, "time": "2018-06-04 10:44:44"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/twitter.py", "func_name": "TwitterCommand.setup_cmd_parser", "original_string": "def setup_cmd_parser(cls):\n        \"\"\"Returns the Twitter argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              token_auth=True,\n                                              archive=True)\n\n        # Backend token is required\n        action = parser.parser._option_string_actions['--api-token']\n        action.required = True\n\n        # Meetup options\n        group = parser.parser.add_argument_group('Twitter arguments')\n        group.add_argument('--max-items', dest='max_items',\n                           type=int, default=MAX_ITEMS,\n                           help=\"Maximum number of items requested on the same query\")\n        group.add_argument('--no-entities', dest='include_entities',\n                           action='store_false',\n                           help=\" Exclude entities node\")\n        group.add_argument('--geo-code', dest='geocode',\n                           help=\"Select tweets by users located at latitude,longitude,radius\")\n        group.add_argument('--lang', dest='lang',\n                           help=\"Select tweets to the given language in ISO 639-1 code\")\n        group.add_argument('--tweets-type', dest='tweets_type', default=TWEET_TYPE_MIXED,\n                           help=\"Type of tweets returned. Default is 'mixed', others are 'recent' and 'popular'\")\n        group.add_argument('--sleep-for-rate', dest='sleep_for_rate',\n                           action='store_true',\n                           help=\"sleep for getting more rate\")\n        group.add_argument('--min-rate-to-sleep', dest='min_rate_to_sleep',\n                           default=MIN_RATE_LIMIT, type=int,\n                           help=\"sleep until reset when the rate limit reaches this value\")\n        group.add_argument('--sleep-time', dest='sleep_time',\n                           default=SLEEP_TIME, type=int,\n                           help=\"minimun sleeping time to avoid too many request exception\")\n\n        # Required arguments\n        parser.parser.add_argument('query',\n                                   help=\"Search query including operators, max 500 chars\")\n\n        return parser", "language": "python", "code": "def setup_cmd_parser(cls):\n        \"\"\"Returns the Twitter argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              token_auth=True,\n                                              archive=True)\n\n        # Backend token is required\n        action = parser.parser._option_string_actions['--api-token']\n        action.required = True\n\n        # Meetup options\n        group = parser.parser.add_argument_group('Twitter arguments')\n        group.add_argument('--max-items', dest='max_items',\n                           type=int, default=MAX_ITEMS,\n                           help=\"Maximum number of items requested on the same query\")\n        group.add_argument('--no-entities', dest='include_entities',\n                           action='store_false',\n                           help=\" Exclude entities node\")\n        group.add_argument('--geo-code', dest='geocode',\n                           help=\"Select tweets by users located at latitude,longitude,radius\")\n        group.add_argument('--lang', dest='lang',\n                           help=\"Select tweets to the given language in ISO 639-1 code\")\n        group.add_argument('--tweets-type', dest='tweets_type', default=TWEET_TYPE_MIXED,\n                           help=\"Type of tweets returned. Default is 'mixed', others are 'recent' and 'popular'\")\n        group.add_argument('--sleep-for-rate', dest='sleep_for_rate',\n                           action='store_true',\n                           help=\"sleep for getting more rate\")\n        group.add_argument('--min-rate-to-sleep', dest='min_rate_to_sleep',\n                           default=MIN_RATE_LIMIT, type=int,\n                           help=\"sleep until reset when the rate limit reaches this value\")\n        group.add_argument('--sleep-time', dest='sleep_time',\n                           default=SLEEP_TIME, type=int,\n                           help=\"minimun sleeping time to avoid too many request exception\")\n\n        # Required arguments\n        parser.parser.add_argument('query',\n                                   help=\"Search query including operators, max 500 chars\")\n\n        return parser", "code_tokens": ["def", "setup_cmd_parser", "(", "cls", ")", ":", "parser", "=", "BackendCommandArgumentParser", "(", "cls", ".", "BACKEND", ".", "CATEGORIES", ",", "token_auth", "=", "True", ",", "archive", "=", "True", ")", "# Backend token is required", "action", "=", "parser", ".", "parser", ".", "_option_string_actions", "[", "'--api-token'", "]", "action", ".", "required", "=", "True", "# Meetup options", "group", "=", "parser", ".", "parser", ".", "add_argument_group", "(", "'Twitter arguments'", ")", "group", ".", "add_argument", "(", "'--max-items'", ",", "dest", "=", "'max_items'", ",", "type", "=", "int", ",", "default", "=", "MAX_ITEMS", ",", "help", "=", "\"Maximum number of items requested on the same query\"", ")", "group", ".", "add_argument", "(", "'--no-entities'", ",", "dest", "=", "'include_entities'", ",", "action", "=", "'store_false'", ",", "help", "=", "\" Exclude entities node\"", ")", "group", ".", "add_argument", "(", "'--geo-code'", ",", "dest", "=", "'geocode'", ",", "help", "=", "\"Select tweets by users located at latitude,longitude,radius\"", ")", "group", ".", "add_argument", "(", "'--lang'", ",", "dest", "=", "'lang'", ",", "help", "=", "\"Select tweets to the given language in ISO 639-1 code\"", ")", "group", ".", "add_argument", "(", "'--tweets-type'", ",", "dest", "=", "'tweets_type'", ",", "default", "=", "TWEET_TYPE_MIXED", ",", "help", "=", "\"Type of tweets returned. Default is 'mixed', others are 'recent' and 'popular'\"", ")", "group", ".", "add_argument", "(", "'--sleep-for-rate'", ",", "dest", "=", "'sleep_for_rate'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"sleep for getting more rate\"", ")", "group", ".", "add_argument", "(", "'--min-rate-to-sleep'", ",", "dest", "=", "'min_rate_to_sleep'", ",", "default", "=", "MIN_RATE_LIMIT", ",", "type", "=", "int", ",", "help", "=", "\"sleep until reset when the rate limit reaches this value\"", ")", "group", ".", "add_argument", "(", "'--sleep-time'", ",", "dest", "=", "'sleep_time'", ",", "default", "=", "SLEEP_TIME", ",", "type", "=", "int", ",", "help", "=", "\"minimun sleeping time to avoid too many request exception\"", ")", "# Required arguments", "parser", ".", "parser", ".", "add_argument", "(", "'query'", ",", "help", "=", "\"Search query including operators, max 500 chars\"", ")", "return", "parser"], "docstring": "Returns the Twitter argument parser.", "docstring_tokens": ["Returns", "the", "Twitter", "argument", "parser", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/twitter.py#L347-L386", "partition": "test", "index": 3289, "time": "2018-06-10 01:50:47"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/twitter.py", "func_name": "Twitter.fetch", "original_string": "def fetch(self, category=CATEGORY_TWEET, since_id=None, max_id=None,\n              geocode=None, lang=None,\n              include_entities=True, tweets_type=TWEET_TYPE_MIXED):\n        \"\"\"Fetch the tweets from the server.\n\n        This method fetches tweets from the TwitterSearch API published in the last seven days.\n\n        :param category: the category of items to fetch\n        :param since_id: if not null, it returns results with an ID greater than the specified ID\n        :param max_id: when it is set or if not None, it returns results with an ID less than the specified ID\n        :param geocode: if enabled, returns tweets by users located at latitude,longitude,\"mi\"|\"km\"\n        :param lang: if enabled, restricts tweets to the given language, given by an ISO 639-1 code\n        :param include_entities: if disabled, it excludes entities node\n        :param tweets_type: type of tweets returned. Default is \u201cmixed\u201d, others are \"recent\" and \"popular\"\n\n        :returns: a generator of tweets\n        \"\"\"\n        kwargs = {\"since_id\": since_id,\n                  \"max_id\": max_id,\n                  \"geocode\": geocode,\n                  \"lang\": lang,\n                  \"include_entities\": include_entities,\n                  \"result_type\": tweets_type}\n        items = super().fetch(category, **kwargs)\n\n        return items", "language": "python", "code": "def fetch(self, category=CATEGORY_TWEET, since_id=None, max_id=None,\n              geocode=None, lang=None,\n              include_entities=True, tweets_type=TWEET_TYPE_MIXED):\n        \"\"\"Fetch the tweets from the server.\n\n        This method fetches tweets from the TwitterSearch API published in the last seven days.\n\n        :param category: the category of items to fetch\n        :param since_id: if not null, it returns results with an ID greater than the specified ID\n        :param max_id: when it is set or if not None, it returns results with an ID less than the specified ID\n        :param geocode: if enabled, returns tweets by users located at latitude,longitude,\"mi\"|\"km\"\n        :param lang: if enabled, restricts tweets to the given language, given by an ISO 639-1 code\n        :param include_entities: if disabled, it excludes entities node\n        :param tweets_type: type of tweets returned. Default is \u201cmixed\u201d, others are \"recent\" and \"popular\"\n\n        :returns: a generator of tweets\n        \"\"\"\n        kwargs = {\"since_id\": since_id,\n                  \"max_id\": max_id,\n                  \"geocode\": geocode,\n                  \"lang\": lang,\n                  \"include_entities\": include_entities,\n                  \"result_type\": tweets_type}\n        items = super().fetch(category, **kwargs)\n\n        return items", "code_tokens": ["def", "fetch", "(", "self", ",", "category", "=", "CATEGORY_TWEET", ",", "since_id", "=", "None", ",", "max_id", "=", "None", ",", "geocode", "=", "None", ",", "lang", "=", "None", ",", "include_entities", "=", "True", ",", "tweets_type", "=", "TWEET_TYPE_MIXED", ")", ":", "kwargs", "=", "{", "\"since_id\"", ":", "since_id", ",", "\"max_id\"", ":", "max_id", ",", "\"geocode\"", ":", "geocode", ",", "\"lang\"", ":", "lang", ",", "\"include_entities\"", ":", "include_entities", ",", "\"result_type\"", ":", "tweets_type", "}", "items", "=", "super", "(", ")", ".", "fetch", "(", "category", ",", "*", "*", "kwargs", ")", "return", "items"], "docstring": "Fetch the tweets from the server.\n\n        This method fetches tweets from the TwitterSearch API published in the last seven days.\n\n        :param category: the category of items to fetch\n        :param since_id: if not null, it returns results with an ID greater than the specified ID\n        :param max_id: when it is set or if not None, it returns results with an ID less than the specified ID\n        :param geocode: if enabled, returns tweets by users located at latitude,longitude,\"mi\"|\"km\"\n        :param lang: if enabled, restricts tweets to the given language, given by an ISO 639-1 code\n        :param include_entities: if disabled, it excludes entities node\n        :param tweets_type: type of tweets returned. Default is \u201cmixed\u201d, others are \"recent\" and \"popular\"\n\n        :returns: a generator of tweets", "docstring_tokens": ["Fetch", "the", "tweets", "from", "the", "server", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/twitter.py#L99-L124", "partition": "test", "index": 3286, "time": "2018-06-10 01:50:47"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/twitter.py", "func_name": "Twitter.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the tweets\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        since_id = kwargs['since_id']\n        max_id = kwargs['max_id']\n        geocode = kwargs['geocode']\n        lang = kwargs['lang']\n        entities = kwargs['include_entities']\n        tweets_type = kwargs['result_type']\n\n        logger.info(\"Fetching tweets %s from %s to %s\",\n                    self.query, str(since_id),\n                    str(max_id) if max_id else '--')\n\n        tweets_ids = []\n        min_date = None\n        max_date = None\n        group_tweets = self.client.tweets(self.query, since_id=since_id, max_id=max_id, geocode=geocode,\n                                          lang=lang, include_entities=entities, result_type=tweets_type)\n\n        for tweets in group_tweets:\n            for i in range(len(tweets)):\n                tweet = tweets[i]\n                tweets_ids.append(tweet['id'])\n\n                if tweets[-1] == tweet:\n                    min_date = str_to_datetime(tweets[-1]['created_at'])\n\n                if tweets[0] == tweet and not max_date:\n                    max_date = str_to_datetime(tweets[0]['created_at'])\n\n                yield tweet\n\n        logger.info(\"Fetch process completed: %s (unique %s) tweets fetched, from %s to %s\",\n                    len(tweets_ids), len(list(set(tweets_ids))), min_date, max_date)", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch the tweets\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        since_id = kwargs['since_id']\n        max_id = kwargs['max_id']\n        geocode = kwargs['geocode']\n        lang = kwargs['lang']\n        entities = kwargs['include_entities']\n        tweets_type = kwargs['result_type']\n\n        logger.info(\"Fetching tweets %s from %s to %s\",\n                    self.query, str(since_id),\n                    str(max_id) if max_id else '--')\n\n        tweets_ids = []\n        min_date = None\n        max_date = None\n        group_tweets = self.client.tweets(self.query, since_id=since_id, max_id=max_id, geocode=geocode,\n                                          lang=lang, include_entities=entities, result_type=tweets_type)\n\n        for tweets in group_tweets:\n            for i in range(len(tweets)):\n                tweet = tweets[i]\n                tweets_ids.append(tweet['id'])\n\n                if tweets[-1] == tweet:\n                    min_date = str_to_datetime(tweets[-1]['created_at'])\n\n                if tweets[0] == tweet and not max_date:\n                    max_date = str_to_datetime(tweets[0]['created_at'])\n\n                yield tweet\n\n        logger.info(\"Fetch process completed: %s (unique %s) tweets fetched, from %s to %s\",\n                    len(tweets_ids), len(list(set(tweets_ids))), min_date, max_date)", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "since_id", "=", "kwargs", "[", "'since_id'", "]", "max_id", "=", "kwargs", "[", "'max_id'", "]", "geocode", "=", "kwargs", "[", "'geocode'", "]", "lang", "=", "kwargs", "[", "'lang'", "]", "entities", "=", "kwargs", "[", "'include_entities'", "]", "tweets_type", "=", "kwargs", "[", "'result_type'", "]", "logger", ".", "info", "(", "\"Fetching tweets %s from %s to %s\"", ",", "self", ".", "query", ",", "str", "(", "since_id", ")", ",", "str", "(", "max_id", ")", "if", "max_id", "else", "'--'", ")", "tweets_ids", "=", "[", "]", "min_date", "=", "None", "max_date", "=", "None", "group_tweets", "=", "self", ".", "client", ".", "tweets", "(", "self", ".", "query", ",", "since_id", "=", "since_id", ",", "max_id", "=", "max_id", ",", "geocode", "=", "geocode", ",", "lang", "=", "lang", ",", "include_entities", "=", "entities", ",", "result_type", "=", "tweets_type", ")", "for", "tweets", "in", "group_tweets", ":", "for", "i", "in", "range", "(", "len", "(", "tweets", ")", ")", ":", "tweet", "=", "tweets", "[", "i", "]", "tweets_ids", ".", "append", "(", "tweet", "[", "'id'", "]", ")", "if", "tweets", "[", "-", "1", "]", "==", "tweet", ":", "min_date", "=", "str_to_datetime", "(", "tweets", "[", "-", "1", "]", "[", "'created_at'", "]", ")", "if", "tweets", "[", "0", "]", "==", "tweet", "and", "not", "max_date", ":", "max_date", "=", "str_to_datetime", "(", "tweets", "[", "0", "]", "[", "'created_at'", "]", ")", "yield", "tweet", "logger", ".", "info", "(", "\"Fetch process completed: %s (unique %s) tweets fetched, from %s to %s\"", ",", "len", "(", "tweets_ids", ")", ",", "len", "(", "list", "(", "set", "(", "tweets_ids", ")", ")", ")", ",", "min_date", ",", "max_date", ")"], "docstring": "Fetch the tweets\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "the", "tweets"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/twitter.py#L126-L165", "partition": "test", "index": 3287, "time": "2018-06-10 01:50:47"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/twitter.py", "func_name": "TwitterClient.tweets", "original_string": "def tweets(self, query, since_id=None, max_id=None, geocode=None, lang=None,\n               include_entities=True, result_type=TWEET_TYPE_MIXED):\n        \"\"\"Fetch tweets for a given query between since_id and max_id.\n\n        :param query: query to fetch tweets\n        :param since_id: if not null, it returns results with an ID greater than the specified ID\n        :param max_id: if not null, it returns results with an ID less than the specified ID\n        :param geocode: if enabled, returns tweets by users located at latitude,longitude,\"mi\"|\"km\"\n        :param lang: if enabled, restricts tweets to the given language, given by an ISO 639-1 code\n        :param include_entities: if disabled, it excludes entities node\n        :param result_type: type of tweets returned. Default is \u201cmixed\u201d, others are \"recent\" and \"popular\"\n\n        :returns: a generator of tweets\n        \"\"\"\n        resource = self.base_url\n        params = {'q': query,\n                  'count': self.max_items}\n\n        if since_id:\n            params['since_id'] = since_id\n\n        if max_id:\n            params['max_id'] = max_id\n\n        if geocode:\n            params['geocode'] = geocode\n\n        if lang:\n            params['lang'] = lang\n\n        params['include_entities'] = include_entities\n        params['result_type'] = result_type\n\n        while True:\n            raw_tweets = self._fetch(resource, params=params)\n            tweets = json.loads(raw_tweets)\n\n            if not tweets['statuses']:\n                break\n\n            params['max_id'] = tweets['statuses'][-1]['id'] - 1\n            yield tweets['statuses']", "language": "python", "code": "def tweets(self, query, since_id=None, max_id=None, geocode=None, lang=None,\n               include_entities=True, result_type=TWEET_TYPE_MIXED):\n        \"\"\"Fetch tweets for a given query between since_id and max_id.\n\n        :param query: query to fetch tweets\n        :param since_id: if not null, it returns results with an ID greater than the specified ID\n        :param max_id: if not null, it returns results with an ID less than the specified ID\n        :param geocode: if enabled, returns tweets by users located at latitude,longitude,\"mi\"|\"km\"\n        :param lang: if enabled, restricts tweets to the given language, given by an ISO 639-1 code\n        :param include_entities: if disabled, it excludes entities node\n        :param result_type: type of tweets returned. Default is \u201cmixed\u201d, others are \"recent\" and \"popular\"\n\n        :returns: a generator of tweets\n        \"\"\"\n        resource = self.base_url\n        params = {'q': query,\n                  'count': self.max_items}\n\n        if since_id:\n            params['since_id'] = since_id\n\n        if max_id:\n            params['max_id'] = max_id\n\n        if geocode:\n            params['geocode'] = geocode\n\n        if lang:\n            params['lang'] = lang\n\n        params['include_entities'] = include_entities\n        params['result_type'] = result_type\n\n        while True:\n            raw_tweets = self._fetch(resource, params=params)\n            tweets = json.loads(raw_tweets)\n\n            if not tweets['statuses']:\n                break\n\n            params['max_id'] = tweets['statuses'][-1]['id'] - 1\n            yield tweets['statuses']", "code_tokens": ["def", "tweets", "(", "self", ",", "query", ",", "since_id", "=", "None", ",", "max_id", "=", "None", ",", "geocode", "=", "None", ",", "lang", "=", "None", ",", "include_entities", "=", "True", ",", "result_type", "=", "TWEET_TYPE_MIXED", ")", ":", "resource", "=", "self", ".", "base_url", "params", "=", "{", "'q'", ":", "query", ",", "'count'", ":", "self", ".", "max_items", "}", "if", "since_id", ":", "params", "[", "'since_id'", "]", "=", "since_id", "if", "max_id", ":", "params", "[", "'max_id'", "]", "=", "max_id", "if", "geocode", ":", "params", "[", "'geocode'", "]", "=", "geocode", "if", "lang", ":", "params", "[", "'lang'", "]", "=", "lang", "params", "[", "'include_entities'", "]", "=", "include_entities", "params", "[", "'result_type'", "]", "=", "result_type", "while", "True", ":", "raw_tweets", "=", "self", ".", "_fetch", "(", "resource", ",", "params", "=", "params", ")", "tweets", "=", "json", ".", "loads", "(", "raw_tweets", ")", "if", "not", "tweets", "[", "'statuses'", "]", ":", "break", "params", "[", "'max_id'", "]", "=", "tweets", "[", "'statuses'", "]", "[", "-", "1", "]", "[", "'id'", "]", "-", "1", "yield", "tweets", "[", "'statuses'", "]"], "docstring": "Fetch tweets for a given query between since_id and max_id.\n\n        :param query: query to fetch tweets\n        :param since_id: if not null, it returns results with an ID greater than the specified ID\n        :param max_id: if not null, it returns results with an ID less than the specified ID\n        :param geocode: if enabled, returns tweets by users located at latitude,longitude,\"mi\"|\"km\"\n        :param lang: if enabled, restricts tweets to the given language, given by an ISO 639-1 code\n        :param include_entities: if disabled, it excludes entities node\n        :param result_type: type of tweets returned. Default is \u201cmixed\u201d, others are \"recent\" and \"popular\"\n\n        :returns: a generator of tweets", "docstring_tokens": ["Fetch", "tweets", "for", "a", "given", "query", "between", "since_id", "and", "max_id", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/twitter.py#L274-L315", "partition": "test", "index": 3288, "time": "2018-06-10 01:50:47"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/groupsio.py", "func_name": "GroupsioCommand.setup_cmd_parser", "original_string": "def setup_cmd_parser(cls):\n        \"\"\"Returns the Groupsio argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              from_date=True,\n                                              token_auth=True)\n\n        # Backend token is required\n        action = parser.parser._option_string_actions['--api-token']\n        action.required = True\n\n        # Optional arguments\n        group = parser.parser.add_argument_group('Groupsio arguments')\n        group.add_argument('--mboxes-path', dest='mboxes_path',\n                           help=\"Path where mbox files will be stored\")\n        group.add_argument('--no-verify', dest='verify',\n                           action='store_false',\n                           help=\"Value 'True' enable SSL verification\")\n\n        # Required arguments\n        parser.parser.add_argument('group_name',\n                                   help=\"Name of the group on Groups.io\")\n\n        return parser", "language": "python", "code": "def setup_cmd_parser(cls):\n        \"\"\"Returns the Groupsio argument parser.\"\"\"\n\n        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,\n                                              from_date=True,\n                                              token_auth=True)\n\n        # Backend token is required\n        action = parser.parser._option_string_actions['--api-token']\n        action.required = True\n\n        # Optional arguments\n        group = parser.parser.add_argument_group('Groupsio arguments')\n        group.add_argument('--mboxes-path', dest='mboxes_path',\n                           help=\"Path where mbox files will be stored\")\n        group.add_argument('--no-verify', dest='verify',\n                           action='store_false',\n                           help=\"Value 'True' enable SSL verification\")\n\n        # Required arguments\n        parser.parser.add_argument('group_name',\n                                   help=\"Name of the group on Groups.io\")\n\n        return parser", "code_tokens": ["def", "setup_cmd_parser", "(", "cls", ")", ":", "parser", "=", "BackendCommandArgumentParser", "(", "cls", ".", "BACKEND", ".", "CATEGORIES", ",", "from_date", "=", "True", ",", "token_auth", "=", "True", ")", "# Backend token is required", "action", "=", "parser", ".", "parser", ".", "_option_string_actions", "[", "'--api-token'", "]", "action", ".", "required", "=", "True", "# Optional arguments", "group", "=", "parser", ".", "parser", ".", "add_argument_group", "(", "'Groupsio arguments'", ")", "group", ".", "add_argument", "(", "'--mboxes-path'", ",", "dest", "=", "'mboxes_path'", ",", "help", "=", "\"Path where mbox files will be stored\"", ")", "group", ".", "add_argument", "(", "'--no-verify'", ",", "dest", "=", "'verify'", ",", "action", "=", "'store_false'", ",", "help", "=", "\"Value 'True' enable SSL verification\"", ")", "# Required arguments", "parser", ".", "parser", ".", "add_argument", "(", "'group_name'", ",", "help", "=", "\"Name of the group on Groups.io\"", ")", "return", "parser"], "docstring": "Returns the Groupsio argument parser.", "docstring_tokens": ["Returns", "the", "Groupsio", "argument", "parser", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/groupsio.py#L271-L294", "partition": "test", "index": 3243, "time": "2018-07-05 17:10:53"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/googlehits.py", "func_name": "GoogleHits.fetch", "original_string": "def fetch(self, category=CATEGORY_HITS):\n        \"\"\"Fetch data from Google API.\n\n        The method retrieves a list of hits for some\n        given keywords using the Google API.\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of data\n        \"\"\"\n        kwargs = {}\n        items = super().fetch(category, **kwargs)\n\n        return items", "language": "python", "code": "def fetch(self, category=CATEGORY_HITS):\n        \"\"\"Fetch data from Google API.\n\n        The method retrieves a list of hits for some\n        given keywords using the Google API.\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of data\n        \"\"\"\n        kwargs = {}\n        items = super().fetch(category, **kwargs)\n\n        return items", "code_tokens": ["def", "fetch", "(", "self", ",", "category", "=", "CATEGORY_HITS", ")", ":", "kwargs", "=", "{", "}", "items", "=", "super", "(", ")", ".", "fetch", "(", "category", ",", "*", "*", "kwargs", ")", "return", "items"], "docstring": "Fetch data from Google API.\n\n        The method retrieves a list of hits for some\n        given keywords using the Google API.\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of data", "docstring_tokens": ["Fetch", "data", "from", "Google", "API", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/googlehits.py#L81-L94", "partition": "test", "index": 3290, "time": "2018-07-19 16:26:05"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/googlehits.py", "func_name": "GoogleHits.fetch_items", "original_string": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch Google hit items\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        logger.info(\"Fetching data for '%s'\", self.keywords)\n\n        hits_raw = self.client.hits(self.keywords)\n        hits = self.__parse_hits(hits_raw)\n\n        yield hits\n\n        logger.info(\"Fetch process completed\")", "language": "python", "code": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch Google hit items\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        logger.info(\"Fetching data for '%s'\", self.keywords)\n\n        hits_raw = self.client.hits(self.keywords)\n        hits = self.__parse_hits(hits_raw)\n\n        yield hits\n\n        logger.info(\"Fetch process completed\")", "code_tokens": ["def", "fetch_items", "(", "self", ",", "category", ",", "*", "*", "kwargs", ")", ":", "logger", ".", "info", "(", "\"Fetching data for '%s'\"", ",", "self", ".", "keywords", ")", "hits_raw", "=", "self", ".", "client", ".", "hits", "(", "self", ".", "keywords", ")", "hits", "=", "self", ".", "__parse_hits", "(", "hits_raw", ")", "yield", "hits", "logger", ".", "info", "(", "\"Fetch process completed\"", ")"], "docstring": "Fetch Google hit items\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items", "docstring_tokens": ["Fetch", "Google", "hit", "items"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/googlehits.py#L96-L111", "partition": "test", "index": 3291, "time": "2018-07-19 16:26:05"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/googlehits.py", "func_name": "GoogleHits.__parse_hits", "original_string": "def __parse_hits(self, hit_raw):\n        \"\"\"Parse the hits returned by the Google Search API\"\"\"\n\n        # Create the soup and get the desired div\n        bs_result = bs4.BeautifulSoup(hit_raw, 'html.parser')\n        hit_string = bs_result.find(\"div\", id=\"resultStats\").text\n\n        # Remove commas or dots\n        hit_string = hit_string.replace(',', u'')\n        hit_string = hit_string.replace('.', u'')\n\n        fetched_on = datetime_utcnow().timestamp()\n        id_args = self.keywords[:]\n        id_args.append(str(fetched_on))\n\n        hits_json = {\n            'fetched_on': fetched_on,\n            'id': uuid(*id_args),\n            'keywords': self.keywords,\n            'type': 'googleSearchHits'\n        }\n\n        if not hit_string:\n            logger.warning(\"No hits for %s\", self.keywords)\n            hits_json['hits'] = 0\n\n            return hits_json\n\n        str_hits = re.search(r'\\d+', hit_string).group(0)\n        hits = int(str_hits)\n        hits_json['hits'] = hits\n\n        return hits_json", "language": "python", "code": "def __parse_hits(self, hit_raw):\n        \"\"\"Parse the hits returned by the Google Search API\"\"\"\n\n        # Create the soup and get the desired div\n        bs_result = bs4.BeautifulSoup(hit_raw, 'html.parser')\n        hit_string = bs_result.find(\"div\", id=\"resultStats\").text\n\n        # Remove commas or dots\n        hit_string = hit_string.replace(',', u'')\n        hit_string = hit_string.replace('.', u'')\n\n        fetched_on = datetime_utcnow().timestamp()\n        id_args = self.keywords[:]\n        id_args.append(str(fetched_on))\n\n        hits_json = {\n            'fetched_on': fetched_on,\n            'id': uuid(*id_args),\n            'keywords': self.keywords,\n            'type': 'googleSearchHits'\n        }\n\n        if not hit_string:\n            logger.warning(\"No hits for %s\", self.keywords)\n            hits_json['hits'] = 0\n\n            return hits_json\n\n        str_hits = re.search(r'\\d+', hit_string).group(0)\n        hits = int(str_hits)\n        hits_json['hits'] = hits\n\n        return hits_json", "code_tokens": ["def", "__parse_hits", "(", "self", ",", "hit_raw", ")", ":", "# Create the soup and get the desired div", "bs_result", "=", "bs4", ".", "BeautifulSoup", "(", "hit_raw", ",", "'html.parser'", ")", "hit_string", "=", "bs_result", ".", "find", "(", "\"div\"", ",", "id", "=", "\"resultStats\"", ")", ".", "text", "# Remove commas or dots", "hit_string", "=", "hit_string", ".", "replace", "(", "','", ",", "u''", ")", "hit_string", "=", "hit_string", ".", "replace", "(", "'.'", ",", "u''", ")", "fetched_on", "=", "datetime_utcnow", "(", ")", ".", "timestamp", "(", ")", "id_args", "=", "self", ".", "keywords", "[", ":", "]", "id_args", ".", "append", "(", "str", "(", "fetched_on", ")", ")", "hits_json", "=", "{", "'fetched_on'", ":", "fetched_on", ",", "'id'", ":", "uuid", "(", "*", "id_args", ")", ",", "'keywords'", ":", "self", ".", "keywords", ",", "'type'", ":", "'googleSearchHits'", "}", "if", "not", "hit_string", ":", "logger", ".", "warning", "(", "\"No hits for %s\"", ",", "self", ".", "keywords", ")", "hits_json", "[", "'hits'", "]", "=", "0", "return", "hits_json", "str_hits", "=", "re", ".", "search", "(", "r'\\d+'", ",", "hit_string", ")", ".", "group", "(", "0", ")", "hits", "=", "int", "(", "str_hits", ")", "hits_json", "[", "'hits'", "]", "=", "hits", "return", "hits_json"], "docstring": "Parse the hits returned by the Google Search API", "docstring_tokens": ["Parse", "the", "hits", "returned", "by", "the", "Google", "Search", "API"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/googlehits.py#L164-L196", "partition": "test", "index": 3292, "time": "2018-07-19 16:26:05"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/googlehits.py", "func_name": "GoogleHitsClient.hits", "original_string": "def hits(self, keywords):\n        \"\"\"Fetch information about a list of keywords.\"\"\"\n\n        if len(keywords) == 1:\n            query_str = keywords[0]\n        else:\n            query_str = ' '.join([k for k in keywords])\n\n        logger.info(\"Fetching hits for '%s'\", query_str)\n        params = {'q': query_str}\n\n        # Make the request\n        req = self.fetch(GOOGLE_SEARCH_URL, payload=params)\n\n        return req.text", "language": "python", "code": "def hits(self, keywords):\n        \"\"\"Fetch information about a list of keywords.\"\"\"\n\n        if len(keywords) == 1:\n            query_str = keywords[0]\n        else:\n            query_str = ' '.join([k for k in keywords])\n\n        logger.info(\"Fetching hits for '%s'\", query_str)\n        params = {'q': query_str}\n\n        # Make the request\n        req = self.fetch(GOOGLE_SEARCH_URL, payload=params)\n\n        return req.text", "code_tokens": ["def", "hits", "(", "self", ",", "keywords", ")", ":", "if", "len", "(", "keywords", ")", "==", "1", ":", "query_str", "=", "keywords", "[", "0", "]", "else", ":", "query_str", "=", "' '", ".", "join", "(", "[", "k", "for", "k", "in", "keywords", "]", ")", "logger", ".", "info", "(", "\"Fetching hits for '%s'\"", ",", "query_str", ")", "params", "=", "{", "'q'", ":", "query_str", "}", "# Make the request", "req", "=", "self", ".", "fetch", "(", "GOOGLE_SEARCH_URL", ",", "payload", "=", "params", ")", "return", "req", ".", "text"], "docstring": "Fetch information about a list of keywords.", "docstring_tokens": ["Fetch", "information", "about", "a", "list", "of", "keywords", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/googlehits.py#L219-L233", "partition": "test", "index": 3293, "time": "2018-07-19 16:26:05"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabClient._init_rate_limit", "original_string": "def _init_rate_limit(self):\n        \"\"\"Initialize rate limit information\"\"\"\n\n        url = urijoin(self.base_url, 'projects', self.owner + '%2F' + self.repository)\n        try:\n            response = super().fetch(url)\n            self.update_rate_limit(response)\n        except requests.exceptions.HTTPError as error:\n            if error.response.status_code == 401:\n                raise error\n            else:\n                logger.warning(\"Rate limit not initialized: %s\", error)", "language": "python", "code": "def _init_rate_limit(self):\n        \"\"\"Initialize rate limit information\"\"\"\n\n        url = urijoin(self.base_url, 'projects', self.owner + '%2F' + self.repository)\n        try:\n            response = super().fetch(url)\n            self.update_rate_limit(response)\n        except requests.exceptions.HTTPError as error:\n            if error.response.status_code == 401:\n                raise error\n            else:\n                logger.warning(\"Rate limit not initialized: %s\", error)", "code_tokens": ["def", "_init_rate_limit", "(", "self", ")", ":", "url", "=", "urijoin", "(", "self", ".", "base_url", ",", "'projects'", ",", "self", ".", "owner", "+", "'%2F'", "+", "self", ".", "repository", ")", "try", ":", "response", "=", "super", "(", ")", ".", "fetch", "(", "url", ")", "self", ".", "update_rate_limit", "(", "response", ")", "except", "requests", ".", "exceptions", ".", "HTTPError", "as", "error", ":", "if", "error", ".", "response", ".", "status_code", "==", "401", ":", "raise", "error", "else", ":", "logger", ".", "warning", "(", "\"Rate limit not initialized: %s\"", ",", "error", ")"], "docstring": "Initialize rate limit information", "docstring_tokens": ["Initialize", "rate", "limit", "information"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L612-L623", "partition": "test", "index": 3188, "time": "2018-07-20 20:31:43"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/slack.py", "func_name": "SlackClient.conversation_members", "original_string": "def conversation_members(self, conversation):\n        \"\"\"Fetch the number of members in a conversation, which is a supertype for public and\n        private ones, DM and group DM.\n\n        :param conversation: the ID of the conversation\n        \"\"\"\n        members = 0\n\n        resource = self.RCONVERSATION_INFO\n\n        params = {\n            self.PCHANNEL: conversation,\n        }\n\n        raw_response = self._fetch(resource, params)\n        response = json.loads(raw_response)\n\n        members += len(response[\"members\"])\n        while 'next_cursor' in response['response_metadata'] and response['response_metadata']['next_cursor']:\n            params['cursor'] = response['response_metadata']['next_cursor']\n            raw_response = self._fetch(resource, params)\n            response = json.loads(raw_response)\n            members += len(response[\"members\"])\n\n        return members", "language": "python", "code": "def conversation_members(self, conversation):\n        \"\"\"Fetch the number of members in a conversation, which is a supertype for public and\n        private ones, DM and group DM.\n\n        :param conversation: the ID of the conversation\n        \"\"\"\n        members = 0\n\n        resource = self.RCONVERSATION_INFO\n\n        params = {\n            self.PCHANNEL: conversation,\n        }\n\n        raw_response = self._fetch(resource, params)\n        response = json.loads(raw_response)\n\n        members += len(response[\"members\"])\n        while 'next_cursor' in response['response_metadata'] and response['response_metadata']['next_cursor']:\n            params['cursor'] = response['response_metadata']['next_cursor']\n            raw_response = self._fetch(resource, params)\n            response = json.loads(raw_response)\n            members += len(response[\"members\"])\n\n        return members", "code_tokens": ["def", "conversation_members", "(", "self", ",", "conversation", ")", ":", "members", "=", "0", "resource", "=", "self", ".", "RCONVERSATION_INFO", "params", "=", "{", "self", ".", "PCHANNEL", ":", "conversation", ",", "}", "raw_response", "=", "self", ".", "_fetch", "(", "resource", ",", "params", ")", "response", "=", "json", ".", "loads", "(", "raw_response", ")", "members", "+=", "len", "(", "response", "[", "\"members\"", "]", ")", "while", "'next_cursor'", "in", "response", "[", "'response_metadata'", "]", "and", "response", "[", "'response_metadata'", "]", "[", "'next_cursor'", "]", ":", "params", "[", "'cursor'", "]", "=", "response", "[", "'response_metadata'", "]", "[", "'next_cursor'", "]", "raw_response", "=", "self", ".", "_fetch", "(", "resource", ",", "params", ")", "response", "=", "json", ".", "loads", "(", "raw_response", ")", "members", "+=", "len", "(", "response", "[", "\"members\"", "]", ")", "return", "members"], "docstring": "Fetch the number of members in a conversation, which is a supertype for public and\n        private ones, DM and group DM.\n\n        :param conversation: the ID of the conversation", "docstring_tokens": ["Fetch", "the", "number", "of", "members", "in", "a", "conversation", "which", "is", "a", "supertype", "for", "public", "and", "private", "ones", "DM", "and", "group", "DM", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/slack.py#L318-L342", "partition": "test", "index": 3192, "time": "2018-08-09 15:42:54"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLab.__fetch_merge_requests", "original_string": "def __fetch_merge_requests(self, from_date):\n        \"\"\"Fetch the merge requests\"\"\"\n\n        merges_groups = self.client.merges(from_date=from_date)\n\n        for raw_merges in merges_groups:\n            merges = json.loads(raw_merges)\n            for merge in merges:\n                merge_id = merge['iid']\n\n                if self.blacklist_ids and merge_id in self.blacklist_ids:\n                    logger.warning(\"Skipping blacklisted merge request %s\", merge_id)\n                    continue\n\n                # The single merge_request API call returns a more\n                # complete merge request, thus we inflate it with\n                # other data (e.g., notes, emojis, versions)\n                merge_full_raw = self.client.merge(merge_id)\n                merge_full = json.loads(merge_full_raw)\n\n                self.__init_merge_extra_fields(merge_full)\n\n                merge_full['notes_data'] = self.__get_merge_notes(merge_id)\n                merge_full['award_emoji_data'] = self.__get_award_emoji(GitLabClient.MERGES, merge_id)\n                merge_full['versions_data'] = self.__get_merge_versions(merge_id)\n\n                yield merge_full", "language": "python", "code": "def __fetch_merge_requests(self, from_date):\n        \"\"\"Fetch the merge requests\"\"\"\n\n        merges_groups = self.client.merges(from_date=from_date)\n\n        for raw_merges in merges_groups:\n            merges = json.loads(raw_merges)\n            for merge in merges:\n                merge_id = merge['iid']\n\n                if self.blacklist_ids and merge_id in self.blacklist_ids:\n                    logger.warning(\"Skipping blacklisted merge request %s\", merge_id)\n                    continue\n\n                # The single merge_request API call returns a more\n                # complete merge request, thus we inflate it with\n                # other data (e.g., notes, emojis, versions)\n                merge_full_raw = self.client.merge(merge_id)\n                merge_full = json.loads(merge_full_raw)\n\n                self.__init_merge_extra_fields(merge_full)\n\n                merge_full['notes_data'] = self.__get_merge_notes(merge_id)\n                merge_full['award_emoji_data'] = self.__get_award_emoji(GitLabClient.MERGES, merge_id)\n                merge_full['versions_data'] = self.__get_merge_versions(merge_id)\n\n                yield merge_full", "code_tokens": ["def", "__fetch_merge_requests", "(", "self", ",", "from_date", ")", ":", "merges_groups", "=", "self", ".", "client", ".", "merges", "(", "from_date", "=", "from_date", ")", "for", "raw_merges", "in", "merges_groups", ":", "merges", "=", "json", ".", "loads", "(", "raw_merges", ")", "for", "merge", "in", "merges", ":", "merge_id", "=", "merge", "[", "'iid'", "]", "if", "self", ".", "blacklist_ids", "and", "merge_id", "in", "self", ".", "blacklist_ids", ":", "logger", ".", "warning", "(", "\"Skipping blacklisted merge request %s\"", ",", "merge_id", ")", "continue", "# The single merge_request API call returns a more", "# complete merge request, thus we inflate it with", "# other data (e.g., notes, emojis, versions)", "merge_full_raw", "=", "self", ".", "client", ".", "merge", "(", "merge_id", ")", "merge_full", "=", "json", ".", "loads", "(", "merge_full_raw", ")", "self", ".", "__init_merge_extra_fields", "(", "merge_full", ")", "merge_full", "[", "'notes_data'", "]", "=", "self", ".", "__get_merge_notes", "(", "merge_id", ")", "merge_full", "[", "'award_emoji_data'", "]", "=", "self", ".", "__get_award_emoji", "(", "GitLabClient", ".", "MERGES", ",", "merge_id", ")", "merge_full", "[", "'versions_data'", "]", "=", "self", ".", "__get_merge_versions", "(", "merge_id", ")", "yield", "merge_full"], "docstring": "Fetch the merge requests", "docstring_tokens": ["Fetch", "the", "merge", "requests"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L249-L275", "partition": "test", "index": 3176, "time": "2018-09-13 15:21:37"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabClient.merge_version", "original_string": "def merge_version(self, merge_id, version_id):\n        \"\"\"Get merge version detail\"\"\"\n\n        path = urijoin(self.base_url,\n                       GitLabClient.PROJECTS, self.owner + '%2F' + self.repository,\n                       GitLabClient.MERGES, merge_id, GitLabClient.VERSIONS, version_id)\n\n        response = self.fetch(path)\n\n        return response.text", "language": "python", "code": "def merge_version(self, merge_id, version_id):\n        \"\"\"Get merge version detail\"\"\"\n\n        path = urijoin(self.base_url,\n                       GitLabClient.PROJECTS, self.owner + '%2F' + self.repository,\n                       GitLabClient.MERGES, merge_id, GitLabClient.VERSIONS, version_id)\n\n        response = self.fetch(path)\n\n        return response.text", "code_tokens": ["def", "merge_version", "(", "self", ",", "merge_id", ",", "version_id", ")", ":", "path", "=", "urijoin", "(", "self", ".", "base_url", ",", "GitLabClient", ".", "PROJECTS", ",", "self", ".", "owner", "+", "'%2F'", "+", "self", ".", "repository", ",", "GitLabClient", ".", "MERGES", ",", "merge_id", ",", "GitLabClient", ".", "VERSIONS", ",", "version_id", ")", "response", "=", "self", ".", "fetch", "(", "path", ")", "return", "response", ".", "text"], "docstring": "Get merge version detail", "docstring_tokens": ["Get", "merge", "version", "detail"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L470-L479", "partition": "test", "index": 3182, "time": "2018-09-13 15:21:37"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLabClient.emojis", "original_string": "def emojis(self, item_type, item_id):\n        \"\"\"Get emojis from pagination\"\"\"\n\n        payload = {\n            'order_by': 'updated_at',\n            'sort': 'asc',\n            'per_page': PER_PAGE\n        }\n\n        path = urijoin(item_type, str(item_id), GitLabClient.EMOJI)\n\n        return self.fetch_items(path, payload)", "language": "python", "code": "def emojis(self, item_type, item_id):\n        \"\"\"Get emojis from pagination\"\"\"\n\n        payload = {\n            'order_by': 'updated_at',\n            'sort': 'asc',\n            'per_page': PER_PAGE\n        }\n\n        path = urijoin(item_type, str(item_id), GitLabClient.EMOJI)\n\n        return self.fetch_items(path, payload)", "code_tokens": ["def", "emojis", "(", "self", ",", "item_type", ",", "item_id", ")", ":", "payload", "=", "{", "'order_by'", ":", "'updated_at'", ",", "'sort'", ":", "'asc'", ",", "'per_page'", ":", "PER_PAGE", "}", "path", "=", "urijoin", "(", "item_type", ",", "str", "(", "item_id", ")", ",", "GitLabClient", ".", "EMOJI", ")", "return", "self", ".", "fetch_items", "(", "path", ",", "payload", ")"], "docstring": "Get emojis from pagination", "docstring_tokens": ["Get", "emojis", "from", "pagination"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L494-L505", "partition": "test", "index": 3184, "time": "2018-09-13 15:21:37"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/gitlab.py", "func_name": "GitLab.__get_merge_versions", "original_string": "def __get_merge_versions(self, merge_id):\n        \"\"\"Get merge versions\"\"\"\n\n        versions = []\n\n        group_versions = self.client.merge_versions(merge_id)\n\n        for raw_versions in group_versions:\n            for version in json.loads(raw_versions):\n                version_id = version['id']\n                version_full_raw = self.client.merge_version(merge_id, version_id)\n                version_full = json.loads(version_full_raw)\n\n                version_full.pop('diffs', None)\n                versions.append(version_full)\n\n        return versions", "language": "python", "code": "def __get_merge_versions(self, merge_id):\n        \"\"\"Get merge versions\"\"\"\n\n        versions = []\n\n        group_versions = self.client.merge_versions(merge_id)\n\n        for raw_versions in group_versions:\n            for version in json.loads(raw_versions):\n                version_id = version['id']\n                version_full_raw = self.client.merge_version(merge_id, version_id)\n                version_full = json.loads(version_full_raw)\n\n                version_full.pop('diffs', None)\n                versions.append(version_full)\n\n        return versions", "code_tokens": ["def", "__get_merge_versions", "(", "self", ",", "merge_id", ")", ":", "versions", "=", "[", "]", "group_versions", "=", "self", ".", "client", ".", "merge_versions", "(", "merge_id", ")", "for", "raw_versions", "in", "group_versions", ":", "for", "version", "in", "json", ".", "loads", "(", "raw_versions", ")", ":", "version_id", "=", "version", "[", "'id'", "]", "version_full_raw", "=", "self", ".", "client", ".", "merge_version", "(", "merge_id", ",", "version_id", ")", "version_full", "=", "json", ".", "loads", "(", "version_full_raw", ")", "version_full", ".", "pop", "(", "'diffs'", ",", "None", ")", "versions", ".", "append", "(", "version_full", ")", "return", "versions"], "docstring": "Get merge versions", "docstring_tokens": ["Get", "merge", "versions"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/gitlab.py#L293-L309", "partition": "test", "index": 3178, "time": "2018-09-13 15:21:37"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/groupsio.py", "func_name": "GroupsioClient.subscriptions", "original_string": "def subscriptions(self, per_page=PER_PAGE):\n        \"\"\"Fetch the groupsio paginated subscriptions for a given token\n\n        :param per_page: number of subscriptions per page\n\n        :returns: an iterator of subscriptions\n        \"\"\"\n        url = urijoin(GROUPSIO_API_URL, self.GET_SUBSCRIPTIONS)\n        logger.debug(\"Get groupsio paginated subscriptions from \" + url)\n\n        keep_fetching = True\n        payload = {\n            \"limit\": per_page\n        }\n\n        while keep_fetching:\n            r = self.__fetch(url, payload)\n            response_raw = r.json()\n            subscriptions = response_raw['data']\n            yield subscriptions\n\n            total_subscriptions = response_raw['total_count']\n            logger.debug(\"Subscriptions: %i/%i\" % (response_raw['end_item'], total_subscriptions))\n\n            payload['page_token'] = response_raw['next_page_token']\n            keep_fetching = response_raw['has_more']", "language": "python", "code": "def subscriptions(self, per_page=PER_PAGE):\n        \"\"\"Fetch the groupsio paginated subscriptions for a given token\n\n        :param per_page: number of subscriptions per page\n\n        :returns: an iterator of subscriptions\n        \"\"\"\n        url = urijoin(GROUPSIO_API_URL, self.GET_SUBSCRIPTIONS)\n        logger.debug(\"Get groupsio paginated subscriptions from \" + url)\n\n        keep_fetching = True\n        payload = {\n            \"limit\": per_page\n        }\n\n        while keep_fetching:\n            r = self.__fetch(url, payload)\n            response_raw = r.json()\n            subscriptions = response_raw['data']\n            yield subscriptions\n\n            total_subscriptions = response_raw['total_count']\n            logger.debug(\"Subscriptions: %i/%i\" % (response_raw['end_item'], total_subscriptions))\n\n            payload['page_token'] = response_raw['next_page_token']\n            keep_fetching = response_raw['has_more']", "code_tokens": ["def", "subscriptions", "(", "self", ",", "per_page", "=", "PER_PAGE", ")", ":", "url", "=", "urijoin", "(", "GROUPSIO_API_URL", ",", "self", ".", "GET_SUBSCRIPTIONS", ")", "logger", ".", "debug", "(", "\"Get groupsio paginated subscriptions from \"", "+", "url", ")", "keep_fetching", "=", "True", "payload", "=", "{", "\"limit\"", ":", "per_page", "}", "while", "keep_fetching", ":", "r", "=", "self", ".", "__fetch", "(", "url", ",", "payload", ")", "response_raw", "=", "r", ".", "json", "(", ")", "subscriptions", "=", "response_raw", "[", "'data'", "]", "yield", "subscriptions", "total_subscriptions", "=", "response_raw", "[", "'total_count'", "]", "logger", ".", "debug", "(", "\"Subscriptions: %i/%i\"", "%", "(", "response_raw", "[", "'end_item'", "]", ",", "total_subscriptions", ")", ")", "payload", "[", "'page_token'", "]", "=", "response_raw", "[", "'next_page_token'", "]", "keep_fetching", "=", "response_raw", "[", "'has_more'", "]"], "docstring": "Fetch the groupsio paginated subscriptions for a given token\n\n        :param per_page: number of subscriptions per page\n\n        :returns: an iterator of subscriptions", "docstring_tokens": ["Fetch", "the", "groupsio", "paginated", "subscriptions", "for", "a", "given", "token"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/groupsio.py#L182-L207", "partition": "test", "index": 3240, "time": "2018-10-14 19:34:13"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/groupsio.py", "func_name": "GroupsioClient.__fetch", "original_string": "def __fetch(self, url, payload):\n        \"\"\"Fetch requests from groupsio API\"\"\"\n\n        r = requests.get(url, params=payload, auth=self.auth, verify=self.verify)\n        try:\n            r.raise_for_status()\n        except requests.exceptions.HTTPError as e:\n            raise e\n\n        return r", "language": "python", "code": "def __fetch(self, url, payload):\n        \"\"\"Fetch requests from groupsio API\"\"\"\n\n        r = requests.get(url, params=payload, auth=self.auth, verify=self.verify)\n        try:\n            r.raise_for_status()\n        except requests.exceptions.HTTPError as e:\n            raise e\n\n        return r", "code_tokens": ["def", "__fetch", "(", "self", ",", "url", ",", "payload", ")", ":", "r", "=", "requests", ".", "get", "(", "url", ",", "params", "=", "payload", ",", "auth", "=", "self", ".", "auth", ",", "verify", "=", "self", ".", "verify", ")", "try", ":", "r", ".", "raise_for_status", "(", ")", "except", "requests", ".", "exceptions", ".", "HTTPError", "as", "e", ":", "raise", "e", "return", "r"], "docstring": "Fetch requests from groupsio API", "docstring_tokens": ["Fetch", "requests", "from", "groupsio", "API"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/groupsio.py#L242-L251", "partition": "test", "index": 3242, "time": "2018-10-14 19:34:13"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/groupsio.py", "func_name": "GroupsioClient.__find_group_id", "original_string": "def __find_group_id(self):\n        \"\"\"Find the id of a group given its name by iterating on the list of subscriptions\"\"\"\n\n        group_subscriptions = self.subscriptions(self.auth)\n\n        for subscriptions in group_subscriptions:\n            for sub in subscriptions:\n                if sub['group_name'] == self.group_name:\n                    return sub['group_id']\n\n        msg = \"Group id not found for group name %s\" % self.group_name\n        raise BackendError(cause=msg)", "language": "python", "code": "def __find_group_id(self):\n        \"\"\"Find the id of a group given its name by iterating on the list of subscriptions\"\"\"\n\n        group_subscriptions = self.subscriptions(self.auth)\n\n        for subscriptions in group_subscriptions:\n            for sub in subscriptions:\n                if sub['group_name'] == self.group_name:\n                    return sub['group_id']\n\n        msg = \"Group id not found for group name %s\" % self.group_name\n        raise BackendError(cause=msg)", "code_tokens": ["def", "__find_group_id", "(", "self", ")", ":", "group_subscriptions", "=", "self", ".", "subscriptions", "(", "self", ".", "auth", ")", "for", "subscriptions", "in", "group_subscriptions", ":", "for", "sub", "in", "subscriptions", ":", "if", "sub", "[", "'group_name'", "]", "==", "self", ".", "group_name", ":", "return", "sub", "[", "'group_id'", "]", "msg", "=", "\"Group id not found for group name %s\"", "%", "self", ".", "group_name", "raise", "BackendError", "(", "cause", "=", "msg", ")"], "docstring": "Find the id of a group given its name by iterating on the list of subscriptions", "docstring_tokens": ["Find", "the", "id", "of", "a", "group", "given", "its", "name", "by", "iterating", "on", "the", "list", "of", "subscriptions"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/groupsio.py#L229-L240", "partition": "test", "index": 3241, "time": "2018-10-14 19:34:13"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient._get_tokens_rate_limits", "original_string": "def _get_tokens_rate_limits(self):\n        \"\"\"Return array of all tokens remaining API points\"\"\"\n\n        remainings = [0] * self.n_tokens\n        # Turn off archiving when checking rates, because that would cause\n        # archive key conflict (the same URLs giving different responses)\n        arch = self.archive\n        self.archive = None\n        for idx, token in enumerate(self.tokens):\n            # Pass flag to skip disabling archiving because this function doies it\n            remainings[idx] = self._get_token_rate_limit(token)\n        # Restore archiving to whatever state it was\n        self.archive = arch\n        logger.debug(\"Remaining API points: {}\".format(remainings))\n        return remainings", "language": "python", "code": "def _get_tokens_rate_limits(self):\n        \"\"\"Return array of all tokens remaining API points\"\"\"\n\n        remainings = [0] * self.n_tokens\n        # Turn off archiving when checking rates, because that would cause\n        # archive key conflict (the same URLs giving different responses)\n        arch = self.archive\n        self.archive = None\n        for idx, token in enumerate(self.tokens):\n            # Pass flag to skip disabling archiving because this function doies it\n            remainings[idx] = self._get_token_rate_limit(token)\n        # Restore archiving to whatever state it was\n        self.archive = arch\n        logger.debug(\"Remaining API points: {}\".format(remainings))\n        return remainings", "code_tokens": ["def", "_get_tokens_rate_limits", "(", "self", ")", ":", "remainings", "=", "[", "0", "]", "*", "self", ".", "n_tokens", "# Turn off archiving when checking rates, because that would cause", "# archive key conflict (the same URLs giving different responses)", "arch", "=", "self", ".", "archive", "self", ".", "archive", "=", "None", "for", "idx", ",", "token", "in", "enumerate", "(", "self", ".", "tokens", ")", ":", "# Pass flag to skip disabling archiving because this function doies it", "remainings", "[", "idx", "]", "=", "self", ".", "_get_token_rate_limit", "(", "token", ")", "# Restore archiving to whatever state it was", "self", ".", "archive", "=", "arch", "logger", ".", "debug", "(", "\"Remaining API points: {}\"", ".", "format", "(", "remainings", ")", ")", "return", "remainings"], "docstring": "Return array of all tokens remaining API points", "docstring_tokens": ["Return", "array", "of", "all", "tokens", "remaining", "API", "points"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L786-L800", "partition": "test", "index": 3315, "time": "2019-01-22 09:14:48"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient._choose_best_api_token", "original_string": "def _choose_best_api_token(self):\n        \"\"\"Check all API tokens defined and choose one with most remaining API points\"\"\"\n\n        # Return if no tokens given\n        if self.n_tokens == 0:\n            return\n\n        # If multiple tokens given, choose best\n        token_idx = 0\n        if self.n_tokens > 1:\n            remainings = self._get_tokens_rate_limits()\n            token_idx = remainings.index(max(remainings))\n            logger.debug(\"Remaining API points: {}, choosen index: {}\".format(remainings, token_idx))\n\n        # If we have any tokens - use best of them\n        self.current_token = self.tokens[token_idx]\n        self.session.headers.update({'Authorization': 'token ' + self.current_token})\n        # Update rate limit data for the current token\n        self._update_current_rate_limit()", "language": "python", "code": "def _choose_best_api_token(self):\n        \"\"\"Check all API tokens defined and choose one with most remaining API points\"\"\"\n\n        # Return if no tokens given\n        if self.n_tokens == 0:\n            return\n\n        # If multiple tokens given, choose best\n        token_idx = 0\n        if self.n_tokens > 1:\n            remainings = self._get_tokens_rate_limits()\n            token_idx = remainings.index(max(remainings))\n            logger.debug(\"Remaining API points: {}, choosen index: {}\".format(remainings, token_idx))\n\n        # If we have any tokens - use best of them\n        self.current_token = self.tokens[token_idx]\n        self.session.headers.update({'Authorization': 'token ' + self.current_token})\n        # Update rate limit data for the current token\n        self._update_current_rate_limit()", "code_tokens": ["def", "_choose_best_api_token", "(", "self", ")", ":", "# Return if no tokens given", "if", "self", ".", "n_tokens", "==", "0", ":", "return", "# If multiple tokens given, choose best", "token_idx", "=", "0", "if", "self", ".", "n_tokens", ">", "1", ":", "remainings", "=", "self", ".", "_get_tokens_rate_limits", "(", ")", "token_idx", "=", "remainings", ".", "index", "(", "max", "(", "remainings", ")", ")", "logger", ".", "debug", "(", "\"Remaining API points: {}, choosen index: {}\"", ".", "format", "(", "remainings", ",", "token_idx", ")", ")", "# If we have any tokens - use best of them", "self", ".", "current_token", "=", "self", ".", "tokens", "[", "token_idx", "]", "self", ".", "session", ".", "headers", ".", "update", "(", "{", "'Authorization'", ":", "'token '", "+", "self", ".", "current_token", "}", ")", "# Update rate limit data for the current token", "self", ".", "_update_current_rate_limit", "(", ")"], "docstring": "Check all API tokens defined and choose one with most remaining API points", "docstring_tokens": ["Check", "all", "API", "tokens", "defined", "and", "choose", "one", "with", "most", "remaining", "API", "points"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L802-L820", "partition": "test", "index": 3316, "time": "2019-01-22 09:14:48"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient._need_check_tokens", "original_string": "def _need_check_tokens(self):\n        \"\"\"Check if we need to switch GitHub API tokens\"\"\"\n\n        if self.n_tokens <= 1 or self.rate_limit is None:\n            return False\n        elif self.last_rate_limit_checked is None:\n            self.last_rate_limit_checked = self.rate_limit\n            return True\n\n        # If approaching minimum rate limit for sleep\n        approaching_limit = float(self.min_rate_to_sleep) * (1.0 + TOKEN_USAGE_BEFORE_SWITCH) + 1\n        if self.rate_limit <= approaching_limit:\n            self.last_rate_limit_checked = self.rate_limit\n            return True\n\n        # Only switch token when used predefined factor of the current token's remaining API points\n        ratio = float(self.rate_limit) / float(self.last_rate_limit_checked)\n        if ratio < 1.0 - TOKEN_USAGE_BEFORE_SWITCH:\n            self.last_rate_limit_checked = self.rate_limit\n            return True\n        elif ratio > 1.0:\n            self.last_rate_limit_checked = self.rate_limit\n            return False\n        else:\n            return False", "language": "python", "code": "def _need_check_tokens(self):\n        \"\"\"Check if we need to switch GitHub API tokens\"\"\"\n\n        if self.n_tokens <= 1 or self.rate_limit is None:\n            return False\n        elif self.last_rate_limit_checked is None:\n            self.last_rate_limit_checked = self.rate_limit\n            return True\n\n        # If approaching minimum rate limit for sleep\n        approaching_limit = float(self.min_rate_to_sleep) * (1.0 + TOKEN_USAGE_BEFORE_SWITCH) + 1\n        if self.rate_limit <= approaching_limit:\n            self.last_rate_limit_checked = self.rate_limit\n            return True\n\n        # Only switch token when used predefined factor of the current token's remaining API points\n        ratio = float(self.rate_limit) / float(self.last_rate_limit_checked)\n        if ratio < 1.0 - TOKEN_USAGE_BEFORE_SWITCH:\n            self.last_rate_limit_checked = self.rate_limit\n            return True\n        elif ratio > 1.0:\n            self.last_rate_limit_checked = self.rate_limit\n            return False\n        else:\n            return False", "code_tokens": ["def", "_need_check_tokens", "(", "self", ")", ":", "if", "self", ".", "n_tokens", "<=", "1", "or", "self", ".", "rate_limit", "is", "None", ":", "return", "False", "elif", "self", ".", "last_rate_limit_checked", "is", "None", ":", "self", ".", "last_rate_limit_checked", "=", "self", ".", "rate_limit", "return", "True", "# If approaching minimum rate limit for sleep", "approaching_limit", "=", "float", "(", "self", ".", "min_rate_to_sleep", ")", "*", "(", "1.0", "+", "TOKEN_USAGE_BEFORE_SWITCH", ")", "+", "1", "if", "self", ".", "rate_limit", "<=", "approaching_limit", ":", "self", ".", "last_rate_limit_checked", "=", "self", ".", "rate_limit", "return", "True", "# Only switch token when used predefined factor of the current token's remaining API points", "ratio", "=", "float", "(", "self", ".", "rate_limit", ")", "/", "float", "(", "self", ".", "last_rate_limit_checked", ")", "if", "ratio", "<", "1.0", "-", "TOKEN_USAGE_BEFORE_SWITCH", ":", "self", ".", "last_rate_limit_checked", "=", "self", ".", "rate_limit", "return", "True", "elif", "ratio", ">", "1.0", ":", "self", ".", "last_rate_limit_checked", "=", "self", ".", "rate_limit", "return", "False", "else", ":", "return", "False"], "docstring": "Check if we need to switch GitHub API tokens", "docstring_tokens": ["Check", "if", "we", "need", "to", "switch", "GitHub", "API", "tokens"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L822-L846", "partition": "test", "index": 3317, "time": "2019-01-22 09:14:48"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/git.py", "func_name": "GitRepository.rev_list", "original_string": "def rev_list(self, branches=None):\n        \"\"\"Read the list commits from the repository\n\n        The list of branches is a list of strings, with the names of the\n        branches to fetch. If the list of branches is empty, no commit\n        is fetched. If the list of branches is None, all commits\n        for all branches will be fetched.\n\n        The method returns the Git rev-list of the repository using the\n        following options:\n\n            git rev-list --topo-order\n\n        :param branches: names of branches to fetch from (default: None)\n\n        :raises EmptyRepositoryError: when the repository is empty and\n            the action cannot be performed\n        :raises RepositoryError: when an error occurs executing the command\n        \"\"\"\n        if self.is_empty():\n            logger.warning(\"Git %s repository is empty; unable to get the rev-list\",\n                           self.uri)\n            raise EmptyRepositoryError(repository=self.uri)\n\n        cmd_rev_list = ['git', 'rev-list', '--topo-order']\n\n        if branches is None:\n            cmd_rev_list.extend(['--branches', '--tags', '--remotes=origin'])\n        elif len(branches) == 0:\n            cmd_rev_list.extend(['--branches', '--tags', '--max-count=0'])\n        else:\n            branches = ['refs/heads/' + branch for branch in branches]\n            cmd_rev_list.extend(branches)\n\n        for line in self._exec_nb(cmd_rev_list, cwd=self.dirpath, env=self.gitenv):\n            yield line.rstrip('\\n')\n\n        logger.debug(\"Git rev-list fetched from %s repository (%s)\",\n                     self.uri, self.dirpath)", "language": "python", "code": "def rev_list(self, branches=None):\n        \"\"\"Read the list commits from the repository\n\n        The list of branches is a list of strings, with the names of the\n        branches to fetch. If the list of branches is empty, no commit\n        is fetched. If the list of branches is None, all commits\n        for all branches will be fetched.\n\n        The method returns the Git rev-list of the repository using the\n        following options:\n\n            git rev-list --topo-order\n\n        :param branches: names of branches to fetch from (default: None)\n\n        :raises EmptyRepositoryError: when the repository is empty and\n            the action cannot be performed\n        :raises RepositoryError: when an error occurs executing the command\n        \"\"\"\n        if self.is_empty():\n            logger.warning(\"Git %s repository is empty; unable to get the rev-list\",\n                           self.uri)\n            raise EmptyRepositoryError(repository=self.uri)\n\n        cmd_rev_list = ['git', 'rev-list', '--topo-order']\n\n        if branches is None:\n            cmd_rev_list.extend(['--branches', '--tags', '--remotes=origin'])\n        elif len(branches) == 0:\n            cmd_rev_list.extend(['--branches', '--tags', '--max-count=0'])\n        else:\n            branches = ['refs/heads/' + branch for branch in branches]\n            cmd_rev_list.extend(branches)\n\n        for line in self._exec_nb(cmd_rev_list, cwd=self.dirpath, env=self.gitenv):\n            yield line.rstrip('\\n')\n\n        logger.debug(\"Git rev-list fetched from %s repository (%s)\",\n                     self.uri, self.dirpath)", "code_tokens": ["def", "rev_list", "(", "self", ",", "branches", "=", "None", ")", ":", "if", "self", ".", "is_empty", "(", ")", ":", "logger", ".", "warning", "(", "\"Git %s repository is empty; unable to get the rev-list\"", ",", "self", ".", "uri", ")", "raise", "EmptyRepositoryError", "(", "repository", "=", "self", ".", "uri", ")", "cmd_rev_list", "=", "[", "'git'", ",", "'rev-list'", ",", "'--topo-order'", "]", "if", "branches", "is", "None", ":", "cmd_rev_list", ".", "extend", "(", "[", "'--branches'", ",", "'--tags'", ",", "'--remotes=origin'", "]", ")", "elif", "len", "(", "branches", ")", "==", "0", ":", "cmd_rev_list", ".", "extend", "(", "[", "'--branches'", ",", "'--tags'", ",", "'--max-count=0'", "]", ")", "else", ":", "branches", "=", "[", "'refs/heads/'", "+", "branch", "for", "branch", "in", "branches", "]", "cmd_rev_list", ".", "extend", "(", "branches", ")", "for", "line", "in", "self", ".", "_exec_nb", "(", "cmd_rev_list", ",", "cwd", "=", "self", ".", "dirpath", ",", "env", "=", "self", ".", "gitenv", ")", ":", "yield", "line", ".", "rstrip", "(", "'\\n'", ")", "logger", ".", "debug", "(", "\"Git rev-list fetched from %s repository (%s)\"", ",", "self", ".", "uri", ",", "self", ".", "dirpath", ")"], "docstring": "Read the list commits from the repository\n\n        The list of branches is a list of strings, with the names of the\n        branches to fetch. If the list of branches is empty, no commit\n        is fetched. If the list of branches is None, all commits\n        for all branches will be fetched.\n\n        The method returns the Git rev-list of the repository using the\n        following options:\n\n            git rev-list --topo-order\n\n        :param branches: names of branches to fetch from (default: None)\n\n        :raises EmptyRepositoryError: when the repository is empty and\n            the action cannot be performed\n        :raises RepositoryError: when an error occurs executing the command", "docstring_tokens": ["Read", "the", "list", "commits", "from", "the", "repository"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/git.py#L944-L982", "partition": "test", "index": 3275, "time": "2019-01-22 10:46:37"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHub.__fetch_repo_info", "original_string": "def __fetch_repo_info(self):\n        \"\"\"Get repo info about stars, watchers and forks\"\"\"\n\n        raw_repo = self.client.repo()\n        repo = json.loads(raw_repo)\n\n        fetched_on = datetime_utcnow()\n        repo['fetched_on'] = fetched_on.timestamp()\n\n        yield repo", "language": "python", "code": "def __fetch_repo_info(self):\n        \"\"\"Get repo info about stars, watchers and forks\"\"\"\n\n        raw_repo = self.client.repo()\n        repo = json.loads(raw_repo)\n\n        fetched_on = datetime_utcnow()\n        repo['fetched_on'] = fetched_on.timestamp()\n\n        yield repo", "code_tokens": ["def", "__fetch_repo_info", "(", "self", ")", ":", "raw_repo", "=", "self", ".", "client", ".", "repo", "(", ")", "repo", "=", "json", ".", "loads", "(", "raw_repo", ")", "fetched_on", "=", "datetime_utcnow", "(", ")", "repo", "[", "'fetched_on'", "]", "=", "fetched_on", ".", "timestamp", "(", ")", "yield", "repo"], "docstring": "Get repo info about stars, watchers and forks", "docstring_tokens": ["Get", "repo", "info", "about", "stars", "watchers", "and", "forks"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L296-L305", "partition": "test", "index": 3297, "time": "2019-02-14 17:57:45"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/github.py", "func_name": "GitHubClient.repo", "original_string": "def repo(self):\n        \"\"\"Get repository data\"\"\"\n\n        path = urijoin(self.base_url, 'repos', self.owner, self.repository)\n\n        r = self.fetch(path)\n        repo = r.text\n\n        return repo", "language": "python", "code": "def repo(self):\n        \"\"\"Get repository data\"\"\"\n\n        path = urijoin(self.base_url, 'repos', self.owner, self.repository)\n\n        r = self.fetch(path)\n        repo = r.text\n\n        return repo", "code_tokens": ["def", "repo", "(", "self", ")", ":", "path", "=", "urijoin", "(", "self", ".", "base_url", ",", "'repos'", ",", "self", ".", "owner", ",", "self", ".", "repository", ")", "r", "=", "self", ".", "fetch", "(", "path", ")", "repo", "=", "r", ".", "text", "return", "repo"], "docstring": "Get repository data", "docstring_tokens": ["Get", "repository", "data"], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/github.py#L627-L635", "partition": "test", "index": 3308, "time": "2019-02-14 17:57:45"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backend.py", "func_name": "Backend.filter_classified_data", "original_string": "def filter_classified_data(self, item):\n        \"\"\"Remove classified or confidential data from an item.\n\n        It removes those fields that contain data considered as classified.\n        Classified fields are defined in `CLASSIFIED_FIELDS` class attribute.\n\n        :param item: fields will be removed from this item\n\n        :returns: the same item but with confidential data filtered\n        \"\"\"\n        item_uuid = uuid(self.origin, self.metadata_id(item))\n\n        logger.debug(\"Filtering classified data for item %s\", item_uuid)\n\n        for cf in self.CLASSIFIED_FIELDS:\n            try:\n                _remove_key_from_nested_dict(item, cf)\n            except KeyError:\n                logger.debug(\"Classified field '%s' not found for item %s; field ignored\",\n                             '.'.join(cf), item_uuid)\n\n        logger.debug(\"Classified data filtered for item %s\", item_uuid)\n\n        return item", "language": "python", "code": "def filter_classified_data(self, item):\n        \"\"\"Remove classified or confidential data from an item.\n\n        It removes those fields that contain data considered as classified.\n        Classified fields are defined in `CLASSIFIED_FIELDS` class attribute.\n\n        :param item: fields will be removed from this item\n\n        :returns: the same item but with confidential data filtered\n        \"\"\"\n        item_uuid = uuid(self.origin, self.metadata_id(item))\n\n        logger.debug(\"Filtering classified data for item %s\", item_uuid)\n\n        for cf in self.CLASSIFIED_FIELDS:\n            try:\n                _remove_key_from_nested_dict(item, cf)\n            except KeyError:\n                logger.debug(\"Classified field '%s' not found for item %s; field ignored\",\n                             '.'.join(cf), item_uuid)\n\n        logger.debug(\"Classified data filtered for item %s\", item_uuid)\n\n        return item", "code_tokens": ["def", "filter_classified_data", "(", "self", ",", "item", ")", ":", "item_uuid", "=", "uuid", "(", "self", ".", "origin", ",", "self", ".", "metadata_id", "(", "item", ")", ")", "logger", ".", "debug", "(", "\"Filtering classified data for item %s\"", ",", "item_uuid", ")", "for", "cf", "in", "self", ".", "CLASSIFIED_FIELDS", ":", "try", ":", "_remove_key_from_nested_dict", "(", "item", ",", "cf", ")", "except", "KeyError", ":", "logger", ".", "debug", "(", "\"Classified field '%s' not found for item %s; field ignored\"", ",", "'.'", ".", "join", "(", "cf", ")", ",", "item_uuid", ")", "logger", ".", "debug", "(", "\"Classified data filtered for item %s\"", ",", "item_uuid", ")", "return", "item"], "docstring": "Remove classified or confidential data from an item.\n\n        It removes those fields that contain data considered as classified.\n        Classified fields are defined in `CLASSIFIED_FIELDS` class attribute.\n\n        :param item: fields will be removed from this item\n\n        :returns: the same item but with confidential data filtered", "docstring_tokens": ["Remove", "classified", "or", "confidential", "data", "from", "an", "item", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backend.py#L186-L209", "partition": "test", "index": 3250, "time": "2019-03-24 14:20:43"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/jira.py", "func_name": "JiraClient.get_issues", "original_string": "def get_issues(self, from_date):\n        \"\"\"Retrieve all the issues from a given date.\n\n        :param from_date: obtain issues updated since this date\n        \"\"\"\n        url = urijoin(self.base_url, self.RESOURCE, self.VERSION_API, 'search')\n        issues = self.get_items(from_date, url)\n\n        return issues", "language": "python", "code": "def get_issues(self, from_date):\n        \"\"\"Retrieve all the issues from a given date.\n\n        :param from_date: obtain issues updated since this date\n        \"\"\"\n        url = urijoin(self.base_url, self.RESOURCE, self.VERSION_API, 'search')\n        issues = self.get_items(from_date, url)\n\n        return issues", "code_tokens": ["def", "get_issues", "(", "self", ",", "from_date", ")", ":", "url", "=", "urijoin", "(", "self", ".", "base_url", ",", "self", ".", "RESOURCE", ",", "self", ".", "VERSION_API", ",", "'search'", ")", "issues", "=", "self", ".", "get_items", "(", "from_date", ",", "url", ")", "return", "issues"], "docstring": "Retrieve all the issues from a given date.\n\n        :param from_date: obtain issues updated since this date", "docstring_tokens": ["Retrieve", "all", "the", "issues", "from", "a", "given", "date", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/jira.py#L326-L334", "partition": "test", "index": 3349, "time": "2019-04-09 17:25:49"}
{"repo": "chaoss/grimoirelab-perceval", "path": "perceval/backends/core/jira.py", "func_name": "JiraClient.get_comments", "original_string": "def get_comments(self, issue_id):\n        \"\"\"Retrieve all the comments of a given issue.\n\n        :param issue_id: ID of the issue\n        \"\"\"\n        url = urijoin(self.base_url, self.RESOURCE, self.VERSION_API, self.ISSUE, issue_id, self.COMMENT)\n        comments = self.get_items(DEFAULT_DATETIME, url, expand_fields=False)\n\n        return comments", "language": "python", "code": "def get_comments(self, issue_id):\n        \"\"\"Retrieve all the comments of a given issue.\n\n        :param issue_id: ID of the issue\n        \"\"\"\n        url = urijoin(self.base_url, self.RESOURCE, self.VERSION_API, self.ISSUE, issue_id, self.COMMENT)\n        comments = self.get_items(DEFAULT_DATETIME, url, expand_fields=False)\n\n        return comments", "code_tokens": ["def", "get_comments", "(", "self", ",", "issue_id", ")", ":", "url", "=", "urijoin", "(", "self", ".", "base_url", ",", "self", ".", "RESOURCE", ",", "self", ".", "VERSION_API", ",", "self", ".", "ISSUE", ",", "issue_id", ",", "self", ".", "COMMENT", ")", "comments", "=", "self", ".", "get_items", "(", "DEFAULT_DATETIME", ",", "url", ",", "expand_fields", "=", "False", ")", "return", "comments"], "docstring": "Retrieve all the comments of a given issue.\n\n        :param issue_id: ID of the issue", "docstring_tokens": ["Retrieve", "all", "the", "comments", "of", "a", "given", "issue", "."], "sha": "41c908605e88b7ebc3a536c643fa0f212eaf9e0e", "url": "https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/jira.py#L336-L344", "partition": "test", "index": 3350, "time": "2019-04-09 17:25:49"}
